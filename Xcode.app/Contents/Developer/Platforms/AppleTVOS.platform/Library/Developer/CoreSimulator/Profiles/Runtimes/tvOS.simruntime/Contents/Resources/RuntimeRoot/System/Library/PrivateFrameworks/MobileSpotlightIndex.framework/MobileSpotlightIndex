0EattachmentDomain
                SQLite format 3
@(#)PROGRAM:MobileSpotlightIndex  PROJECT:Matador-2183.16
journalRepair.1
kMDItemRelatedUniqueIdentifier
""#"$"%"&"<"A"C"D"E"G"H"I"M"m"a"b"d"p"e"q"r"t"s"u"v"x"w"y"z"
FH
0K0L0M0N0O0P0Q0R0S0T0U0V0W0X0Y0Z0[0\0]0^0_0`0a0b0d0e0f0g0h0i0o0p0r0s0u0v0x0y0{0|0
0o0q0r0t0u0w0x0z0{0}0
 !"#$%&'()*+,-./0123456789:;<=>?@abcdefghijklmnopqrstuvwxyz[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`ABCDEFGHIJKLMNOPQRSTUVWXYZ{|}~
`!p!a!q!b!r!c!s!d!t!e!u!f!v!g!w!h!x!i!y!j!z!k!{!l!|!m!}!n!~!o!
!p!`!q!a!r!b!s!c!t!d!u!e!v!f!w!g!x!h!y!i!z!j!{!k!|!l!}!m!~!n!
FV
ABCDEFGHIJKLMNOPQRSTUVWXYZ
0123456789abcdef
tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt7
tttttttttttt
ttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt
?333333
?333333
?ffffff
?333333
?333333
?ffffff

InRange(_kMDItemGroupId,2,2)
InRange(_kMDItemGroupId,1,1)
InRange(_kMDItemGroupId,3,3)
InRange(_kMDItemGroupId,4,4)
InRange(_kMDItemGroupId,5,5)
InRange(_kMDItemGroupId,6,6)
InRange(_kMDItemGroupId,7,7)
InRange(_kMDItemGroupId,8,8)
InRange(_kMDItemGroupId,9,9)
InRange(_kMDItemGroupId,10,10)
InRange(_kMDItemGroupId,11,11)
InRange(_kMDItemGroupId,12,12)
InRange(_kMDItemGroupId,13,13)
InRange(_kMDItemGroupId,14,14)
InRange(_kMDItemGroupId,15,15)
InRange(_kMDItemGroupId,16,16)
InRange(_kMDItemGroupId,18,18)
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
bcdefghijk#lm$%&'()*+,-nopqrst.02468:<>@BDFHJLNPRTVXZ\^`uvwxyz/13579;=?ACEGIKMOQSUWY[]_a{|}~
-0123456789AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz#$%&'()*+,./:;<=>?@[\]^_`{|}~
SQLite format 3
 !"#$%&'()*+,-./0123456789:;<=>?@abcdefghijklmnopqrstuvwxyz[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
!%-MASTER-FID-%!
get_persistent_id_store
release_persistent_id_store
sync_persistent_id_store
rename_path
_sqlite_insert
_sqlite_bulkEnd
_psid_insert_locked
remove_path_locked
.migratedphotolibrary/
.migratedaplibrary/
.photolibrary/
.aplibrary/
.photoslibrary/
psid.db
FileTree_Overlay.c
fileId >2
FileTree_UpdateSet.c
(uint32_t)outChildren == (uint32_t)root->children->childCount
lastPosting
directory->fileid>=2
depth >= 0
parents[i] > 0
%s:%u: failed assertion '%s' %s Got parent with id %lld
(uint64_t)parents[i-1] > 2
directory->children->nodes[slot].fileid==p1[0]
directory->fileid
directory->children->childCount < directory->children->pageSize-1
%s:%u: failed assertion '%s' %s got file id %lld
newDirectory.fileid >2
newDirectory.fileid != directory->fileid
directory->children->nodes[slot].fileid<=1
dir==0
uniqued
getFlagsFromAttributes
multivalued
nosearch
Attributes
SIIndexInternals.cpp
fieldName.ptr()
setOneLocalizedFieldWithFlags
((flags & DB_FIELD_EXTENDED_ATTR) && isCoreSpotlight) == 0
:PR:
_kMD
:INC:
_kMDItemIncomingCounts
_kMDItemIncomingMailCounts
_kMDItemOutgoingSMSCounts
_kMDItemIncomingSMSCounts
_kMDItemIncomingCalendarCounts
_kMDItemIncomingFileProviderCounts
_kMDItemIncomingVideoCallDates
_kMDItemOutgoingVideoCallDates
_kMDItemIncomingAudioCallDates
_kMDItemOutgoingAudioCallDates
kMDItemFinderComment
_kMDItemFinderLabel
_kMDItemSizingIsNeeded
kMDItemContentType!='com.apple.ical.ics.todo' || _kMDItemFinderExcluded!=1
_kMDItemGroupId!=6 || (kMDItemContentType=='com.apple.ical.ics.todo' || _kMDItemFinderExcluded!=1)
SIQuery.cpp
qp->_free_cache_data==(void*)ContentIndexQueryNodeDispose
count < (CFIndex)4294967295U && count>=0
tmpB
SIUINT32Set
SIUINT64Set
v==key
popped<peeked
popped==peeked
(key & fMask) == fPfx
newLevel->children[i]==0
com_apple_mail_flagged
com_apple_mail_flagColor
com.apple.searchstressattr
_kMDItemStateInfo_com.apple.searchstressattr.state.test
com.apple.mobilemail
com.apple.mobilenotes
com.apple.mobilecal
_kMDItemStateInfo_com.apple.mobilemail.contentIndex
com_apple_mobilemail_transaction
com.apple.CloudDocs.MobileDocumentsFileProvider
com.apple.FileProvider.LocalStorage
kSIRepairedIndex
kSIConsistencyCheck
kSITokenizerUseCRF
kSITokenizerVersion
kSITokenizerUnigrams
kSIRepairSizes
kSIIdentifierHashVersion
activityJournal
Cab.created
tmp.Lion
Lion.created
com.apple.SpotlightServer
_kMDItemTextContentLength
kMDItemUserTags
kMDItemSupportFileType
_kMDItemSnippet
_kMDItemStorageSize
_kMDItemPersonaID
Shutdown
Preheat
Throttled Volume Query
Volume Query
Throttled Index Query
Utility Index Query
Index Query
Fast Index Query
Set Attributes
Flush
Compaction
Background Helper
Helper
Throttled Index Query Init
Utility Index Query Init
Index Query Init
Fast Index Query Init
kMDStoreUUID
/Library/Caches/com.apple.xbs/Sources/SpotlightCore_Sim/Spotlight-2183.16/spotlight/index/SpotlightIndex/SpotlightIndex.c
void syncIndex(si_sync_ctx *, Boolean)
kIndexRemappingData
database.recoverscantime
GroupAssignments
JournalSerialNumber
ConsumedJournalSerialNumber
kMDSIndexSyncCount
kMDSIndexDeferSyncCount
sync err
syncIndex
com.apple.spotlight.missingparent
v32@?0i8^q12i20^q24
void si_mergeIndex(void *, Boolean)
Full
Partial
Vacuum
Normal
Forced
Voluntary
SpotlightIndex.c
!ref->workqueues.queues[SI_DEFER_QUEUE_IDX]
DarkMerge
Index merge in dark wake
 canceled
si_mergeIndex
ContentIndexWritable(indexSet->index[indexSet->currentIndex])
void si_initialIndexingEndedQueueOnFlush(si_sync_ctx *, Boolean)
si_writeBackDBO
!ContentIndexWritable(indexSet->index[i-1])
indexLiveSet->currentIndex==~0 || ContentIndexWritable(indexLiveSet->index[indexLiveSet->currentIndex])
ContentIndexValidIndex(cindex)
ContentIndexWritable(cindex)
si_getSyncIndex
indexSet->indexCount
indexSet->index[indexSet->indexCount-1]
ContentIndexValidIndex(indexSet->index[indexSet->indexCount-1])
callbacks
SICreateNewIndex
tmp.Cab
tmp.Star
_kMDXXXX___DUMMY
_kMDItemTimeMachinePath
kMDStoreProperties
si_recycleForBadIndex
si_store_propery_cache
database.shutdowntime
recovery
flush err
_SIFlushAndSyncIndex
v16@?0@?<v@?B>8
SISetCSAttributes
void SIInitialIndexingEnded(SIRef, int32_t)
int32_t SIGetMaxTransactionID(SIRef)
SIGetMaxTransactionID
SISetTransactionCount
int32_t SISetScanCount(SIRef, CFIndex, _Bool)
oldLiveSet->indexCount==0 || (CFIndex)ContentIndexBaseDocId(oldLiveSet->index[0]) >= count
SISetScanCount
SIGetLargestOid
void _SIIssueFullMergeWithGroup(SIRef, dispatch_group_t)
void _SIIssueMerge(SIRef, int)
[%p] %s
_SIReverseStoreIterate
_SIDirectoryStoreIterate
Scheduler state:
<<<<<<<<
>>>>>>>>
_SIIssueSchedulerDump
low disk space
_kMDItemImporterResult
si_get_object_for_identifier_createParentDBO
v24@?0^{__CFArray=}8q16
(count & 0x7 ) == 0
i<=count/8
clean
fast flush
needs shadow
dirty
unknown
tmp.spotlight.state
si_read_index_state
si_write_index_state
state==kSIIndexStateDirty
SICopyCorrections
default_corrections
com.apple.lastuseddate#PS
kMDItemFileProviderID
kMDItemIsTrashed
LISearchObjTypeReturnAll
LISearchFileNameContains
si_create_indexmetadata
sync_datastore
ctx->syncSet && ctx->liveSet
dirStore.overlay
tmp.spotlight.loc
commit_sync_datastore
!ctx->syncDirtyChunks
shadow_datastore
post_shadow_datastore
kMDStoreAccumulatedCounts
si_storesizes
kIndexRemappings
ref->workqueues.queues[SI_DEFER_QUEUE_IDX]
OuterMerge
tmp.merge.%ld.
InnerMerge
com.apple.spotlightindex.%s.%s.%d
merge
live
_kMDItemExternalID
noindex
notokenize
v40@?0r*8Q16{?=*{?=IC}}24
com.apple.spotlight.mds.index-lifecycle
SetupRemapping
ContentIndexGetId(oldIndexSet->index[start])==anchor
si_swapIndexSet(ref, oldIndexSet, indexSet, indexSetPtr,1, live)
indexFd != -1
syncCount < 2147483647
%s%d
Failure in db_shrink_cache at si_remapForIndex
Unknown
ExternalVacuum
Deletes
Count
ExternalForce
ExternalInitialIndexingEnd
ExternalScanEnd
HoldCount
UpdateCount
tmp.
indexSet2->currentIndex==~0
!ContentIndexWritable(indexSet2->index[i])
live.0.
si_swapIndexSet(ref,oldIndexSet2,indexSet2,&ref->syncSet,0, 0)
si_swapIndexSet(ref,oldIndexSet1,indexSet1,&ref->liveSet,1, 1)
SetupDeferQueue
live.%d.
start+count <= oldIndexSet->indexCount
oldIndexSet->indexCount+(mergeCount-1) >= preCount
com.apple.spotlight.mds.index-darkwake
ScanEnded
void si_scanEnded(si_sync_ctx *, Boolean)
void setupAndIssueMergeScan(SIRef, int32_t, _Bool, xpc_activity_t, _Bool *, dispatch_group_t)
Failure in db_shrink_cache at si_initialIndexingEnded
InitialIndexingEnded
void si_initialIndexingEnded(si_sync_ctx *, Boolean)
void setupAndIssueMerge(SIRef, uint32_t, _Bool, xpc_activity_t, _Bool *, dispatch_group_t)
invalid path
Rebuilding index
_SIOpenIndex
Rebuilding index because of repeated crashes
open meta info error
handleDirStoreOverlay failed
recover datastore error
invalid datastore
ds dirty, rs needs shadow 
ds needs shadow, rs dirty
invalid reverse store
restore db dirty pages failed
restore rs dirty pages failed
invalid index version recovering
invalid index version reindexing
.store.db
open index error
invalid term update set from lion
open dirstore failed
open datastore failed
index setup error
fs_only || newIndex->dirStore
init index error
index not created with unigrams error
missing system dbo
_SIOpenIndexFilesWithState
!fast_flush_failed
newIndex->syncSet->indexCount==0
newIndex->liveSet->indexCount==0
s->directory_state!=kSIIndexStateFastFlush
db_corespotlight_store(newIndex->store) || version == 99 || version == 100
scanCount == newIndex->syncSet->indexCount
liveCount == newIndex->liveSet->indexCount
handleIndexRepair
_kMDItemWillModify
tmp.SnowLeopard
tmp.spotlight
tmp.store.recovery
tmp.journals.
new_path[ptr-direntry->d_name-4]=='.'
si_handle_tmp_files
void holdAndIssueMerge(SIRef, int32_t, SIIndexSetRef, _Bool, _Bool)
void si_compactReadOnlyIndexes1(void *, Boolean)
void si_compactReadOnlyIndexes2(void *, Boolean)
void si_compactReadOnlyIndexes3(void *, Boolean)
store.db.recover
.store.db.recover
/store.db.recoverStr-%d.map.header
/store.db.recoverStr-%d.map.offsets
/store.db.recoverStr-%d.map.data
/store.db.recoverStr-%d.map.buckets
com.apple.spotlight.index.free
com.apple.searchd.indexes.count
^v8@?0
com.apple.searchd.indexes.merge.immediate.count
com.apple.searchd.indexes.merge.scheduled.count
IndexOpenCompact
com.apple.searchd.indexes.uncompacted.merge.scheduled.count
v12@?0C8
com.apple.searchd.indexes.uncompacted.merge.immediate.count
si_repair_sizes_block_invoke
si_repair_sizes
void setupAndIssueMergeCleanup(SIRef, int32_t, _Bool, xpc_activity_t, _Bool *, dispatch_group_t)
guarded_dup
Failure in db_shrink_cache at si_index_inactivate
doFastFlushIndex
SIIndexingMallocZone
SIInitIndex
rebuild for tokenizer
open persistent id store error
LOW_LATENCY
%s scheduler for index at %s
newIndex->workqueues.schedulers[schedId]==0
newIndex->workqueues.queues[queueId]==0
%s scheduler for spindle %d
YukonRecomputedSizes
fs_only||newIndex->dirStore
process terminating
!ref->uniqueLocalizedTerms
database.localizedtermsuuid
_si_init_localized_terms
i12@?0B8
_kMDItemOwnerUserID
_kMDItemDomainIdentifier
kMDItemPhysicalSize
kMDItemWhereFroms
_SIInitSDB
si_getsizes
0 <= count && count < pathBufferSize
journalFdPtr
journal replay
preparseMobileJournal
playBackMobileJournal
void si_sync_index_delayed2(si_sync_ctx *, Boolean)
setCSAttributes2
com.apple.FileProvider
setCSAttributes2_block_invoke_2
com.apple.spotlight.SyndicatedContentDeleted
setCSAttributes2_block_invoke_4
com.apple.spotlight.SyndicatedContentRefreshed
_kMDItemStateInfo_%@
com.apple.MobileSMS
_si_delete_attributes_inner
com_apple_mobilesms_isHighlightedContent
kMDItemSyndicationStatus
_kMDItemExpirationDate
_kMDItemIsZombie
_kMDItemRelatedObjectsWithBundle
com.apple.searchd.deletes
bundleid
itemcount
indexingtime
aggregatedatasize
_MDItemDeletedWithRelatedUniqueIdentifier
__class:
CSLocalizedString
v24@?0{?=*{?=IC}}8
kMDItemFileItemID
_kMDItemUserActivityRequiredString
kMDItemRelatedUniqueIdentifier
_kMDItemClientExternalID
_kMDItemClientBundleID
com_apple_mobilesms_isChatAutoDonating
com_apple_mobilesms_groupPhotoPath
com_apple_mobilesms_fromMe
com_apple_mobilesms_highlightedContentServerDate
com_apple_mobilesms_chatAutoDonatingServerDate
kMDItemAuthors
kMDItemRecipientAddresses
com.apple.spotlight.category
com.apple.spotlight.contacts
_kMDItemRenderDate
_kMDItemEngagementDate
_kMDItemLaunchString
processOneCS
public.item
processing item
_kMDItemHasClientData
FPParentFileItemID
com.apple.MobileAddressBook
com.apple.Music
%@:%@
_kMDItemRequiresImport
_kMDItemImportSandboxExtension
_kMDItemImportHasSandboxExtension
kMDItemExpirationDate
_kMDItemInterestingDate
kMDItemInterestingDate_Ranking
public.data
dyn.
%s%@
__fpdefault/
__fp/
%@%@
com_apple_mail_read
%@ %@
_kMDItemOutgoingCounts
_kMDItemOutgoingMailCounts
_kMDItemOutgoingCalendarCounts
_kMDItemOutgoingFileProviderCounts
kMDItemAuthorContactIdentifiers
kMDItemRecipientContactIdentifiers
kMDItemStartDate
_Bool processOneCS(SIRef, int64_t, oid_t, CFStringRef, CFStringRef, int, MDPlistObject, MDPlistObject, CFStringRef, size_t, CFAllocatorRef, _Bool, dispatch_group_t, _Bool *)
_kMDItemRelatedBundleID
dbop && *dbop
(fieldFlags & (DB_FIELD_UNIQUED_VALS|DB_FIELD_LOCALIZED_STR)) == 0
kMDItemDocumentIdentifier
identifierCStrSize
_kMDItemRelatedActivityLaunchCount
CFBundleDocumentTypes
CFBundleTypeName
LSItemContentTypes
v16@?0^{__CFDictionary=}8
InfoPlist.strings
v32@?0^{__CFString=}8[1024c]16Q24
.lproj
base
com_apple_metadata_modtime
_kMDItemIsFromImporter
_kMDItemOCRContentTitle
_kMDItemOCRContentLevel1
_kMDItemOCRContentLevel2
_kMDItemOCRContentLevel3
kMDItemPrimaryRecipients
kMDItemAdditionalRecipients
kMDItemHiddenAdditionalRecipients
kMDItemPrimaryRecipientContactIdentifiers
kMDItemAdditionalRecipientContactIdentifiers
kMDItemHiddenAdditionalRecipientContactIdentifiers
kMDItemThumbnailData
Marker
_kMDItemPortraitStaticScore
kMDItemCurationScore
kMDItemContainerIdentifier
kMDItemEmailConversationID
_kMDItemFinderExcluded
com_apple_mail_dateReceived
kMDItemMailDateReceived_Ranking
com_apple_mail_dateLastViewed
kMDItemMailDateLastViewed_Ranking
kMDItemContentCreationDate_Ranking
kMDItemContentModificationDate_Ranking
_kMDItemApplicationLastLaunchedDate
_kMDItemApplicationLastLaunchedDate_Ranking
kMDItemStartDate_Ranking
kMDItemCompletionDate
kMDItemCompletionDate_Ranking
kMDItemDueDate
kMDItemDueDate_Ranking
kMDItemDateAdded
kMDItemDateAdded_Ranking
_kMDItemRelatedActivityLastLaunchDate
kMDItemPlayCount
_kMDItemSupportFileType
:MD:
:EA:
kMDItemIsUploading
:MD:kMDItemIsUploading
kMDItemIsUploaded
:MD:kMDItemIsUploaded
_kMDItemBackupMoveMarker
_kMDItemBackupNameSpace
_kMDItemTimeMachineMarkerNeedsFixup
kMDItemApproximateModTime
kMDItemSeedLastUsedDate
kMDPreviewImageData
kMDItemWorkerHandled
kMDItemPath
DeviceId
public.text
kMDItemAlbum
kMDItemArtist
kMDItemComposer
_kTimeMachineNewestSnapshot
_kTimeMachineOldestSnapshot
MDSystemFile
:EA:_kMDItemUserTags
com.apple.searchd.indexing
CFArrayGetValueAtIndex(inValues,i) == valueArray[i+1]
valueArray[0]==kCFNull
si_setstorecookie
_SIShutdownIndex
com.apple.spotlight.index.shutdown.shortlived
indexSpindleId==si_indices[0]->indexSpindleId
_SIShutdownSetup
notify_lowspace
DeviceNumber
com.apple.Spotlight.lowdiskspace
si_set_property
si_create_propertydict
void si_sync_index_delayed0(si_sync_ctx *, Boolean)
void si_sync_index_delayed1(si_sync_ctx *, Boolean)
fastflush
kIndexCheckDupOids
void si_sync_index_delayed_if_dirty0(si_sync_ctx *, Boolean)
void si_sync_index_delayed_if_dirty(si_sync_ctx *, Boolean)
PermissionCache
Validate
Permission cache in dark wake
void si_bulk_delete_attributes(si_bulk_delete_ctx *, Boolean)
Failure in db_shrink_cache at setIndexingCaughtUp
mobile_journal
finishRegisterQuery
void si_initialIndexingEndedQueueOnHold(si_sync_ctx *, Boolean)
void si_initialIndexingEndedQueueOnSet(si_sync_ctx *, Boolean)
prepareForTransaction
void si_set_scan_count(void *, Boolean)
si_set_scan_count
%s:%u: failed assertion '%s' %s No writable index available for %s
(ci_rc != ContentIndex_OpenedNew) || (indexSet->currentIndex==~0) || ContentIndexWritable(indexSet->index[indexSet->currentIndex])
!ref->liveSet || ref->liveSet->currentIndex==~0 || ContentIndexWritable(ref->liveSet->index[ref->liveSet->currentIndex])
could not create live index
void _SIContinueIssueMerge0(void *, Boolean)
void _SIContinueIssueMerge(void *, Boolean)
Merge
 (on battery)
Merge(2)
void _SIContinueIssueMerge2(void *, Boolean)_block_invoke
indexCount <= indexSet->indexCount
void _SIContinueIssueMerge2(void *, Boolean)
_si_merge_for_badness_on_flush_queue
_si_merge_for_badness_on_compact_queue
void _si_merge_for_badness_on_compact_queue(void *, Boolean)
com.apple.spotlightindex.verify
si_verify
verify err
si_CleanupCommit
_kMDItemDeleted
indexing: %s
%s:%u: failed assertion '%s' %s src: %d id: %d oid: %lld parent: %lld options: %x extra: %p
(CFTypeRef)ctx->attrdict!=(CFTypeRef)kCFNull
_setAttributes
:MD:kMDItemPath
processing oid: %lld source: %d %s
processing oid: %lld source: %d
:MD:_kMDItemBackupMoveMarker
ctx->attrdict==((void*)0)
void _setAttributes(si_set_attr_ctx *, _Bool, dispatch_group_t, Boolean)
setAttributesBulk_block_invoke
_si_get_object_for_identifier_createParentDBO
setCSAttributes1
setCSAttributes1_block_invoke_3
setCSAttributes1_block_invoke_2
deleteCSAttributes
deleteCSAttributes_block_invoke_2
%s:%u: failed assertion '%s' %s Got parent id %lld for oid %lld
dbo->parent_oid>=2 || dbo->parent_oid==-1
failed
sourcePath[0]>=2
destPath[i]>=2
processOneChildlessDirectory
parent===1
dbo->parent_oid == parent
dbo->parent_oid==0
handleMovingContent
i<=ctx->count
i+advanceLen<=ctx->count
processOneFile
_SIResolveDirectory
!(sourceOid==destPath[i] || destPath[0] == destPath[i])
moveDirectoriesInner
dbo->parent_oid == directoryStoreGetParent(ref->dirStore, dbo->oid)
!(s->state==kSIIndexStateNeedsShadow && state==kSIIndexStateDirty)
!(s->state==kSIIndexStateDirty && state==kSIIndexStateClean)
s->sdb_state!=kSIIndexStateNeedsShadow
s->directory_state!=kSIIndexStateNeedsShadow
_si_dump_index_state
compute_transitions
transition_table.mm
it != unprocessed.end()
store_stream_init_fd
store_stream_flush
SIScheduler.c
child->parent==scheduler
com.apple.metadata.spotlightindex.mq.%s
com.apple.metadata.spotlightindex.%s
kSISchedulerQOSClass
MQ: %s
scheduler->suspended
scheduler->running==0
scheduler->force_resumed == 1 || scheduler->suspended==0
%sWork queue %p; dq: %p %ld items enqueued
queue
root
%s:%u: failed assertion '%s' %s Bad CRC on work unit. %p %p %p %p %p %p
cu->u.crc==compute_workunit_crc(cu->u)
work_fun
%sScheduler %p %s dq:%p parent:%p; %d suspensions suspended:%s (stop waiting: %s stopped: %s)
SISimpleQueue.c
queue->end == (queue->end&(queue->size-1))
queue->start == (queue->start&(queue->size-1))
simple queue
destroyed simple queue
%s:%u: failed assertion '%s' %s Expected valid queue entry type. Got %d
SIResultQueue.c
queue->lowWaterMark!=0
[%d,%d] %s
v40@?0{?=qq}8d24^B32
com.apple.mobileslideshow
SICompletions.cpp
depth < 20
d188@?0^{?=^SQ}8Q16Q24d32d40{ci_rankingbits_wrapped_s={ci_rankingbits_s=TTTIfI}}48q112i120i124i128i132i136B140B144B148i152C156C160d164^{_SIWordTrieFragmentBundleIDs=}172^v180
%s:%u: failed assertion '%s' %s No query work queue for priority %d
SIJob.c
ref->workqueues.queues[SI_QUERY_QUEUE_IDX+priority]!=0
ref->workqueues.queues[SI_FS_QUEUE_IDX]!=0
RootDirectory
com.apple.spotlight
/var/mobile/Library/Caches/com.apple.parsecd
spotlight_stopword
spotlight_phrase_dictionary
General
Query
LiveQuery
Scheduler
Store
Fetch
Path
State
Power
Completions
com.apple.spotlightindex
indexPositions
indexPositionTable
BurstTrie.c
bt_openTrie
bt_recoverTrie
getNum(t->baseFat[s].termInfo.termId.ptr)==0
getNum(b->termInfo.termId.ptr)==0
old==s
flatStoreGetOffset(ptr) < storageGetCount(&t->flatStore)
%s:%u: failed assertion '%s' %s s: %d, c: %d
ptr.next<=getNum(t->baseFatCount)
ptr.next
bt_shadowTrie
v12@?0{TokenRange=ss}8
BurstTrie.h
ptrM(newptr).next == ptr.next
BurstTrie-Internal.h
offset<=0x3FFFFFFF
%s:%u: failed assertion '%s' %s offset %ld past bounds %ld %ld
offset<t->bases.size
%s:%u: failed assertion '%s' %s %d < %d
shadowFlatStore
ptr.kind
ptr.kind || ms->err
ms->err
*string
j<=count
z<=count
j+z<=count
(flatStoreGetOffset(range[k].info) >= flatStoreGetOffset(range[k-1].info) && range[k-1].info.next !=0) || range[k].info.next==0
TrieMergeUpdates
s<=getNum(t->baseFatCount)
!(offset>flatPagePtr && offset<flatPageEnd)
_dumpTrie
oldPtr.kind == FLAT
v16@?0^{storage_reader_t=^{storage_t}^{storage_reader_window_s}Bi}8
_bt_findBulk_block_invoke_2
ctx->la
%s:%u: failed assertion '%s' %s next: %d, max: %d
ptr.next < ctx->trie_fat_max
ptr.next < ctx->trie_max
child.next < ctx->trie_fat_max
child.next < ctx->trie_max
%s:%u: failed assertion '%s' %s invalid len
str_len
ch_start==0
%s:%u: failed assertion '%s' %s max depth exceeded: %d
ctx->stringLen<CI_UTF8CHARS_BUFFER_SIZE
v28@?0{?=Ii}8*16i24
v36@?0{?=Ii}8^{lt_trie_node=*^^{lt_trie_node}CCC}16*24i32
match_function
v16@?0^{FindTermIDsContext=^B^{_TrieHead}^{ForwardDirectoryStore_s}^{FileTree_Overlay_s}^^{FlatPageSearchBucket}i{?=Ii}QQQ[1052C]I^{QueryNode}I^^{?}^^{?}III^vII^{AllocSlab}I**^{QueryNode}^{?}^{?}^{levenstein_automaton}^{automaton_state}ifBB}8
match 
i24@?0^{FindTermIDsContext=^B^{_TrieHead}^{ForwardDirectoryStore_s}^{FileTree_Overlay_s}^^{FlatPageSearchBucket}i{?=Ii}QQQ[1052C]I^{QueryNode}I^^{?}^^{?}III^vII^{AllocSlab}I**^{QueryNode}^{?}^{?}^{levenstein_automaton}^{automaton_state}ifBB}8*16
pushMove
MoveHolder.c
holder->count==0 || holder->count + holder->data == ((char*)current) + sizeof(PossibleFileMoves_t)+sizeof(oid_t)*current->count
_CISetEmergency
ContentIndex.c
(!baseId) || newIndex->base==baseId
_CIUpdateState
open canceled
No meta info
invalid meta info
success: no data in index, rebuilding
create index error
_CIOpenBulk
needs recovery
open index shadow error
recover index error
open recovered index error
_CIFlushCache
_CISyncContextDestroy
_CISyncContextSync
_CISyncContextCommitData
_CISyncContextCommitHeader
_CISyncContextShadow
_CICompact
tmp.can_write.%d.%d
_CIDisableUpdates
%s_%d.
_CIMergeDeletes
_CIUpdateContent
((cindex)->coreSpotlight?({ ((uint8_t *)(cindex)->groups)[(relDocId)]; }):({ uint32_t __where=(uint32_t)(relDocId); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((cindex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
_CIUpdateGroupAndDate
_CIDelete
_CIReassign
ref->payloadCount <= 1
_CIRebaseDocId
_CIDocIdForOID
(ref)->groupMap[gslot]
((ref)->coreSpotlight?({ ((uint8_t *)(ref)->groups)[(i)]; }):({ uint32_t __where=(uint32_t)(i); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((ref)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
_CIDeleteDuplicates
ref->readOnly
ref->payloadMaxCount >= ref->payloadCount
_CIFindTokens
_CIPreHeatIndex
_CIGetOIDForDocId
_CIGetGroupForDocId
_CIAddOids
((cindex)->coreSpotlight?({ ((uint8_t *)(cindex)->groups)[(i)]; }):({ uint32_t __where=(uint32_t)(i); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((cindex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
_CIDeleteByOidsBulk
_CIMoveDirectory
%sindexHead
gatherAndLockIndexCallback
indexPrepareForSyncBulk
indexPerformSyncBulk
io_state[i]==0
indexCommitSyncBulk
indexShadowAndCommitBulk
_indexShadowBulk
_indexCommitShadowBulk
_ContentIndexSyncIndexBulk
ContentIndexVerifyIndex
newDocId > newBase && newDocId <= newMax
((newIndex)->coreSpotlight?({ ((uint8_t *)(newIndex)->groups)[(docID)]; }):({ uint32_t __where=(uint32_t)(docID); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((newIndex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
_MergeDeletes
expandMap
expandUnsafeMapNew
%s:%u: failed assertion '%s' %s offset: %lld, freeRegion: %lld, kind:%d
FlatStore.c
flatStoreGetOffset(ptr)+roundup2(pageEnd+int_sizeof(*page) <= freeRegion)
%s:%u: failed assertion '%s' %s ps:%d, pe:%d, pk:%d, po:%llx, ss:%llx se:%llx
pageSize >= pageEnd && pageSize && (__builtin_popcount(pageSize+int_sizeof(*page)) == 1)
%s:%u: failed assertion '%s' %s %ld, ps:%d, pe:%d, pk:%d, po:%llx, ss:%llx se:%llx
ms->currentStringLen <= CMPBUFFER_SIZE
%s:%u: failed assertion '%s' %s flat store
ms->pageOffset.next==_ptr.next
ptr.kind==FLAT
flatStoreGetOffset(ptr) < freeRegion
ms->type == kTermInfoTypeId
oldEntry.pfxLen + oldEntry.len <= CMPBUFFER_SIZE
newEntry.len
(int)pageEnd==storePageEnd(page)
pageEnd<pageSize
pageEnd < pageSize
pageEnd + newEntrySize <= pageSize
termID == getNum(newEntry.termInfo.termInfo.termId.ptr)
i < entry.len
i<=newEntry.len
entry.len > 0
entry.len==entryCopy.len
entry.pfxLen==entryCopy.pfxLen
len2 <= len1
flatStoreGetOffset(info) < storageGetCount(store)
entry.len
(int)pageEnd==storePageEnd(page) || trie_unavailable(t)
oldPageEnd == iter.pageEnd
iter.pageCursor==iter.pageEnd
__builtin_popcount(pageSize+(uint32_t)sizeof(*page)) == 1
pageEnd <= pageSize
(!compacted && t->type==kTermInfoTypeId) || (compacted && t->type!=kTermInfoTypeId)
*canceled || iter.pageCursor==iter.pageEnd
%s:%u: failed assertion '%s' %s len:%d cursor:%d, pe:%d, ps:%d, valid cursor:%s
FlatStore.h
entry->len > 0 || pageCursor == v2_vInt32Size(0)
pageCursor<=pageEnd
_checkFlatPage
storePageEnd(page) <= storePageDataSize(page)
reSize<=4096*16
flatStoreGetOffset(*newOffset) < storageGetCount(store)
entry->len > 0 || iter->pageCursor == v2_vInt32Size(0)
iter->pageCursor <= iter->pageEnd
index_FlushCache
%s:%u: failed assertion '%s' %s Expected cindex->_oldSet==0, got %p
JHContentIndex.c
cindex->_oldSet==0
indexFindBulk
*canceled || pqcount_bulk_TermIdQueue_t(q_pqueue) == 0
!((renamed != cindex->trie.renamed) || (!isCompact && (cindex->flags & kIndexFlagCompact)))
parentDirFd!=-1
createIndex
openIndex
invalid term update set
restoring term update set failed
index_verify
indexMarkDirtyForce
indexMarkDirty
indexMakeInvalid
indexPrepareForSync
indexCommitSync
_indexShadowGroups
indexShadowFiles
0 == TermUpdateSetTermCount(cindex->_deltaSet)
indexHead
fullShadowIndex
indexGroups
shadowIndexGroups
indexTermIds
shadowIndexTermIds
indexDirectory
shadowIndexDirectory
indexCompactDirectory
shadowIndexCompactDirectory
indexArrays
shadowIndexArrays
shadowIndexHead
recoverIndex
setDocumentAttributes
(cindex)->groupMap[gslot]
((cindex)->coreSpotlight?({ ((uint8_t *)(cindex)->groups)[((uint32_t)(oldDocID-cindex->base))]; }):({ uint32_t __where=(uint32_t)((uint32_t)(oldDocID-cindex->base)); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((cindex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
indexGrowDocumentPayloads
deleteDocument
((cindex)->coreSpotlight?({ ((uint8_t *)(cindex)->groups)[(payloadIndex)]; }):({ uint32_t __where=(uint32_t)(payloadIndex); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((cindex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
reassignDocument
index_compact
tmp.%scmpt.
newTermIDMap
%s:%u: failed assertion '%s' %s duplicate term id (%d)
0 == uint32_map_get(ctx->newTermIds, (uint32_t)termId)
%s:%u: failed assertion '%s' %s inconsistent term counts (%d %d)
%s:%u: failed assertion '%s' %s invalid rename %s %s
newPrefix[0]!='l'
%s:%u: failed assertion '%s' %s failed to read offset for term %d
TermIdStore.h
(intptr_t)ptr!=-1
indexIds
indexDates
indexBigDates
indexScores
indexUpdates
open_index_file
openPayload
indexPostings
verifyTermsCallback
%s:%u: failed assertion '%s' %s Expected non-zero docid
docid
((cindex)->coreSpotlight?({ ((uint8_t *)(cindex)->groups)[(docid)]; }):({ uint32_t __where=(uint32_t)(docid); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((cindex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
v60@?0^{TermBurstTrie={?=AI}^{AllocSlab}{TermTrieFat=^{tree_node}[256q]}[4{?=^vq}][256C]}8^{TermTrieFat=^{tree_node}[256q]}16B24^AI28@?<v@?^{tree_node={?=b63b1}{?=b63b1}{TermUpdate=(?={?={RelativePosting=I{?=II}}I}{?={UpdatePosting=I{?=IQ}}})S[0C]}}>36@?<v@?^vi>44@?<v@?^vi>52
index docId array
index date array
index score array
index group array
bases
fat bases
log_map_access_error
log_map_access_error_mini
len > 0 && len <= 32
indexRestoreHeaderFromBuffer
indexRestoreFromBuffer
preflight_compact
flat
termIdStore
0 == uint32_map_get(ctx->newTermIds, termId)
%s:%u: failed assertion '%s' %s no posting for term (%s %s)
initPayload
expandPayload
JHPayload.c
wb->buffer
pd->payloadIndex >= pd->payloadLimit
PayloadWriteBufferWrite
pd->payloadIndex - pd->payloadLimit >= sizeof(PulseHeaderDisk)
pos == pd->payloadIndex
%s:%u: failed assertion '%s' %s i:%d count:%d last:%d termId:%d prevTermId:%d flags:%x
(termId > prevTermId) || (i == last && termId == prevTermId)
postingStart-postingTermIdStart
JHPayload.h
src == ptr || wb->err
HashPriorityTable.h
fRankingbits[slot].containerId()!=0
initMF
%s:%u: failed assertion '%s' %s NULL file reference
MFMalloc.c
m->fdPtr
Watchdog workloop
Watchdog timer queue
si_indexingWatchdogInit_block_invoke_2
Indexing watchdog fired, delta:%lld, startTime:%lld, itemCount:%ld suspendTime:%lld resumeTime:%lld endtime:%lld pc:%u
si_indexingWatchdogPerform
-001_
n2s.c
(exponent >= 0) && (exponent <= 0x7FF)
conversionSucceeded
PQueue.c
!offset || offset_t_GET_VALUE(queue->offsets[i])<offset*2
queue->top <= queue->end
current >= offset
current <= offset
last>=offset
current >= last
last<offset
storage.c
reader->storage->_window1.memory
storageHeaderRestore
storageInit
result
storageSyncPages
storageTruncate
idx < (16)
((uint32_t)8<<idx) >= inSize - baseSize
rsize+baseSize >= inSize
success
result < inStorage->_freeRegion
inSize - baseSize <= rsize
inOffset < inStorage->_size
inOffset < inStorage->_freeRegion
inOffset+inNewSize <= inStorage->_freeRegion
oldIdx <= newIdx
freeListVerify
inStorage->_window1.mappedStart==0&&inStorage->_window1.mappedStart==0&&inStorage->_window1.memory==((void*)0)
_storageMapInit
%s:%u: failed assertion '%s' %s mmap(%p, offset: %llx, size: %ld) error:%d, fSize:%lld
%s:%u: failed assertion '%s' %s offset: 0x%llx, freeRegion: 0x%llx
inOffset==0 || inOffset < inStorage->_freeRegion
storageMoveWindow
mem:%p so:%lld eo:%lld ms:%ld s:%lld
storage_copy_read_window
%s:%u: failed assertion '%s' %s offset: 0x%lld, freeRegion: 0x%lld
(head==0) || (head < storage->_freeRegion)
_storeageSetFreeListHead
_storageExpand
TermUpdateSet.c
0 == kr
updateTermCount == ctx.termCount
TermUpdateSetRestore
termUpdateSet->reportedSize <= gTotalCurrentUsage
%s:%u: failed assertion '%s' %s Expected non-zero docID
docID
%s:%u: failed assertion '%s' %s expected non-zero docID for term
DocPosting.h
message:%3C
ptr==end
_getContentTokensCallback
%s:%u: failed assertion '%s' %s expected non-zero docID for term %s
ctx->docID
_getContentRankedTokensCallback
tu->termLen <= (1024+20)
SIUserCtx.c
CFArrayGetTypeID()==CFGetTypeID(languages)
SIUserCtx
v12@?0s8
v20@?0i8^q12
FileTree.c
getStoreOID(root->fileId)==2
%s:%u: failed assertion '%s' %s %lld != %lld
element->fileId.storeOID == source.fileId.storeOID
directoryStoreMoveDirectory
target.directory
rootDirectory->children==0
rootDirectory->lastPosting.posting.docId==0
rootDirectory->fileid == getStoreOID(root.directory->fileId)
directoryStoreMergeUpdateSet
%s%s
directoryStoreFile
directoryStoreFile.shadow
openForwardStore
flushForwardStore
shadowForwardStore
.shadow
postings<9223372036854775807LL
getStoreOID(root.directory->fileId)==2
!target.directory->childPage.offset
!((refPage.pageOffset[0] & (1ull << 63)) || refPage.pageOffset[0]==0)
directoryStoreMakePathWithPostingsOffset
%s:%u: failed assertion '%s' %s invalid posting 0x%llx for 0x%llx
postingOffset
dumpDirectoryStore
.shadow.shadow
0==strstr(shadowpathPtr, ".shadow.shadow")
0==strstr(path, ".shadow.shadow")
%s%s.shadow
directoryStoreGetParent
directoryStoreGetPath
directoryStoreWriterGetParent
parent
(getStoreOID(element->fileId)==item && &page->items[slot]==element)
directoryStoreSetParentForMove
%s:%u: failed assertion '%s' %s %d, %d, %d, %llx
depth< olddepth
%s:%u: failed assertion '%s' %s %d, %d, %d, %llx, %llx
item!=parents[depth]
%s:%u: failure log '%s' %s %d, %d, %d
hitPath==-1
depth<512
item!=inItem
directoryStoreEnsurePath
directoryStoreWriterGetPath
(!page)
_reverseStoreIterate
flushReverseStore
commitSyncReverseStore
shadowReverseStore
%s:%u: failed assertion '%s' %s invalid state
metadata != kIndexShutDownStateFastFlush
reverseDirectoryStore
reverseDirectoryStore.shadow
%s:%u: failed assertion '%s' %s Expected bitmap to be clean for index in state %x. Dirty bit at index %lx
dirtyBitIx == kCFNotFound || dirtyBitIx >= (CFIndex)(store->storage._freeRegion/STORAGE_SHADOWPAGESIZE)
commitShadowReverseStore
(store->state != kIndexShutDownStateNeedsShadow || readOnly)
reverseStoreUpdateState
reverseStore.updates
bits
!(offset & (1ull << 63))
(offset & (1ull << 63))
storePageEnd((StorePageRef)page) <= storePageDataSize((StorePageRef)page)
__builtin_popcount((storePageDataSize((StorePageRef)page))/((int)(sizeof(disk_offset_t))) + 1) == 1
!flat
getNum16(page->depth)==(unsigned)pageDepth
pageSize
%s:%u: failed assertion '%s' %s Expected offset (%llx) to be less than free region (%llx)
CHILDLESS(offset) || MASKPAGE(offset) <store->_freeRegion
flat
%s:%u: failed assertion '%s' %s Got end %d and size %d
refPage->pathDepth==getNum16(page->depth)
%s:%u: failed assertion '%s' %s Expected depth %d; page has %d
getNum16(page->depth)==(unsigned)depth
!((pageOffset & (1ull << 63)) || pageOffset==0)
flat==0
(directoryStorePageGetItemCount(subPage)+1) * 5 < (directoryStorePageGetSize(subPage)) * 4
element==0
*flat==0
*flat
outPage.leafPageOffset != getOffset(newChildPage)
page
specialBits == 0
!(((realOffset & (1ull << 63)) ==0) && (realOffset & (1ull << 62 ))==(1ull << 62 ))
%s:%u: failed assertion '%s' %s file tree
getOffset(info) < storageGetCount(store)
reSize<=((1<<(10))* sizeof(CIDirectory_t))
getOffset(*newOffset) < storageGetCount(store)
%s:%u: failed assertion '%s' %s error %d expanding from old:%d new:%d
newRealOffset
getStoreOID(newDirectory.fileId) >= 2
getStoreOID(newDirectory.fileId)==fileid
elem==0
directoryStorePageGetSize(page)*4>directoryStorePageGetItemCount(page)*5
!result
realOffset==(64)
dirStoreInit
dirStore->store._fdPtr!=0
page->items[i].childPage.offset==0
itemCount==count
!postingsOnly
!(page->items[i].fileId.storeOID==markerOid.storeOID)
storePageEnd((StorePageRef)page)/sizeof(CIDirectory_t) <= storePageDataSize((StorePageRef)page)/sizeof(CIDirectory_t)
__builtin_popcount((storePageDataSize((StorePageRef)page))/((int)(sizeof(CIDirectory_t))) + 1) == 1
dir.fileId.storeOID!=0
getStoreOID(dir.fileId)!=1
page->items[i].fileId.storeOID!=markerOid.storeOID
item!=parent
(element==0 || (getStoreOID(element->fileId)==item && getOffset(element->childPage) == (offset_t)parent))
parent == _directoryStoreGetParent(store, item)
storePageEnd((StorePageRef)page) <= storePageDataSize((StorePageRef)page) && storePageDataSize((StorePageRef)page)
result && (offset_t)(intptr_t)result != inOffset
itemCount == 0
%s:%u: failed assertion '%s' %s state:%d header:%llx
getNum(page->metadata)==kIndexShutDownStateDirty
getOffset(addr) == REVERSE_MAP_ROOT_OFFSET
reverseDirStoreInit
recoverReverseStore
get_state
/Library/Caches/com.apple.xbs/Sources/SpotlightCore_Sim/Spotlight-2183.16/spotlight/index/SpotlightIndex/SILiveQuerySupport.c
siquerynode.c
s!=NONE
node->lchild==lchild
node->rchild==rchild
_kMDItemFS
source!=NONE
node->kind<=QN_FACTOR
count==scount
%s:%u: failed assertion '%s' %s Unexpected node type %x
sinode->node.mnode.nodeCount>=2
_kMDItemOID
_FPIsTrashed
_kMDItemIndexID
_FPItemIdentifier
_kMDItemCachedIcon
_kMDItemRenderValues
kMDItemFinderOpenDate
kMDStoreLastHealthCheck
kMDStoreAccumulatedSizes
_kMDItemCachedTextContent
kMDItemFSLocked
_kMDItemThumbnailData
_kMDItemFSGroupId
_kMDItemSyntheticGroupId
_kMDItemThumbnailDataPath
_kMDItemFSDataSize
_kMDItemFSSize
_kMDItemFileId
kMDItemLabelIDs
_kMDItemFSDisplayName
_kMDItemFSRsrcSize
_kMDItemEngagementValues
_kMDItemServerVersion
_kMDItemFSForkSize
_FPParentFileItemID
_kMDItemIndexGroupId
_kMDItemFSDisplayKind
_kMDItemOIDPath
_kMDItemOIDParent
_kMDItemOnBootVolume
_kMDItemAllOldestSnapshotDates
_FPUserFSUSBFileProviderID
_kMDItemAllNewestSnapshotDates
NSFileProviderRootContainerItemIdentifier
_kMDItemFileName
_kMDItemThumbnailDataExists
_kMDItemRenderData
kStorePropertyHealthCheckCompleteTime
kMDItemEditors
kMDItemProjects
kMDItemLyricist
kMDItemMusicalGenre
kMDItemOrganizations
kMDItemPublishers
kMDItemContributors
kMDItemCoverage
kMDItemIdentifier
kMDItemCreator
kMDItemCity
kMDItemStateOrProvince
kMDItemCountry
kMDItemInformation
kMDItemDirector
kMDItemProducer
kMDItemGenre
kMDItemPerformers
kMDItemFullyFormattedAddress
kMDItemParticipants
kMDItemAlternateNames
kMDItemNamedLocation
kMDItemDescription
kMDItemHeadline
kMDItemRecipients
kMDItemEmailAddresses
kMDItemInstantMessageAddresses
kMDItemAuthorAddresses
kMDItemDisplayName
kMDLabel_
_kMDItemEngagementData
parent_oid
index_id
index_group
flags
/%lld
oid_path
_kMDItemPSIDPath
store_properties
_kMDItemDisplayNameWithExtensions
com.apple.filesystems.UserFS.FileProvider
SIQueryMallocZone
compute_non_combining_chars
levenstein_automaton.mm
v32@?0d8*16Q24
%04i-%02i-%02iT%02i:%02i:%02iZ
time.
absolute(
iso(
today
yesterday
two_days_ago
three_days_ago
this_week
this_month
this_year
SISearchCtx_METADATA.cpp
_store->store
nodeSize>=nodeCount
db->store
Recycle for error during query
err==0
!dbo || !dbo->oid || dbo->oid == oid
^v44@?0i8{?=(?={?=^vI}{?=^vQ}{?=*Q}{?=*I}*BCSIQTcsiqtdfdq^v)}12Q28^v36
UniversalSearch
d32@?0^I8^B16^B24
performSearch_METADATA
_performSearch_degenerate
fPlistBytes[slot]
_performSearch
self->currentOid!=0
kMDQueryResultMatchedDisplayNameField
kMDQueryResultMatchedFields
kMDQueryResultContentRelevance
kMDQueryResultGroupId
kMDQueryResultTopMatchedField
kMDQueryResultTextContentDistances
kMDQueryResultHasTextContentMatch
attributeCount==0
fOids[slot]
B16@?0Q8
Query result pack queue
Query result check queue
readSDBForOids_block_invoke_2
batchCount > i
processItems_block_invoke_2
packItems
v120@?0{rankAndFetchInfo={ci_rankingbits_s=TTTIfI}T{?=[5C]}qC}8
v120@?0{rankAndFetchInfo_q2={ci_rankingbits_s=TTTIfI}T{?=[5C]}qC}8
gatherIndexInfo
(size_t)docs[i]<j
cidocs[(size_t)docs[i]]
idx==ctx->cinodeCount
v24@?0^{query_piece=*^?iCiiii*(?=^v^^v)^v^?^III[16(value_type=*^*qiscfd^d^q)]}8^{_ContentIndexDocSet=}16
addString
kMDItemAuthorEmailAddresses
kMDItemContentCreationDate
kMDItemContentModificationDate
fAttributeVector
fUniqueingSets
fCompletionAttributeVector
CIIndexSet.c
(int32_t)set->_hole <= (int32_t)set->_count
(int32_t)hole < (int32_t)set->_size
CIIndexSet
<CIIndexSet: %p count: %u>
<CIIndexSet: %p count: %u isBitMap: %d>
(int32_t)hole <= set->_count
at < set->_blob[hole-1]
set->_blob
set->_count >= set->_hole-hole
start <=end
startSlot <=endSlot
startSlot < set->_size
sourceStart >= sourceEnd
oldData >= hole
!(USE_MMAP(oldsize) || USE_MMAP(newsize))
set->_blob[set->_hole-1] > at
right < (int32_t)set->_size
set->_hole-1 < (int32_t)set->_size
PostingChunk.c
rb->current > docID
%s:%u: failed assertion '%s' %s Offset past bounds; incoming %ld, current %ld, buffer length %ld, val %llu from %d
offset < bufferLength
%s:%u: failed assertion '%s' %s %d, %d
docID > delta
docID < maxValidId
firstDocID < maxValidId
secondDocID <= maxValidId
%s:%u: failed assertion '%s' %s %ld, %ld
newOffset <= bufferLength
delta <= docID
docID >= firstDocID
docID+1 < maxValidId
docID <= maxValidId
packCtx->chunkChanges
bitVectorCount > 0
docIDLast > docIDStart
docIDLast < docIDEnd
docIDLast >= docIDs[i]
SIWordTrieContainer
ContentIndexDocSetsCreateIterator
ContentIndexQuery.c
!(!target || target->docIdSetType==Empty || target->docIdSetType==Mute)
ContentIndexDocSet_Step
!groupDone || (uint32_t)group<groupDone->groupCount
collecting
dropping
ContentIndexDocSetResolveOIDsAndGroups_Step
assert_invalid_doc_type
_ContentIndexDocSetIteratorProcessIterHits
oldNodeCount >= nodeCount
processCount || nodeCount == 0
transition_trie.c
lt_trie_make_with_icu_element_at_index
com.apple.spotlightui
SIBullseyeNoForceUnigrams
versionNineResetSentinelData
versionNineUpdateDataAndLength
markItemAsRenderedOrEngaged
db_set_garbage_collector
core-db.c
db_set_dirty_callback
db_datastore_largest_oid
db_get_object_count
db_io_error
db_dirty_datastore
db_fast_dirty_datastore_if_necessary
db_is_dirty
db_get_size
db_lock_datastore
db_unlock_datastore
db_downgrade_datastore
db_flush_datastore
db_commit_sync_datastore
db_shadow_datastore
db_commit_shadow_datastore
db_commit_shadow_complete_datastore
db_release_datastore_no_sync
db_shrink_cache
db_ensure_open_files
db_cooldown_files
db_copy_field_ids_with_buffer
db_copy_field_ids_with_buffer_locked
db_get_id_for_field
db_get_id_for_field_locked
db_get_fields_generation
db_create_obj
db_create_obj_with_buffer
db_get_obj_callback
db_store_obj
db_update_obj
db_update_obj_callback
db_perform_callback
db_validate_obj
db_delete_obj
db_delete_obj_with_flags
db_create_id_for_value
db_add_field
db_add_field_with_cache
db_delete_fields_with_flags
db_delete_field
db_get_field
db_get_field_locked
db_get_field_by_id
db_get_offsets_for_fields
db_get_id_for_string
db_get_string_for_id_locked
db_get_field_name_for_id_locked
db_get_string_for_id
db_get_field_name_for_id
db_get_field_id_limit
db_get_localized_string
db_next_field
db_clear_docids_setup
db_clear_docids
db_clear_docids_cleanup
db_open_files
db_apply
db_get_dirty_chunks
db_create_static_strings
db_match_address
db_garbage_collect_strings
db_copy_delete_localized_term_ids
db_serialize_cache
db_obj_iter_create_with_filter
store.updates
db_store_dirty_chunk_info
dirty_chunks[i].pgnum > dirty_chunks[i-1].pgnum
!info->dirty_chunks
db_restore_dirty_chunk_info
info->dirty_chunks
copyVolumeInfoStr
(%s, t: 0x%x, st: 0x%x, f: 0x%x)
mds64-crash-state
check_crash_state
ContentIndex_catch_exception_raise
ContentIndex_catch_exception_raise_state
ContentIndexExceptionHandler.c
ContentIndex_catch_exception_raise_state_identity
krc==KERN_SUCCESS
%s:%u: failed assertion '%s' %s Active handlers > MAX_CI_THREAD_COUNT
entry
%s:%u: failed assertion '%s' %s invalid count %d
entry->count == -1
td->itemCount < td->itemSize
td->itemCount
seqNum <= td->items[j].seqNum
seqNum == td->items[td->itemCount].seqNum
td->cleanUpSize
td->cleanUpCount
td->cleanUpCount >= position
__THREAD_SLOT_KEY
loc>0 && loc<=1024
td->onThreadCleanUpSize
td->onThreadCleanUpCount
td->onThreadCleanUpCount >= position
/private/var/db/Spotlight-V100/%s-%s
setPC
entry->count==0
mapping
slab_allocator.c
kr == 0
tmp.merge.termIdFile.%d
mergeIndexData
mergeIndexData_block_invoke
CIMerging.c
count <= k
B20@?0^{?={?=QI*i}q}8i16
(newIndex)->groupMap[gslot]
4096*(gslot*8+bslot) <=slot
4096*(gslot*8+bslot+1) >slot
((newIndex)->coreSpotlight?({ ((uint8_t *)(newIndex)->groups)[(docId)]; }):({ uint32_t __where=(uint32_t)(docId); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((newIndex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
(((newIndex->coreSpotlight?({ ((uint8_t *)newIndex->groups)[docId]; }):({ uint32_t __where=(uint32_t)docId; uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)(newIndex->groups[__slot])); (__word >> __shift) & 0x3F ; }))&0x1F)) == 0
newIndex->payloadCount + newIndex->base <= sources[idx_cnt-1]->payloadCount + sources[idx_cnt-1]->base
hitCount
hitCount<=idx_cnt
_last>(uint32_t)idx
idx<idx_cnt
packContext.packbuffer[k-1] > packContext.packbuffer[k]
lastId>=lastStringId
sourceItems[i].item.postingOffset
termIdFd == -1
MergeSuccess
vacuum
MergeCanceled
MergeException
MergeError
Complete
Canceled
%s:%u: failed assertion '%s' %s expected %d > %d
i==0 || context->packbuffer[i-i] > context->packbuffer[i]
context->packbuffer[i] > context->packbuffer[i+1]
context->count<=1 || context->packbuffer[context->count-2] > context->packbuffer[context->count-1]
context->count<=2 || context->packbuffer[context->count-3] > context->packbuffer[context->count-2]
lastItem.item.termLen==0 || TermItem_compare(&lastItem, &sourceTerm[0]) < 0
sourceTerm[k].idx<sourceTerm[k-1].idx
moredata&(1<<sourceTerm[i].idx)
iterateTermsForIndexes
%s:%u: failed assertion '%s' %s Got 0 from calloc for allocation of count %ld size %ld
p||count==0||size==0
B28@?0i8^q12Q20
mergeIndexDataTrampoline
%s:%u: failed assertion '%s' %s corrupt ro index need to rebuild %s
!buffers->badIndex
strlen((char*)strbuf) == workItem.termLen
_excReadBufferMatch
unpackAndCleanse
offset < readBuffer->mappedSize
nxtLink==0||!isCompact
changeHolder->count == 0 || changeHolder->hole
next != nxtLink
changes->hole>0
sdb2_rwlock.c
lock->writer != pthread_self()
list->head==0
waiter->threadid
AppleLanguages
/var/log/CDIS.custom
LANGUAGE=%s
UNICODE MATCH:%s
addValue
MDPlistBytesAdditions.c
%s:%u: failed assertion '%s' %s NLStringTokenizerCreate err:%d
CITokenizer.c
version>=0 && version<=kCITokenizerVersionCurrent
%s:%u: failed assertion '%s' %s alloc err:%d (%x)
state->uniChars
fd_create_protected
fd_create_sibling_protected
fd_lseek
fd_pread
fd_obj.c
!obj->forbidder
fd_pwrite
fd_write
fd_rename
obj->_magic==(0xFCFCFCF3)
%s:%u: failed assertion '%s' %s Unexpected delete of %s from %d
!unlinked
obj->prev
g_fd_list->item_count==0
g_fd_list->item_count
g_fd_list->item_count>=0
!obj->prev
g_fd_list->fd_count>=0
processed++ < g_fd_list->item_count
processed == g_fd_list->item_count
obj->fd != -1
g_fd_list->item_count!=0
g_fd_list->head
_fd_acquire_fd
obj->fd == fd
obj->open_count
_safe_open_at
%s:%u: failed assertion '%s' %s Too many open files %d (%d) (%d)
%s:%u: failed assertion '%s' %s Too many open files in system %d
RLEOIDArray
SIValueSetInternals.h
s->sharedDepth>=0
((sizeof(ValueType) * 8) -4*(1+(s->sharedDepth))) <= sizeof(ValueType)*8
SIValueSet
CombLevel_s
s->sharedDepth
holder->GetRawCount() <= (63)
startPrefix == (startPrefix & startMask)
%s:%u: failed assertion '%s' %s next: 0x%llx, max: 0x%llx
FindTermIDs.c
flatStoreGetOffset(child) < ctx->flat_max
%s:%u: failed assertion '%s' %s grow buckets error, bucket count:%d
buckets
%s:%u: failed assertion '%s' %s invalid key_len %d
key_len>0 && key_len <= 4
t->size>=t->count
%s:%u: failed assertion '%s' %s duplicate pages %ld %ld
%s:%u: failed assertion '%s' %s type: %d
icu_utils.c
b->_type>kICUBaseType&&b->_type<kICUBaseEndType
%s:%u: failed assertion '%s' %s unexpected type %d
@collation=search
icu_rules_
%s:%u: failed assertion '%s' %s %s count %d
ctx->count>1
MATCH
NO_MATCH
%s:%u: failed assertion '%s' %s %s level: %d count: %d
cur_state.level+1>=ctx->count
cur_state.level+1<ctx->count
cur_state.level==0 && (cur_state.level+1<ctx->count)
cur_state.level+1!=ctx->count
cur_state.cur==(u_int8_t*)string
item.start_mask&U_MASK(u_charType(utf8_to_code_point((u_int8_t*)cur_state.cur)))
icu_rules_%s_%d_%d
%s:%u: failed assertion '%s' %s bad length: %d
size <= 256
v36@?0i8^S12i20^S24i32
expansion_len<EXPANSION_LIMIT
%s:%u: failed assertion '%s' %s size: %d count:%d
b->size>=b->count
%s:%u: failed assertion '%s' %s len %d
key_len
%s:%u: failed assertion '%s' %s bad type: %d
%s:%u: failed assertion '%s' %s invalid utf8 %u
%s:%u: failed assertion '%s' %s invalid char %u
%s:%u: failed assertion '%s' %s token len %d
p->token_len<TOKEN_MAX
[last tertiary ignorable]
[last primary ignorable]
[variable top]
[last regular]
[import 
%s:%u: failed assertion '%s' %s unexpected %d
v28@?0*8I16^{?=^{term_expansions}[8I]CC[0q]}20
rules_offset <= rules_size
expansions_offset <= rules_size+expansions_size
string_offset <= total_size
ne->expansions[i][needed-1] == 0
ctx->_base._type==kICUSearchType
ctx->_base._type==kICURangeType
__checkIndexSet
unexpected index base
overlapping doc ids
Cache/%x/%llx.%s
Cache/%4.4x/%4.4x/%4.4x/%lld.%s
%s:%u: failed assertion '%s' %s no field name for id %d of localize id %d
SIStoring.c
field_name
v24@?0r*8^{db_field=SSII[0C]}16
/Library/Caches/com.apple.xbs/Sources/SpotlightCore_Sim/Spotlight-2183.16/spotlight/index/SpotlightIndex/SIStoring.c
void _SIRecomputeSizesWithCallback(SIRef, off_t, dispatch_block_t)
%s:%u: failed assertion '%s' %s magic:%llx
ctx->magic==RECOMPUTE_SIZE_MAGIC
si_populategroup
si_writeBackAndIndex detected corrupted sdb on entry
_kMDItemContentIndexVersion
ContentIndexWritable(content_index)
_kMDItemBundleID
FPDomainIdentifier
si_writeBackAndIndexWithLiveQueryToggle
db->liveSet->indexCount
com.apple.searchd
content_index
_kMDItemUserTags
set attributes err
%s:%u: failed assertion '%s' %s si_writeBackDBO failed %d
si_writeBackAndIndex detected corrupted sdb on exit
void _swapIndex(struct flush_index_ctx *, Boolean)
tmp.%ld.
i8@?0
!ContentIndexWritable(indexSet->index[i])
!found
indexSet->index[spot-1]==ctx->idx
%s:%u: failed assertion '%s' %s This should be impossible; this thread is supposed to be  suspended when the other thread changes index sets.
OSAtomicCompareAndSwapPtrBarrier(oldIndexSet,indexSet,(void* volatile*)indexSetPtr)
!ContentIndexWritable(ci)
flush
flush cache err
void _flushCache(struct flush_index_ctx *, Boolean)
ctx->suspend_token == 0
startIndex < indexSet->indexCount
indexSet->indexCount >= j
kMDItemPrimaryRecipientEmailAddresses
kMDItemAdditionalRecipientEmailAddresses
kMDItemHiddenAdditionalRecipientEmailAddresses
kMDItemRecipientEmailAddresses
_Ranking
kMDItemUseCount
canceled
%s:%u: failed assertion '%s' %s magic:%llx ctx:%p ref:%p
ref->magic == (0xc0de10de10dec0de)
void si_recompute_sizes(void *, Boolean)
v24@?0^q8Q16
 inflight
repair_lookupPath
%s:%u: failed assertion '%s' %s Got parent[%d] with id %lld depth: %d
newpath[i] > 0
psid_lookupPath
updateWithNewPath
SIStoring.h
indexSet->currentIndex==~0 || (uint32_t)indexSet->currentIndex<(uint32_t)indexSet->indexCount
indexSet->currentIndex==~0 || ContentIndexWritable(indexSet->index[indexSet->currentIndex])
computePathFP
computePathFS
dbo->parent_oid||dbo->oid==2
_kMDItemStateInfo
com_apple_system_prefs_keywords
kMDItemKeywords
swapIndex
v40@?0^{__SI=Q{SIFileOps=^?^?^?}{SIGuardedFd=iQ}isIi^{SIWatchDog}^{__CFDictionary}{si_missing_oids_s={os_unfair_lock_s=I}^{__RLEOIDArray}^{__RLEOIDArray}}{si_missing_oids_s={os_unfair_lock_s=I}^{__RLEOIDArray}^{__RLEOIDArray}}{os_unfair_lock_s=I}{si_comm_dates_s=^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}}{si_comm_dates_s=^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}}{si_comm_dates_s=^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}}{si_comm_dates_s=^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}}{si_comm_dates_s=^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}}^{__CFDictionary}Bi[18^{si_scheduler_token_s}]iI[4^{dispatch_semaphore_s}]{?=[18^{_si_work_scheduler}][20^{_si_workqueue}]}^{datastore_info}{CIMetaInfo=i^{fd_obj}iIIIIIIIIqqiiB}QQ{_opaque_pthread_mutex_t=q[56c]}^{ContentIndexList}^{ContentIndexList}iII^{_SI_PersistentIDStore}{__SIStoreToken={?=CCCCCCCCCCCCCCCC}^{__CFUUID}}ACAIdiI^{__CFDictionary}{_opaque_pthread_mutex_t=q[56c]}{_opaque_pthread_mutex_t=q[56c]}{_opaque_pthread_mutex_t=q[56c]}{os_unfair_lock_s=I}^{__CFBag}{_opaque_pthread_mutex_t=q[56c]}^{__CFSet}^{__CFDictionary}Q^{__CFBag}^{__CFDictionary}{_opaque_pthread_mutex_t=q[56c]}{_opaque_pthread_mutex_t=q[56c]}{_opaque_pthread_cond_t=q[40c]}iIIIIIIIIIIIIIIIIIIIBBAq^{__CFDictionary}{os_unfair_lock_s=I}^{__CFDictionary}^{__CFBitVector}^{si_mobile_journal}^{si_mobile_journal}AqAqd^?^vd{?=^{fd_obj}IIIBq{os_unfair_lock_s=I}}III^{FinderDateFields}{_opaque_pthread_mutex_t=q[56c]}^{fd_obj}^{fd_obj}ii^{_SIIndexCallbacks}^{__CFArray}^{__CFArray}qqqQIIiiBBBBBBBABB^{si_scheduler_token_s}BBBBBQ[4096c]{os_unfair_lock_s=I}{os_unfair_lock_s=I}b1b1b1b1b1b1b1b1b1b1b1b1b1b1b1b2b1^i^{__CFSet}^{__CFDictionary}^{__SIUINT64Set}^{ReverseDirStore_s}^{FileTree_Overlay_s}^{__CFSet}{AccumulatedCounts_s={_opaque_pthread_mutex_t=q[56c]}[256q][256I]}^{TermUpdateSet}{_opaque_pthread_rwlock_t=q[192c]}[16C]Bi^{datastore_info}AIBB[5i]*iI}8^{_xpc_activity_s=}16^B24^{dispatch_group_s=}32
void _swapIndex1(struct flush_index_ctx *, Boolean)
void _swapIndex2(struct flush_index_ctx *, Boolean)
compact err
kMDItemFSCreationDate
kMDItemFSContentChangeDate
kMDItemFSOwnerUserID
kMDItemFSOwnerGroupID
kMDItemFSNodeCount
kMDItemFSFinderFlags
kMDItemFSHasCustomIcon
kMDItemFSIsExtensionHidden
SIFetching.c
uid==0
kMDItemLangugeStrId
_kMDItemDisplayNameWithExtensionsSynth
flattenedIndex < totalFlattenedFieldCount
sortedFieldIdPairIndex < totalFlattenedFieldCount
cannedRequiredAttributeCount == cannedRequiredAttributeIndex
dbIter
_fillPlistBytes
kSISDBPages
kSISDBIterators
kSISDBObjects
kSISDBCacheHits
kSISetupTime
kSITermTime
kSIPostingsTime
kSIAttributeTime
kSISetupTimeFirstBatch
kSITermTimeFirstBatch
kSIPostingsTimeFirstBatch
kSIAttributeTimeFirstBatch
kSIStartTime
kSIEndTime
kSIEndTimeFirstBatch
kSIWaitTime
kSIActiveTime
kSIQoSLevel
_kMDItemBundleID=com.apple.searchd
_kMDItemSDBInfo
SIQueryAddResultFilter
SIQueryC.c
query->_liveUniquedSet==0
query->_liveUniquedQuery==0
query->_liveUniquedFilterQuery==0
query->queryNodes==0
_kMDQueryScope
_kMDItemQuery
kMDLabel_zya2exypzrhulknkk5enqbj33y
kMDLabel_yekauorssrbpta3hdteqgbglma
kMDLabel_26x2uentpjgt7lka65qdcazuya
kMDLabel_j3w3eydksrbbzleqdyl7kbqkuu
kMDLabel_kqde5prblvaibjifrcn4saxjwi
kMDLabel_veyixt7jjffe3g7nfailqcbxny
kMDLabel_qygkxhrfarhtxanqhi264amkku
kMDLabel_hlsi7t7nerhynemqvydgeb26de
adds
_kMDItemTextContentIndexExists
Title
Level1
Level2
Level3
%s:%u: failed assertion '%s' %s Bad query node; unexpected op %d
%s:%u: failed assertion '%s' %s Bad query node; unexpected type %d
holder
!isNegativeQuery(node->lchild)
%llx
processScopes
_kMDQueryItemInScopeForRankingOnly
kMDItemFSFileId
kMDItemFSSize
kMDItemFSName
kMDItemFSLabel
kMDItemFSIsStationery
kMDItemFSTypeCode
kMDItemFSCreatorCode
_kMDItemFSContentType
_kMDItemFSContentTypeTree
kMDItemLogicalSize
_kMDItemCreationDate
_kMDItemContentChangeDate
_kMDItemOwnerGroupID
_kMDItemHasCustomIcon
_kMDItemIsExtensionHidden
_kMDItemNodeCount
_kMDItemIsStationery
_kMDItemTypeCode
_kMDItemCreatorCode
_kMDItemFinderFlags
kMDItemContentType
kMDItemFS
com.apple
com.apple.MobileNotes
_kMDItemQueryPath
Flat
_showAllExtensions
_kMDItemDisplayNameWithExtensions == "X" || (_kMDItemDisplayNameWithExtensions != * && kMDItemDisplayName == "X")
%s:%u: failed assertion '%s' %s Bad generated query mid-node; unexpected type %d
midNode->type == AND_NODE
%s=*||%s=*||%s=*||%s=*||%s=*||%s=*||%s=*
!(%s=*||%s=*||%s=*||%s=*||%s=*||%s=*||%s=*)
kMDItemSubject
kMDItemTitle
v32@?0r*8s16^{TokenRange=ss}20s28
CFGetTypeID(completionQueryString) == CFStringGetTypeID()
Spotlight
Bullseye
false
kCIMatchArray
kCIBitCount
kMDItemContentTypeTree
public.message
com.apple.mail.emlx
com.apple.mail.eml
com.microsoft.entourage.virtual.message
com.apple.ichat.transcript
public.contact
public.vcard
com.apple.addressbook.person
com.apple.addressbook.group
com.microsoft.entourage.virtual.contact
com.microsoft.entourage.virtual.group
com.apple.systempreference.prefpane
public.font
public.bookmark
com.apple.safari.bookmark
com.apple.safari.history
public.to-do-item
public.calendar-event
com.apple.ical.bookmark
com.apple.ical.bookmark.todo
com.apple.ical.ics.event
com.apple.ical.ics.todo
com.microsoft.entourage.virtual.event
com.microsoft.entourage.virtual.task
public.movie
com.apple.quicktime-movie
public.mpeg-video
public.mpeg-4
public.mpeg
public.3gpp
public.3gpp2
com.apple.application-bundle
com.apple.application-file
com.apple.dashboard-widget
public.folder
com.apple.mount-point
public.audio
public.mpeg-4-audio
com.apple.protected-mpeg-4-audio
com.adobe.pdf
com.apple.localized-pdf-bundle
public.presentation
com.microsoft.powerpoint.ppt
com.apple.keynote.key
com.apple.iwork.keynote.key
public.image
com.apple.motion.project
com.apple.iwork.pages.pages
com.apple.iwork.pages.sffpages
com.apple.iwork.pages.template
com.apple.iwork.pages.sfftemplate
public.rtf
com.apple.rtfd
com.apple.flat-rtfd
com.microsoft.word.doc
org.khronos.collada.digital-asset-exchange
public.plain-text
public.html
public.xhtml
public.shell-script
public.source-code
public.unix-executable
com.apple.xcode.project
com.apple.xcode.model
com.apple.xcode.archive
com.apple.xcode.docset
com.apple.xcode.projectdata
com.apple.xcode.dsym
com.apple.xcode.configsettings
com.apple.xcode.usersettings
com.apple.xcode.strings-text
com.apple.xcode.plugin
com.apple.xcode.mom
com.apple.property-list
dyn.ah62d4rv4ge81a7dk
dyn.ah62d4rv4ge80u5pbsa
com.apple.dashcode.xml
com.apple.dashcode.css
com.apple.dashcode.javascript
com.apple.dashcode.json
com.apple.dashcode.manifest
com.apple.interfacebuilder.document
com.apple.interfacebuilder.document.cocoa
com.apple.rez-source
com.apple.iphone.developerprofile
com.apple.iphone.mobileprovision
com.apple.coreanimation-bundle
com.apple.coreanimation-xml
com.sun.java-class
com.apple.scripting-definition
com.apple.dt.document.workspace
com.apple.dt.document.scheme
com.apple.dt.ide.plug-in
com.apple.dt.dvt.plug-in
com.apple.dt.document.snapshot
com.apple.dt.bundle.unit-test.objective-c
com.apple.instruments.tracetemplate
com.apple.quartzdebug.introspectiontrace
com.apple.applescript.text-object
com.apple.applescript.data-object
com.apple.applescript.url-object
com.apple.applescript.alias-object
com.apple.symbol-export
com.apple.mach-o-binary
com.apple.mach-o-object
com.apple.mach-o-executable
com.apple.x11-mach-o-executable
public.object-code
com.microsoft.windows-executable
com.microsoft.windows-dynamic-link-library
com.sun.java-archive
com.sun.web-application-archive
com.apple.xcode.plugindata
com.apple.dt.playground
com.apple.iwork.numbers.sffnumbers
com.apple.iwork.numbers.numbers
com.apple.iwork.numbers.template
com.microsoft.excel.xls
org.openxmlformats.spreadsheetml.sheet
public.spreadsheet
public.xml
com.apple.log
com.apple.crashreport
com.apple.spinreport
com.apple.panicreport
com.apple.shutdownstall
com.apple.hangreport
public.json
public.log
public.content
com.microsoft.excel.sheet.binary.macroenabled
org.openxmlformats.spreadsheetml.sheet.macroenabled
com.apple.protected-mpeg-4-audio-b
com.audible.aa-audiobook
com.audible.aax-audiobook
%s/%s
_kMDItemQueryPath = "stuff"
_kMDItemTimeMachinePath = "stuff" && _kTimeMachineOldestSnapshot<=0 && _kTimeMachineNewestSnapshot>=0))
%s%lld
_kMDItemTimeMachinePath = "stuff"
_kMDItemTimeMachinePath%lld
_copyFile
copyFile.c
wLen <= actual
copyFileFallback
journalAttr.
deferAttr.
v16@?0r^{si_playback_info=IIIIq(?={?=IdIIIqqQ}{?=IQ}{?=II}{?=q*iccc}{?=ii*I}{?=dQ}{?=i}{?=q})}8
CreateIndex
OpenIndex
OpenIndexShadow
UpdateItem
AddItemError
DeleteItem
DeleteItemError
AddJournalItem
UpdateJournalItem
DeleteJournalItem
CloseIndex
SyncIndex
SyncIndexError
ShadowIndex
ShadowIndexError
NewJournal
UnlinkJournal
NewDeferJournal
UnlinkDeferJournal
MergeLive
MergeScan
ShutDown
Dirty
%s pid: %d time: %s syncCount: %d scanCount: %d liveCount: %d serialNumber: %lld consumedSerialNumber: %lld recoverTimeStamp:%s (%ld)
%s pid: %d time: %s syncCount: %d scanCount: %d liveCount: %d serialNumber: %lld consumedSerialNumber: %lld
%s pid: %d time: %s syncCount: %d scanCount: %d liveCount: %d
%s time: %s
%s time: %s recoverTimeStamp:%s (%ld)
%s journal.%d
%s oid: 0x%llx %lld transaction: %d
%s oid: 0x%llx %lld
%s id: %d oid: 0x%llx %lld
NewLiveIndex position: %d base: %lld
%s position: %d count: %d
NewBundleGroup %d 0x%x %s
Playback start
Playback end
%s transaction: %d id: %s oid: 0x%llx serial: %lld
%s id: %s oid: 0x%llx serial: %lld
%s transaction: %d id: %s oid: 0x%llx serial: %lld read: %d
%s id: %s oid: 0x%llx serial: %lld read: %d
%s transaction: %d id: %s oid: 0x%llx serial: %lld read: %d flagged: %d
%s transaction: %d id: %s oid: 0x%llx serial: %lld read: %d flagged: %d color: <null>
%s transaction: %d id: %s oid: 0x%llx serial: %lld read: %d flagged: %d color: %d
si_activity_journal.c
offset+dataSize<1024
### invalid type %d at offset %ld
%lld
### unknown type %d at offset %ld
%F %T
yMdHms
%04d-%02d-%02d %02d:%02d:%02d
indexState
CIMetaInfoCreate
CIMetaInfoRead
ContentIndexCommon.c
metaInfo->shadowedGeneration <= metaInfo->cleanGeneration
i20@?0^{__ContentIndex=}8B16
remapping%ld
remapping%d
newId>0 && newId < count
_CIMetaInfoSync
CURRENT_PROJECT_VERSION
IOPrimaryInterface
IOPropertyMatch
IOService
IOMACAddress
%02x
CIRemapping
kIndexRemappingBarrier
kIndexRemappingIndex
qsort_oids.c
TermIdStore.c
getNum(ts->termIdCount)
getNum(ts->termIdSize) >= getNum(ts->termIdCount)
%s:%u: failed assertion '%s' %s tid:%d, ct:%d, fr:%llx
termID+count == ts->store._freeRegion / sizeof(disk_TermData)
ts->store._freeRegion == ((offset_t)getNum(ts->termIdCount)) * sizeof(disk_TermData)
readBuffer
termIdStoreShadow
TermTrie.c
trie->dataAllocator
%s:%u: failed assertion '%s' %s invalid length for %s
term_len
level->follows[i]==0
level->follows[pos]==0
l->data.termLen <= (1024+20)
[fl] 
[l] 
[f] 
(2) 
(0) 
[*] 
cur->data.termLen>=term_offset
tmpLevel.payload==((void*)0)
TermTrieKindList==((unsigned)((tmpLevel.follows[cur->data.termData[term_offset]]) & 3))
((void*)((tmpLevel.follows[e->data.termData[term_offset]]) & ((~(uintptr_t)0)-3)))!=0
term_len <= CI_UTF8CHARS_BUFFER_SIZE
__builtin_popcount(compactLevel->size)==1 && slot > 1 && slot <= 5
level->size>=level->count
depth<15
count<size
__builtin_popcount(entry_size)==1 && slot > 1 && slot <= 5
result!=0
result==0
kIndexOptionReadOnly
B16@?0i8i12
Suspend
Resume
SIOpenIndexAtPathWithCallbacks_block_invoke_3
index flush suspend queue
SIVirtualPSIDSupport.c
malloc_size(map)==0
SI_PersistentIDStore
depth<=513
_oidParentForOid
/Network/
CIPayloadData.c
PayloadIterator.c
!queue->split
changes->hole <= changes->count
changes->hole<=changes->count
i <= changes->hole
(((iter->ptr) & 0x3FFFFFFFFFFFFFFF))==next
((iter->ptr) & 0x3FFFFFFFFFFFFFFF)==next
%s:%u: failed assertion '%s' %s nxtLink: %lld. compact
iter->compact == false
%s:%u: failed assertion '%s' %s Unexpected value for nextLink: %lld. next=%lld barrier=%lld split=%lld
(OFFSET_GET_VALUE(nxtLink) <= barrier && next>barrier)|| (OFFSET_GET_VALUE(nxtLink)<iter->split)
(((iter->ptr) & 0x3FFFFFFFFFFFFFFF)) >= ((oldPtr) & 0x3FFFFFFFFFFFFFFF) || oldPtr==0x3FFFFFFFFFFFFFFF
range.length == 1
bits == ((void*)0)
range.location > 0
PQueue.h
!queue->split || queue->splitPoint>=offset_t_GET_VALUE(value)
MDUnicodeConverter
CIQuery.c
pos<(secondaryCount+nodeCount)
fields
v28@?0I8^{RelativePosting=I{?=II}}12^{RelativePosting=I{?=II}}20
field >= 1
asserted
__CIMatchQueryNodesLazy
v20@?0^v8i16
v16@?0^{tree_node={?=b63b1}{?=b63b1}{TermUpdate=(?={?={RelativePosting=I{?=II}}I}{?={UpdatePosting=I{?=IQ}}})S[0C]}}8
kSearchItemTypeInvalid!=item_type
v16@?0^{RelativePosting=I{?=II}}8
v16@?0q8
v24@?0q8^{lt_trie_node=*^^{lt_trie_node}CCC}16
TermTrie.h
str_len==resolve_len
%s:%u: failed assertion '%s' %s %d
termLen <= CI_UTF8CHARS_BUFFER_SIZE
loc 
v20@?0^{QueryNode=**Iii^{icu_search_context}^{icu_regex}^{levenstein_automaton}I}8I16
posting
%s.mds.%d.%d.compactPayloads1.idx
%s.mds.%d.%d.compactPayloads2.idx
CIPayloadCompact.c
*canceled || PayloadPulsesCount(&ctx.src) > PayloadPulsesCount(&ctx.dst)
PayloadPulsesCount(&ctx.src) == 1
CICompactPayloads
PayloadScannerPosition(&ctx.scanner) > p.offset && PayloadScannerPosition(&ctx.scanner) < p.offset+p.length
_PayloadScannerReadNextChar
PayloadPulsesWrite
PayloadPulsesReorder
list
list->items
PayloadScannerPosition(s) + runLength <= s->end
type >= 0 && type <= 2
i < 10
i < 5
storage.h
position && position < inMap->count
%s:%u: failed assertion '%s' %s offset:%lld, free_region:%lld
inOffset<inStorage->_freeRegion
%s:%u: failed assertion '%s' %s offset:%lld, size:%lld, free_region:%lld
!check_size||inOffset+inSize<=inStorage->_freeRegion
(offset_t)(intptr_t)result !=inOffset
%s:%u: failed assertion '%s' %s offset: %lld end: %lld
p1.hasLength==p2.hasLength
(pe1.docId == 0 || pe2.docId == 0) || pe1.docId > pe2.docId || (type1 != postingTypeNormal || type2 != postingTypeNormal)
pe1.docId == 0
pe2.docId == 0
PayloadScannerPosition(s) + remaining <= s->end
_type >= 0 && _type <= 2
PayloadScannerPosition(scanner) == position
termId < maxTermId
PayloadScannerPosition(s) + docInfoLength <= s->end
%s:%u: failed assertion '%s' %s %s
ldb.c
len > (off1-off)
copyDataForUniquedValue
%s:%u: failed assertion '%s' %s Expected offset %ld to fit in size %ld
fLen >= fOffset
last_id<dbfs[i].name_id
last_offset == pdbo_offset
field
%s:%u: failed assertion '%s' %s field:%d(%s), type:%d, flags:0x%x
field_id!=0
*offset <= buffer_size
%s:%u: failed assertion '%s' %s Overflow %ld + %ld
(size_t)dbo->used_bytes+(size_t)dbf->data_len < (size_t)UINT32_MAX
dbo->size == (old_size<<1)
%s:%u: failed assertion '%s' %s Buffer overflow %ld + %ld > %ld
(size_t)dbo->used_bytes+(size_t)dbf->data_len <= (size_t)dbo->size
inflateDBFData
sizeof(db_uint32_t) + (size_t)dbo->used_bytes <= (size_t)dbo->size
%s:%u: failed assertion '%s' %s Buffer overflow: %ld + %ld > %ld
*offset+len <= buffer_size
%s:%u: failed assertion '%s' %s dbo overflow: %ld + %ld > %ld
(size_t)len + (size_t)dbo->used_bytes <= (size_t)dbo->size
%s:%u: failed assertion '%s' %s Expected %ld + %ld <= %ld
sizeof(uint8_t) + (size_t)dbo->used_bytes <= (size_t)dbo->size
sizeof(uint16_t) + (size_t)dbo->used_bytes <= (size_t)dbo->size
sizeof(uint32_t) + (size_t)dbo->used_bytes <= (size_t)dbo->size
sizeof(uint64_t) + (size_t)dbo->used_bytes <= (size_t)dbo->size
%s:%u: failed assertion '%s' %s Expected len %ld to contain new data size %ld - %ld
(size_t)len >= (size_t)(fOffset-saveOffset)
(size_t)dbf->data_len + (size_t)dbo->used_bytes <= (size_t)dbo->size
%s:%u: failed assertion '%s' %s Expected offset %ld plus len %ld to fit in size %ld
*offset+dbf->data_len <= buffer_size
%s:%u: failed assertion '%s' %s Expected %ld <= %ld
%s:%u: failed assertion '%s' %s Expected len %ld plus used_bytes %ld to fit in dbo %ld
%s:%u: failed assertion '%s' %s Unexpected type %d
db2_open_query_with_expr
/Library/Caches/com.apple.xbs/Sources/SpotlightCore_Sim/Spotlight-2183.16/spotlight/core-db/serial-db2/sdb2_query.c
db2_read_query
sdb2_die
%s:%u: failed assertion '%s' %s %s:%d : %s : %s
sdb2.c
db2_page_uncompress_swap
lzfse
deflate
db2_create_datastore
/Library/Caches/com.apple.xbs/Sources/SpotlightCore_Sim/Spotlight-2183.16/spotlight/core-db/serial-db2/sdb2.c
Multiple threads entering in sdb!
store.db
%sStr-%d.map
Multiple threads in sdb! (leaving)
v16@?0^v8
i12@?0i8
db2_update_datastore_state
db2_check_datastore
db2_get_datastore
_kMDItemRelatedObjects
_kMDItemRelatedObjectsWithBundleID
_kMDItemActivityLaunchDates
_kMDItemRankingLaunchStrings
_kMDItemRankingLaunchDates
_kMDItemGroupId
_kMDItemShortcutLastUsedDate
kMDItemAttributeChangeDate
kMDItemLastUsedDate
kMDItemLastUsedDate_Ranking
kMDItemUsedDates
_kStoreMetadataVersion
kMDStore
db2_shrink_cache
db2_flush_datastore
db2_commit_sync_datastore
db2_shadow_datastore
db2_commit_shadow_datastore
db2_commit_shadow_complete_datastore
db2_release_datastore_no_sync
db2_dirty_datastore
db2_sync_datastore
db2_clear_docids
newSize<=oldSize
db2_apply
%s:%u: Unexpected code path %s 
db2_store_obj
db2_cas_obj
db2_update_obj_callback
db2_delete_obj_with_flags
obj iter read queue
dboi->version==0xdb2
dboi->isSuspended
db2_perform_callback
db2_get_obj_callback
db2_add_field_with_cache
field_flags & DB_FIELD_ARRAY_VAL
field:%d extras:%d expected:%d type:%d expected:%d  %s
(db_uint32_t)name_id!=((db_uint32_t)~0) && (db_uint32_t)name_id!=((db_uint32_t)-2)
dbf->flags & DB_FIELD_ARRAY_VAL
B24@?0r*8r*16
_data_map_needs_sync(dst->_string_table[i]) == 0
dst->string_table[i]->dirty_page == 0
(dst->dbm->flags& 0x0001) == 0
db2_set_dirty_chunks
kMDItemLanguages
kMDItemKind
i20@?0^{data_map_s=}8i16
db2_garbage_collect_strings
db2_deserialize_cache_block_invoke
v24@?0^I8Q16
(write_size & ((1 << 12)-1)) == 0
(offset & ((1 << 12)-1)) == 0
update_db_header
copy_datastore
load_map
sdb_string_table_zone
page_free
(((off_t)(pgnum) << (dst->pg_shift)) & ((1 << 12)-1))==0
!updatedDirty
_add_dirty_chunk
%s:%u: failed assertion '%s' %s ERR: Can't add dirty chunks to a read-only db %s
%s:%u: failed assertion '%s' %s ERR: Chunk size is null
size
flush_updateset_locked_block_invoke
flush_updateset_locked_block_invoke_2
i32@?0q8r^{?=I[0C]}16B24i28
i20@?0q8I16
ldb.h
b0 < 0xE0
(dst->const_flags & 0x8) == 0
_flush_cache_entry
db_compress_cache
(size_t)dbp->used_bytes <= sz
db_split_page
in_cached==entry->cache_dbps
(size_t)(*dbpp)->size <= malloc_size(*dbpp)
map_check_size
db_shove_page
do_string_update || (flags & 0x000000f0)==0
page_release_dirty_compressed
map_write
page_release
sync_dirty_chunks
num_chunks == dst->num_chunks
_dirty_datastore_locked
_page_alloc_fetch
load_string_table
prev_dnt->_next_ptr==0
num_string_pages == 0
string_id == str_index
_get_string_and_length_for_id
!(flags& 0x80000000)
string_table->dirty_page == 0 ||string_table->dirty_page==dnt
this_ret!=17
string_table->dirty_pgnum==cur_pgnum || (int)string_table->dirty_pgnum==-1
string_table->dirty_page==cur_dnt || string_table->dirty_page==0
grow_string_table
db2_create_obj_postamble
db2_store_obj_preamble
db2_store_obj_inner
cas_obj
_insert_obj
_page_update_obj
%s:%u: failed assertion '%s' %s dbo ends past end of page ([%p, %p] > [%p, %p])
dbo<=end
page_split
dbo<end || prev_dbo<end
copy_end < end
map_update
%s:%u: failed assertion '%s' %s %s : ERR: map_update: page offset doesn't match! 0x%x != 0x%x
dbme->pgnum == pgnum
_real_page_insert_obj
_page_delete_obj_by_oid_and_type
prev
%s:%u: failed assertion '%s' %s Unexpected
dbp->used_bytes != sizeof(db_page)
_page_obj_exists_by_oid_and_type
(ssize_t)subiters[base+i]->count>=0
iter==&dboi->subiterator
iter->dbp->signature == 0x64627032 || (iter->dbp->signature==0 && iter->dbp->size==0)
^v32@?0^v8Q16Q24
v16@?0Q8
subiter_fetch_page
%s:%u: failed assertion '%s' %s obj_iter_fetch_page: ERR: tried to read attr name table data! pgnum 0x%x, flags 0x%x
(dbp->flags & DB_PAGE_STRING_DATA)==0
((*dbpp)->flags & DB_PAGE_STRING_DATA)==0
_page_fetch_with_fd
iter->next_dbp == 0
%s:%u: failed assertion '%s' %s obj_iter_fetch_page: ERR: page came back compressed! pgnum 0x%x
(dbp->flags & DB_PAGE_COMPRESSED)==0
subiter_fetch_next_page_block_invoke
subiter_fetch_next_page_block_invoke_2
page_find_oid_with_flags
dbo->used_bytes >= sizeof(external_db_obj)
core-query.c
up_count>2
up_count==0
count==0
^v16@?0^{query_node=^{query_node}^{query_node}^{query_piece}^v^vSIb8b1b1b1Q}8
^v32@?0^{query_node=^{query_node}^{query_node}^{query_piece}^v^vSIb8b1b1b1Q}8^v16^v24
db_compare_val
<NULL>
$time.iso(%s)
*16@?0*8
bad op
node:%p hash:%llx type:%d lc:%p rc:%p
<null>
node:%p hash:%llx type:%d qp:%p op:%d fn:%s s:%@ lc:%p rc:%p
kMDItemTextContent
_kMDItemOCRContent
<<anon store>>
stack_depth < 2048
parent_item->state == CompareStackItemStateComplete
SYS:mod
q && q->type == 0x04 && q->qp && q->qp->string_buffer
%s%s%s
v32@?0Q8Q16r*24
true
InRange
FieldMatch
created.
date
kMDItemUserCreatedUserHandle
user
kMDItemUserCreatedDate
downloaded.
kMDItemUserDownloadedUserHandle
kMDItemUserDownloadedDate
modified.
kMDItemUserModifiedDate
kMDItemUserModifiedUserHandle
printed.
kMDItemUserPrintedDate
kMDItemUserPrintedUserHandle
received.
kMDItemUserSharedReceivedDate
sender
kMDItemUserSharedReceivedSender
receivers
kMDItemUserSharedReceivedRecipient
transport
kMDItemUserSharedReceivedTransport
senderHandle
kMDItemUserSharedReceivedSenderHandle
receiverHandles
kMDItemUserSharedReceivedRecipientHandle
sent.
kMDItemUserSharedSentDate
kMDItemUserSharedSentSender
recipients
kMDItemUserSharedSentRecipient
kMDItemUserSharedSentTransport
kMDItemUserSharedSentSenderHandle
recipientHandles
kMDItemUserSharedSentRecipientHandle
v12@?0I8
(%d) 
ALWAYS FALSE node
@0x%p
ALWAYS TRUE node
@0x%p
OR node     @ 0x%p
AND node    @ 0x%p
NOR node     @ 0x%p
NAND node    @ 0x%p
factor node @ 0x%p flags 0x%x value <%s%s(%s,%s,%s)>
INRANGE
OUTRANGE
factor node @ 0x%p flags 0x%x value <%s%s(%s
FIELD_MATCH
OUT_FIELD_MATCH
factor node @ 0x%p flags 0x%x value <%s%s[] %s %s>
factor node @ 0x%p flags 0x%x value <%s%s[%s%d] %s %s>
factor node @ 0x%p flags 0x%x value <%s%s %s %s>
we got garbage for node @ 0x%p (type %d qp 0x%p)
sdb2_qsort.cpp
q>=left
flushsize
right < count
sdb_uniquing_zone
db-common.c
data == name - ht->extra_bytes - sizeof(db_uint32_t)
slot<table->size
bucket.used
probe!=start
slot < table->size
com.apple.spotlightindex.purgablectrl
page-cache.c
dbp->used_bytes<=dbp->size
page_cache_fetch
i16@?0^{db_cache_entry_s=I^{db_page}^{db_page}iqIq}8
%s:%u: failed assertion '%s' %s Pgnum: %u dbp:%p cached_pgnum::%u cached_dbp:%p index:%d size:%d
cache->cache_pgnum[i]==pgnum || (cache->cache_pgnum[i]==0 && (flags & PAGE_DIRTY)==0)
cache->cache_pgnum[i] == pgnum
cache->cache_pgnum[i] != pgnum
pgnum != cache->cache_pgnum[i]
dbp != cache->cache_entries[i].cache_dbps
dbp->flags & 0x0000000C
entry.cache_dirty==0
entry.cache_dbps == dbp
page_cache_deserialize_entries
v12@?0B8
com.apple.metadata.framework.sdb_page_cache
%s:%u: failed assertion '%s' %s Bad cache page at index %d; max %d, start %d
cache->cache_entries[i].cache_dbps->flags & DB_PAGE_COMPRESSION_ENABLED
v28@?0I8S12^q16I24
v20@?0^{search_ctx_s=^{SISearchCtx}d*^vB@?}8C16
query
executeSearchContextCracked
i24@?0r^v8r^v16
kMDQueryResult
SpotlightRelevance
GroupId
MatchedExtraQueriesField
MenuRelevance
NewMatchedExtraQueriesField
ContentRelevance
TextContentDistances
HasTextContentMatch
v20@?0q8B16
SISearchCtx.cpp
kr==0
en-US
v24@?0^{?=QQQQQdd{ci_rankingbits_s=TTTIfI}^{__CFString}iiii[3I]dddfiCBBBB}8^B16
executeSearchCtx_Start
executeSearchContextCracked_2 (overflow)
executeSearchContextCracked_2
lowWaterRoutine
resumeQuery
self->_stoken[i]==0
SISearchCtx.h
ffillPtr[slot] == 0
kMDItemFSInvisible
ffillPtr[0] == 0
accurate_realpath
MDFileUtil.c
rc == 0
/.vol/%llu/%llu
state_find_max_i
generic_state.c
s != 0
v8@?0
_data_map_rdlock
_data_map_unlock
.header
data_map_init
%s.map
%s.header
%s.data
tmp.%s.data.1
tmp.%s.data.2
%s.offsets
%s.buckets
_data_map_needs_sync
sync
update
_data_map_sync_data
_data_map_sync_header
data_map_flush
data_map_destroy
data_map_id_get_with_key_noextra
data_map_id_get_with_key
data_map_get_extra_with_key
data_map_get_data_locked
data ro header
data header
data storage
data offsets
data buckets
i20@?0^{data_map_s={db_rwlock_s={_opaque_pthread_mutex_t=q[56c]}[6{db_rwlock_waiter_list_s=^{db_rwlock_waiter_s}^{db_rwlock_waiter_s}}]^{db_rwlock_waiter_s}^{db_rwlock_waiter_s}^{pthread_override_s}^{_opaque_pthread_t}iiiiB}I^{header_map_read_only}I^{fd_obj}I^{header_map}^{fd_obj}II*I^{fd_obj}II^{offset_entry_t}I^{fd_obj}II^{bucket_entry_t}IIIII{os_unfair_lock_s=I}^{bit_vector}BBBBBBi}8i16
%s:%u: failed assertion '%s' %s 
_data_map_rehash
_data_map_get_bucket_entry
_data_map_commit
commit
syncless commit
data_map_ids_get_locked_with_hash
_data_map_get_offset_entry
_data_map_get_data_entry
disk_utils.h
(b4 & 0x80) == 0
bit_vector.h
bitIndex >= 0
newCapacity > bv->capacity
newBV
_data_map_get_data_id
_data_map_wrlock
bv->_cfbv
%s %s
tmp.%s
_data_map_garbage_compact_collect
/var/tmp
/usr/tmp
/tmp
abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789
%s/sqlite_
/dev/urandom
%s:%d: sqlite3BtreeOpen failed; dbname:%s; rc = %d
sqlite3BtreeCursor failed; rc = %d
sqlite3BtreeMoveto failed; rc = %d
psid: could not find master fid; rc = %d
psid: %s : danger! master fid %d looks bad! resetting
psid: creating db: %s
(%d), page size %d
Couldn't begin transaction; rc = %d
Couldn't create table; rc = %d
%s:%d: psid: %s : danger! ps store table id %d looks bad! resetting
Couldn't create cursor; rc = %d
Couldn't insert key; rc = %d
Couldn't commit btree; rc = %d
%s:%d: release_psid_store: danger! master_fid %d looks bad.
%s:%d: psid-release: Failed to update the master fid! (0x%x)
sync_psid_store: danger! master_fid %d looks bad. not syncing.
%s:%d: psid-sync: Failed to update the master fid! (0x%x)
Couldn't sync btree; rc = %d
Couldn't commit; rc = %d
get_path_for_id: bogus part len %d (%d/%d/%s)
get_path_for_id: bogus looking part fid (cur fid %d, part fid %d name %s)
get_path_for_id: path index too large! (%d %d : %s)
get_path_for_id: cur fid %d should have parent fid 2 but part->fid == %d
%s:%d: psid-rename: begin error %d updating the file-fid record for fid %d pid %d / %s. 
%s:%d: psid-rename: Could not update the file-fid record for fid %d
%s:%d: psid-rename: failed to insert new record for %d / %s.
%s:%d: psid-rename: failed to delete old record for %d / %s
%s:%d: psid-rename: end error %d updating the file-fid record for fid %d pid %d / %s. 
_sqlite_get: buffer is too small
%s:%d: sqlite3BtreeInsert failed; rc = %d
sqlite3BtreeInsert failed in _sqlite_bulkEnd; rc = %d
sqlite3BtreeDelete failed; rc = %d
%s:%d: sqlite3BtreeCommit failed; rc = %d
psid_insert: master fid corrupted (%d)
%s:%d: psid-insert: failed to store fid 0x%x for path %s
psid-insert: fid 0x%x for path %s
%s:%d: psid-insert: failed to store path %s for fid 0x%x
psid-insert: store path %s for fid 0x%x
%s:%d: psid-remove: Could not delete the file-fid record for fid %d
fsgetpath like %d/%llx
found %s for %llx
Got error
found %x for %s
found %lld for %llx
======^^^^^ si_psid_check_sandbox sandbox (NOT IMPLEMENTED!) count:%ld
%s:%d: Invalid type:%d for schema field:"%s"
%s:%d: Error:%d setting field:%s for oid:%lld
Trying to store %@ = %@
No attribute %s for %llx
No dbo for %llx
We do have a primary query
We do have %d secondary queries
True live query: (%lld) %@
update dbo:%lld %p
no match dbo:%lld %p
slow path dbo:%lld %p
live query:%p time:%f query:%@
*warn* Failed getting store cookie
Starting sync!
%p state: %s
clean -- skip sync
(%d)Unlinked journal %s
synced SIRef:%p recoverTime:%llu
Recovery Complete!
Finished sync!
Failed to get cpumon_params
*warn* Failed to set cpumon_params
*warn* Failed to reset cpumon_params
Attempt to merge (%s/%s/%s/%s)
Failed to transfer live indexes
Merging (%s/%s/%s/%s/%d)
Skipped merge (%s/%s/%s/%s/%d/%d)%s
Advanced transaction id
Deleting empty object failed with error %d
%s:%d: Error %d storing dbo(%llx,%x,%x,%llx,%llx,%llx,%x)
%s:%d: Error %d updating dbo(%llx,%x,%x,%llx,%llx,%llx,%x)
%s:%d: Unexpected transaction id %d != %d
Creating New Index
Opened %s successfully
Try %s/%s
%s:%d: Could not create new content index
Creating store at %s/%s.
%s:%d: Could not create store at path '%s/%s'
%s:%d: Could not create reverse dir store at path '%s'
Failed at %d (%d)
SICloseIndex, terminating:%d
*warn* Index already unavailable, error:%d, reason:"%s", options:0x%lx
*warn* Marking the index as unavailable, error:%d, reason:"%s", options:0x%lx, path:%s
%s:%d: recycle %s
%s:%d: Failed to add field "%s", length:%ld, rc:%d
%s:%d: Failed to store the dbo for field "%s", rc:%d
Recovery issued for %s
Starting forced sync!
Finished forced sync!
Do attribute transfer.
SITransferAttributes from %lld to %lld
Leave.
time stamp%s
Do attribute change.
Enqueue attribute change %llx.
PUSH REPAIR oid: %lld, f:%x
Defer work for %@
Enqueue work for %@
Callback for %@
%s:%d: bad object %@
#index too much enqueued (%ld); defer callback for work unit of %ld
Execute query %@
Starting query %@
QueryId=%{signpost.description:attribute}lld CurrentQoS=%{signpost.description:attribute}x JobType=%{signpost.description:attribute}d
Stalled getAttr because task had pending sets
_SIStartPreheatScheduler for %p
Started initial indexing of %s
Finished initial indexing of %s
*warn* %s called on fs-only or null index %p
%s:%d: No live index
Not supported for read only index
SISetScanCount:%ld full:%s
full scan:%ld
SISetScanCount: Counted %d live indexes
_SIIssueSplit called
%s:%d: %@
Fixed up (formerly) childless item %lld, new parent %lld
Skipped fix up; item %lld, new parent %lld %s
Do directory move.
%s:%d: %p read index state error:%d
%s:%d: %p invalid version:%d
%p read state:%s
%p open index state error:%d
%s:%d: %p open index state error:%d
%s:%d: %p write index state error:%d
%p write state:%s
*warn* invalid corrections commit
*warn* no correction dict passed
*warn* exceeded max for %@
*warn* correctDict exceeded max for %@
*warn* Failed updating index state
%s:%d: Caught mach exception
%s:%d: db_flush_datastore err:%d
%s:%d: flushReverseStore err:%d
%s:%d: store dirStore overlay err:%d
%s:%d: db_store_dirty_chunk_info err:%d
%s:%d: reverseStoreStoreDirtyBitmap err:%d
%s:%d: si_set_index_state err:%d
%s:%d: db_commit_sync_datastore err:%d
%s:%d: commitSyncReverseStore err:%d
%s:%d: db_shadow_datastore err:%d
%s:%d: shadowReverseStore err:%d
%s:%d: db_commit_shadow_datastore err:%d
%s:%d: commitShadowReverseStore err:%d
*warn* Failed storing sizes (%d)
Outer Merge - count:%d live:%s %s
%s:%d: error (%d) getting free space
*warn* Merge canceled - low disk space (%lld %lld %lld)
used:%lld, free:%lld
cindex was added during merge, old start %d new start: %d cindex count:%d
%s:%d: Merging failed
%s:%d: Failed to merge; index at %d is writable
%s:%d: Failed to merge; index at %d is current
Inner Merge - count:%d live:%s %s
%s:%d: open remp failed: %s
Finalizing journal %p %p %lx %s
remapping canceled
Updating item for remap failed with error %d
%s:%d: invalid range - size:%d start:%d count:%d
size:%d start:%d count:%d
mergeCount:%d != count:%d
Not tracing com.apple.spotlight.mds.index-darkwake %s %d %s %s %ld
%p Open fd %s
last_crash_delta: %ld for %s
%s:%d: check_crash_state: %d for %s
%p si state: %s
%p _SIOpenIndexFilesWithState: %d
%s:%d: open meta info error %d
db_check_datastore: %d
file didn't exist, try shadow
reverse store state: %x
*warn* datastore dirty, reverse store needs shadow -- forcing repair (%u, %u, %u)
*warn* datastore needs shadow, reverse store dirty -- forcing repair
*warn* Index version %d out of date, expected %d, recovering
*warn* Index version %d out of date, expected %d, reindexing
ContentIndexOpenBulk: %d opened %p with recovery time %llu
Could not open existing content index
*warn* datastore clean, index dirty, recovering...
%s:%d: %p CIMetaInfoRead err:%d
%s:%d: %p Too many live indexes %d/%d
%s:%d: %p db_update_datastore_state err:%d
%s:%d: %p ContentIndexOpenBulk err:%d
opened SIRef:%p from fast flush with recovery time %llu
%p open from fast flush canceled:%d
*warn* %p open from fast flush failed:%d
Update reverse store with state: %d (%d, %d)
%s:%d: Ignoring missing path store
%s:%d: reverseStoreUpdateState err:%d
Got reverse store with state: %d
%s:%d: si_write_index_state err:%d
%s:%d: openReverseStore err:%d
%s:%d: %p ContentIndexUpdateState err:%d
%s:%d: %p si_write_index_state err:%d
opened index %p with recovery time is %llu)
*warn* clean scan count mis-match expected:%d got %d
*warn* shadow scan count mis-match expected:%d got %d
*warn* clean live count mis-match expected:%d got %d
*warn* shadow live count mis-match expected:%d got %d
%p repair - catchup scan time stamp: %s, base: %ld, repair count: %d, remair max: %ld
Error writing to log file: %d
renaming: %s to %s
%s:%d: move error:%d, %s to %s
unlink (%s)
Disable updates for index in transaction %d
deleting %s
%p _SIOpenIndex: %d %s
Gathering size data for repair
Skipping because index is shut down
Gathering size data for repair (%lld, %lld)
%s:%d: Failed to protect fd with %d %d
flushing idle index at %s.
%s:%d: ContentIndexSyncIndexBulk err:%d
%s:%d: rebuild index for tokenizer (%d) %@
setting low latency: %s
Suspending root scheduler for %p (%s)
Created volume scheduler %p
Created index scheduler %p
restored localized terms
new loc term %d
Size %d: %lld
%s:%d: Failed to get kMDStoreAccumulatedSizes
Count %d: %d
%s:%d: Failed to get kMDStoreAccumulatedCounts
%s:%d: Failed to get metadata dbo
Found %s, size:%lld, syncCount:%d, first:%d, last:%d
Moving %s to %s, syncCount:%d, first:%d, last:%d
No journals to replay for %p, syncCount:%d, first:%d, last:%d, journalSerialNumber:%lld, consumedJournalSerialNumber:%lld
Replaying %d journals for %p, syncCount:%d, first:%d, last:%d, journalSerialNumber:%lld, consumedJournalSerialNumber:%lld
No defer journals to replay for %p, deferSyncCount:%d, first:%d, last:%d, journalSerialNumber:%lld, consumedJournalSerialNumber:%lld
Replaying %d defer journals for %p, syncCount:%d, first:%d, last:%d, journalSerialNumber:%lld, consumedJournalSerialNumber:%lld
Missing %s, syncCount:%d, first:%d, last:%d
Replaying %s, syncCount:%d, first:%d, last:%d
Unlinking dropped file %s
journalSerialNumber:%lld, consumedJournalSerialNumber:%lld
Played back %ld records (skipped %ld), read %lld/%lld bytes
%s:%d: Invalid journal entry - nil bundleID, magic:0x%08lx, size:%ld, pos:%ld, end:%ld
%s:%d: Invalid journal entry, magic:0x%08lx, size:%ld, pos:%ld, end:%ld
%s:%d: Invalid journal entry, magic:0x%08lx, size:%ld, pos:%ld, end:%ld, len:%ld(%ld)
Played back %ld records (skipped %ld), read %lld/%lld bytes, consumedJournalSerialNumber:%lld, minReplaySerialNumber:%lld, maxReplaySerialNumber:%lld
Activated journal %p %p %lx %s
Interrupting indexing; process quitting
*warn* Playback skipping sn: %lld mrsn: %lld csn: %lld
Playback finished.
%s:%d: Invalid journal entry, diskRecord:%p, journalEntryOffset:%lld, journalEntrySize:%ld
%s:%d: Invalid journal entry, magic:0x%08lx, journalEntryOffset:%lld, journalEntrySize:%ld
%s:%d: Invalid journal entry, size:%ld, journalEntryOffset:%lld, journalEntrySize:%ld
%s:%d: Invalid journal entry, size:%ld, extraSize:%ld, journalEntryOffset:%lld, journalEntrySize:%ld
%s:%d: Invalid journal entry, checkSum:0x%08lx, storedCheckSum:0x%08lx, journalEntryOffset:%lld, journalEntrySize:%ld
%s:%d: Invalid journal entry, bundleID:%p, journalEntryOffset:%lld, journalEntrySize:%ld
Index delete bundleID:%@, identifier:%@
Get_base for journal %s
si_delete_attributes_inner oid: %lld
%s:%d: Deleting item failed with error %d
couldn't get dbo for oid: %lld
Zombifying oid %lld
Deleting related item for %s (%s , %s)
Found related item for %s (%s , %s), oid: %lld
Failed to find related item for %s (%s , %s)
%s:%d: bad identifier %@
Deleting item, bundleID:%@ identifier:%@
Index Add bundleID:%@ identifier:%@
Index update bundleID:%@ identifier:%@
isDummy :%@ %@
*warn* update requires existing item :%@ %@
date:%x
found parent oid: %lld (%@) for %@
%s:%d: Failed to update the index for bundleId:%@, serial:%lld, options:0x%x, oid:0x%lld(%lld), updateErr:%d
%s:%d: No write back for bundleId:%@, identifier:%@ serial:%lld, options:0x%x, oid:0x%lld(%lld)
incoming or outgoing counts size mismatch: identifier=%s incomingArraySize=%lld outgoingArraySize=%lld incomingMailArraySize=%lld outgoingMailArraySize=%lld incomingSMSArraySize=%lld outgoingSMSArraySize=%lld incomingCalendarArraySize=%lld outgoingCalendarArraySize=%lld incomingFileProviderArraySize=%lld outgoingFileProviderArraySize=%lld
~~~ sSIMeEmailAddresses: %@, authorPersons: %@
~~~ authorIsMe, recipients: %@
~~~ !authorIsMe, authorContacts: %@
Schedule index flush
Flush not required
*warn* Failed to fetch the dbo for identifier:%@, bundleID:%@, rc:%d
*warn* Failed to find the db field "%s" for identifier:%@, bundleID:%@, rc:%d
*warn* Failed to fetch the dbo for relatedIdentifier:%@, bundleID:%@, rc:%d
Found the dbo for relatedIdentifier: %@, bundleID: %@, identifier: %@, oid: %lld
Failed to fetch the dbo for relatedIdentifier:%@, bundleID:%@, rc:%d (dropping %@)
Remapped related identifier for %@ to relatedIdent %@, bundleID:%@
*warn* Failed to fetch the dbo for relatedIdentifier:%@, bundleID:%@, identifier:%@, rc:%d
Updated "%s" field for relatedIdentifier:%@, bundleID:%@, identifier:%@
*warn* Skipping %@ %@ already had %@
*warn* ====^ Found _kMDItemRequiresImport!
Skipping :EA:%@ %@
New last used date: %@
Skipping :MD:%@ %@ already had %@
%s%@ = %@
Skipping :MD:%@ %@
Deactivating journal %p %p %lx %s
*warn* Failed setting store cookie (%d)
awakenPreheat entered for %p
awakenPreheat continued for %p
awakenPreheat skipped for %p
Shutdown started
Shutdown ended after %f seconds
Index shut down starting for index at %s.
%s:%d: setDir 2 error %d (%s)
Index closed for %s after %f seconds.
Index shut down finished for index at %s after %f seconds.
Shedulers stopped for %s after %f seconds.
shut down starting for spindle:%d count:%d
shutdown setup complete for spindle:%d after %f seconds.
shutdown sync complete for spindle:%d after %f seconds.
shutdown sync-fsync for spindle:%d after %f seconds.
shutdown commit data complete for spindle:%d after %f seconds.
shutdown commit-fsync for spindle:%d after %f seconds.
shutdown commit header complete for spindle:%d after %f seconds.
shut down complete for spindle:%d after %f seconds.
Index shut down starting for index at %d %s.
%s:%d: setDir 1 error %d (%s)
fstat(%d) err: %d
%s:%d: low space for device %d (%s)
%s:%d: Couldn't get index property dictionary
Creating index property dictionary
*warn* Skipping consistency check for %s
*warn* Starting internal consistency check for %s
*warn* Finished internal consistency check for %s. Checks: %d Missing:%d Inconsistent:%d Missing deletes:%d
Index/sdb inconsistency for (sdb)oid %lld; index has oid %lld. doc id: %lld. path: %s
delete attributes consistancy oid: %lld
delete attributes consistancy 2 oid: %lld
Index/sdb inconsistency; wrong doc id for oid %lld; has %lld. path:%s
delete attributes consistancy 3 oid: %lld
*warn* Skipping duplicate oid check for %s
*warn* Starting duplicate oid check for %s
*warn* Finished duplicate oid check for %s. Missing deletes:%d
oid: %lld > max_oid: %lld
Delete (bulk) oid: %lld
#index too much enqueued (%lld/%lld), bundleID:%@ - deferring callback
%s:%d: missing bundle %p 0x%x %@
Search waited %f seconds on the scheduler at qos 0x%x
finishRegisterQuery %@
Search was active (setup) for %f seconds on the scheduler at qos 0x%x
%s:%d: Could not create new live index %@
%s:%d: Prepare for transaction %d
*warn* %s called on fs-only index
%s:%d: Couldn't create live store at %s.
si_set_scancount: Counted %d live indexes
Starting cleanup for transactions below %d
defer vacuum
Vacuum scheduled
Vacuum started
Vacuum needed%s
Merge(2) scheduled
Merge(2) started
full vacuum needed - count: %lld, live count: %lld, delete count: %lld, live delete count: %lld
%s:%d: transfer_live_indexes failed
verifying %s
%s:%d: verify index: %s, err: %d, (%d %d) , (%d, %d)
Set attributes waited for %f seconds
Dummy coming in oid: %lld
deleting oid: %lld
%s:%d: ctx->source: %d != source: %d oid: %lld options: %x
DEQUEUE oid: %lld, o: %x t: %d
Duplicate in flight oid: %lld
*warn* Unexpected transaction id %d. Expected %d. Attempting repair
*warn* Transaction id is now %d
*warn* Items's transaction id %d is too low for the current index %d. Discarding oid %llx.
isDummy oid: %lld
oid is zero: %lld
Couldn't get the group id.
Dictionary claims the importer was the origin, but trail tells us it was not. Treating as normal setAttr call.
%@ = %@
Deleting importer fields failed, rc:%d
db didn't find any existing values
%s:%d: marking item as rendered/engaged failed
%s:%d: db get field failed in counts code
%s:%d: Couldn't update index oid: %lld options: %x updateErr: %d resolveErr: %d
No write back for %lld
Schedule index flush.
All recovery items processed
Dummy for oid %lld
Canceled oid: %lld
Begin setattr with %ld items on %ld threads
%s setattr
%s:%d: Failed to fetch the bundleId/identifier field, oid:0x%llx(%lld), rc1:%d, rc2:%d
%s:%d: Invalid type for bundleId/identifier field, oid:0x%llx(%lld), type1:%d, flags1:0x%x, type2:%d, flags2:0x%x
%s:%d: Missing identifier field, oid:0x%llx(%lld), type:%d, flags:0x%x
%s:%d: Missing bundleId field, oid:0x%llx(%lld), type:%d, flags:0x%x
%s:%d: Failed to update the dbo for oid:0x%llx(%lld), flags:0x%lx, rc:%d
*warn* Got a journal exception at address:%p, map:[%p, %p), name: %s.
*warn* map:[%p, %p), size: %llx
*warn* Stat failed for name: %s.
Set attributes waited for %f seconds%s
%s:%d: Invalid bundleID %ld %@
oid: %lld moved to parent oid: %lld (file)
%s:%d: move dropped %llx retry count exceeded
Move for bad oid: %lld
No parent for oid: %lld
oid: %lld moved to parent oid: %lld
parent %lld unchanged for %lld
%s:%d: Got parent %lld for %lld. Expected %lld (doc %llu)(%d)
%s:%d: Write error %d updating parent
%s:%d: (%p ver:%d main:%s sdb:%s path:%s scan:%d %s, live:%d %s)
(%p ver:%d main:%s sdb:%s path:%s scan:%d %s, live:%d %s)
%s:%d: store_stream_init err:%d
%s:%d: store_stream_flush write err:%d
%s:%d: store_stream_flush sync err:%d
Remove scheduler %s from %s
Workqueue qos: 0x%x relative_priority: %d %@ %@
%d != %d
Stopped %s
boosting %@
Freeing %p
Peek for %p to %p
Peek tags for %p on queue %s
Peek for  %p on queue %s with tagbag %p
Found oid bag for %p on queue %s
Empty oid bag for %p on queue %s
No oid bag for %p on queue %s with tags %p
Found tags for %p on queue %s
No tags for %p on queue %s
QOS work_fun: %d %p
qos: 0x%x %@
QOS enqueue_work: %d %p
Scheduler qos: 0x%x relative_priority: %d %@ %@
Push %p to tags %p
Created tag bag for %p
Enqueueing result: %d %d
Canceling result queue
*warn* Non-numeric in factor array at index %ld: %@
*warn* Bad value in factor array at index %ld: %@
completion weight array too large (%ld): %@
*warn* completion weight array incomplete (%ld): %@
*warn* Non-numeric in weight array at index %ld: %@
*warn* Bad value in weight array at index %ld: %@
extracting field id %d: '%s'
Completion v1 count:%llu
 weight_F:%g score_F:%g len_F:%g fragment_F:%g wf1_F:%g wf2_F:%g wf3_F:%g phrase_F:%g field_F:%g thread_F:%g shortcut_F:%g used_F:%g age_F:%g
len:%ld scoringFragmentCount:%ld fragmentCount:%ld age:%f score:(%llu, %llu) weight:%d computed score:(%g)
Pop: %ld %ld %f (%llu,%llu) %d (%g)
Comparing to parent at %ld (%g) %g
Dropping weak child %ld (%g) %g
Dropping weak parent (%g) %g
Creating suggestion string %@, type %d, with completion %s length:%d weight:%d score:%g
Completion v2 options: 0x%x count:%llu
Dropping similar completion of length %ld
Completion v3 options: 0x%x count:%llu
Creating unescaped string %s with from %s
Dropping dangling parent (%g) %g
Canceling query in SICancel at QoS: %d for job id:%p
QOS si_sdb_enqueue: %d priority: %d
No RootDirectory set for Suggestions
%s:%d: fstat err:%d %s
%s:%d: FAT: bad file size:%d (expected %d - %d) %s
%s:%d: fd_mmap err: %d, %ld
%s:%d: open %s err: %d
%s:%d: COMP: bad file size:%d (expected %d - %d) %s%s
%s:%d: fstat err:%d %s%s
%s:%d: FLAT: file size:%lld (expected %lld - %lld) %s%s
%s:%d: FLAT: bad file size:%lld (expected %lld - %lld) %s%s
%s:%d: Could not recover %s
syncTrie took %f seconds
Re-burst!
%s:%d: copyFile error, src: %s, dst: %s
shadowIndexCompactDirectory took %f seconds
%s:%d: write err: %d, %s
shadowIndexDirectory took %f seconds
Merge update set ... 
Done
Merge took %f seconds
Total merge time: %f seconds
%s:%d: fd_open err: %d
%s:%d: read err: %d
%s:%d: pread err: %d
%s:%d: pwrite err: %d
shadowIndexArrays took %f seconds
Merge %lu terms
Merge Canceled
Copied term data: %f seconds
Computed ranges: %f seconds
Flush yielded %d times.
Merged terms: %f seconds
%s:%d: compressPostings err:%d
Compressed postings data: %f seconds %f total
Mapped Bases: %luKB (%f%% used)
Sparse Bases: %luKB for %d entries (%f%% used)
String arrays: %lluKB %f%% used
resolve trie terms bc:%u : %f seconds
Index %lu starting at %lu ending at %lu
Applier %lu starting at %lu ending at %lu
node count: %d, compare count %d
resolve flat page terms: %f seconds
bucket[%ld] %x %d %s
%s:%d: can't resolve flat store page
String: %s
%s:%d: invalid flat store page (0x%llx)
### trie processing - %d ###
%s:%d: Setting index emergency state
%s:%d: Clearing index emergency state
%s:%d: Reaffirming index emergency state to true
No meta info
invalid meta info, cleanGeneration:%ld, shadowedGeneraton:%ld
no data in index - rebuilding, result:%d
%s:%d: Failed creating %s/%s, result:%d
%s invalid head (%d), will rebuild
%s invalid head (%d), will try to recover
preflight index %s base:%ld count:%d
Unclean shutdown of %s/%s; needs recovery
Open index - no recovery path
Could not open %s/%s; needs recovery
index %s base:%ld count:%d
Open index - recovery path
recovery not allowed for %s/%s
could not recover %s/%s
could not open %s/%s
recover needed, scan date: %s, last valid doc id:%ld, %s
deleting index %s/%s
limbo counts live:%ld scan:%ld recover:%ld internal:%d priority:%d setAttr:%d migrate:%d
Open index bulk: %d
*warn* time stamp should be more recent new:%ld, old:%ld
%s:%d: index invalid
%s:%d: pre-error:%d
%s:%d: indexPrepareForSyncBulk error:%d
%s:%d: preSync error:%d %d
%s:%d: indexPerformSyncBulk error:%d
%s:%d: postSync error:%d %d
%s:%d: indexCommitSyncBulk error:%d
%s:%d: pre-error %d
%s:%d: indexShadowAndCommitBulk error:%d
%s:%d: corrupt index (%s), will rebuild
_CIUpdateContent oid: %lld
delete docId: %d oid: %lld
reassign docId: %d
dup oid (%lld)
%s:%d: index invalid %s
%s:%d: indexPrepareForSync error: %d, %s
%s:%d: indexPerformSync error: %d, %s
%s:%d: indexCommitSync error %d %s
%s:%d: preShadow error:%d %d
%s:%d: postShadow error:%d %d
%s:%d: indexShadowFiles error: %d, %s
%s:%d: indexCommitShadow error: %d, %s
%s:%d: Sync context init error: %d
%s:%d: Sync sync error: %d
%s:%d: Sync commit error: %d
%s:%d: Got error %d passing sync counts to journals
%s:%d: Sync retire error: %d
%s:%d: Sync shadow error: %d
%s:%d: mmap err: %d
%s:%d: expandUnsafeMap errno: %d err: %d
%s:%d: invalid offset %d, %p (%d)
%s:%d: invalid offset %d, %p (%d) s:%d l1:%d l2:%d
%s:%d: error %d updating sync count
Force split for high delete count; %d %d
resolve term ids: %f seconds
creating index at %s
%s:%d: Couldn't statfs parent directory: %s
open index at %s
%s:%d: Failed to open path index
%s:%d: Ignoring failed dirstore open for corespotlight
last term offset: %llu
%s:%d: unexpected sync count %lld %lld %lld %lld, expected %lld
head:%lld fat:%lld compact:%lld flat:%lld dir:%lld
Post init at %lld
At start %lld
Post version at %lld
Pre-loop at %lld
%s:%d: index shadow err:%d at %s
%s:%d: index commit shadow err:%d at %s
Validating %s
%s:%d: %s invalid type %d
%s:%d: %s error walking terms
oid: %lld depth: %d offset: %llu 
%s:%d: %s error walking directoyr store
Validate %s complete %d
%s:%d: trying to modify read only index %s
%s:%d: indexMarkDirty failed - state:%x closing:%d
index updates disabled for %p (%d) from %d
skip index updates disable for %p (%d) from %d; flags 0x%x, disabled at %d
%s:%d: %s marking invalid at %d
%s:%d: can't commit %s
bases.size: %ld (%s)
%s:%d: write(%d) %d err: %d, %s
shadowIndexGroups took %f seconds
%s:%d: can't shadow %s
shadowIndexTermIds took %f seconds
%s:%d: write err: %d
%s:%d: error copying (%s)
recoverIndex: %s
%s:%d: Unrecoverable error: Missing postings file (%s)
*warn* Unrecoverable error: Missing shadow head file (%s) %d
*warn* Unrecoverable error: Missing data in index head file (%s) %d %d
%s:%d: Unrecoverable error: Malformed index head file (%s)
%s:%d: Unrecoverable error: could not open update file (%s)
%s:%d: Unrecoverable error: could not recover term id file (%s)
%s:%d: Unrecoverable error: could not recover term index (%s)
%s:%d: Unrecoverable error: could not recover path index (%s)
%s:%d: Unrecoverable error: could not recover groups file (%s)
%s:%d: Unrecoverable error: could not open shadow head file (%s) %d
%s:%d: Unrecoverable error: could not read shadow head file (%s) %d, %d
%s:%d: Unrecoverable error: could not open index head file (%s) %d
%s:%d: Unrecoverable error: could not write index head file (%s) %d
*warn* recover canceled (%s)
close requested
%s:%d: trying to set to invalid index %s/%s
setDocumentAttributes canceled
%s:%d: trying to add to read only index
%s:%d: TermUpdateSetCreate failed
%s:%d: indexMarkDirty failed
%s:%d: %s setDocumentAttributes error - bad oid/docid mapping oid: %lld, docId: %d, old oid: %lld 
%s:%d: Got error %d
%s:%d: trying to delete from invalid index %s/%s
%s:%d: trying to modify read only index %s/%s
%s:%d: deleteDocument error - docId (%lld) >= max (%d) 
*warn* deleteDocument error: mismatch oid: %ld docId: %ld idxOid: %ld
%s:%d: reassignDocument error - docId (%lld) >= max (%d) 
*warn* reassignDocument error: oid mismatch oldOid: %ld newOid: %ld docId: %ld idxOid: %ld
%s:%d: invalid index: %s
%s:%d: index alreay compact: %s
%s:%d: cant compact writable index: %s
computer new term ids time (%f)
%s:%d: Failed compacting postings
compact_trie time (%f)
index_compact time (%f) - %d
%s:%d: open file error: %d, %s
%s:%d: bad file size: %d, min size %d, %s
%s:%d: map error: %d, size: %lld, %s
%s:%d: ftruncate error: %d, size: %lld, %s
%s:%d: open err: %d, %s
%s:%d: stat err: %d
%s:%d: bad file size: %lldd, min size %lldd, %s
%s:%d: invalid term length: %d
%s:%d: invalid termID: %d, max: %d
%s:%d: invalid posting offset: %lld, max: %lld
Post counts at %lld
Post bv1 at %lld
Post bv3 at %lld
Post bv4 at %lld
should exit
should cancel
Got unexpected 0 payloadCount. Attempting repair.
should flush, tc:%d, limit:%d
Terms + Postings exceed limit, used:%ld, limit:%ld
should flush term info (global), used:%ld, max:%ld
should flush, all:%ld, used:%ld, limit:%ld, total limit:%ld
Flush for high delete count
Out of space growing payloads.
Mark index needs flush
%s:%d: Got exception on %s %s addr:%p start:%p map end:%p sres:%d file_size:%lld dev:%d ino:%lld
%s:%d: Got exception on %s %s addr:%p %s sres:%d file_size:%lld dev:%d ino:%lld
%s:%d: Invalid version (%d) expected (%d)
%s:%d: invalid file (%d, %d, %d)
%s:%d: fstatfs(%d) err:%d
%s:%d: not enought space to compact index - needed: %lld, avail: %lld, device: %lld
%s:%d: NULL payload fd obj
Payloads: %lluKB %f
%s:%d: ftruncate(%s, %lld) err: %d
%s:%d: open error; %ld
%s:%d: pwrite error; %ld
resolve term id offsets: %f
make hot: %f
write postings: %f
update term id offsets: %f
Memsize: %luKB %f%% used
%s:%d: ftruncate err: %d
%s watchdog for %s
%s:%d: Indexing watchdog fired, thread:%p delta:%llus, startTime:%.3f, itemCount:%lu, perItemCost:%lu resumeTime:%.3f endtime:%lld protectionClass:%u
Starting the indexing watchdog, timer:%p, delta:%llus, startTime:%.3f, itemCount:%lu, bundleID:%@
Stopping the indexing watchdog, timer:%p, delta:%llus, time:%.3f, itemCount:%lu, bundleId:%@
%s:%d: invalid storage data
%s:%d: storageInit - inFdPtr == NULL
Memsize: %uKB %f%% used
%s:%d: mmap(%d, %lld) err:%d, %s
sync pages (%d, %d) took %f seconds
%s:%d: ftruncate error %d
%s:%d: head:0x%llx, freeRegion: 0x%llx
mmap (%p) %llx-%llx
%s:%d: mmap(%p, offset: %llx, size: %ld) error:%d, fSize:%lld
mmap (%p) %llx-%llx (%llx-%llx)
%s:%d: offset(%lld) < freeRegion (%lld)
%s:%d: _storageExpand %s error:%d
%s:%d: ftruncate(%lld) error:%d
Store Update Set (t %d, d %d, p %d) took %f seconds
%s:%d: invalid store version %d, expected %d or %d
%s:%d: Failed restoring update set for paths
%s:%d: invalid termLen %d
%s:%d: invalid  postingCount %u > %u
%s:%d: storeStream error %d
%s:%d: lastPosting==0
%s:%d: invalid doc id %d exceeded (%d, %d)
Restore Update Set (t %d, d %d, p %d) took %f seconds
invalid type for %d %@
%s:%d: invalid content token (%d) for %s
createForwardStore:%s
recoverForwardStore:%s
openForwardStore:%s
%s:%d: Failed to open dir store
%s:%d: no path for shadow
Move %llx/%llx
%s:%d: Move would loop in reverse directory store, skipping %lld to %lld
completed flushReverseStore
skip flushReverseStore; %x
completed commitSyncReverseStore: %d
%s:%d: shadowReverseStore fail. metadata = %d
shadowReverseStore: %d
%s:%d: copyFile error, src: reverseDirectoryStore, dst: reverseDirectoryStore.shadow
Completed shadowReverseStore
%s:%d: Failed shadowReverseStore
Completed commitShadowReverseStore
Recovering reverse store on open
Shadowing reverse store on open
Successfully opened from reverse store
Failed open for reverse store
%s:%d: update state (%d) failed err:%d at %d
%s:%d: init storage failed %s
%s:%d: init storage failed %s; could not read header got %ld bytes
leafPageOffset: %llx
_directoryStoreGetParent failed. leafPageOffset: %llx
Set %llx/%llx
Tree page:%p level: %d depth: %d origin: %d size: %d
page:%p depth: %d idx: %d offset: 0x%8.8llx
Flat page:%p level: %d depth: %d origin: %d size: %d
*warn* Flat page: 0x%8.8llx depth: %d exected: %d
oid: %lld parent: %lld
recoverReverseStore
%s:%d: Copy file failed for %s
%s:%d: Failed to read reverse store file %s
%s:%d: Failed to write reverse store header %s
%s:%d: Unexpected state in shadow header %x
Successfully recovered from %s to %s with state %x
skip dbo:%lld %p
live query nodes: %@
Passing up deletion
Attempt to append to queue failed. Releasing result batch
*warn* failed to parse %s
Computed time (%lld) %s from %s
Passing up out of results
Index Should Merge id:%d %p %s
enqueue at qos 0x%x
at qos 0x%x
bitCount: %ld
QueryId=%{signpost.description:attribute}lld CurrentQoS=%{signpost.description:attribute}x
Preiterate
Pack match bits %llx
No permission for %llx
Query detected merge is needed
Result count: %lld
Encoded results in %f seconds!
%p found %ld results
Enter %s
Batch size: %ld. Timeout: %f. Waiting: %d
Refilled oids. More: %s
Not enough data yet. More to collect: %s
Count: %ld
Real Count: %ld
Available at %ld loops: %ld (%ld) keep going:%d
Canceled; leaving with: %ld
Available after %ld loops: %ld (%ld)
(Full)Available: %ld
(Full)Count: %ld
Timeout
keepGoing: %d
Couldn't gather.
Abandoning %ld %ld %d
(Loop end)Available: %ld
Extracted %ld oids in %f seconds! bad batch:%s batch full:%s timeout:%s keepgoing:%s iterator:%s check needed:%s
QueryRefillOids
Early exit %llx%016llx %d
Scope checked %ld dbos in %f seconds!
Permission for %ld items!
Read/evaluated %ld oids in %f seconds!
readSDBForOids %p item count: %ld
categoryCount:%ld
readSDBForOids early exit %p
Created iterator for %ld oids in %f seconds!
Iterator out of results after %ld items
duplicate oid 0x%llx
Query was canceled
Read/evaluated %ld dbos in %f seconds!
QueryReadSDB
readSDBForOids exit %p
Set match bits %llx
%s:%d: Assertion caught during query
Get doc set!
alloc %ld cinodes for %ld noded
Got NULL context from processNodes
Computed doc set in %f seconds!
Couldn't create raw sdb iterator
1 - count: %ld
2 - count: %ld
QueryGatherIndexInfo
Looping %ld
No data for uniqued string %u
%s:%d: Bad string id for %d
No data for uniqued array %u
Clipping at 1.0 for %llx
Clipping at 0.0 for %llx
No last opened date for %llx
No useful date for %llx
%d start, end:%d
Skip at %ld
Updates from %d to %d
1 Disk from %d to %d
Got (%d to %d) Squashed (%d to %d)
Range %d to %d
Finished iterator. Squashed (0 to %d) end:  %d
OID Range %d to %d
Found: %ld
%s:%d: Caught assertion
%s:%d: Caught assertion for iterator %p %s
%s %d %llx%016llx %d
adding oid %ld (%ld %ld)
%s:%d: Expected valid doc set type for %p. Got %d
%s:%d: Date too distant while restting sentinel
%s:%d: Failed reseting sentinel date
%s:%d: Beyond max entries in counts or tried adding out of order
%s:%d: Beyond max entries in counts or tried adding out of order in adding new
%s:%d: Incorrect data size in counts code
%s:%d: Failed updating render/engagement data
%s:%d: unexpected db signature %x
%s:%d: Error unliking store.updates: %d
%s:%d: Error opening store.updates: %d
%s:%d: Error storing dirty sdb pages: %d
%s:%d: err:%d num_chunks:%d > max_chunks:%d
*warn* Restore error: %d, recovering from shadow
%s:%d: fstatfs err:%d
crash data for %s in volume %s?!?
%s:%d: Detected recurring crashes 3 hour window
%s:%d: Detected recurring crashes during compacting
%s:%d: crash count: %d
%s:%d: invalid crash state file (%s) deleting
%s:%d: Retry operation on address %p (%p) %f %d
%s:%d: Repeated error on address %p
%s:%d: state)Got some sort of signal!
%s:%d: state identity)Got some sort of signal!
exception handler not resolved for thread 0x%x
Allocating threads and such.
Creating exception handler thread
Done allocating threads and such.
Adding handler slot:%u port:%d
%s:%d: thread_get_state: %s
%s:%d: thread_set_state: %s
Dropped handler slot:%u port:%d
starting exc_thread loop in task %d
*warn* Got exception on %s addr:%p start:%p map end:%p sres:%d file_size:%lld dev:%d ino:%lld
Merging started (%s) count:%d
%s:%d: open termIdFile error: %d
%s:%d: pwrite error: %d
%s:%d: ftruncate error: %d
%s:%d: Exception raised during merging
Merging %s (%s)
Had to take slow path, items out of order. Inserted at index %d of %d
Mismatched changed count for %lld, count %d
Creating CI mergeIndexDataTrampoline thread
%s:%d: Exception on new index merging
%s:%d: Caught exception  on merge postings %p
start %lld
%p offset %lld
%s:%d: Nextlink out of bounds %lld %lld
%s:%d: %lld %lld %lld
%s:%d: Element outside legal range %lld>=%lld type %d (starting max %lld)
merging lat id %d
Bad doc id %lld (adjusted:%d) encountered during checking (current = %lld)
Mismatched changed count %d for %lld
fd limit %d
%s:%d: fd_open failed, path:%s, name:%s, flags:0x%x, parent_fd:%d, errno:%d
fd_open failed, path:%s, name:%s, flags:0x%x, parent_fd:%d, errno:%d
%s:%d: Open failed on %s child of %d with error %d
%s:%d: lseek(%d %s, o:%lx, w:%d) err:%d
%s:%d: pread(%d %s, o:%lx, s:%d) err:%d
%s:%d: pwrite(%d %s, o:%lx, s:%d) err:%d
%s:%d: write(%d %s, s:%d) err:%d
%s:%d: rename(%s, %s) err:%d
%s:%d: fd_ptr instance was invalidated
open error NULL obj
%s:%d: faccurate_realpath() failed, parent_fd:%d, path:%s, flags:0x%lx, errno:%d
%s:%d: Invalid parent path, currentPath:%s, path:%s, flags:0x%lx
*warn* too many open files, err: %d, closing inactive and trying again
*warn* (%d) - %@
%s:%d: Read depth %d in serialized value set
%s:%d: Read duplicate child entry at %d(%d) in serialized value set
%s:%d: missing end marker
FindTermIDsContext %p empty bucket %x %s %s
FindTermIDsContext %p fuzzy sort %d flat pages: %f seconds
FindTermIDsContext %p, fuzzy bc: %d -> %d
sort %d flat pages: %f seconds
FindTermIDsContext %p invalidate fuzzy pages bc: %u fc: %u gc: %u mc:%u lc: %u s: %f took %f seconds
FUZZY MATCH BEGIN, string:"%s", pattern:"%s", word_match:%s, word_start:%s, threshold:%d
%s match!
no match!
string: %s 
prefix matched against pattern 
normally matched against pattern 
FUZZY MATCH END: %s
%s:%d: Unexpected index base id order, recycling
%s:%d: Overlapping doc ids (%lld>%lld) between indexes %d and %d out of %d. Recycling
new loc field(%d): %@
ctx:%p idx:%p
%s:%d: db_add_field(_kMDItemGroupId) failed, oid:0x%llx(%lld), rc:%d
%s:%d: computePath error: %d oid: %lld parent: %lld
limit:%llu, used:%lld - using live index
DocID<->OID mapping out of sync. Had to do a brute force search. (Expected docId:%lld. Actual docID: %lld. OID: %llu
DocID<->OID mapping out of sync. Orphaned oid. (DocId:%lld. OID: %llu
sdb only update docId: %lld oid: %llu
%s:%d: ContentIndexUpdateContent failed (%d)
%s:%d: ContentIndexUpdateContent failed  (%d)
Update date to %d for oid %llx docId %llx
bad data in dbo (%lld) reimporting flags:%d
%s:%d: si_writeBackDBO failed, oid:0x%llx(%lld), rc:%d
Skipped swapindex
Starting flush
Failed index flush
Completed index flush
Merge slow at %f
force split; index size %lld
force split used:%lld, count:%d, deletes: %ld
force split; disk free %lld less than index size %lld
Flush took %f seconds, split state %d
Finished flush
Skipped flush
Skipped flushing
Transfer from %lld to %lld
Origin exists for %lld to %lld
Target does not exists for %lld to %lld
Reassigning %lld to %lld
Target exists for %lld to %lld
Target needs reimport for %lld to %lld
Target good for %lld to %lld
Store failed during attribute transfer on safe-save (%d)
No origin dbo exists for %lld to %lld
No target dbo exists for %lld to %lld
Target dbo exists for %lld to %lld
New last used date was not in the previous array: %f != %f
Failed adding used date
Failed adding ranking used date
New last used date was not in the previous array: %f
Failed adding used dates
Failed adding use count
ctx:%p %s
repair%s oid: %lld orphan parent: %lld
repair oid: %lld parent oid: %lld skipped
repair oid: %lld skipped
%s:%d: error: %d oid: %lld parent: %lld
%s:%d: SIPersistentIDStoreGetOidPathForOid error:%d at:%d oid:%lld parent:%lld
%s:%d: si_directoryStoreEnsurePath error:%d at:%d oid:%lld parent:%lld
%s:%d: db_cas_obj error: %d oid: %lld
lookupPathByDBO enter oid: %lld  parent: %lld
lookupPathByDBO oid: %lld p1: %lld p2: %lld
lookupPathByDBO error: %d oid: %lld  parent: %lld
*warn* forceToOrphanParent oid: %lld dbo parent oid: %lld parent: %lld original: %d
%s:%d: SIPersistentIDStoreGetParentForOid error:%d at:%d oid:%lld parent:%lld
Skipped compacting
skipping CFNull
no type conversion for %@
Waited %f seconds on scheduler
Running query at priority %d
Current QOS %d
*warn* Invalid query paramater version %d
Adding filter %@ to query %@
%s:%d: Failed adding filter: %@
Passing up change to not match
Stalling query because the task has data in the set queue
check (%s) %@ old:%@ new:%@
siquery_addactivetime %g seconds to %g seconds 0x%x
Metadata or Content.
Range query.
Found *=* query
Invalid property name %s
No string for %s = %s
Factor.
Range query: %@ < %s < %@
Matched factor %s = %@ in %f seconds
*warn* Too few arguments for query: %d
%d: %s
This node is always false.
This node is always true.
And.
%s:%d: scopePath: %@ / %s %f
Unpalatable ranking query: %@
%p: Query completely done
live filter query nodes: %@
no tags
long defer query for %@
defer query for %@
do defer query for %@
don't defer query for %@
_queryGoCracked
Segmenting %s %s
Started normal (grouping) query threadlet.
Started normal query threadlet.
Could not execute query for %p (!)
Couldn't make query string
Sanitized to %@
initWithQuery %@ for fields:%@ and scopes:%@
*warn* queryFromCFString failed for %@
*warn* grouping queryFromCFString failed for %@
*warn* Error creating ranking query for %@
*warn* rulecount %ld bitCount: %ld error
*warn* lifting queryFromCFString failed for %@
*warn* dboFilter queryFromCFString failed for %@
*warn* no fields for CoalescingCollectingQuery
*warn* No primary query
Query is limited to one group; turn off server side grouping
*warn* no or false _completeQuery
Failed creating query
msync(%p) err %d
fsync time %f - %s
ftruncate(%d %s, %lld) error:%d
canceled
%s:%d: fstat error (%d)
%s:%d: error (%d) opening %s
%s:%d: ftruncate error (%d)
%s:%d: read error (%d)
%s:%d: write error (%d)
%s:%d: write failed
%s:%d: write failed - expected:%lld, actual: %lld
copy file %s to %s
%s:%d: copy file error(%d) (%s) (%s)
%s:%d: copy file error(%d) resolving dest fd %d for %s
%s:%d: copy file error(%d) resolving source fd %d for %s
%s:%d: Tried to create index when index already existed %s
%s:%d: flock err: %d,  %s
*warn* flock err: %d,  %s
*warn* Couldn't statfs the CIMetaInfo. errno:%d
*warn* Failed to acquire lock on SMB CIMetaInfo; it might already be open by another machine's mds_stores.
*warn* Trying to acquire lock on CIMetaInfo again fd:%d
*warn* Failed to acquire lock on CIMetaInfo object: errno=%d
%s:%d: invalid generation file, resetting %s
*warn* indexSet:%p count:%d current:%d
*warn* 
%s id:%d flags:%x
%s:%d: sync err: %d
*warn* Failed writing remapping data. Will cause index corruption if remapping fails.
%s(%d) [%d] %s
%s(%d) %s%s
%s(%d) %s
%s%s%s%s
%s fd:%d, error:%d
%s:%d: EFAULT: Retry operation
Couldn't make psid store at %s
%s:%d: getattrlist returned parent id %lld for %lld (%s)
%s:%d: stat succeeded, getattrlist returned error  %d for %lld (%s = %s)
%s:%d: Error (%d) for 0x%llx
Squashed update %u (%llu) from %p
Add %lld to change holder %p
*warn* Failed to map postings: %d
*warn* Failed to allocated guard page error %d
range: %llu %u (%p)
rMin:%lld, uMax:%lld, 
rMax:%lld, uMin:%lld, 
la_transition_context_for_state, current_state: %llu %d: transition_ctx.default_state: %llu %d
### %supdateset processing - %d ###
Compacting %s payloads 
Reorder time (%f)
Compact iteration:%d, src cnt:%d, new cnt:%d, time (%f) ERROR: %d
Compact iteration:%d, src cnt:%d, new cnt:%d, time (%f)
%s:%d: expected term id 1%d
Compacted payloads (%f)
%s:%d: Error %d compacting, retrying
%s:%d: open err: %d
%s:%d: open err:%d
%s:%d: pwrite err:%d
%s:%d: compact missing termID %u
Merge (offset: %llx, length: %llx) (offset: %llx, length: %llx)
Merge (offset: %llx, length: %llx)
Merge time (%f)
%s:%d: Failed to fetch the field for index:%d, nameId:%lu, dst->flags:0x%lx, dst->name:%s
DB Raw
*warn* could not resolve unique dbf value for field %d
DB_FIELD_LOCALIZED_STR: %@. 
DB_VAL: %@. 
db_utf8str: %@. 
Scalar array: %@. 
%s:%d: Invalid string_id:%lu, map_count:%lu, index:%d, dst->name:%s, dst->flags:0x%x valid:%s
%s:%d: marking invalid %s flags:0x%x
%s:%d: Failed to fetch the field for index:%d, nameId:%lu, type:%d, flags:0x%lx(0x%lx), dst->flags:0x%lx, dst->name:%s
Got the wrong field for index:%d, nameId:%lu, type:%d, flags:0x%lx(0x%lx), dst->flags:0x%lx, dst->name:%s
String: %@
C String: %s
%s:%d: Lock failed with error %d
%s:%d: %s : read_query: page at offset 0x%llx not valid (skipping %d)! (0x%x %d %d 0x%x)
%s:%d: %s:%d : %s : %s
%s:%d: db2_page_uncompress_swap: invalid page size, flags:0x%lx, used_bytes:%lu, size:%ld
%s:%d: db2_page_uncompress_swap: invalid page, flags:0x%lx, used_bytes:%lu, uncompressed_used_bytes:%ld
%s:%d: db2_page_uncompress_swap: invalid page, flags:0x%lx, uncompressed_size:%lu, uncompressed_used_bytes:%lu, compression_size_estimate:%lu
%s:%d: db2_page_uncompress_swap: invalid page, flags:0x%lx, uncompressed_size:%lu, uncompressed_used_bytes:%lu
%s:%d: db2_page_uncompress_swap: uncompress(%s) failed, status:%d, flags:0x%lx, src_size:%lu, out_size:%lu, uncompressed_used_bytes:%lu
%s:%d: db2_page_uncompress_swap: uncompressed size mismatch (%lu/%lu)
%s:%d: db2_create_datastore: ERR: Can't create file (%s : %s)
%s:%d: %s : ERR: can't init the map! (%s)
%s:%d: %s : ERR: can't init the string table! (%s)
%s:%d: %s : ERR: Can't write DST header (%s)
%s:%d: %s : ERR: Can't write shadow DST header (%s)
%s:%d: update state (%d) failed err:%d
%s:%d: db2_check_datastore: ERR: could not get parent fdp
%s:%d: db2_check_datastore: ERR: could not open parent
%s:%d: db2_check_datastore: ERR:%d could not get shadow fdp
%s:%d: db2_check_datastore: ERR:%d could not open shadow
%s:%d: %s : db2_check_datastore: ERR: could not read %d bytes
%s:%d: %s : db2_check_datastore: ERR: signature 0x%x != 0x%x. bailing out.
%s:%d: %s : db2_check_datastore: ERR: DST_BUSY
%s : db2_check_datastore:%d (s_flags:%x m_flags:%x)
%s:%d: %s : db2_get_datastore: ERR: could not read %d bytes
%s:%d: %s : db2_get_datastore: ERR: signature 0x%x != 0x%x. bailing out.
%s:%d: %s : db2_get_datastore: ERR: bad page size %d bailing out.
%s:%d: bad shadow. recover.
%s : db2_get_datastore opening - clean needs shadow
%s:%d: %s : db2_get_datastore: ERR: requested recovery from dirty master.
%s : db2_get_datastore open - shadow to master
%s:%d: %s : db2_get_datastore copyFile or copy_datastore err:%d
%s:%d: %s : db2_get_datastore: ERR: both shadow and master are dirty!  no recovery possible.
%s:%d: Invalid string table version (%d %d)
%s:%d: Upgrading string flag data
Flush starting at %f
%s:%d: %s : db2_sync_datastore: !WARNING! write-errors flushing cache. %d
%s:%d: %s : db2_sync_datastore: !WARNING! write-errors writing map. %d
Push dirty string page %d to disk (%d). %d strings
No dirty string page for %d. %d strings
Flush ending at %f
Defragging index...
%s:%d: copyFile: ERR:%d (%s)
%s:%d: sync_dirty_chunks: ERR:%d (%s)
%s:%d: %s : ERR: Can't write DST master header (2: %d)
%s:%d: %s : ERR: Can't write DST header (2: %d)
%s:%d: %s : db2_sync_datastore: !WARNING! prior write-errors invalidate sync.
Push dirty string page %d to disk (%d)
%s:%d: %s : db2_sync_datastore: !WARNING! write-errors flushing cache/writing map.
%s:%d: %s : db2_sync_datastore: ERR: Can't write DST header (%s)
%s:%d: %s : ERR: Can't write DST header (2: %s)
%s:%d: Failed syncing db
Read page:%d sig:0x%4.4x sz:0x%4.4x used:0x%4.4x flags:0x%4.4x
%s:%d: invalid entry oid: 0x%llx type:%d, map[%d] oid:0x%llx type:%d, map[%d] oid:0x%llx type:%d
%s:%d: Delete failed
Expected %ld, found %ld
Missing item: %lld page:%d type %d. Lookup %ld of %ld. startIndex %ld of %ld
%s:%d: Field type %d out of bounds
%s:%d: Field name %s out of bounds
%s:%d: types don't match dbf_flags:%x dfb_type:%d flags:%x type:%d
original field not an array, dbf_flags:%x dfb_type:%d flags:%x type:%d
db_add_field: ERR: dbf is not valid! (dbf %p dbo %p size 0x%x)
%s : ERR: XXXdbg - whoa dude... can't get name ptr for name id %d
%s:%d: invalid sdb page in cache %d
%s:%d: update_db_header failed err:%d at %d for %s
%s:%d: sdb: ERR: copy_datastore: source is not a valid fd
%s:%d: sdb: ERR: copy_datastore: destination is not a valid fd
%s:%d: sdb: ERR: invalid master datastore! (%s)
%s:%d: %s : ERR: 2: failed to write %d bytes at %lld to to_fdp
%s:%d: %s : copy_datastore: ERR: failed to update the header! (%s)
%s:%d: %s : copy_datastore: ERR: failed to update the header 2! (%s)
%s:%d: sdb: copy_datastore: ERR: %d %s: error restoring from master datastore.
%s:%d: %s : copy_datastore:2: ERR: failed to update the header! (%s)
sdb: validate_datastore: ERR: invalid datastore header size
sdb: validate_datastore: ERR: invalid datastore signature: 0x%x
sdb: validate_datastore: ERR: invalid page @ 0x%llx (sig: 0x%x)
sdb: validate_datastore: ERR: failed to read %d bytes at offset 0x%llx
%s:%d: Invalid header ms: %u hs: %u fs: %lld
%s:%d: %s : load_map, invalid entry at %ld, oid:0x%.16llx/0x%.16llx, type:0x%lx/0x%lx, pgnum:%ld/%ld
%s:%d: %s : free: ERR: Danger! page num 0x%x looks bad (signature 0x%x expected 0x%x flags 0x%x)
%s:%d: page_free: ERR: error moving page from %lld to %d (%s)
Skipping string page move from %d to %d -- no string table!
Object page move from %d to %d
%s:%d: page_free: ERR: failed to change the map page offset from %lld to %d
%s:%d: ftruncate(%s, %lld) error: %d
page_free: ERR: tried to free the first & only page of the file (pgnum 0x%x).
Moving string page from %d to %d
Change dirty string page %d to %d (%d)
Change first string page %d to %d (%d)
Push chain string page %d to disk (%d)
%s : ERR: map_change_pgnum: BAD NEWS! pgnum 0x%x not found
%s:%d: %s: ERR: Can't add dirty chunks to a read-only db!
%s:%d: Bad sdb in db_updateset_iterate at page %d
%s:%d: Failed page allocation, oid:0x%llx(%lld), type:%ld, pgnum:%ld, rc:%d
%s:%d: Failed insert, oid:0x%llx(%lld), type:%ld, pgnum:%ld, rc:%d
%s:%d: Failed update, oid:0x%llx(%lld), type:%ld, pgnum:%ld, rc:%d
%s:%d: Failed %s, oid:0x%llx(%lld), type:%ld, pgnum:%ld, rc:%d
Failed delete after failed add/update, oid:0x%llx(%lld), type:%ld, pgnum:%ld, pageRc:%d updateSetRc:%d
%s:%d: Bad sdb in db_updateset_iterate (delete) at page %d
%s:%d: Failed delete, oid:0x%llx(%lld), type:%ld, pgnum:%ld, rc:%d
%s:%d: Failed compressing/splitting page %d error %d
%s:%d: Failed compressing/splitting page %d
%s:%d: ERR: page compression error %d with page %d used_bytes %d disk page size %d
%s:%d: ERR: db_split_page error %d with page %d used_bytes %d disk page size %d
page_compress: ERR: page is already compressed!
Zip Compression ratio: %f good:%lld bad:%lld
Zip Failed compressing %ld bytes
Compression ratio: %f good:%lld bad:%lld
Failed compressing %d bytes
%s:%d: Failed splitting compressed page %d
%s:%d: should not need to split a compressed cache
%s:%d: Failed page_alloc for %d
%s:%d: Failed page_fetch for %d
Nothing found on page %d used_bytes %d
%s:%d: ERR: page_resize error %d with page %d used_bytes %d new page size %d
Forced to split page %d used_bytes %d into pieces of size %d
%s:%d: Page compress failed with error %d at %d/%d
Failure to split page %d used_bytes %d into pieces of size %d
splitting map page %x, new page %x max_oid %llx type %d
%s:%d: Failed releasing dity compressed cache page %d with error %d
%s : ERR: map_split_page: BAD NEWS! pgnum 0x%x not found
%s:%d: %s : map_check_size: ERR FATAL: too many entries! %d / %ld
%s:%d: Failed releasing null page
%s:%d: Failed writing page
%s:%d: Failed writing map
%s:%d: page_release: ERROR: page_fetch caller responsible for making sure compressed page fits after changes.
%s:%d: page_release: page %d used_bytes %d disk page size %d
%s:%d: page_release: ERR: compress error %d with page %d used_bytes %d disk page size %d
%s:%d: Failed writing pgnum %d
%s:%d: sync_dirty_chunks: ERR: Can't determine the shadow file size! (%s)
sync_dirty_chunks: ERR: Failed to map shadow
sync_dirty_chunks: ERR: Failed to map master
sync_dirty_chunks: ERR: Failed to truncate master fd to %lld
%s:%d: sync_dirty_chunks: ERR:%d count:%d expected %d! (%s)
%s:%d: sync_dirty_chunks: ERR: Can't determine the master file size! (%s)
%s:%d: dirty callback returned non-zero
%s:%d: %s : db2_dirty_datastore: ERR: Can't write DST header (%s)
*warn* sdb not page-size aligned. Extending.
%s:%d: Failed allocating page
%s:%d: pwrite(%s, %d, %lld) error: %d
%s:%d: load_string_table: circular string table (pgnum %d)
sdb: load_string_table: ERR: failed to load page @ 0x%x
%s:%d: load_string_table: unexpected page flags (%x %x)
%s:%d: load_string_table: read past bound: dstr (%tx) str_index (%d)
%s:%d: load_string_table: hash_insert: string %s (id %d) already exists (id %p)!
Loaded %d strings for %d
%s:%d: load_string_table: string id mismatch: dstr (%tx) str_id (%d) str_index (%d)
Grow string table %p (%d)
Inserted field name %s with id %d for %d
Push empty string page %d to disk (%d)
Push old dirty string page %p %d to disk (%d)
New string table page %d (%d)
%s:%d: dbo too small
%s:%d: Error %d, oid %llx
%s:%d: Previous write error
test_compress_obj: ERR %d: compressing %d dbo with oid 0x%llx (%d bytes)
%s:%d: Error %d from db_updateset_insert_object
%s:%d: Error %d from flush_updateset_locked
%s:%d: page_update_obj: ERR: tried to read attr name table data! pgnum 0x%x
%s:%d: page_update_obj: ERR: page is still compressed! pgnum 0x%x
%s : update pgnum %d
%s : page_update_obj: ERR: page at num 0x%x has a bad object pgnum %p
%s:%d: page_split: ERR: tried to read attr name table data! pgnum 0x%x
%s : no map update for split at pgnum %d oid (%.16llx) to(%.16llx) dbo:%p end:%p next:%p dbp:%p
dbo %p beyond end of page at %p. Resetting to last at %p
%s : ERR: try_push_insert_obj: BAD NEWS! pgnum 0x%x not found
try_push_right: weird! end %p first %p but num_bytes %d
try_push_left: issshhhn't dat strange? decrease %d num_bytes %d
%s:%d: %s : ERR: map_update: page offset doesn't match! 0x%x != 0x%x
%s : ERR: map_update: did not find old oid %.16llx (%.16llx) dropping update to (%.16llx)
%s : map_update: update pgnum %d oid (%.16llx) to(%.16llx)
%s:%d: page_insert_obj: ERR: tried to read attr name table data! pgnum 0x%x
%s:%d: page_insert_obj: ERR: page is still compressed! pgnum 0x%x
%s : no map update for inserting at pgnum %d (%.16llx)
%s:%d: %s: page_insert_obj, page pgnum:%ld has a bad object at offset:%p
%s : ERR: map_insert: key already present! idx %d %.16llx
%s:%d: page_delete_obj: ERR: tried to read attr name table data! pgnum 0x%x
%s:%d: page_delete_obj: ERR: page is still compressed! pgnum 0x%x
%s : no map update for deleting at pgnum %d (%.16llx)
%s : ERR: map_delete: trying to delete non-existent oid %.16llx (%.16llx), (%d, %d)
Prefetch pages from %ld
(nextpage)Skip prefetch of %ld cache:%d
Failed to find %lld (%d) (offset:%lu first:%llu)
Already found %lld
Wrong next page in db iterator 0x%x %p
%s:%d: obj_iter_fetch_page: ERR: page came back compressed! pgnum 0x%x
%s:%d: Failed reading pgnum %d
%s:%d: db2_page_uncompress_swap failed, error:%d, pgnum:%lu, pgoff:0x%llx, signature:0x%x, size:%d, used_bytes:%d, flags:0x%x, name:%s
%s:%d: page_fetch found an invalid page, pgnum:%lu, pgoff:0x%llx, signature:0x%x, size:%d, used_bytes:%d, flags:0x%x, name:%s
%s:%d: page_fetch marking the dst as corrupted, pgnum:%lu, pgoff:0x%llx, flags:0x%x, name:%s
Prefetch page %d(%d) for db %p
1) Skipping oid %lld at index %ld
2) Skipping oid %lld at index %ld
%s:%d: page_find_oid: ERR: tried to read attr name table data! pgnum 0x%x
%s:%d: page_find_oid: ERR: page is still compressed! pgnum 0x%x
convert_value_to_type: unknown data type 0x%x (val 0x%p)
%s:%d: nil str_val converted_bits: 0x%x field: %s string: %s
NULL
-------------------------------------------------------------------------------------------
%s : node @ 0x%p looks trashed
%s : failed to convert qp @ 0x%p to type 0x%x
Growing hash table %d %d
%s:%d: Large page cache fetch fail for pgnum:%ld, ret:%d
Cache add %d %p %d %p %d %d %d
Forcing Cache Cleanup
%s:%d: Unexpected EOF in page cache preload; got %ld bytes at offset %lld
%s:%d: Missing signature in page cache preload %llx
Pre-loaded %ld cache pages
Cache remove %p %d
QOS executeSearchCtx: %d
Scopes: %@
Entering
File without dbo
File with dbo: ignored for search during initial indexing
File failed primary query
File failed secondary query
PQR had nothing!
Appended datum: %@
Encoding %ld items from set %p for field %s
Setting locale to %s
QOS executeSearchCtx_Start: %d
Search canceled while waiting on scheduler
Search waited %f seconds on the scheduler at qos 0x%x
Search was active (preIterate) for %f seconds on the scheduler at qos 0x%x
Search was active for %f seconds on the scheduler at qos 0x%x
QOS executeSearchContextCracked_2: %d
Search was active (performSearch) for %f seconds on the scheduler at qos 0x%x
Got %ld results
Coalesced result set: %p
Result queue overflowed. Not rescheduling
Query canceled
Low water routine triggered
resumeQuery triggered
QOS executeSearchCtx2: %d
Suspending root query scheduler(%d)
Passing up %ld results for mode %d (removed %ld duplicates)
%s:%d: _data_map_rdlock error %d
%s:%d: _data_map_unlock error %d
%s:%d: param error
found allocated size %lld for %lld %s
%s:%d: offsets fd_mmap error
%s:%d: fd_truncate error
%s:%d: hash fd_mmap error
%s:%d: invalid header size %ld
%s:%d: header fd_mmap error
%s:%d: storage fd_mmap error
%s:%d: offset fd_mmap error
%s:%d: invalid offset size 1 - %ld %d
%s:%d: invalid offset signature
%s:%d: invalid version %d
%s:%d: invalid extra_size %d %d
%s:%d: invalid header size
%s:%d: invalid storage size 1
%s:%d: re-build hash error
%s:%d: invalid hash size 1
%s:%d: exception processing %s
Opened map %s with counts: %d
%s complete %s map with count: %d
%s complete %s header with count: %d
rename %p %s to %s
Deleted %d items from %p[%d]
*warn* Delete strings canceled
rehash %p max id: %d deletes: %d count: %d hash_size: %d
%s:%d: re-build hash error %p
%s complete %s with count: %d
%s:%d: invalid data id %d max %d %p %s
%s:%d: invalid data offset 0x%lx 0x%lx %p %s
added %d to %p
*warn* Got exception on %s addr:%p start:%p map end:%p file end:%d sres:%d dev:%d ino:%lld
%s:%d: _data_map_wrlock error %d
Delete data for id:%d size:%d %s from %p
Delete data for id:%d size:%d from %p
Found %d deleted strings from %p
Deleting id: %d size: %d %s from %p
Deleting id: %d size: %d from %p
Q P&
333?
333?
333?
333?
333?
333?
333?
333?
333?
fff?
?333333
@@5^
Oiir
I&*-
15;IAE
C%C'
&,06V
6%(+.14
:lo
  65\5
7<<<<<<<<
<<<<<<<<<<<<<<<<<<<<<
<j<<
~~~~~~~~(~~<~Px
O@(#)PROGRAM:MobileSpotlightIndex  PROJECT:Matador-2183.16
journalRepair.1
kMDItemRelatedUniqueIdentifier
""#"$"%"&"<"A"C"D"E"G"H"I"M"m"a"b"d"p"e"q"r"t"s"u"v"x"w"y"z"
FH
0K0L0M0N0O0P0Q0R0S0T0U0V0W0X0Y0Z0[0\0]0^0_0`0a0b0d0e0f0g0h0i0o0p0r0s0u0v0x0y0{0|0
0o0q0r0t0u0w0x0z0{0}0
 !"#$%&'()*+,-./0123456789:;<=>?@abcdefghijklmnopqrstuvwxyz[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`ABCDEFGHIJKLMNOPQRSTUVWXYZ{|}~
`!p!a!q!b!r!c!s!d!t!e!u!f!v!g!w!h!x!i!y!j!z!k!{!l!|!m!}!n!~!o!
!p!`!q!a!r!b!s!c!t!d!u!e!v!f!w!g!x!h!y!i!z!j!{!k!|!l!}!m!~!n!
FV
ABCDEFGHIJKLMNOPQRSTUVWXYZ
0123456789abcdef
tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt7
tttttttttttt
ttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt
?333333
?333333
?ffffff
?333333
?333333
?ffffff

InRange(_kMDItemGroupId,2,2)
InRange(_kMDItemGroupId,1,1)
InRange(_kMDItemGroupId,3,3)
InRange(_kMDItemGroupId,4,4)
InRange(_kMDItemGroupId,5,5)
InRange(_kMDItemGroupId,6,6)
InRange(_kMDItemGroupId,7,7)
InRange(_kMDItemGroupId,8,8)
InRange(_kMDItemGroupId,9,9)
InRange(_kMDItemGroupId,10,10)
InRange(_kMDItemGroupId,11,11)
InRange(_kMDItemGroupId,12,12)
InRange(_kMDItemGroupId,13,13)
InRange(_kMDItemGroupId,14,14)
InRange(_kMDItemGroupId,15,15)
InRange(_kMDItemGroupId,16,16)
InRange(_kMDItemGroupId,18,18)
 !"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
bcdefghijk#lm$%&'()*+,-nopqrst.02468:<>@BDFHJLNPRTVXZ\^`uvwxyz/13579;=?ACEGIKMOQSUWY[]_a{|}~
-0123456789AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz#$%&'()*+,./:;<=>?@[\]^_`{|}~
SQLite format 3
 !"#$%&'()*+,-./0123456789:;<=>?@abcdefghijklmnopqrstuvwxyz[\]^_`abcdefghijklmnopqrstuvwxyz{|}~
!%-MASTER-FID-%!
get_persistent_id_store
release_persistent_id_store
sync_persistent_id_store
rename_path
_sqlite_insert
_sqlite_bulkEnd
_psid_insert_locked
remove_path_locked
.migratedphotolibrary/
.migratedaplibrary/
.photolibrary/
.aplibrary/
.photoslibrary/
psid.db
FileTree_Overlay.c
fileId >2
FileTree_UpdateSet.c
(uint32_t)outChildren == (uint32_t)root->children->childCount
lastPosting
directory->fileid>=2
depth >= 0
parents[i] > 0
%s:%u: failed assertion '%s' %s Got parent with id %lld
(uint64_t)parents[i-1] > 2
directory->children->nodes[slot].fileid==p1[0]
directory->fileid
directory->children->childCount < directory->children->pageSize-1
%s:%u: failed assertion '%s' %s got file id %lld
newDirectory.fileid >2
newDirectory.fileid != directory->fileid
directory->children->nodes[slot].fileid<=1
dir==0
uniqued
getFlagsFromAttributes
multivalued
nosearch
Attributes
SIIndexInternals.cpp
fieldName.ptr()
setOneLocalizedFieldWithFlags
((flags & DB_FIELD_EXTENDED_ATTR) && isCoreSpotlight) == 0
:EA:
:PR:
_kMD
:INC:
_kMDItemOutgoingCounts
_kMDItemIncomingCounts
_kMDItemOutgoingMailCounts
_kMDItemIncomingMailCounts
_kMDItemOutgoingSMSCounts
_kMDItemIncomingSMSCounts
_kMDItemOutgoingCalendarCounts
_kMDItemIncomingCalendarCounts
_kMDItemOutgoingFileProviderCounts
_kMDItemIncomingFileProviderCounts
_kMDItemIncomingVideoCallDates
_kMDItemOutgoingVideoCallDates
_kMDItemIncomingAudioCallDates
_kMDItemOutgoingAudioCallDates
kMDItemUserTags
kMDItemFinderComment
_kMDItemFinderLabel
_kMDItemSizingIsNeeded
kMDItemAlternateNames
kMDItemContentType!='com.apple.ical.ics.todo' || _kMDItemFinderExcluded!=1
_kMDItemGroupId!=6 || (kMDItemContentType=='com.apple.ical.ics.todo' || _kMDItemFinderExcluded!=1)
SIQuery.cpp
qp->_free_cache_data==(void*)ContentIndexQueryNodeDispose
count < (CFIndex)4294967295U && count>=0
tmpB
SIUINT32Set
SIUINT64Set
v==key
popped<peeked
popped==peeked
(key & fMask) == fPfx
newLevel->children[i]==0
com_apple_mail_flagged
com_apple_mail_flagColor
com.apple.searchstressattr
_kMDItemStateInfo_com.apple.searchstressattr.state.test
com.apple.mobilemail
com.apple.mobilenotes
com.apple.mobilecal
_kMDItemStateInfo_com.apple.mobilemail.contentIndex
com_apple_mobilemail_transaction
com.apple.CloudDocs.MobileDocumentsFileProvider
com.apple.FileProvider.LocalStorage
kSIRepairedIndex
kSIConsistencyCheck
kSITokenizerUseCRF
kSITokenizerVersion
kSITokenizerUnigrams
kSIRepairSizes
kSIIdentifierHashVersion
activityJournal
Cab.created
tmp.Lion
Lion.created
com.apple.SpotlightServer
_kMDItemTextContentLength
_kMDItemSnippet
_kMDItemPersonaID
Shutdown
Preheat
Throttled Volume Query
Volume Query
Throttled Index Query
Utility Index Query
Index Query
Fast Index Query
Set Attributes
Flush
Compaction
Background Helper
Helper
Throttled Index Query Init
Utility Index Query Init
Index Query Init
Fast Index Query Init
kMDStoreUUID
/Library/Caches/com.apple.xbs/Sources/SpotlightCore_Sim/Spotlight-2183.16/spotlight/index/SpotlightIndex/SpotlightIndex.c
void syncIndex(si_sync_ctx *, Boolean)
kIndexRemappingData
database.recoverscantime
GroupAssignments
JournalSerialNumber
ConsumedJournalSerialNumber
kMDSIndexSyncCount
kMDSIndexDeferSyncCount
sync err
syncIndex
com.apple.spotlight.missingparent
v32@?0i8^q12i20^q24
void si_mergeIndex(void *, Boolean)
Full
Partial
Vacuum
Normal
Forced
Voluntary
SpotlightIndex.c
!ref->workqueues.queues[SI_DEFER_QUEUE_IDX]
DarkMerge
Index merge in dark wake
 canceled
si_mergeIndex
ContentIndexWritable(indexSet->index[indexSet->currentIndex])
void si_initialIndexingEndedQueueOnFlush(si_sync_ctx *, Boolean)
si_writeBackDBO
!ContentIndexWritable(indexSet->index[i-1])
indexLiveSet->currentIndex==~0 || ContentIndexWritable(indexLiveSet->index[indexLiveSet->currentIndex])
ContentIndexValidIndex(cindex)
ContentIndexWritable(cindex)
si_getSyncIndex
indexSet->indexCount
indexSet->index[indexSet->indexCount-1]
ContentIndexValidIndex(indexSet->index[indexSet->indexCount-1])
callbacks
SICreateNewIndex
tmp.Cab
tmp.Star
_kMDXXXX___DUMMY
_kMDItemTimeMachinePath
kMDStoreProperties
si_recycleForBadIndex
si_store_propery_cache
database.shutdowntime
recovery
flush err
_SIFlushAndSyncIndex
v16@?0@?<v@?B>8
SISetCSAttributes
void SIInitialIndexingEnded(SIRef, int32_t)
int32_t SIGetMaxTransactionID(SIRef)
SIGetMaxTransactionID
SISetTransactionCount
int32_t SISetScanCount(SIRef, CFIndex, _Bool)
oldLiveSet->indexCount==0 || (CFIndex)ContentIndexBaseDocId(oldLiveSet->index[0]) >= count
SISetScanCount
SIGetLargestOid
void _SIIssueFullMergeWithGroup(SIRef, dispatch_group_t)
void _SIIssueMerge(SIRef, int)
[%p] %s
_SIReverseStoreIterate
_SIDirectoryStoreIterate
Scheduler state:
<<<<<<<<
>>>>>>>>
_SIIssueSchedulerDump
low disk space
_kMDItemImporterResult
si_get_object_for_identifier_createParentDBO
v24@?0^{__CFArray=}8q16
(count & 0x7 ) == 0
i<=count/8
clean
fast flush
needs shadow
dirty
unknown
tmp.spotlight.state
si_read_index_state
si_write_index_state
state==kSIIndexStateDirty
SICopyCorrections
default_corrections
com.apple.lastuseddate#PS
kMDItemIsTrashed
kMDItemFileProviderID
LISearchObjTypeReturnAll
LISearchFileNameContains
si_create_indexmetadata
sync_datastore
ctx->syncSet && ctx->liveSet
dirStore.overlay
tmp.spotlight.loc
commit_sync_datastore
!ctx->syncDirtyChunks
shadow_datastore
post_shadow_datastore
kMDStoreAccumulatedCounts
si_storesizes
kIndexRemappingIndex
kIndexRemappings
ref->workqueues.queues[SI_DEFER_QUEUE_IDX]
OuterMerge
tmp.merge.%ld.
InnerMerge
com.apple.spotlightindex.%s.%s.%d
merge
live
_kMDItemExternalID
noindex
notokenize
v40@?0r*8Q16{?=*{?=IC}}24
com.apple.spotlight.mds.index-lifecycle
SetupRemapping
ContentIndexGetId(oldIndexSet->index[start])==anchor
si_swapIndexSet(ref, oldIndexSet, indexSet, indexSetPtr,1, live)
indexFd != -1
syncCount < 2147483647
%s%d
Failure in db_shrink_cache at si_remapForIndex
Unknown
ExternalVacuum
Deletes
Count
ExternalForce
ExternalInitialIndexingEnd
ExternalScanEnd
HoldCount
UpdateCount
indexSet2->currentIndex==~0
!ContentIndexWritable(indexSet2->index[i])
live.0.
si_swapIndexSet(ref,oldIndexSet2,indexSet2,&ref->syncSet,0, 0)
si_swapIndexSet(ref,oldIndexSet1,indexSet1,&ref->liveSet,1, 1)
SetupDeferQueue
start+count <= oldIndexSet->indexCount
oldIndexSet->indexCount+(mergeCount-1) >= preCount
com.apple.spotlight.mds.index-darkwake
ScanEnded
void si_scanEnded(si_sync_ctx *, Boolean)
void setupAndIssueMergeScan(SIRef, int32_t, _Bool, xpc_activity_t, _Bool *, dispatch_group_t)
Failure in db_shrink_cache at si_initialIndexingEnded
InitialIndexingEnded
void si_initialIndexingEnded(si_sync_ctx *, Boolean)
void setupAndIssueMerge(SIRef, uint32_t, _Bool, xpc_activity_t, _Bool *, dispatch_group_t)
invalid path
Rebuilding index
_SIOpenIndex
Rebuilding index because of repeated crashes
open meta info error
handleDirStoreOverlay failed
recover datastore error
invalid datastore
ds dirty, rs needs shadow 
ds needs shadow, rs dirty
invalid reverse store
restore db dirty pages failed
restore rs dirty pages failed
invalid index version recovering
invalid index version reindexing
.store.db
open index error
invalid term update set from lion
open dirstore failed
open datastore failed
index setup error
fs_only || newIndex->dirStore
init index error
index not created with unigrams error
missing system dbo
_SIOpenIndexFilesWithState
!fast_flush_failed
newIndex->syncSet->indexCount==0
newIndex->liveSet->indexCount==0
s->directory_state!=kSIIndexStateFastFlush
db_corespotlight_store(newIndex->store) || version == 99 || version == 100
scanCount == newIndex->syncSet->indexCount
liveCount == newIndex->liveSet->indexCount
handleIndexRepair
_kMDItemWillModify
tmp.
tmp.SnowLeopard
tmp.spotlight
tmp.store.recovery
tmp.journals.
new_path[ptr-direntry->d_name-4]=='.'
si_handle_tmp_files
void holdAndIssueMerge(SIRef, int32_t, SIIndexSetRef, _Bool, _Bool)
void si_compactReadOnlyIndexes1(void *, Boolean)
void si_compactReadOnlyIndexes2(void *, Boolean)
void si_compactReadOnlyIndexes3(void *, Boolean)
store.db.recover
.store.db.recover
/store.db.recoverStr-%d.map.header
/store.db.recoverStr-%d.map.offsets
/store.db.recoverStr-%d.map.data
/store.db.recoverStr-%d.map.buckets
com.apple.spotlight.index.free
com.apple.searchd.indexes.count
^v8@?0
com.apple.searchd.indexes.merge.immediate.count
com.apple.searchd.indexes.merge.scheduled.count
IndexOpenCompact
com.apple.searchd.indexes.uncompacted.merge.scheduled.count
v12@?0C8
com.apple.searchd.indexes.uncompacted.merge.immediate.count
si_repair_sizes_block_invoke
si_repair_sizes
void setupAndIssueMergeCleanup(SIRef, int32_t, _Bool, xpc_activity_t, _Bool *, dispatch_group_t)
guarded_dup
Failure in db_shrink_cache at si_index_inactivate
doFastFlushIndex
SIIndexingMallocZone
SIInitIndex
rebuild for tokenizer
open persistent id store error
LOW_LATENCY
%s scheduler for index at %s
newIndex->workqueues.schedulers[schedId]==0
newIndex->workqueues.queues[queueId]==0
%s scheduler for spindle %d
YukonRecomputedSizes
fs_only||newIndex->dirStore
process terminating
!ref->uniqueLocalizedTerms
database.localizedtermsuuid
_si_init_localized_terms
i12@?0B8
_kMDItemOwnerUserID
_kMDItemDomainIdentifier
kMDItemPhysicalSize
_kMDItemStorageSize
kMDItemWhereFroms
_SIInitSDB
si_getsizes
0 <= count && count < pathBufferSize
journalFdPtr
journal replay
preparseMobileJournal
playBackMobileJournal
void si_sync_index_delayed2(si_sync_ctx *, Boolean)
setCSAttributes2
com.apple.FileProvider
setCSAttributes2_block_invoke_2
com.apple.spotlight.SyndicatedContentDeleted
setCSAttributes2_block_invoke_4
com.apple.spotlight.SyndicatedContentRefreshed
com.apple.searchd
_kMDItemStateInfo_%@
com.apple.MobileSMS
_si_delete_attributes_inner
com_apple_mobilesms_isHighlightedContent
kMDItemSyndicationStatus
com_apple_mobilesms_isChatAutoDonating
_kMDItemExpirationDate
_kMDItemIsZombie
_kMDItemRelatedObjectsWithBundle
com.apple.searchd.deletes
bundleid
itemcount
indexingtime
aggregatedatasize
_MDItemDeletedWithRelatedUniqueIdentifier
__class:
CSLocalizedString
v24@?0{?=*{?=IC}}8
kMDItemFileItemID
_kMDItemUserActivityRequiredString
kMDItemRelatedUniqueIdentifier
_kMDItemClientExternalID
_kMDItemClientBundleID
com_apple_mobilesms_groupPhotoPath
com_apple_mobilesms_fromMe
com_apple_mobilesms_highlightedContentServerDate
com_apple_mobilesms_chatAutoDonatingServerDate
kMDItemAuthorAddresses
kMDItemRecipientAddresses
com.apple.spotlight.category
com.apple.spotlight.contacts
_kMDItemRenderDate
_kMDItemEngagementDate
processOneCS
public.item
processing item
_kMDItemHasClientData
FPParentFileItemID
com.apple.MobileAddressBook
com.apple.Music
%@:%@
_kMDItemRequiresImport
_kMDItemImportSandboxExtension
_kMDItemImportHasSandboxExtension
kMDItemExpirationDate
_kMDItemInterestingDate
kMDItemInterestingDate_Ranking
public.data
dyn.
%s%@
__fpdefault/
__fp/
%@%@
com_apple_mail_read
%@ %@
kMDItemEmailAddresses
kMDItemAuthorContactIdentifiers
kMDItemRecipientContactIdentifiers
kMDItemStartDate
_Bool processOneCS(SIRef, int64_t, oid_t, CFStringRef, CFStringRef, int, MDPlistObject, MDPlistObject, CFStringRef, size_t, CFAllocatorRef, _Bool, dispatch_group_t, _Bool *)
_kMDItemRelatedBundleID
dbop && *dbop
(fieldFlags & (DB_FIELD_UNIQUED_VALS|DB_FIELD_LOCALIZED_STR)) == 0
kMDItemDocumentIdentifier
identifierCStrSize
_kMDItemRelatedActivityLaunchCount
_kMDItemRelatedActivityLastLaunchDate
/Info.plist
CFBundleDocumentTypes
CFBundleTypeName
LSItemContentTypes
v16@?0^{__CFDictionary=}8
InfoPlist.strings
v32@?0^{__CFString=}8[1024c]16Q24
.lproj
base
com_apple_metadata_modtime
_kMDItemIsFromImporter
_kMDItemOCRContentTitle
_kMDItemOCRContentLevel1
_kMDItemOCRContentLevel2
_kMDItemOCRContentLevel3
kMDItemPrimaryRecipients
kMDItemAdditionalRecipients
kMDItemHiddenAdditionalRecipients
kMDItemPrimaryRecipientContactIdentifiers
kMDItemAdditionalRecipientContactIdentifiers
kMDItemHiddenAdditionalRecipientContactIdentifiers
kMDItemThumbnailData
Marker
_kMDItemPortraitStaticScore
kMDItemCurationScore
kMDItemContainerIdentifier
com_apple_mail_dateReceived
kMDItemMailDateReceived_Ranking
com_apple_mail_dateLastViewed
kMDItemMailDateLastViewed_Ranking
kMDItemContentCreationDate_Ranking
kMDItemContentModificationDate_Ranking
_kMDItemApplicationLastLaunchedDate
_kMDItemApplicationLastLaunchedDate_Ranking
kMDItemStartDate_Ranking
kMDItemCompletionDate
kMDItemCompletionDate_Ranking
kMDItemDueDate
kMDItemDueDate_Ranking
kMDItemDateAdded
kMDItemDateAdded_Ranking
kMDItemPlayCount
_kMDItemSupportFileType
:MD:
kMDItemIsUploading
:MD:kMDItemIsUploading
kMDItemIsUploaded
:MD:kMDItemIsUploaded
_kMDItemBackupNameSpace
_kMDItemTimeMachineMarkerNeedsFixup
kMDItemApproximateModTime
kMDItemSeedLastUsedDate
kMDPreviewImageData
kMDItemWorkerHandled
DeviceId
public.text
kMDItemAlbum
kMDItemArtist
kMDItemComposer
_kTimeMachineNewestSnapshot
_kTimeMachineOldestSnapshot
MDSystemFile
:EA:_kMDItemUserTags
com.apple.searchd.indexing
CFArrayGetValueAtIndex(inValues,i) == valueArray[i+1]
valueArray[0]==kCFNull
si_setstorecookie
_SIShutdownIndex
com.apple.spotlight.index.shutdown.shortlived
indexSpindleId==si_indices[0]->indexSpindleId
_SIShutdownSetup
notify_lowspace
DeviceNumber
com.apple.Spotlight.lowdiskspace
si_set_property
si_create_propertydict
void si_sync_index_delayed0(si_sync_ctx *, Boolean)
void si_sync_index_delayed1(si_sync_ctx *, Boolean)
fastflush
kIndexCheckDupOids
void si_sync_index_delayed_if_dirty0(si_sync_ctx *, Boolean)
void si_sync_index_delayed_if_dirty(si_sync_ctx *, Boolean)
PermissionCache
Validate
Permission cache in dark wake
void si_bulk_delete_attributes(si_bulk_delete_ctx *, Boolean)
Failure in db_shrink_cache at setIndexingCaughtUp
mobile_journal
finishRegisterQuery
void si_initialIndexingEndedQueueOnHold(si_sync_ctx *, Boolean)
void si_initialIndexingEndedQueueOnSet(si_sync_ctx *, Boolean)
prepareForTransaction
void si_set_scan_count(void *, Boolean)
si_set_scan_count
%s:%u: failed assertion '%s' %s No writable index available for %s
(ci_rc != ContentIndex_OpenedNew) || (indexSet->currentIndex==~0) || ContentIndexWritable(indexSet->index[indexSet->currentIndex])
!ref->liveSet || ref->liveSet->currentIndex==~0 || ContentIndexWritable(ref->liveSet->index[ref->liveSet->currentIndex])
could not create live index
void _SIContinueIssueMerge0(void *, Boolean)
void _SIContinueIssueMerge(void *, Boolean)
 (on battery)
Merge(2)
void _SIContinueIssueMerge2(void *, Boolean)_block_invoke
indexCount <= indexSet->indexCount
void _SIContinueIssueMerge2(void *, Boolean)
_si_merge_for_badness_on_flush_queue
_si_merge_for_badness_on_compact_queue
void _si_merge_for_badness_on_compact_queue(void *, Boolean)
com.apple.spotlightindex.verify
si_verify
verify err
si_CleanupCommit
_kMDItemDeleted
indexing: %s
%s:%u: failed assertion '%s' %s src: %d id: %d oid: %lld parent: %lld options: %x extra: %p
(CFTypeRef)ctx->attrdict!=(CFTypeRef)kCFNull
_setAttributes
:MD:kMDItemPath
processing oid: %lld source: %d %s
processing oid: %lld source: %d
:MD:_kMDItemBackupMoveMarker
_kMDItemUserTags
ctx->attrdict==((void*)0)
void _setAttributes(si_set_attr_ctx *, _Bool, dispatch_group_t, Boolean)
_kMDItemBackupMoveMarker
setAttributesBulk_block_invoke
_si_get_object_for_identifier_createParentDBO
setCSAttributes1
setCSAttributes1_block_invoke_3
setCSAttributes1_block_invoke_2
deleteCSAttributes
deleteCSAttributes_block_invoke_2
%s:%u: failed assertion '%s' %s Got parent id %lld for oid %lld
dbo->parent_oid>=2 || dbo->parent_oid==-1
failed
sourcePath[0]>=2
destPath[i]>=2
processOneChildlessDirectory
parent===1
dbo->parent_oid == parent
dbo->parent_oid==0
handleMovingContent
i<=ctx->count
i+advanceLen<=ctx->count
processOneFile
_SIResolveDirectory
!(sourceOid==destPath[i] || destPath[0] == destPath[i])
moveDirectoriesInner
dbo->parent_oid == directoryStoreGetParent(ref->dirStore, dbo->oid)
!(s->state==kSIIndexStateNeedsShadow && state==kSIIndexStateDirty)
!(s->state==kSIIndexStateDirty && state==kSIIndexStateClean)
s->sdb_state!=kSIIndexStateNeedsShadow
s->directory_state!=kSIIndexStateNeedsShadow
_si_dump_index_state
compute_transitions
transition_table.mm
it != unprocessed.end()
store_stream_init_fd
store_stream_flush
SIScheduler.c
child->parent==scheduler
com.apple.metadata.spotlightindex.mq.%s
com.apple.metadata.spotlightindex.%s
kSISchedulerQOSClass
MQ: %s
scheduler->suspended
scheduler->running==0
scheduler->force_resumed == 1 || scheduler->suspended==0
%sWork queue %p; dq: %p %ld items enqueued
queue
root
%s:%u: failed assertion '%s' %s Bad CRC on work unit. %p %p %p %p %p %p
cu->u.crc==compute_workunit_crc(cu->u)
work_fun
%sScheduler %p %s dq:%p parent:%p; %d suspensions suspended:%s (stop waiting: %s stopped: %s)
SISimpleQueue.c
queue->end == (queue->end&(queue->size-1))
queue->start == (queue->start&(queue->size-1))
simple queue
destroyed simple queue
%s:%u: failed assertion '%s' %s Expected valid queue entry type. Got %d
SIResultQueue.c
queue->lowWaterMark!=0
[%d,%d] %s
v40@?0{?=qq}8d24^B32
com.apple.mobileslideshow
SICompletions.cpp
depth < 20
d188@?0^{?=^SQ}8Q16Q24d32d40{ci_rankingbits_wrapped_s={ci_rankingbits_s=TTTIfI}}48q112i120i124i128i132i136B140B144B148i152C156C160d164^{_SIWordTrieFragmentBundleIDs=}172^v180
%s:%u: failed assertion '%s' %s No query work queue for priority %d
SIJob.c
ref->workqueues.queues[SI_QUERY_QUEUE_IDX+priority]!=0
ref->workqueues.queues[SI_FS_QUEUE_IDX]!=0
RootDirectory
com.apple.spotlight
/var/mobile/Library/Caches/com.apple.parsecd
spotlight_stopword
spotlight_phrase_dictionary
General
Query
LiveQuery
Scheduler
Store
Fetch
Path
State
Power
Completions
com.apple.spotlightindex
indexPositions
indexPositionTable
BurstTrie.c
bt_openTrie
bt_recoverTrie
getNum(t->baseFat[s].termInfo.termId.ptr)==0
getNum(b->termInfo.termId.ptr)==0
old==s
flatStoreGetOffset(ptr) < storageGetCount(&t->flatStore)
%s:%u: failed assertion '%s' %s s: %d, c: %d
ptr.next<=getNum(t->baseFatCount)
ptr.next
bt_shadowTrie
v12@?0{TokenRange=ss}8
BurstTrie.h
ptrM(newptr).next == ptr.next
BurstTrie-Internal.h
offset<=0x3FFFFFFF
%s:%u: failed assertion '%s' %s offset %ld past bounds %ld %ld
offset<t->bases.size
%s:%u: failed assertion '%s' %s %d < %d
shadowFlatStore
ptr.kind
ptr.kind || ms->err
ms->err
*string
j<=count
z<=count
j+z<=count
(flatStoreGetOffset(range[k].info) >= flatStoreGetOffset(range[k-1].info) && range[k-1].info.next !=0) || range[k].info.next==0
TrieMergeUpdates
s<=getNum(t->baseFatCount)
!(offset>flatPagePtr && offset<flatPageEnd)
_dumpTrie
oldPtr.kind == FLAT
v16@?0^{storage_reader_t=^{storage_t}^{storage_reader_window_s}Bi}8
_bt_findBulk_block_invoke_2
ctx->la
%s:%u: failed assertion '%s' %s next: %d, max: %d
ptr.next < ctx->trie_fat_max
ptr.next < ctx->trie_max
child.next < ctx->trie_fat_max
child.next < ctx->trie_max
%s:%u: failed assertion '%s' %s invalid len
str_len
ch_start==0
%s:%u: failed assertion '%s' %s max depth exceeded: %d
ctx->stringLen<CI_UTF8CHARS_BUFFER_SIZE
v28@?0{?=Ii}8*16i24
v36@?0{?=Ii}8^{lt_trie_node=*^^{lt_trie_node}CCC}16*24i32
match_function
v16@?0^{FindTermIDsContext=^B^{_TrieHead}^{ForwardDirectoryStore_s}^{FileTree_Overlay_s}^^{FlatPageSearchBucket}i{?=Ii}QQQ[1052C]I^{QueryNode}I^^{?}^^{?}III^vII^{AllocSlab}I**^{QueryNode}^{?}^{?}^{levenstein_automaton}^{automaton_state}ifBB}8
match 
i24@?0^{FindTermIDsContext=^B^{_TrieHead}^{ForwardDirectoryStore_s}^{FileTree_Overlay_s}^^{FlatPageSearchBucket}i{?=Ii}QQQ[1052C]I^{QueryNode}I^^{?}^^{?}III^vII^{AllocSlab}I**^{QueryNode}^{?}^{?}^{levenstein_automaton}^{automaton_state}ifBB}8*16
pushMove
MoveHolder.c
holder->count==0 || holder->count + holder->data == ((char*)current) + sizeof(PossibleFileMoves_t)+sizeof(oid_t)*current->count
_CISetEmergency
ContentIndex.c
(!baseId) || newIndex->base==baseId
_CIUpdateState
open canceled
No meta info
invalid meta info
success: no data in index, rebuilding
create index error
_CIOpenBulk
needs recovery
open index shadow error
recover index error
open recovered index error
_CIFlushCache
_CISyncContextDestroy
_CISyncContextSync
_CISyncContextCommitData
_CISyncContextCommitHeader
_CISyncContextShadow
_CICompact
tmp.can_write.%d.%d
_CIDisableUpdates
%s_%d.
_CIMergeDeletes
_CIUpdateContent
((cindex)->coreSpotlight?({ ((uint8_t *)(cindex)->groups)[(relDocId)]; }):({ uint32_t __where=(uint32_t)(relDocId); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((cindex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
_CIUpdateGroupAndDate
_CIDelete
_CIReassign
ref->payloadCount <= 1
_CIRebaseDocId
_CIDocIdForOID
(ref)->groupMap[gslot]
((ref)->coreSpotlight?({ ((uint8_t *)(ref)->groups)[(i)]; }):({ uint32_t __where=(uint32_t)(i); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((ref)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
_CIDeleteDuplicates
ref->readOnly
ref->payloadMaxCount >= ref->payloadCount
_CIFindTokens
_CIPreHeatIndex
_CIGetOIDForDocId
_CIGetGroupForDocId
_CIAddOids
((cindex)->coreSpotlight?({ ((uint8_t *)(cindex)->groups)[(i)]; }):({ uint32_t __where=(uint32_t)(i); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((cindex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
_CIDeleteByOidsBulk
_CIMoveDirectory
%sindexHead
gatherAndLockIndexCallback
indexPrepareForSyncBulk
indexPerformSyncBulk
io_state[i]==0
indexCommitSyncBulk
indexShadowAndCommitBulk
_indexShadowBulk
_indexCommitShadowBulk
_ContentIndexSyncIndexBulk
ContentIndexVerifyIndex
newDocId > newBase && newDocId <= newMax
((newIndex)->coreSpotlight?({ ((uint8_t *)(newIndex)->groups)[(docID)]; }):({ uint32_t __where=(uint32_t)(docID); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((newIndex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
_MergeDeletes
expandMap
expandUnsafeMapNew
%s:%u: failed assertion '%s' %s offset: %lld, freeRegion: %lld, kind:%d
FlatStore.c
flatStoreGetOffset(ptr)+roundup2(pageEnd+int_sizeof(*page) <= freeRegion)
%s:%u: failed assertion '%s' %s ps:%d, pe:%d, pk:%d, po:%llx, ss:%llx se:%llx
pageSize >= pageEnd && pageSize && (__builtin_popcount(pageSize+int_sizeof(*page)) == 1)
%s:%u: failed assertion '%s' %s %ld, ps:%d, pe:%d, pk:%d, po:%llx, ss:%llx se:%llx
ms->currentStringLen <= CMPBUFFER_SIZE
%s:%u: failed assertion '%s' %s flat store
ms->pageOffset.next==_ptr.next
ptr.kind==FLAT
flatStoreGetOffset(ptr) < freeRegion
ms->type == kTermInfoTypeId
oldEntry.pfxLen + oldEntry.len <= CMPBUFFER_SIZE
newEntry.len
(int)pageEnd==storePageEnd(page)
pageEnd<pageSize
pageEnd < pageSize
pageEnd + newEntrySize <= pageSize
termID == getNum(newEntry.termInfo.termInfo.termId.ptr)
i < entry.len
i<=newEntry.len
entry.len > 0
entry.len==entryCopy.len
entry.pfxLen==entryCopy.pfxLen
len2 <= len1
flatStoreGetOffset(info) < storageGetCount(store)
entry.len
(int)pageEnd==storePageEnd(page) || trie_unavailable(t)
oldPageEnd == iter.pageEnd
iter.pageCursor==iter.pageEnd
__builtin_popcount(pageSize+(uint32_t)sizeof(*page)) == 1
pageEnd <= pageSize
(!compacted && t->type==kTermInfoTypeId) || (compacted && t->type!=kTermInfoTypeId)
*canceled || iter.pageCursor==iter.pageEnd
%s:%u: failed assertion '%s' %s len:%d cursor:%d, pe:%d, ps:%d, valid cursor:%s
FlatStore.h
entry->len > 0 || pageCursor == v2_vInt32Size(0)
pageCursor<=pageEnd
_checkFlatPage
storePageEnd(page) <= storePageDataSize(page)
reSize<=4096*16
flatStoreGetOffset(*newOffset) < storageGetCount(store)
entry->len > 0 || iter->pageCursor == v2_vInt32Size(0)
iter->pageCursor <= iter->pageEnd
index_FlushCache
%s:%u: failed assertion '%s' %s Expected cindex->_oldSet==0, got %p
JHContentIndex.c
cindex->_oldSet==0
indexFindBulk
*canceled || pqcount_bulk_TermIdQueue_t(q_pqueue) == 0
!((renamed != cindex->trie.renamed) || (!isCompact && (cindex->flags & kIndexFlagCompact)))
parentDirFd!=-1
createIndex
openIndex
invalid term update set
restoring term update set failed
index_verify
indexMarkDirtyForce
indexMarkDirty
indexMakeInvalid
indexPrepareForSync
indexCommitSync
_indexShadowGroups
indexShadowFiles
0 == TermUpdateSetTermCount(cindex->_deltaSet)
indexHead
fullShadowIndex
indexGroups
shadowIndexGroups
indexTermIds
shadowIndexTermIds
indexDirectory
shadowIndexDirectory
indexCompactDirectory
shadowIndexCompactDirectory
indexArrays
shadowIndexArrays
shadowIndexHead
recoverIndex
setDocumentAttributes
(cindex)->groupMap[gslot]
((cindex)->coreSpotlight?({ ((uint8_t *)(cindex)->groups)[((uint32_t)(oldDocID-cindex->base))]; }):({ uint32_t __where=(uint32_t)((uint32_t)(oldDocID-cindex->base)); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((cindex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
indexGrowDocumentPayloads
deleteDocument
((cindex)->coreSpotlight?({ ((uint8_t *)(cindex)->groups)[(payloadIndex)]; }):({ uint32_t __where=(uint32_t)(payloadIndex); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((cindex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
reassignDocument
index_compact
tmp.%scmpt.
newTermIDMap
%s:%u: failed assertion '%s' %s duplicate term id (%d)
0 == uint32_map_get(ctx->newTermIds, (uint32_t)termId)
%s:%u: failed assertion '%s' %s inconsistent term counts (%d %d)
%s:%u: failed assertion '%s' %s invalid rename %s %s
newPrefix[0]!='l'
%s:%u: failed assertion '%s' %s failed to read offset for term %d
TermIdStore.h
(intptr_t)ptr!=-1
indexIds
indexDates
indexBigDates
indexScores
indexUpdates
open_index_file
openPayload
indexPostings
verifyTermsCallback
%s:%u: failed assertion '%s' %s Expected non-zero docid
docid
((cindex)->coreSpotlight?({ ((uint8_t *)(cindex)->groups)[(docid)]; }):({ uint32_t __where=(uint32_t)(docid); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((cindex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
v60@?0^{TermBurstTrie={?=AI}^{AllocSlab}{TermTrieFat=^{tree_node}[256q]}[4{?=^vq}][256C]}8^{TermTrieFat=^{tree_node}[256q]}16B24^AI28@?<v@?^{tree_node={?=b63b1}{?=b63b1}{TermUpdate=(?={?={RelativePosting=I{?=II}}I}{?={UpdatePosting=I{?=IQ}}})S[0C]}}>36@?<v@?^vi>44@?<v@?^vi>52
index docId array
index date array
index score array
index group array
bases
fat bases
log_map_access_error
log_map_access_error_mini
len > 0 && len <= 32
indexRestoreHeaderFromBuffer
indexRestoreFromBuffer
preflight_compact
flat
termIdStore
0 == uint32_map_get(ctx->newTermIds, termId)
%s:%u: failed assertion '%s' %s no posting for term (%s %s)
initPayload
expandPayload
JHPayload.c
wb->buffer
pd->payloadIndex >= pd->payloadLimit
PayloadWriteBufferWrite
pd->payloadIndex - pd->payloadLimit >= sizeof(PulseHeaderDisk)
pos == pd->payloadIndex
%s:%u: failed assertion '%s' %s i:%d count:%d last:%d termId:%d prevTermId:%d flags:%x
(termId > prevTermId) || (i == last && termId == prevTermId)
postingStart-postingTermIdStart
JHPayload.h
src == ptr || wb->err
HashPriorityTable.h
fRankingbits[slot].containerId()!=0
initMF
%s:%u: failed assertion '%s' %s NULL file reference
MFMalloc.c
m->fdPtr
Watchdog workloop
Watchdog timer queue
si_indexingWatchdogInit_block_invoke_2
Indexing watchdog fired, delta:%lld, startTime:%lld, itemCount:%ld suspendTime:%lld resumeTime:%lld endtime:%lld pc:%u
si_indexingWatchdogPerform
-001_
n2s.c
(exponent >= 0) && (exponent <= 0x7FF)
conversionSucceeded
PQueue.c
!offset || offset_t_GET_VALUE(queue->offsets[i])<offset*2
queue->top <= queue->end
current >= offset
current <= offset
last>=offset
current >= last
last<offset
storage.c
reader->storage->_window1.memory
storageHeaderRestore
storageInit
result
storageSyncPages
storageTruncate
idx < (16)
((uint32_t)8<<idx) >= inSize - baseSize
rsize+baseSize >= inSize
success
result < inStorage->_freeRegion
inSize - baseSize <= rsize
inOffset < inStorage->_size
inOffset < inStorage->_freeRegion
inOffset+inNewSize <= inStorage->_freeRegion
oldIdx <= newIdx
freeListVerify
inStorage->_window1.mappedStart==0&&inStorage->_window1.mappedStart==0&&inStorage->_window1.memory==((void*)0)
_storageMapInit
%s:%u: failed assertion '%s' %s mmap(%p, offset: %llx, size: %ld) error:%d, fSize:%lld
%s:%u: failed assertion '%s' %s offset: 0x%llx, freeRegion: 0x%llx
inOffset==0 || inOffset < inStorage->_freeRegion
storageMoveWindow
mem:%p so:%lld eo:%lld ms:%ld s:%lld
storage_copy_read_window
%s:%u: failed assertion '%s' %s offset: 0x%lld, freeRegion: 0x%lld
(head==0) || (head < storage->_freeRegion)
_storeageSetFreeListHead
_storageExpand
TermUpdateSet.c
0 == kr
updateTermCount == ctx.termCount
TermUpdateSetRestore
termUpdateSet->reportedSize <= gTotalCurrentUsage
%s:%u: failed assertion '%s' %s Expected non-zero docID
docID
%s:%u: failed assertion '%s' %s expected non-zero docID for term
DocPosting.h
message:%3C
ptr==end
_getContentTokensCallback
%s:%u: failed assertion '%s' %s expected non-zero docID for term %s
ctx->docID
_getContentRankedTokensCallback
tu->termLen <= (1024+20)
SIUserCtx.c
CFArrayGetTypeID()==CFGetTypeID(languages)
SIUserCtx
v12@?0s8
v20@?0i8^q12
FileTree.c
getStoreOID(root->fileId)==2
%s:%u: failed assertion '%s' %s %lld != %lld
element->fileId.storeOID == source.fileId.storeOID
directoryStoreMoveDirectory
target.directory
rootDirectory->children==0
rootDirectory->lastPosting.posting.docId==0
rootDirectory->fileid == getStoreOID(root.directory->fileId)
directoryStoreMergeUpdateSet
%s%s
directoryStoreFile
directoryStoreFile.shadow
openForwardStore
flushForwardStore
shadowForwardStore
.shadow
postings<9223372036854775807LL
getStoreOID(root.directory->fileId)==2
!target.directory->childPage.offset
!((refPage.pageOffset[0] & (1ull << 63)) || refPage.pageOffset[0]==0)
directoryStoreMakePathWithPostingsOffset
%s:%u: failed assertion '%s' %s invalid posting 0x%llx for 0x%llx
postingOffset
dumpDirectoryStore
.shadow.shadow
0==strstr(shadowpathPtr, ".shadow.shadow")
0==strstr(path, ".shadow.shadow")
%s%s.shadow
directoryStoreGetParent
directoryStoreGetPath
directoryStoreWriterGetParent
parent
(getStoreOID(element->fileId)==item && &page->items[slot]==element)
directoryStoreSetParentForMove
%s:%u: failed assertion '%s' %s %d, %d, %d, %llx
depth< olddepth
%s:%u: failed assertion '%s' %s %d, %d, %d, %llx, %llx
item!=parents[depth]
%s:%u: failure log '%s' %s %d, %d, %d
hitPath==-1
depth<512
item!=inItem
directoryStoreEnsurePath
directoryStoreWriterGetPath
(!page)
_reverseStoreIterate
flushReverseStore
commitSyncReverseStore
shadowReverseStore
%s:%u: failed assertion '%s' %s invalid state
metadata != kIndexShutDownStateFastFlush
reverseDirectoryStore
reverseDirectoryStore.shadow
%s:%u: failed assertion '%s' %s Expected bitmap to be clean for index in state %x. Dirty bit at index %lx
dirtyBitIx == kCFNotFound || dirtyBitIx >= (CFIndex)(store->storage._freeRegion/STORAGE_SHADOWPAGESIZE)
commitShadowReverseStore
(store->state != kIndexShutDownStateNeedsShadow || readOnly)
reverseStoreUpdateState
reverseStore.updates
bits
!(offset & (1ull << 63))
(offset & (1ull << 63))
storePageEnd((StorePageRef)page) <= storePageDataSize((StorePageRef)page)
__builtin_popcount((storePageDataSize((StorePageRef)page))/((int)(sizeof(disk_offset_t))) + 1) == 1
!flat
getNum16(page->depth)==(unsigned)pageDepth
pageSize
%s:%u: failed assertion '%s' %s Expected offset (%llx) to be less than free region (%llx)
CHILDLESS(offset) || MASKPAGE(offset) <store->_freeRegion
flat
%s:%u: failed assertion '%s' %s Got end %d and size %d
refPage->pathDepth==getNum16(page->depth)
%s:%u: failed assertion '%s' %s Expected depth %d; page has %d
getNum16(page->depth)==(unsigned)depth
!((pageOffset & (1ull << 63)) || pageOffset==0)
flat==0
(directoryStorePageGetItemCount(subPage)+1) * 5 < (directoryStorePageGetSize(subPage)) * 4
element==0
*flat==0
*flat
outPage.leafPageOffset != getOffset(newChildPage)
page
specialBits == 0
!(((realOffset & (1ull << 63)) ==0) && (realOffset & (1ull << 62 ))==(1ull << 62 ))
%s:%u: failed assertion '%s' %s file tree
getOffset(info) < storageGetCount(store)
reSize<=((1<<(10))* sizeof(CIDirectory_t))
getOffset(*newOffset) < storageGetCount(store)
%s:%u: failed assertion '%s' %s error %d expanding from old:%d new:%d
newRealOffset
getStoreOID(newDirectory.fileId) >= 2
getStoreOID(newDirectory.fileId)==fileid
elem==0
directoryStorePageGetSize(page)*4>directoryStorePageGetItemCount(page)*5
!result
realOffset==(64)
dirStoreInit
dirStore->store._fdPtr!=0
range.location >= 0
page->items[i].childPage.offset==0
itemCount==count
!postingsOnly
!(page->items[i].fileId.storeOID==markerOid.storeOID)
storePageEnd((StorePageRef)page)/sizeof(CIDirectory_t) <= storePageDataSize((StorePageRef)page)/sizeof(CIDirectory_t)
__builtin_popcount((storePageDataSize((StorePageRef)page))/((int)(sizeof(CIDirectory_t))) + 1) == 1
dir.fileId.storeOID!=0
getStoreOID(dir.fileId)!=1
page->items[i].fileId.storeOID!=markerOid.storeOID
item!=parent
(element==0 || (getStoreOID(element->fileId)==item && getOffset(element->childPage) == (offset_t)parent))
parent == _directoryStoreGetParent(store, item)
storePageEnd((StorePageRef)page) <= storePageDataSize((StorePageRef)page) && storePageDataSize((StorePageRef)page)
result && (offset_t)(intptr_t)result != inOffset
itemCount == 0
%s:%u: failed assertion '%s' %s state:%d header:%llx
getNum(page->metadata)==kIndexShutDownStateDirty
getOffset(addr) == REVERSE_MAP_ROOT_OFFSET
reverseDirStoreInit
recoverReverseStore
get_state
/Library/Caches/com.apple.xbs/Sources/SpotlightCore_Sim/Spotlight-2183.16/spotlight/index/SpotlightIndex/SILiveQuerySupport.c
siquerynode.c
s!=NONE
node->lchild==lchild
node->rchild==rchild
_kMDItemFS
source!=NONE
node->kind<=QN_FACTOR
count==scount
%s:%u: failed assertion '%s' %s Unexpected node type %x
sinode->node.mnode.nodeCount>=2
_kMDItemOID
_FPIsTrashed
_kMDItemIndexID
_kMDItemPSIDPath
_FPItemIdentifier
_kMDItemCachedIcon
_kMDItemRenderValues
kMDItemFinderOpenDate
kMDStoreLastHealthCheck
kMDStoreAccumulatedSizes
_kMDItemCachedTextContent
kMDItemFSLocked
_kMDItemThumbnailData
_kMDItemFSGroupId
_kMDItemSyntheticGroupId
_kMDItemThumbnailDataPath
_kMDItemFSDataSize
_kMDItemFSSize
_kMDItemFileId
kMDItemLabelIDs
_kMDItemFSDisplayName
_kMDItemFSRsrcSize
_kMDItemEngagementValues
_kMDItemServerVersion
_kMDItemFSForkSize
_FPParentFileItemID
_kMDItemIndexGroupId
_kMDItemFSDisplayKind
_kMDItemOIDPath
_kMDItemFSContentType
_kMDItemOIDParent
_kMDItemFSContentTypeTree
_kMDItemOnBootVolume
_kMDItemAllOldestSnapshotDates
_FPUserFSUSBFileProviderID
_kMDItemAllNewestSnapshotDates
NSFileProviderRootContainerItemIdentifier
_kMDItemFileName
_kMDItemThumbnailDataExists
_kMDItemRenderData
kStorePropertyHealthCheckCompleteTime
kMDItemEditors
kMDItemProjects
kMDItemLyricist
kMDItemMusicalGenre
kMDItemOrganizations
kMDItemPublishers
kMDItemContributors
kMDItemCoverage
kMDItemIdentifier
kMDItemCreator
kMDItemCity
kMDItemStateOrProvince
kMDItemCountry
kMDItemInformation
kMDItemDirector
kMDItemProducer
kMDItemGenre
kMDItemPerformers
kMDItemFullyFormattedAddress
kMDItemParticipants
kMDItemNamedLocation
kMDItemDescription
kMDItemHeadline
kMDItemInstantMessageAddresses
kMDLabel_
_kMDItemEngagementData
parent_oid
index_id
index_group
flags
/%lld
oid_path
store_properties
_kMDItemDisplayNameWithExtensions
com.apple.filesystems.UserFS.FileProvider
SIQueryMallocZone
compute_non_combining_chars
levenstein_automaton.mm
v32@?0d8*16Q24
%04i-%02i-%02iT%02i:%02i:%02iZ
time.
absolute(
iso(
today
yesterday
two_days_ago
three_days_ago
this_week
this_month
this_year
SISearchCtx_METADATA.cpp
_store->store
nodeSize>=nodeCount
db->store
Recycle for error during query
err==0
!dbo || !dbo->oid || dbo->oid == oid
^v44@?0i8{?=(?={?=^vI}{?=^vQ}{?=*Q}{?=*I}*BCSIQTcsiqtdfdq^v)}12Q28^v36
UniversalSearch
d32@?0^I8^B16^B24
performSearch_METADATA
_performSearch_degenerate
fPlistBytes[slot]
_performSearch
self->currentOid!=0
kMDQueryResultMatchedDisplayNameField
kMDQueryResultMatchedFields
kMDQueryResultContentRelevance
kMDQueryResultGroupId
kMDQueryResultTopMatchedField
kMDQueryResultTextContentDistances
kMDQueryResultHasTextContentMatch
attributeCount==0
fOids[slot]
B16@?0Q8
Query result pack queue
Query result check queue
readSDBForOids_block_invoke_2
batchCount > i
processItems_block_invoke_2
packItems
v120@?0{rankAndFetchInfo={ci_rankingbits_s=TTTIfI}T{?=[5C]}qC}8
v120@?0{rankAndFetchInfo_q2={ci_rankingbits_s=TTTIfI}T{?=[5C]}qC}8
gatherIndexInfo
(size_t)docs[i]<j
cidocs[(size_t)docs[i]]
idx==ctx->cinodeCount
v24@?0^{query_piece=*^?iCiiii*(?=^v^^v)^v^?^III[16(value_type=*^*qiscfd^d^q)]}8^{_ContentIndexDocSet=}16
addString
kMDItemAuthorEmailAddresses
kMDItemContentCreationDate
kMDItemContentModificationDate
fAttributeVector
kMDItemEmailConversationID
fUniqueingSets
fCompletionAttributeVector
CIIndexSet.c
(int32_t)set->_hole <= (int32_t)set->_count
(int32_t)hole < (int32_t)set->_size
CIIndexSet
<CIIndexSet: %p count: %u>
<CIIndexSet: %p count: %u isBitMap: %d>
(int32_t)hole <= set->_count
at < set->_blob[hole-1]
set->_blob
set->_count >= set->_hole-hole
start <=end
startSlot <=endSlot
startSlot < set->_size
sourceStart >= sourceEnd
oldData >= hole
!(USE_MMAP(oldsize) || USE_MMAP(newsize))
set->_blob[set->_hole-1] > at
right < (int32_t)set->_size
set->_hole-1 < (int32_t)set->_size
PostingChunk.c
rb->current > docID
%s:%u: failed assertion '%s' %s Offset past bounds; incoming %ld, current %ld, buffer length %ld, val %llu from %d
offset < bufferLength
%s:%u: failed assertion '%s' %s %d, %d
docID > delta
docID < maxValidId
firstDocID < maxValidId
secondDocID <= maxValidId
%s:%u: failed assertion '%s' %s %ld, %ld
newOffset <= bufferLength
delta <= docID
docID >= firstDocID
docID+1 < maxValidId
docID <= maxValidId
packCtx->chunkChanges
bitVectorCount > 0
docIDLast > docIDStart
docIDLast < docIDEnd
docIDLast >= docIDs[i]
SIWordTrieContainer
ContentIndexDocSetsCreateIterator
ContentIndexQuery.c
!(!target || target->docIdSetType==Empty || target->docIdSetType==Mute)
ContentIndexDocSet_Step
!groupDone || (uint32_t)group<groupDone->groupCount
collecting
dropping
ContentIndexDocSetResolveOIDsAndGroups_Step
assert_invalid_doc_type
_ContentIndexDocSetIteratorProcessIterHits
oldNodeCount >= nodeCount
processCount || nodeCount == 0
transition_trie.c
lt_trie_make_with_icu_element_at_index
com.apple.spotlightui
SIBullseyeNoForceUnigrams
versionNineResetSentinelData
versionNineUpdateDataAndLength
markItemAsRenderedOrEngaged
db_set_garbage_collector
core-db.c
db_set_dirty_callback
db_datastore_largest_oid
db_get_object_count
db_io_error
db_dirty_datastore
db_fast_dirty_datastore_if_necessary
db_is_dirty
db_get_size
db_lock_datastore
db_unlock_datastore
db_downgrade_datastore
db_flush_datastore
db_commit_sync_datastore
db_shadow_datastore
db_commit_shadow_datastore
db_commit_shadow_complete_datastore
db_release_datastore_no_sync
db_shrink_cache
db_ensure_open_files
db_cooldown_files
db_copy_field_ids_with_buffer
db_copy_field_ids_with_buffer_locked
db_get_id_for_field
db_get_id_for_field_locked
db_get_fields_generation
db_create_obj
db_create_obj_with_buffer
db_get_obj_callback
db_store_obj
db_update_obj
db_update_obj_callback
db_perform_callback
db_validate_obj
db_delete_obj
db_delete_obj_with_flags
db_create_id_for_value
db_add_field
db_add_field_with_cache
db_delete_fields_with_flags
db_delete_field
db_get_field
db_get_field_locked
db_get_field_by_id
db_get_offsets_for_fields
db_get_id_for_string
db_get_string_for_id_locked
db_get_field_name_for_id_locked
db_get_string_for_id
db_get_field_name_for_id
db_get_field_id_limit
db_get_localized_string
db_next_field
db_clear_docids_setup
db_clear_docids
db_clear_docids_cleanup
db_open_files
db_apply
db_get_dirty_chunks
db_create_static_strings
db_match_address
db_garbage_collect_strings
db_copy_delete_localized_term_ids
db_serialize_cache
db_obj_iter_create_with_filter
store.updates
db_store_dirty_chunk_info
dirty_chunks[i].pgnum > dirty_chunks[i-1].pgnum
!info->dirty_chunks
db_restore_dirty_chunk_info
info->dirty_chunks
copyVolumeInfoStr
(%s, t: 0x%x, st: 0x%x, f: 0x%x)
mds64-crash-state
check_crash_state
ContentIndex_catch_exception_raise
ContentIndex_catch_exception_raise_state
ContentIndexExceptionHandler.c
ContentIndex_catch_exception_raise_state_identity
krc==KERN_SUCCESS
%s:%u: failed assertion '%s' %s Active handlers > MAX_CI_THREAD_COUNT
entry
%s:%u: failed assertion '%s' %s invalid count %d
entry->count == -1
td->itemCount < td->itemSize
td->itemCount
seqNum <= td->items[j].seqNum
seqNum == td->items[td->itemCount].seqNum
td->cleanUpSize
td->cleanUpCount
td->cleanUpCount >= position
__THREAD_SLOT_KEY
loc>0 && loc<=1024
td->onThreadCleanUpSize
td->onThreadCleanUpCount
td->onThreadCleanUpCount >= position
/private/var/db/Spotlight-V100/%s-%s
setPC
entry->count==0
mapping
slab_allocator.c
kr == 0
tmp.merge.termIdFile.%d
mergeIndexData
mergeIndexData_block_invoke
CIMerging.c
count <= k
B20@?0^{?={?=QI*i}q}8i16
(newIndex)->groupMap[gslot]
vm_page_size*(gslot*8+bslot) <=slot
vm_page_size*(gslot*8+bslot+1) >slot
((newIndex)->coreSpotlight?({ ((uint8_t *)(newIndex)->groups)[(docId)]; }):({ uint32_t __where=(uint32_t)(docId); uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)((newIndex)->groups[__slot])); (__word >> __shift) & 0x3F ; }))==(inval&0x3F)
(((newIndex->coreSpotlight?({ ((uint8_t *)newIndex->groups)[docId]; }):({ uint32_t __where=(uint32_t)docId; uint32_t __slot = __where/5; uint32_t __shift= (__where-(__slot*5))*6; uint32_t __word = ((uint32_t)(newIndex->groups[__slot])); (__word >> __shift) & 0x3F ; }))&0x1F)) == 0
newIndex->payloadCount + newIndex->base <= sources[idx_cnt-1]->payloadCount + sources[idx_cnt-1]->base
hitCount
hitCount<=idx_cnt
_last>(uint32_t)idx
idx<idx_cnt
packContext.packbuffer[k-1] > packContext.packbuffer[k]
lastId>=lastStringId
sourceItems[i].item.postingOffset
termIdFd == -1
Merge
MergeSuccess
vacuum
MergeCanceled
MergeException
MergeError
Complete
Canceled
%s:%u: failed assertion '%s' %s expected %d > %d
i==0 || context->packbuffer[i-i] > context->packbuffer[i]
context->packbuffer[i] > context->packbuffer[i+1]
context->count<=1 || context->packbuffer[context->count-2] > context->packbuffer[context->count-1]
context->count<=2 || context->packbuffer[context->count-3] > context->packbuffer[context->count-2]
lastItem.item.termLen==0 || TermItem_compare(&lastItem, &sourceTerm[0]) < 0
sourceTerm[k].idx<sourceTerm[k-1].idx
moredata&(1<<sourceTerm[i].idx)
iterateTermsForIndexes
%s:%u: failed assertion '%s' %s Got 0 from calloc for allocation of count %ld size %ld
p||count==0||size==0
B28@?0i8^q12Q20
mergeIndexDataTrampoline
%s:%u: failed assertion '%s' %s corrupt ro index need to rebuild %s
!buffers->badIndex
strlen((char*)strbuf) == workItem.termLen
_excReadBufferMatch
unpackAndCleanse
offset < readBuffer->mappedSize
nxtLink==0||!isCompact
changeHolder->count == 0 || changeHolder->hole
next != nxtLink
changes->hole>0
sdb2_rwlock.c
lock->writer != pthread_self()
list->head==0
waiter->threadid
AppleLanguages
/var/log/CDIS.custom
LANGUAGE=%s
UNICODE MATCH:%s
addValue
MDPlistBytesAdditions.c
%s:%u: failed assertion '%s' %s NLStringTokenizerCreate err:%d
CITokenizer.c
version>=0 && version<=kCITokenizerVersionCurrent
%s:%u: failed assertion '%s' %s alloc err:%d (%x)
state->uniChars
fd_create_protected
fd_create_sibling_protected
fd_lseek
fd_pread
fd_obj.c
!obj->forbidder
fd_pwrite
fd_write
fd_rename
obj->_magic==(0xFCFCFCF3)
%s:%u: failed assertion '%s' %s Unexpected delete of %s from %d
!unlinked
obj->prev
g_fd_list->item_count==0
g_fd_list->item_count
g_fd_list->item_count>=0
!obj->prev
g_fd_list->fd_count>=0
processed++ < g_fd_list->item_count
processed == g_fd_list->item_count
obj->fd != -1
g_fd_list->item_count!=0
g_fd_list->head
_fd_acquire_fd
obj->fd == fd
obj->open_count
_safe_open_at
%s:%u: failed assertion '%s' %s Too many open files %d (%d) (%d)
%s:%u: failed assertion '%s' %s Too many open files in system %d
RLEOIDArray
SIValueSetInternals.h
s->sharedDepth>=0
((sizeof(ValueType) * 8) -4*(1+(s->sharedDepth))) <= sizeof(ValueType)*8
SIValueSet
CombLevel_s
s->sharedDepth
holder->GetRawCount() <= (63)
startPrefix == (startPrefix & startMask)
%s:%u: failed assertion '%s' %s next: 0x%llx, max: 0x%llx
FindTermIDs.c
flatStoreGetOffset(child) < ctx->flat_max
%s:%u: failed assertion '%s' %s grow buckets error, bucket count:%d
buckets
%s:%u: failed assertion '%s' %s invalid key_len %d
key_len>0 && key_len <= 4
t->size>=t->count
%s:%u: failed assertion '%s' %s duplicate pages %ld %ld
%s:%u: failed assertion '%s' %s type: %d
icu_utils.c
b->_type>kICUBaseType&&b->_type<kICUBaseEndType
%s:%u: failed assertion '%s' %s unexpected type %d
@collation=search
icu_rules_
%s:%u: failed assertion '%s' %s %s count %d
ctx->count>1
MATCH
NO_MATCH
%s:%u: failed assertion '%s' %s %s level: %d count: %d
cur_state.level+1>=ctx->count
cur_state.level+1<ctx->count
cur_state.level==0 && (cur_state.level+1<ctx->count)
cur_state.level+1!=ctx->count
cur_state.cur==(u_int8_t*)string
item.start_mask&U_MASK(u_charType(utf8_to_code_point((u_int8_t*)cur_state.cur)))
icu_rules_%s_%d_%d
%s:%u: failed assertion '%s' %s bad length: %d
size <= 256
v36@?0i8^S12i20^S24i32
expansion_len<EXPANSION_LIMIT
%s:%u: failed assertion '%s' %s size: %d count:%d
b->size>=b->count
%s:%u: failed assertion '%s' %s len %d
key_len
%s:%u: failed assertion '%s' %s bad type: %d
%s:%u: failed assertion '%s' %s invalid utf8 %u
%s:%u: failed assertion '%s' %s invalid char %u
%s:%u: failed assertion '%s' %s token len %d
p->token_len<TOKEN_MAX
[last tertiary ignorable]
[last primary ignorable]
[variable top]
[last regular]
[import 
%s:%u: failed assertion '%s' %s unexpected %d
v28@?0*8I16^{?=^{term_expansions}[8I]CC[0q]}20
rules_offset <= rules_size
expansions_offset <= rules_size+expansions_size
string_offset <= total_size
ne->expansions[i][needed-1] == 0
ctx->_base._type==kICUSearchType
ctx->_base._type==kICURangeType
__checkIndexSet
unexpected index base
overlapping doc ids
Cache/%x/%llx.%s
Cache/%4.4x/%4.4x/%4.4x/%lld.%s
%s:%u: failed assertion '%s' %s no field name for id %d of localize id %d
SIStoring.c
field_name
v24@?0r*8^{db_field=SSII[0C]}16
/Library/Caches/com.apple.xbs/Sources/SpotlightCore_Sim/Spotlight-2183.16/spotlight/index/SpotlightIndex/SIStoring.c
void _SIRecomputeSizesWithCallback(SIRef, off_t, dispatch_block_t)
%s:%u: failed assertion '%s' %s magic:%llx
ctx->magic==RECOMPUTE_SIZE_MAGIC
kMDItemSupportFileType
si_populategroup
si_writeBackAndIndex detected corrupted sdb on entry
_kMDItemContentIndexVersion
ContentIndexWritable(content_index)
FPDomainIdentifier
si_writeBackAndIndexWithLiveQueryToggle
db->liveSet->indexCount
content_index
set attributes err
%s:%u: failed assertion '%s' %s si_writeBackDBO failed %d
si_writeBackAndIndex detected corrupted sdb on exit
live.%d.
void _swapIndex(struct flush_index_ctx *, Boolean)
tmp.%ld.
i8@?0
!ContentIndexWritable(indexSet->index[i])
!found
indexSet->index[spot-1]==ctx->idx
%s:%u: failed assertion '%s' %s This should be impossible; this thread is supposed to be  suspended when the other thread changes index sets.
OSAtomicCompareAndSwapPtrBarrier(oldIndexSet,indexSet,(void* volatile*)indexSetPtr)
!ContentIndexWritable(ci)
flush
flush cache err
void _flushCache(struct flush_index_ctx *, Boolean)
ctx->suspend_token == 0
startIndex < indexSet->indexCount
indexSet->indexCount >= j
kMDItemPrimaryRecipientEmailAddresses
kMDItemAdditionalRecipientEmailAddresses
kMDItemHiddenAdditionalRecipientEmailAddresses
kMDItemRecipientEmailAddresses
_Ranking
kMDItemUseCount
canceled
%s:%u: failed assertion '%s' %s magic:%llx ctx:%p ref:%p
ref->magic == (0xc0de10de10dec0de)
void si_recompute_sizes(void *, Boolean)
v24@?0^q8Q16
 inflight
repair_lookupPath
%s:%u: failed assertion '%s' %s Got parent[%d] with id %lld depth: %d
newpath[i] > 0
psid_lookupPath
updateWithNewPath
SIStoring.h
indexSet->currentIndex==~0 || (uint32_t)indexSet->currentIndex<(uint32_t)indexSet->indexCount
indexSet->currentIndex==~0 || ContentIndexWritable(indexSet->index[indexSet->currentIndex])
computePathFP
computePathFS
dbo->parent_oid||dbo->oid==2
_kMDItemStateInfo
com_apple_system_prefs_keywords
kMDItemKeywords
swapIndex
v40@?0^{__SI=Q{SIFileOps=^?^?^?}{SIGuardedFd=iQ}isIi^{SIWatchDog}^{__CFDictionary}{si_missing_oids_s={os_unfair_lock_s=I}^{__RLEOIDArray}^{__RLEOIDArray}}{si_missing_oids_s={os_unfair_lock_s=I}^{__RLEOIDArray}^{__RLEOIDArray}}{os_unfair_lock_s=I}{si_comm_dates_s=^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}}{si_comm_dates_s=^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}}{si_comm_dates_s=^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}}{si_comm_dates_s=^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}}{si_comm_dates_s=^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}^{__CFBag}}^{__CFDictionary}Bi[18^{si_scheduler_token_s}]iI[4^{dispatch_semaphore_s}]{?=[18^{_si_work_scheduler}][20^{_si_workqueue}]}^{datastore_info}{CIMetaInfo=i^{fd_obj}iIIIIIIIIqqiiB}QQ{_opaque_pthread_mutex_t=q[56c]}^{ContentIndexList}^{ContentIndexList}iII^{_SI_PersistentIDStore}{__SIStoreToken={?=CCCCCCCCCCCCCCCC}^{__CFUUID}}ACAIdiI^{__CFDictionary}{_opaque_pthread_mutex_t=q[56c]}{_opaque_pthread_mutex_t=q[56c]}{_opaque_pthread_mutex_t=q[56c]}{os_unfair_lock_s=I}^{__CFBag}{_opaque_pthread_mutex_t=q[56c]}^{__CFSet}^{__CFDictionary}Q^{__CFBag}^{__CFDictionary}{_opaque_pthread_mutex_t=q[56c]}{_opaque_pthread_mutex_t=q[56c]}{_opaque_pthread_cond_t=q[40c]}iIIIIIIIIIIIIIIIIIIIBBAq^{__CFDictionary}{os_unfair_lock_s=I}^{__CFDictionary}^{__CFBitVector}^{si_mobile_journal}^{si_mobile_journal}AqAqd^?^vd{?=^{fd_obj}IIIBq{os_unfair_lock_s=I}}III^{FinderDateFields}{_opaque_pthread_mutex_t=q[56c]}^{fd_obj}^{fd_obj}ii^{_SIIndexCallbacks}^{__CFArray}^{__CFArray}qqqQIIiiBBBBBBBABB^{si_scheduler_token_s}BBBBBQ[4096c]{os_unfair_lock_s=I}{os_unfair_lock_s=I}b1b1b1b1b1b1b1b1b1b1b1b1b1b1b1b2b1^i^{__CFSet}^{__CFDictionary}^{__SIUINT64Set}^{ReverseDirStore_s}^{FileTree_Overlay_s}^{__CFSet}{AccumulatedCounts_s={_opaque_pthread_mutex_t=q[56c]}[256q][256I]}^{TermUpdateSet}{_opaque_pthread_rwlock_t=q[192c]}[16C]Bi^{datastore_info}AIBB[5i]*iI}8^{_xpc_activity_s=}16^B24^{dispatch_group_s=}32
void _swapIndex1(struct flush_index_ctx *, Boolean)
void _swapIndex2(struct flush_index_ctx *, Boolean)
compact err
kMDItemFSSize
kMDItemFSCreationDate
kMDItemFSContentChangeDate
kMDItemFSOwnerUserID
kMDItemFSOwnerGroupID
kMDItemFSNodeCount
kMDItemFSTypeCode
kMDItemFSCreatorCode
kMDItemFSFinderFlags
kMDItemFSHasCustomIcon
kMDItemFSIsExtensionHidden
kMDItemFSIsStationery
SIFetching.c
uid==0
_showAllExtensions
kMDItemLangugeStrId
_kMDItemDisplayNameWithExtensionsSynth
_kMDItemSDBInfo
flattenedIndex < totalFlattenedFieldCount
sortedFieldIdPairIndex < totalFlattenedFieldCount
cannedRequiredAttributeCount == cannedRequiredAttributeIndex
dbIter
kMDItemPath
_fillPlistBytes
_kMDItemFinderExcluded
kSISDBPages
kSISDBIterators
kSISDBObjects
kSISDBCacheHits
kSISetupTime
kSITermTime
kSIPostingsTime
kSIAttributeTime
kSISetupTimeFirstBatch
kSITermTimeFirstBatch
kSIPostingsTimeFirstBatch
kSIAttributeTimeFirstBatch
kSIStartTime
kSIEndTime
kSIEndTimeFirstBatch
kSIWaitTime
kSIActiveTime
kSIQoSLevel
_kMDItemBundleID=com.apple.searchd
SIQueryAddResultFilter
SIQueryC.c
query->_liveUniquedSet==0
query->_liveUniquedQuery==0
query->_liveUniquedFilterQuery==0
query->queryNodes==0
_kMDQueryScope
_kMDItemQuery
kMDLabel_zya2exypzrhulknkk5enqbj33y
kMDLabel_yekauorssrbpta3hdteqgbglma
kMDLabel_26x2uentpjgt7lka65qdcazuya
kMDLabel_j3w3eydksrbbzleqdyl7kbqkuu
kMDLabel_kqde5prblvaibjifrcn4saxjwi
kMDLabel_veyixt7jjffe3g7nfailqcbxny
kMDLabel_qygkxhrfarhtxanqhi264amkku
kMDLabel_hlsi7t7nerhynemqvydgeb26de
adds
_kMDItemTextContentIndexExists
Title
Level1
Level2
Level3
%s:%u: failed assertion '%s' %s Bad query node; unexpected op %d
%s:%u: failed assertion '%s' %s Bad query node; unexpected type %d
holder
!isNegativeQuery(node->lchild)
%llx
processScopes
_kMDQueryItemInScopeForRankingOnly
_kMDItemBundleID
kMDItemFSFileId
kMDItemLogicalSize
_kMDItemCreationDate
_kMDItemContentChangeDate
_kMDItemOwnerGroupID
_kMDItemHasCustomIcon
_kMDItemIsExtensionHidden
_kMDItemNodeCount
_kMDItemIsStationery
_kMDItemTypeCode
_kMDItemCreatorCode
_kMDItemFinderFlags
kMDItemFS
com.apple
com.apple.MobileNotes
_kMDItemQueryPath
Flat
_kMDItemDisplayNameWithExtensions == "X" || (_kMDItemDisplayNameWithExtensions != * && kMDItemDisplayName == "X")
%s:%u: failed assertion '%s' %s Bad generated query mid-node; unexpected type %d
midNode->type == AND_NODE
kMDItemFSLabel
%s=*||%s=*||%s=*||%s=*||%s=*||%s=*||%s=*
!(%s=*||%s=*||%s=*||%s=*||%s=*||%s=*||%s=*)
kMDItemSubject
kMDItemTitle
v32@?0r*8s16^{TokenRange=ss}20s28
CFGetTypeID(completionQueryString) == CFStringGetTypeID()
Spotlight
Bullseye
kCIMatchArray
kCIBitCount
kMDItemContentTypeTree
kMDItemContentType
public.message
com.apple.mail.emlx
com.apple.mail.eml
com.microsoft.entourage.virtual.message
com.apple.ichat.transcript
public.contact
public.vcard
com.apple.addressbook.person
com.apple.addressbook.group
com.microsoft.entourage.virtual.contact
com.microsoft.entourage.virtual.group
com.apple.systempreference.prefpane
public.font
public.bookmark
com.apple.safari.bookmark
com.apple.safari.history
public.to-do-item
public.calendar-event
com.apple.ical.bookmark
com.apple.ical.bookmark.todo
com.apple.ical.ics.event
com.apple.ical.ics.todo
com.microsoft.entourage.virtual.event
com.microsoft.entourage.virtual.task
public.movie
com.apple.quicktime-movie
public.mpeg-video
public.mpeg-4
public.mpeg
public.3gpp
public.3gpp2
com.apple.application-bundle
com.apple.application-file
com.apple.dashboard-widget
public.folder
com.apple.mount-point
public.audio
public.mpeg-4-audio
com.apple.protected-mpeg-4-audio
com.adobe.pdf
com.apple.localized-pdf-bundle
public.presentation
com.microsoft.powerpoint.ppt
com.apple.keynote.key
com.apple.iwork.keynote.key
public.image
com.apple.motion.project
com.apple.iwork.pages.pages
com.apple.iwork.pages.sffpages
com.apple.iwork.pages.template
com.apple.iwork.pages.sfftemplate
public.rtf
com.apple.rtfd
com.apple.flat-rtfd
com.microsoft.word.doc
org.khronos.collada.digital-asset-exchange
public.plain-text
public.html
public.xhtml
public.shell-script
public.source-code
public.unix-executable
com.apple.xcode.project
com.apple.xcode.model
com.apple.xcode.archive
com.apple.xcode.docset
com.apple.xcode.projectdata
com.apple.xcode.dsym
com.apple.xcode.configsettings
com.apple.xcode.usersettings
com.apple.xcode.strings-text
com.apple.xcode.plugin
com.apple.xcode.mom
com.apple.property-list
dyn.ah62d4rv4ge81a7dk
dyn.ah62d4rv4ge80u5pbsa
com.apple.dashcode.xml
com.apple.dashcode.css
com.apple.dashcode.javascript
com.apple.dashcode.json
com.apple.dashcode.manifest
com.apple.interfacebuilder.document
com.apple.interfacebuilder.document.cocoa
com.apple.rez-source
com.apple.iphone.developerprofile
com.apple.iphone.mobileprovision
com.apple.coreanimation-bundle
com.apple.coreanimation-xml
com.sun.java-class
com.apple.scripting-definition
com.apple.dt.document.workspace
com.apple.dt.document.scheme
com.apple.dt.ide.plug-in
com.apple.dt.dvt.plug-in
com.apple.dt.document.snapshot
com.apple.dt.bundle.unit-test.objective-c
com.apple.instruments.tracetemplate
com.apple.quartzdebug.introspectiontrace
com.apple.applescript.text-object
com.apple.applescript.data-object
com.apple.applescript.url-object
com.apple.applescript.alias-object
com.apple.symbol-export
com.apple.mach-o-binary
com.apple.mach-o-object
com.apple.mach-o-executable
com.apple.x11-mach-o-executable
public.object-code
com.microsoft.windows-executable
com.microsoft.windows-dynamic-link-library
com.sun.java-archive
com.sun.web-application-archive
com.apple.xcode.plugindata
com.apple.dt.playground
com.apple.iwork.numbers.sffnumbers
com.apple.iwork.numbers.numbers
com.apple.iwork.numbers.template
com.microsoft.excel.xls
org.openxmlformats.spreadsheetml.sheet
public.spreadsheet
public.xml
com.apple.log
com.apple.crashreport
com.apple.spinreport
com.apple.panicreport
com.apple.shutdownstall
com.apple.hangreport
public.json
public.log
public.content
com.microsoft.excel.sheet.binary.macroenabled
org.openxmlformats.spreadsheetml.sheet.macroenabled
com.apple.protected-mpeg-4-audio-b
com.audible.aa-audiobook
com.audible.aax-audiobook
kMDItemAuthors
kMDItemRecipients
%s/%s
_kMDItemQueryPath = "stuff"
_kMDItemTimeMachinePath = "stuff" && _kTimeMachineOldestSnapshot<=0 && _kTimeMachineNewestSnapshot>=0))
%s%lld
_kMDItemTimeMachinePath = "stuff"
_kMDItemTimeMachinePath%lld
_copyFile
copyFile.c
wLen <= actual
copyFileFallback
journalAttr.
deferAttr.
v16@?0r^{si_playback_info=IIIIq(?={?=IdIIIqqQ}{?=IQ}{?=II}{?=q*iccc}{?=ii*I}{?=dQ}{?=i}{?=q})}8
CreateIndex
OpenIndex
OpenIndexShadow
UpdateItem
AddItemError
DeleteItem
DeleteItemError
AddJournalItem
UpdateJournalItem
DeleteJournalItem
CloseIndex
SyncIndex
SyncIndexError
ShadowIndex
ShadowIndexError
NewJournal
UnlinkJournal
NewDeferJournal
UnlinkDeferJournal
MergeLive
MergeScan
ShutDown
Dirty
%s pid: %d time: %s syncCount: %d scanCount: %d liveCount: %d serialNumber: %lld consumedSerialNumber: %lld recoverTimeStamp:%s (%ld)
%s pid: %d time: %s syncCount: %d scanCount: %d liveCount: %d serialNumber: %lld consumedSerialNumber: %lld
%s pid: %d time: %s syncCount: %d scanCount: %d liveCount: %d
%s time: %s
%s time: %s recoverTimeStamp:%s (%ld)
%s journal.%d
%s oid: 0x%llx %lld transaction: %d
%s oid: 0x%llx %lld
%s id: %d oid: 0x%llx %lld
NewLiveIndex position: %d base: %lld
%s position: %d count: %d
NewBundleGroup %d 0x%x %s
Playback start
Playback end
%s transaction: %d id: %s oid: 0x%llx serial: %lld
%s id: %s oid: 0x%llx serial: %lld
%s transaction: %d id: %s oid: 0x%llx serial: %lld read: %d
%s id: %s oid: 0x%llx serial: %lld read: %d
%s transaction: %d id: %s oid: 0x%llx serial: %lld read: %d flagged: %d
%s transaction: %d id: %s oid: 0x%llx serial: %lld read: %d flagged: %d color: <null>
%s transaction: %d id: %s oid: 0x%llx serial: %lld read: %d flagged: %d color: %d
si_activity_journal.c
offset+dataSize<1024
### invalid type %d at offset %ld
%lld
### unknown type %d at offset %ld
%F %T
yMdHms
%04d-%02d-%02d %02d:%02d:%02d
indexState
CIMetaInfoCreate
CIMetaInfoRead
ContentIndexCommon.c
metaInfo->shadowedGeneration <= metaInfo->cleanGeneration
i20@?0^{__ContentIndex=}8B16
remapping%ld
remapping%d
newId>0 && newId < count
_CIMetaInfoSync
CURRENT_PROJECT_VERSION
IOPrimaryInterface
IOPropertyMatch
IOService
IOMACAddress
%02x
CIRemapping
kIndexRemappingBarrier
qsort_oids.c
TermIdStore.c
getNum(ts->termIdCount)
getNum(ts->termIdSize) >= getNum(ts->termIdCount)
%s:%u: failed assertion '%s' %s tid:%d, ct:%d, fr:%llx
termID+count == ts->store._freeRegion / sizeof(disk_TermData)
ts->store._freeRegion == ((offset_t)getNum(ts->termIdCount)) * sizeof(disk_TermData)
readBuffer
termIdStoreShadow
TermTrie.c
trie->dataAllocator
%s:%u: failed assertion '%s' %s invalid length for %s
term_len
level->follows[i]==0
level->follows[pos]==0
l->data.termLen <= (1024+20)
[fl] 
[l] 
[f] 
(2) 
(0) 
[*] 
cur->data.termLen>=term_offset
tmpLevel.payload==((void*)0)
TermTrieKindList==((unsigned)((tmpLevel.follows[cur->data.termData[term_offset]]) & 3))
((void*)((tmpLevel.follows[e->data.termData[term_offset]]) & ((~(uintptr_t)0)-3)))!=0
term_len <= CI_UTF8CHARS_BUFFER_SIZE
__builtin_popcount(compactLevel->size)==1 && slot > 1 && slot <= 5
level->size>=level->count
depth<15
count<size
__builtin_popcount(entry_size)==1 && slot > 1 && slot <= 5
result!=0
result==0
kIndexOptionReadOnly
B16@?0i8i12
Suspend
Resume
SIOpenIndexAtPathWithCallbacks_block_invoke_3
index flush suspend queue
SIVirtualPSIDSupport.c
malloc_size(map)==0
SI_PersistentIDStore
depth<=513
_oidParentForOid
/Network/
CIPayloadData.c
PayloadIterator.c
!queue->split
changes->hole <= changes->count
changes->hole<=changes->count
i <= changes->hole
(((iter->ptr) & 0x3FFFFFFFFFFFFFFF))==next
((iter->ptr) & 0x3FFFFFFFFFFFFFFF)==next
%s:%u: failed assertion '%s' %s nxtLink: %lld. compact
iter->compact == false
%s:%u: failed assertion '%s' %s Unexpected value for nextLink: %lld. next=%lld barrier=%lld split=%lld
(OFFSET_GET_VALUE(nxtLink) <= barrier && next>barrier)|| (OFFSET_GET_VALUE(nxtLink)<iter->split)
(((iter->ptr) & 0x3FFFFFFFFFFFFFFF)) >= ((oldPtr) & 0x3FFFFFFFFFFFFFFF) || oldPtr==0x3FFFFFFFFFFFFFFF
range.length == 1
bits == ((void*)0)
range.location > 0
PQueue.h
!queue->split || queue->splitPoint>=offset_t_GET_VALUE(value)
MDUnicodeConverter
CIQuery.c
pos<(secondaryCount+nodeCount)
fields
v28@?0I8^{RelativePosting=I{?=II}}12^{RelativePosting=I{?=II}}20
field >= 1
asserted
__CIMatchQueryNodesLazy
v20@?0^v8i16
v16@?0^{tree_node={?=b63b1}{?=b63b1}{TermUpdate=(?={?={RelativePosting=I{?=II}}I}{?={UpdatePosting=I{?=IQ}}})S[0C]}}8
kSearchItemTypeInvalid!=item_type
v16@?0^{RelativePosting=I{?=II}}8
v16@?0q8
v24@?0q8^{lt_trie_node=*^^{lt_trie_node}CCC}16
TermTrie.h
str_len==resolve_len
%s:%u: failed assertion '%s' %s %d
termLen <= CI_UTF8CHARS_BUFFER_SIZE
loc 
v20@?0^{QueryNode=**Iii^{icu_search_context}^{icu_regex}^{levenstein_automaton}I}8I16
posting
%s.mds.%d.%d.compactPayloads1.idx
%s.mds.%d.%d.compactPayloads2.idx
CIPayloadCompact.c
*canceled || PayloadPulsesCount(&ctx.src) > PayloadPulsesCount(&ctx.dst)
PayloadPulsesCount(&ctx.src) == 1
CICompactPayloads
PayloadScannerPosition(&ctx.scanner) > p.offset && PayloadScannerPosition(&ctx.scanner) < p.offset+p.length
_PayloadScannerReadNextChar
PayloadPulsesWrite
PayloadPulsesReorder
list
list->items
PayloadScannerPosition(s) + runLength <= s->end
type >= 0 && type <= 2
i < 10
i < 5
storage.h
position && position < inMap->count
%s:%u: failed assertion '%s' %s offset:%lld, free_region:%lld
inOffset<inStorage->_freeRegion
%s:%u: failed assertion '%s' %s offset:%lld, size:%lld, free_region:%lld
!check_size||inOffset+inSize<=inStorage->_freeRegion
(offset_t)(intptr_t)result !=inOffset
%s:%u: failed assertion '%s' %s offset: %lld end: %lld
p1.hasLength==p2.hasLength
(pe1.docId == 0 || pe2.docId == 0) || pe1.docId > pe2.docId || (type1 != postingTypeNormal || type2 != postingTypeNormal)
pe1.docId == 0
pe2.docId == 0
PayloadScannerPosition(s) + remaining <= s->end
_type >= 0 && _type <= 2
PayloadScannerPosition(scanner) == position
termId < maxTermId
PayloadScannerPosition(s) + docInfoLength <= s->end
%s:%u: failed assertion '%s' %s %s
ldb.c
len > (off1-off)
copyDataForUniquedValue
%s:%u: failed assertion '%s' %s Expected offset %ld to fit in size %ld
fLen >= fOffset
last_id<dbfs[i].name_id
last_offset == pdbo_offset
field
%s:%u: failed assertion '%s' %s field:%d(%s), type:%d, flags:0x%x
field_id!=0
*offset <= buffer_size
%s:%u: failed assertion '%s' %s Overflow %ld + %ld
(size_t)dbo->used_bytes+(size_t)dbf->data_len < (size_t)UINT32_MAX
dbo->size == (old_size<<1)
%s:%u: failed assertion '%s' %s Buffer overflow %ld + %ld > %ld
(size_t)dbo->used_bytes+(size_t)dbf->data_len <= (size_t)dbo->size
inflateDBFData
sizeof(db_uint32_t) + (size_t)dbo->used_bytes <= (size_t)dbo->size
%s:%u: failed assertion '%s' %s Buffer overflow: %ld + %ld > %ld
*offset+len <= buffer_size
%s:%u: failed assertion '%s' %s dbo overflow: %ld + %ld > %ld
(size_t)len + (size_t)dbo->used_bytes <= (size_t)dbo->size
%s:%u: failed assertion '%s' %s Expected %ld + %ld <= %ld
sizeof(uint8_t) + (size_t)dbo->used_bytes <= (size_t)dbo->size
sizeof(uint16_t) + (size_t)dbo->used_bytes <= (size_t)dbo->size
sizeof(uint32_t) + (size_t)dbo->used_bytes <= (size_t)dbo->size
sizeof(uint64_t) + (size_t)dbo->used_bytes <= (size_t)dbo->size
%s:%u: failed assertion '%s' %s Expected len %ld to contain new data size %ld - %ld
(size_t)len >= (size_t)(fOffset-saveOffset)
(size_t)dbf->data_len + (size_t)dbo->used_bytes <= (size_t)dbo->size
%s:%u: failed assertion '%s' %s Expected offset %ld plus len %ld to fit in size %ld
*offset+dbf->data_len <= buffer_size
%s:%u: failed assertion '%s' %s Expected %ld <= %ld
%s:%u: failed assertion '%s' %s Expected len %ld plus used_bytes %ld to fit in dbo %ld
%s:%u: failed assertion '%s' %s Unexpected type %d
db2_open_query_with_expr
/Library/Caches/com.apple.xbs/Sources/SpotlightCore_Sim/Spotlight-2183.16/spotlight/core-db/serial-db2/sdb2_query.c
db2_read_query
sdb2_die
%s:%u: failed assertion '%s' %s %s:%d : %s : %s
sdb2.c
db2_page_uncompress_swap
lzfse
deflate
db2_create_datastore
/Library/Caches/com.apple.xbs/Sources/SpotlightCore_Sim/Spotlight-2183.16/spotlight/core-db/serial-db2/sdb2.c
Multiple threads entering in sdb!
store.db
%sStr-%d.map
Multiple threads in sdb! (leaving)
v16@?0^v8
i12@?0i8
db2_update_datastore_state
db2_check_datastore
db2_get_datastore
_kMDItemRelatedObjects
_kMDItemRelatedObjectsWithBundleID
_kMDItemLaunchString
_kMDItemActivityLaunchDates
_kMDItemRankingLaunchStrings
_kMDItemRankingLaunchDates
_kMDItemGroupId
_kMDItemShortcutLastUsedDate
kMDItemAttributeChangeDate
kMDItemLastUsedDate
kMDItemLastUsedDate_Ranking
kMDItemUsedDates
_kStoreMetadataVersion
kMDStore
db2_shrink_cache
db2_flush_datastore
db2_commit_sync_datastore
db2_shadow_datastore
db2_commit_shadow_datastore
db2_commit_shadow_complete_datastore
db2_release_datastore_no_sync
db2_dirty_datastore
db2_sync_datastore
db2_clear_docids
newSize<=oldSize
db2_apply
%s:%u: Unexpected code path %s 
db2_store_obj
db2_cas_obj
db2_update_obj_callback
db2_delete_obj_with_flags
obj iter read queue
dboi->version==0xdb2
dboi->isSuspended
db2_perform_callback
db2_get_obj_callback
db2_add_field_with_cache
field_flags & DB_FIELD_ARRAY_VAL
field:%d extras:%d expected:%d type:%d expected:%d  %s
(db_uint32_t)name_id!=((db_uint32_t)~0) && (db_uint32_t)name_id!=((db_uint32_t)-2)
dbf->flags & DB_FIELD_ARRAY_VAL
B24@?0r*8r*16
_data_map_needs_sync(dst->_string_table[i]) == 0
dst->string_table[i]->dirty_page == 0
(dst->dbm->flags& 0x0001) == 0
db2_set_dirty_chunks
kMDItemLanguages
kMDItemKind
kMDItemDisplayName
i20@?0^{data_map_s=}8i16
db2_garbage_collect_strings
db2_deserialize_cache_block_invoke
v24@?0^I8Q16
(write_size & ((1 << 12)-1)) == 0
(offset & ((1 << 12)-1)) == 0
update_db_header
copy_datastore
load_map
sdb_string_table_zone
page_free
(((off_t)(pgnum) << (dst->pg_shift)) & ((1 << 12)-1))==0
!updatedDirty
_add_dirty_chunk
%s:%u: failed assertion '%s' %s ERR: Can't add dirty chunks to a read-only db %s
%s:%u: failed assertion '%s' %s ERR: Chunk size is null
size
flush_updateset_locked_block_invoke
flush_updateset_locked_block_invoke_2
i32@?0q8r^{?=I[0C]}16B24i28
i20@?0q8I16
ldb.h
b0 < 0xE0
(dst->const_flags & 0x8) == 0
_flush_cache_entry
db_compress_cache
(size_t)dbp->used_bytes <= sz
db_split_page
in_cached==entry->cache_dbps
(size_t)(*dbpp)->size <= malloc_size(*dbpp)
map_check_size
db_shove_page
do_string_update || (flags & 0x000000f0)==0
page_release_dirty_compressed
map_write
page_release
sync_dirty_chunks
num_chunks == dst->num_chunks
_dirty_datastore_locked
_page_alloc_fetch
load_string_table
prev_dnt->_next_ptr==0
num_string_pages == 0
string_id == str_index
_get_string_and_length_for_id
!(flags& 0x80000000)
string_table->dirty_page == 0 ||string_table->dirty_page==dnt
this_ret!=17
string_table->dirty_pgnum==cur_pgnum || (int)string_table->dirty_pgnum==-1
string_table->dirty_page==cur_dnt || string_table->dirty_page==0
grow_string_table
db2_create_obj_postamble
db2_store_obj_preamble
db2_store_obj_inner
cas_obj
_insert_obj
_page_update_obj
%s:%u: failed assertion '%s' %s dbo ends past end of page ([%p, %p] > [%p, %p])
dbo<=end
page_split
dbo<end || prev_dbo<end
copy_end < end
map_update
%s:%u: failed assertion '%s' %s %s : ERR: map_update: page offset doesn't match! 0x%x != 0x%x
dbme->pgnum == pgnum
_real_page_insert_obj
_page_delete_obj_by_oid_and_type
prev
%s:%u: failed assertion '%s' %s Unexpected
dbp->used_bytes != sizeof(db_page)
_page_obj_exists_by_oid_and_type
(ssize_t)subiters[base+i]->count>=0
iter==&dboi->subiterator
iter->dbp->signature == 0x64627032 || (iter->dbp->signature==0 && iter->dbp->size==0)
^v32@?0^v8Q16Q24
v16@?0Q8
subiter_fetch_page
%s:%u: failed assertion '%s' %s obj_iter_fetch_page: ERR: tried to read attr name table data! pgnum 0x%x, flags 0x%x
(dbp->flags & DB_PAGE_STRING_DATA)==0
((*dbpp)->flags & DB_PAGE_STRING_DATA)==0
_page_fetch_with_fd
iter->next_dbp == 0
%s:%u: failed assertion '%s' %s obj_iter_fetch_page: ERR: page came back compressed! pgnum 0x%x
(dbp->flags & DB_PAGE_COMPRESSED)==0
subiter_fetch_next_page_block_invoke
subiter_fetch_next_page_block_invoke_2
page_find_oid_with_flags
dbo->used_bytes >= sizeof(external_db_obj)
core-query.c
up_count>2
up_count==0
count==0
^v16@?0^{query_node=^{query_node}^{query_node}^{query_piece}^v^vSIb8b1b1b1Q}8
^v32@?0^{query_node=^{query_node}^{query_node}^{query_piece}^v^vSIb8b1b1b1Q}8^v16^v24
db_compare_val
<NULL>
$time.iso(%s)
*16@?0*8
bad op
node:%p hash:%llx type:%d lc:%p rc:%p
<null>
node:%p hash:%llx type:%d qp:%p op:%d fn:%s s:%@ lc:%p rc:%p
kMDItemTextContent
_kMDItemOCRContent
<<anon store>>
stack_depth < 2048
parent_item->state == CompareStackItemStateComplete
SYS:mod
q && q->type == 0x04 && q->qp && q->qp->string_buffer
%s%s%s
v32@?0Q8Q16r*24
true
false
InRange
FieldMatch
created.
date
kMDItemUserCreatedUserHandle
user
kMDItemUserCreatedDate
downloaded.
kMDItemUserDownloadedUserHandle
kMDItemUserDownloadedDate
modified.
kMDItemUserModifiedDate
kMDItemUserModifiedUserHandle
printed.
kMDItemUserPrintedDate
kMDItemUserPrintedUserHandle
received.
kMDItemUserSharedReceivedDate
sender
kMDItemUserSharedReceivedSender
receivers
kMDItemUserSharedReceivedRecipient
transport
kMDItemUserSharedReceivedTransport
senderHandle
kMDItemUserSharedReceivedSenderHandle
receiverHandles
kMDItemUserSharedReceivedRecipientHandle
sent.
kMDItemUserSharedSentDate
kMDItemUserSharedSentSender
recipients
kMDItemUserSharedSentRecipient
kMDItemUserSharedSentTransport
kMDItemUserSharedSentSenderHandle
recipientHandles
kMDItemUserSharedSentRecipientHandle
v12@?0I8
(%d) 
ALWAYS FALSE node
@0x%p
ALWAYS TRUE node
@0x%p
OR node     @ 0x%p
AND node    @ 0x%p
NOR node     @ 0x%p
NAND node    @ 0x%p
factor node @ 0x%p flags 0x%x value <%s%s(%s,%s,%s)>
INRANGE
OUTRANGE
factor node @ 0x%p flags 0x%x value <%s%s(%s
FIELD_MATCH
OUT_FIELD_MATCH
factor node @ 0x%p flags 0x%x value <%s%s[] %s %s>
factor node @ 0x%p flags 0x%x value <%s%s[%s%d] %s %s>
factor node @ 0x%p flags 0x%x value <%s%s %s %s>
we got garbage for node @ 0x%p (type %d qp 0x%p)
FieldMatch(
sdb2_qsort.cpp
q>=left
flushsize
right < count
sdb_uniquing_zone
db-common.c
data == name - ht->extra_bytes - sizeof(db_uint32_t)
slot<table->size
bucket.used
probe!=start
slot < table->size
com.apple.spotlightindex.purgablectrl
page-cache.c
dbp->used_bytes<=dbp->size
page_cache_fetch
i16@?0^{db_cache_entry_s=I^{db_page}^{db_page}iqIq}8
%s:%u: failed assertion '%s' %s Pgnum: %u dbp:%p cached_pgnum::%u cached_dbp:%p index:%d size:%d
cache->cache_pgnum[i]==pgnum || (cache->cache_pgnum[i]==0 && (flags & PAGE_DIRTY)==0)
cache->cache_pgnum[i] == pgnum
cache->cache_pgnum[i] != pgnum
pgnum != cache->cache_pgnum[i]
dbp != cache->cache_entries[i].cache_dbps
dbp->flags & 0x0000000C
entry.cache_dirty==0
entry.cache_dbps == dbp
page_cache_deserialize_entries
v12@?0B8
com.apple.metadata.framework.sdb_page_cache
%s:%u: failed assertion '%s' %s Bad cache page at index %d; max %d, start %d
cache->cache_entries[i].cache_dbps->flags & DB_PAGE_COMPRESSION_ENABLED
v28@?0I8S12^q16I24
v20@?0^{search_ctx_s=^{SISearchCtx}d*^vB@?}8C16
query
executeSearchContextCracked
i24@?0r^v8r^v16
kMDQueryResult
SpotlightRelevance
GroupId
MatchedExtraQueriesField
MenuRelevance
NewMatchedExtraQueriesField
ContentRelevance
TextContentDistances
HasTextContentMatch
v20@?0q8B16
SISearchCtx.cpp
kr==0
en-US
v24@?0^{?=QQQQQdd{ci_rankingbits_s=TTTIfI}^{__CFString}iiii[3I]dddfiCBBBB}8^B16
executeSearchCtx_Start
executeSearchContextCracked_2 (overflow)
executeSearchContextCracked_2
lowWaterRoutine
resumeQuery
self->_stoken[i]==0
SISearchCtx.h
ffillPtr[slot] == 0
kMDItemFSInvisible
kMDItemFSName
ffillPtr[0] == 0
accurate_realpath
MDFileUtil.c
rc == 0
/.vol/%llu/%llu
state_find_max_i
generic_state.c
s != 0
v8@?0
_data_map_rdlock
_data_map_unlock
.header
data_map_init
%s.map
%s.header
%s.data
tmp.%s.data.1
tmp.%s.data.2
%s.offsets
%s.buckets
_data_map_needs_sync
sync
update
_data_map_sync_data
_data_map_sync_header
data_map_flush
data_map_destroy
data_map_id_get_with_key_noextra
data_map_id_get_with_key
data_map_get_extra_with_key
data_map_get_data_locked
data ro header
data header
data storage
data offsets
data buckets
i20@?0^{data_map_s={db_rwlock_s={_opaque_pthread_mutex_t=q[56c]}[6{db_rwlock_waiter_list_s=^{db_rwlock_waiter_s}^{db_rwlock_waiter_s}}]^{db_rwlock_waiter_s}^{db_rwlock_waiter_s}^{pthread_override_s}^{_opaque_pthread_t}iiiiB}I^{header_map_read_only}I^{fd_obj}I^{header_map}^{fd_obj}II*I^{fd_obj}II^{offset_entry_t}I^{fd_obj}II^{bucket_entry_t}IIIII{os_unfair_lock_s=I}^{bit_vector}BBBBBBi}8i16
%s:%u: failed assertion '%s' %s 
_data_map_rehash
_data_map_get_bucket_entry
_data_map_commit
commit
syncless commit
data_map_ids_get_locked_with_hash
_data_map_get_offset_entry
_data_map_get_data_entry
disk_utils.h
(b4 & 0x80) == 0
bit_vector.h
bitIndex >= 0
newCapacity > bv->capacity
newBV
_data_map_get_data_id
_data_map_wrlock
bv->_cfbv
%s %s
tmp.%s
_data_map_garbage_compact_collect
/var/tmp
/usr/tmp
/tmp
abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789
%s/sqlite_
/dev/urandom
-journal
%s:%d: sqlite3BtreeOpen failed; dbname:%s; rc = %d
sqlite3BtreeCursor failed; rc = %d
sqlite3BtreeMoveto failed; rc = %d
psid: could not find master fid; rc = %d
psid: %s : danger! master fid %d looks bad! resetting
psid: creating db: %s
(%d), page size %d
Couldn't begin transaction; rc = %d
Couldn't create table; rc = %d
%s:%d: psid: %s : danger! ps store table id %d looks bad! resetting
Couldn't create cursor; rc = %d
Couldn't insert key; rc = %d
Couldn't commit btree; rc = %d
%s:%d: release_psid_store: danger! master_fid %d looks bad.
%s:%d: psid-release: Failed to update the master fid! (0x%x)
sync_psid_store: danger! master_fid %d looks bad. not syncing.
%s:%d: psid-sync: Failed to update the master fid! (0x%x)
Couldn't sync btree; rc = %d
Couldn't commit; rc = %d
get_path_for_id: bogus part len %d (%d/%d/%s)
get_path_for_id: bogus looking part fid (cur fid %d, part fid %d name %s)
get_path_for_id: path index too large! (%d %d : %s)
get_path_for_id: cur fid %d should have parent fid 2 but part->fid == %d
%s:%d: psid-rename: begin error %d updating the file-fid record for fid %d pid %d / %s. 
%s:%d: psid-rename: Could not update the file-fid record for fid %d
%s:%d: psid-rename: failed to insert new record for %d / %s.
%s:%d: psid-rename: failed to delete old record for %d / %s
%s:%d: psid-rename: end error %d updating the file-fid record for fid %d pid %d / %s. 
_sqlite_get: buffer is too small
%s:%d: sqlite3BtreeInsert failed; rc = %d
sqlite3BtreeInsert failed in _sqlite_bulkEnd; rc = %d
sqlite3BtreeDelete failed; rc = %d
%s:%d: sqlite3BtreeCommit failed; rc = %d
psid_insert: master fid corrupted (%d)
%s:%d: psid-insert: failed to store fid 0x%x for path %s
psid-insert: fid 0x%x for path %s
%s:%d: psid-insert: failed to store path %s for fid 0x%x
psid-insert: store path %s for fid 0x%x
%s:%d: psid-remove: Could not delete the file-fid record for fid %d
fsgetpath like %d/%llx
found %s for %llx
Got error
found %x for %s
found %lld for %llx
======^^^^^ si_psid_check_sandbox sandbox (NOT IMPLEMENTED!) count:%ld
%s:%d: Invalid type:%d for schema field:"%s"
%s:%d: Error:%d setting field:%s for oid:%lld
Trying to store %@ = %@
No attribute %s for %llx
No dbo for %llx
We do have a primary query
We do have %d secondary queries
True live query: (%lld) %@
update dbo:%lld %p
no match dbo:%lld %p
slow path dbo:%lld %p
live query:%p time:%f query:%@
*warn* Failed getting store cookie
Starting sync!
%p state: %s
clean -- skip sync
(%d)Unlinked journal %s
synced SIRef:%p recoverTime:%llu
Recovery Complete!
Finished sync!
Failed to get cpumon_params
*warn* Failed to set cpumon_params
*warn* Failed to reset cpumon_params
Attempt to merge (%s/%s/%s/%s)
Failed to transfer live indexes
Merging (%s/%s/%s/%s/%d)
Skipped merge (%s/%s/%s/%s/%d/%d)%s
Advanced transaction id
Deleting empty object failed with error %d
%s:%d: Error %d storing dbo(%llx,%x,%x,%llx,%llx,%llx,%x)
%s:%d: Error %d updating dbo(%llx,%x,%x,%llx,%llx,%llx,%x)
%s:%d: Unexpected transaction id %d != %d
Creating New Index
Opened %s successfully
Try %s/%s
%s:%d: Could not create new content index
Creating store at %s/%s.
%s:%d: Could not create store at path '%s/%s'
%s:%d: Could not create reverse dir store at path '%s'
Failed at %d (%d)
SICloseIndex, terminating:%d
*warn* Index already unavailable, error:%d, reason:"%s", options:0x%lx
*warn* Marking the index as unavailable, error:%d, reason:"%s", options:0x%lx, path:%s
%s:%d: recycle %s
%s:%d: Failed to add field "%s", length:%ld, rc:%d
%s:%d: Failed to store the dbo for field "%s", rc:%d
Recovery issued for %s
Starting forced sync!
Finished forced sync!
Do attribute transfer.
SITransferAttributes from %lld to %lld
Leave.
time stamp%s
Do attribute change.
Enqueue attribute change %llx.
PUSH REPAIR oid: %lld, f:%x
Defer work for %@
Enqueue work for %@
Callback for %@
%s:%d: bad object %@
#index too much enqueued (%ld); defer callback for work unit of %ld
Execute query %@
Starting query %@
QueryId=%{signpost.description:attribute}lld CurrentQoS=%{signpost.description:attribute}x JobType=%{signpost.description:attribute}d
Stalled getAttr because task had pending sets
_SIStartPreheatScheduler for %p
Started initial indexing of %s
Finished initial indexing of %s
*warn* %s called on fs-only or null index %p
%s:%d: No live index
Not supported for read only index
SISetScanCount:%ld full:%s
full scan:%ld
SISetScanCount: Counted %d live indexes
_SIIssueSplit called
%s:%d: %@
Fixed up (formerly) childless item %lld, new parent %lld
Skipped fix up; item %lld, new parent %lld %s
Do directory move.
%s:%d: %p read index state error:%d
%s:%d: %p invalid version:%d
%p read state:%s
%p open index state error:%d
%s:%d: %p open index state error:%d
%s:%d: %p write index state error:%d
%p write state:%s
*warn* invalid corrections commit
*warn* no correction dict passed
*warn* exceeded max for %@
*warn* correctDict exceeded max for %@
*warn* Failed updating index state
%s:%d: Caught mach exception
%s:%d: db_flush_datastore err:%d
%s:%d: flushReverseStore err:%d
%s:%d: store dirStore overlay err:%d
%s:%d: db_store_dirty_chunk_info err:%d
%s:%d: reverseStoreStoreDirtyBitmap err:%d
%s:%d: si_set_index_state err:%d
%s:%d: db_commit_sync_datastore err:%d
%s:%d: commitSyncReverseStore err:%d
%s:%d: db_shadow_datastore err:%d
%s:%d: shadowReverseStore err:%d
%s:%d: db_commit_shadow_datastore err:%d
%s:%d: commitShadowReverseStore err:%d
*warn* Failed storing sizes (%d)
Outer Merge - count:%d live:%s %s
%s:%d: error (%d) getting free space
*warn* Merge canceled - low disk space (%lld %lld %lld)
used:%lld, free:%lld
cindex was added during merge, old start %d new start: %d cindex count:%d
%s:%d: Merging failed
%s:%d: Failed to merge; index at %d is writable
%s:%d: Failed to merge; index at %d is current
Inner Merge - count:%d live:%s %s
%s:%d: open remp failed: %s
Finalizing journal %p %p %lx %s
remapping canceled
Updating item for remap failed with error %d
%s:%d: invalid range - size:%d start:%d count:%d
size:%d start:%d count:%d
mergeCount:%d != count:%d
Not tracing com.apple.spotlight.mds.index-darkwake %s %d %s %s %ld
%p Open fd %s
last_crash_delta: %ld for %s
%s:%d: check_crash_state: %d for %s
%p si state: %s
%p _SIOpenIndexFilesWithState: %d
%s:%d: open meta info error %d
db_check_datastore: %d
file didn't exist, try shadow
reverse store state: %x
*warn* datastore dirty, reverse store needs shadow -- forcing repair (%u, %u, %u)
*warn* datastore needs shadow, reverse store dirty -- forcing repair
*warn* Index version %d out of date, expected %d, recovering
*warn* Index version %d out of date, expected %d, reindexing
ContentIndexOpenBulk: %d opened %p with recovery time %llu
Could not open existing content index
*warn* datastore clean, index dirty, recovering...
%s:%d: %p CIMetaInfoRead err:%d
%s:%d: %p Too many live indexes %d/%d
%s:%d: %p db_update_datastore_state err:%d
%s:%d: %p ContentIndexOpenBulk err:%d
opened SIRef:%p from fast flush with recovery time %llu
%p open from fast flush canceled:%d
*warn* %p open from fast flush failed:%d
Update reverse store with state: %d (%d, %d)
%s:%d: Ignoring missing path store
%s:%d: reverseStoreUpdateState err:%d
Got reverse store with state: %d
%s:%d: si_write_index_state err:%d
%s:%d: openReverseStore err:%d
%s:%d: %p ContentIndexUpdateState err:%d
%s:%d: %p si_write_index_state err:%d
opened index %p with recovery time is %llu)
*warn* clean scan count mis-match expected:%d got %d
*warn* shadow scan count mis-match expected:%d got %d
*warn* clean live count mis-match expected:%d got %d
*warn* shadow live count mis-match expected:%d got %d
%p repair - catchup scan time stamp: %s, base: %ld, repair count: %d, remair max: %ld
Error writing to log file: %d
renaming: %s to %s
%s:%d: move error:%d, %s to %s
unlink (%s)
Disable updates for index in transaction %d
deleting %s
%p _SIOpenIndex: %d %s
Gathering size data for repair
Skipping because index is shut down
Gathering size data for repair (%lld, %lld)
%s:%d: Failed to protect fd with %d %d
flushing idle index at %s.
%s:%d: ContentIndexSyncIndexBulk err:%d
%s:%d: rebuild index for tokenizer (%d) %@
setting low latency: %s
Suspending root scheduler for %p (%s)
Created volume scheduler %p
Created index scheduler %p
restored localized terms
new loc term %d
Size %d: %lld
%s:%d: Failed to get kMDStoreAccumulatedSizes
Count %d: %d
%s:%d: Failed to get kMDStoreAccumulatedCounts
%s:%d: Failed to get metadata dbo
Found %s, size:%lld, syncCount:%d, first:%d, last:%d
Moving %s to %s, syncCount:%d, first:%d, last:%d
No journals to replay for %p, syncCount:%d, first:%d, last:%d, journalSerialNumber:%lld, consumedJournalSerialNumber:%lld
Replaying %d journals for %p, syncCount:%d, first:%d, last:%d, journalSerialNumber:%lld, consumedJournalSerialNumber:%lld
No defer journals to replay for %p, deferSyncCount:%d, first:%d, last:%d, journalSerialNumber:%lld, consumedJournalSerialNumber:%lld
Replaying %d defer journals for %p, syncCount:%d, first:%d, last:%d, journalSerialNumber:%lld, consumedJournalSerialNumber:%lld
Missing %s, syncCount:%d, first:%d, last:%d
Replaying %s, syncCount:%d, first:%d, last:%d
Unlinking dropped file %s
journalSerialNumber:%lld, consumedJournalSerialNumber:%lld
Played back %ld records (skipped %ld), read %lld/%lld bytes
%s:%d: Invalid journal entry - nil bundleID, magic:0x%08lx, size:%ld, pos:%ld, end:%ld
%s:%d: Invalid journal entry, magic:0x%08lx, size:%ld, pos:%ld, end:%ld
%s:%d: Invalid journal entry, magic:0x%08lx, size:%ld, pos:%ld, end:%ld, len:%ld(%ld)
Played back %ld records (skipped %ld), read %lld/%lld bytes, consumedJournalSerialNumber:%lld, minReplaySerialNumber:%lld, maxReplaySerialNumber:%lld
Activated journal %p %p %lx %s
Interrupting indexing; process quitting
*warn* Playback skipping sn: %lld mrsn: %lld csn: %lld
Playback finished.
%s:%d: Invalid journal entry, diskRecord:%p, journalEntryOffset:%lld, journalEntrySize:%ld
%s:%d: Invalid journal entry, magic:0x%08lx, journalEntryOffset:%lld, journalEntrySize:%ld
%s:%d: Invalid journal entry, size:%ld, journalEntryOffset:%lld, journalEntrySize:%ld
%s:%d: Invalid journal entry, size:%ld, extraSize:%ld, journalEntryOffset:%lld, journalEntrySize:%ld
%s:%d: Invalid journal entry, checkSum:0x%08lx, storedCheckSum:0x%08lx, journalEntryOffset:%lld, journalEntrySize:%ld
%s:%d: Invalid journal entry, bundleID:%p, journalEntryOffset:%lld, journalEntrySize:%ld
Index delete bundleID:%@, identifier:%@
Get_base for journal %s
si_delete_attributes_inner oid: %lld
%s:%d: Deleting item failed with error %d
couldn't get dbo for oid: %lld
Zombifying oid %lld
Deleting related item for %s (%s , %s)
Found related item for %s (%s , %s), oid: %lld
Failed to find related item for %s (%s , %s)
%s:%d: bad identifier %@
Deleting item, bundleID:%@ identifier:%@
Index Add bundleID:%@ identifier:%@
Index update bundleID:%@ identifier:%@
isDummy :%@ %@
*warn* update requires existing item :%@ %@
date:%x
found parent oid: %lld (%@) for %@
%s:%d: Failed to update the index for bundleId:%@, serial:%lld, options:0x%x, oid:0x%lld(%lld), updateErr:%d
%s:%d: No write back for bundleId:%@, identifier:%@ serial:%lld, options:0x%x, oid:0x%lld(%lld)
incoming or outgoing counts size mismatch: identifier=%s incomingArraySize=%lld outgoingArraySize=%lld incomingMailArraySize=%lld outgoingMailArraySize=%lld incomingSMSArraySize=%lld outgoingSMSArraySize=%lld incomingCalendarArraySize=%lld outgoingCalendarArraySize=%lld incomingFileProviderArraySize=%lld outgoingFileProviderArraySize=%lld
~~~ sSIMeEmailAddresses: %@, authorPersons: %@
~~~ authorIsMe, recipients: %@
~~~ !authorIsMe, authorContacts: %@
Schedule index flush
Flush not required
*warn* Failed to fetch the dbo for identifier:%@, bundleID:%@, rc:%d
*warn* Failed to find the db field "%s" for identifier:%@, bundleID:%@, rc:%d
*warn* Failed to fetch the dbo for relatedIdentifier:%@, bundleID:%@, rc:%d
Found the dbo for relatedIdentifier: %@, bundleID: %@, identifier: %@, oid: %lld
Failed to fetch the dbo for relatedIdentifier:%@, bundleID:%@, rc:%d (dropping %@)
Remapped related identifier for %@ to relatedIdent %@, bundleID:%@
*warn* Failed to fetch the dbo for relatedIdentifier:%@, bundleID:%@, identifier:%@, rc:%d
Updated "%s" field for relatedIdentifier:%@, bundleID:%@, identifier:%@
*warn* Skipping %@ %@ already had %@
*warn* ====^ Found _kMDItemRequiresImport!
Skipping :EA:%@ %@
New last used date: %@
Skipping :MD:%@ %@ already had %@
%s%@ = %@
Skipping :MD:%@ %@
Deactivating journal %p %p %lx %s
*warn* Failed setting store cookie (%d)
awakenPreheat entered for %p
awakenPreheat continued for %p
awakenPreheat skipped for %p
Shutdown started
Shutdown ended after %f seconds
Index shut down starting for index at %s.
%s:%d: setDir 2 error %d (%s)
Index closed for %s after %f seconds.
Index shut down finished for index at %s after %f seconds.
Shedulers stopped for %s after %f seconds.
shut down starting for spindle:%d count:%d
shutdown setup complete for spindle:%d after %f seconds.
shutdown sync complete for spindle:%d after %f seconds.
shutdown sync-fsync for spindle:%d after %f seconds.
shutdown commit data complete for spindle:%d after %f seconds.
shutdown commit-fsync for spindle:%d after %f seconds.
shutdown commit header complete for spindle:%d after %f seconds.
shut down complete for spindle:%d after %f seconds.
Index shut down starting for index at %d %s.
%s:%d: setDir 1 error %d (%s)
fstat(%d) err: %d
%s:%d: low space for device %d (%s)
%s:%d: Couldn't get index property dictionary
Creating index property dictionary
*warn* Skipping consistency check for %s
*warn* Starting internal consistency check for %s
*warn* Finished internal consistency check for %s. Checks: %d Missing:%d Inconsistent:%d Missing deletes:%d
Index/sdb inconsistency for (sdb)oid %lld; index has oid %lld. doc id: %lld. path: %s
delete attributes consistancy oid: %lld
delete attributes consistancy 2 oid: %lld
Index/sdb inconsistency; wrong doc id for oid %lld; has %lld. path:%s
delete attributes consistancy 3 oid: %lld
*warn* Skipping duplicate oid check for %s
*warn* Starting duplicate oid check for %s
*warn* Finished duplicate oid check for %s. Missing deletes:%d
oid: %lld > max_oid: %lld
Delete (bulk) oid: %lld
#index too much enqueued (%lld/%lld), bundleID:%@ - deferring callback
%s:%d: missing bundle %p 0x%x %@
Search waited %f seconds on the scheduler at qos 0x%x
finishRegisterQuery %@
Search was active (setup) for %f seconds on the scheduler at qos 0x%x
%s:%d: Could not create new live index %@
%s:%d: Prepare for transaction %d
*warn* %s called on fs-only index
%s:%d: Couldn't create live store at %s.
si_set_scancount: Counted %d live indexes
Starting cleanup for transactions below %d
defer vacuum
Vacuum scheduled
Vacuum started
Vacuum needed%s
Merge(2) scheduled
Merge(2) started
full vacuum needed - count: %lld, live count: %lld, delete count: %lld, live delete count: %lld
%s:%d: transfer_live_indexes failed
verifying %s
%s:%d: verify index: %s, err: %d, (%d %d) , (%d, %d)
Set attributes waited for %f seconds
Dummy coming in oid: %lld
deleting oid: %lld
%s:%d: ctx->source: %d != source: %d oid: %lld options: %x
DEQUEUE oid: %lld, o: %x t: %d
Duplicate in flight oid: %lld
*warn* Unexpected transaction id %d. Expected %d. Attempting repair
*warn* Transaction id is now %d
*warn* Items's transaction id %d is too low for the current index %d. Discarding oid %llx.
isDummy oid: %lld
oid is zero: %lld
Couldn't get the group id.
Dictionary claims the importer was the origin, but trail tells us it was not. Treating as normal setAttr call.
%@ = %@
Deleting importer fields failed, rc:%d
db didn't find any existing values
%s:%d: marking item as rendered/engaged failed
%s:%d: db get field failed in counts code
%s:%d: Couldn't update index oid: %lld options: %x updateErr: %d resolveErr: %d
No write back for %lld
Schedule index flush.
All recovery items processed
Dummy for oid %lld
Canceled oid: %lld
Begin setattr with %ld items on %ld threads
%s setattr
%s:%d: Failed to fetch the bundleId/identifier field, oid:0x%llx(%lld), rc1:%d, rc2:%d
%s:%d: Invalid type for bundleId/identifier field, oid:0x%llx(%lld), type1:%d, flags1:0x%x, type2:%d, flags2:0x%x
%s:%d: Missing identifier field, oid:0x%llx(%lld), type:%d, flags:0x%x
%s:%d: Missing bundleId field, oid:0x%llx(%lld), type:%d, flags:0x%x
%s:%d: Failed to update the dbo for oid:0x%llx(%lld), flags:0x%lx, rc:%d
*warn* Got a journal exception at address:%p, map:[%p, %p), name: %s.
*warn* map:[%p, %p), size: %llx
*warn* Stat failed for name: %s.
Set attributes waited for %f seconds%s
%s:%d: Invalid bundleID %ld %@
oid: %lld moved to parent oid: %lld (file)
%s:%d: move dropped %llx retry count exceeded
Move for bad oid: %lld
No parent for oid: %lld
oid: %lld moved to parent oid: %lld
parent %lld unchanged for %lld
%s:%d: Got parent %lld for %lld. Expected %lld (doc %llu)(%d)
%s:%d: Write error %d updating parent
%s:%d: (%p ver:%d main:%s sdb:%s path:%s scan:%d %s, live:%d %s)
(%p ver:%d main:%s sdb:%s path:%s scan:%d %s, live:%d %s)
%s:%d: store_stream_init err:%d
%s:%d: store_stream_flush write err:%d
%s:%d: store_stream_flush sync err:%d
Remove scheduler %s from %s
%d != %d
Workqueue qos: 0x%x relative_priority: %d %@ %@
Stopped %s
boosting %@
Freeing %p
Peek for %p to %p
Peek tags for %p on queue %s
Peek for  %p on queue %s with tagbag %p
Found oid bag for %p on queue %s
Empty oid bag for %p on queue %s
No oid bag for %p on queue %s with tags %p
Found tags for %p on queue %s
No tags for %p on queue %s
QOS work_fun: %d %p
qos: 0x%x %@
QOS enqueue_work: %d %p
Scheduler qos: 0x%x relative_priority: %d %@ %@
Push %p to tags %p
Created tag bag for %p
Enqueueing result: %d %d
Canceling result queue
*warn* Non-numeric in factor array at index %ld: %@
*warn* Bad value in factor array at index %ld: %@
completion weight array too large (%ld): %@
*warn* completion weight array incomplete (%ld): %@
*warn* Non-numeric in weight array at index %ld: %@
*warn* Bad value in weight array at index %ld: %@
extracting field id %d: '%s'
Completion v1 count:%llu
 weight_F:%g score_F:%g len_F:%g fragment_F:%g wf1_F:%g wf2_F:%g wf3_F:%g phrase_F:%g field_F:%g thread_F:%g shortcut_F:%g used_F:%g age_F:%g
len:%ld scoringFragmentCount:%ld fragmentCount:%ld age:%f score:(%llu, %llu) weight:%d computed score:(%g)
Pop: %ld %ld %f (%llu,%llu) %d (%g)
Comparing to parent at %ld (%g) %g
Dropping weak child %ld (%g) %g
Dropping weak parent (%g) %g
Creating suggestion string %@, type %d, with completion %s length:%d weight:%d score:%g
Completion v2 options: 0x%x count:%llu
Dropping similar completion of length %ld
Completion v3 options: 0x%x count:%llu
Creating unescaped string %s with from %s
Dropping dangling parent (%g) %g
Canceling query in SICancel at QoS: %d for job id:%p
QOS si_sdb_enqueue: %d priority: %d
No RootDirectory set for Suggestions
%s:%d: fstat err:%d %s
%s:%d: FAT: bad file size:%d (expected %d - %d) %s
%s:%d: fd_mmap err: %d, %ld
%s:%d: open %s err: %d
%s:%d: COMP: bad file size:%d (expected %d - %d) %s%s
%s:%d: fstat err:%d %s%s
%s:%d: FLAT: file size:%lld (expected %lld - %lld) %s%s
%s:%d: FLAT: bad file size:%lld (expected %lld - %lld) %s%s
%s:%d: Could not recover %s
syncTrie took %f seconds
Re-burst!
%s:%d: copyFile error, src: %s, dst: %s
shadowIndexCompactDirectory took %f seconds
%s:%d: write err: %d, %s
shadowIndexDirectory took %f seconds
Merge update set ... 
Done
Merge took %f seconds
Total merge time: %f seconds
%s:%d: fd_open err: %d
%s:%d: read err: %d
%s:%d: pread err: %d
%s:%d: pwrite err: %d
shadowIndexArrays took %f seconds
Merge %lu terms
Copied term data: %f seconds
Computed ranges: %f seconds
Flush yielded %d times.
Merged terms: %f seconds
Merge Canceled
%s:%d: compressPostings err:%d
Compressed postings data: %f seconds %f total
Mapped Bases: %luKB (%f%% used)
Sparse Bases: %luKB for %d entries (%f%% used)
String arrays: %lluKB %f%% used
resolve trie terms bc:%u : %f seconds
Index %lu starting at %lu ending at %lu
Applier %lu starting at %lu ending at %lu
node count: %d, compare count %d
resolve flat page terms: %f seconds
bucket[%ld] %x %d %s
%s:%d: can't resolve flat store page
String: %s
%s:%d: invalid flat store page (0x%llx)
### trie processing - %d ###
%s:%d: Setting index emergency state
%s:%d: Clearing index emergency state
%s:%d: Reaffirming index emergency state to true
No meta info
invalid meta info, cleanGeneration:%ld, shadowedGeneraton:%ld
no data in index - rebuilding, result:%d
%s:%d: Failed creating %s/%s, result:%d
%s invalid head (%d), will rebuild
%s invalid head (%d), will try to recover
preflight index %s base:%ld count:%d
Unclean shutdown of %s/%s; needs recovery
Open index - no recovery path
Could not open %s/%s; needs recovery
Open index - recovery path
recovery not allowed for %s/%s
index %s base:%ld count:%d
could not recover %s/%s
could not open %s/%s
recover needed, scan date: %s, last valid doc id:%ld, %s
deleting index %s/%s
limbo counts live:%ld scan:%ld recover:%ld internal:%d priority:%d setAttr:%d migrate:%d
Open index bulk: %d
*warn* time stamp should be more recent new:%ld, old:%ld
%s:%d: index invalid
%s:%d: pre-error:%d
%s:%d: indexPrepareForSyncBulk error:%d
%s:%d: preSync error:%d %d
%s:%d: indexPerformSyncBulk error:%d
%s:%d: postSync error:%d %d
%s:%d: indexCommitSyncBulk error:%d
%s:%d: pre-error %d
%s:%d: indexShadowAndCommitBulk error:%d
%s:%d: corrupt index (%s), will rebuild
_CIUpdateContent oid: %lld
delete docId: %d oid: %lld
reassign docId: %d
dup oid (%lld)
%s:%d: index invalid %s
%s:%d: indexPrepareForSync error: %d, %s
%s:%d: indexPerformSync error: %d, %s
%s:%d: indexCommitSync error %d %s
%s:%d: preShadow error:%d %d
%s:%d: postShadow error:%d %d
%s:%d: indexShadowFiles error: %d, %s
%s:%d: indexCommitShadow error: %d, %s
%s:%d: Sync context init error: %d
%s:%d: Sync sync error: %d
%s:%d: Sync commit error: %d
%s:%d: Got error %d passing sync counts to journals
%s:%d: Sync retire error: %d
%s:%d: Sync shadow error: %d
%s:%d: mmap err: %d
%s:%d: expandUnsafeMap errno: %d err: %d
%s:%d: invalid offset %d, %p (%d)
%s:%d: invalid offset %d, %p (%d) s:%d l1:%d l2:%d
%s:%d: error %d updating sync count
Force split for high delete count; %d %d
resolve term ids: %f seconds
creating index at %s
%s:%d: Couldn't statfs parent directory: %s
open index at %s
%s:%d: Failed to open path index
%s:%d: Ignoring failed dirstore open for corespotlight
last term offset: %llu
%s:%d: unexpected sync count %lld %lld %lld %lld, expected %lld
head:%lld fat:%lld compact:%lld flat:%lld dir:%lld
Post init at %lld
At start %lld
Post version at %lld
Pre-loop at %lld
%s:%d: index shadow err:%d at %s
%s:%d: index commit shadow err:%d at %s
Validating %s
%s:%d: %s invalid type %d
%s:%d: %s error walking terms
oid: %lld depth: %d offset: %llu 
%s:%d: %s error walking directoyr store
Validate %s complete %d
%s:%d: trying to modify read only index %s
%s:%d: indexMarkDirty failed - state:%x closing:%d
index updates disabled for %p (%d) from %d
skip index updates disable for %p (%d) from %d; flags 0x%x, disabled at %d
%s:%d: %s marking invalid at %d
%s:%d: can't commit %s
bases.size: %ld (%s)
%s:%d: write(%d) %d err: %d, %s
shadowIndexGroups took %f seconds
%s:%d: can't shadow %s
shadowIndexTermIds took %f seconds
%s:%d: write err: %d
%s:%d: error copying (%s)
recoverIndex: %s
%s:%d: Unrecoverable error: Missing postings file (%s)
*warn* Unrecoverable error: Missing shadow head file (%s) %d
*warn* Unrecoverable error: Missing data in index head file (%s) %d %d
%s:%d: Unrecoverable error: Malformed index head file (%s)
%s:%d: Unrecoverable error: could not open update file (%s)
%s:%d: Unrecoverable error: could not recover term id file (%s)
%s:%d: Unrecoverable error: could not recover term index (%s)
%s:%d: Unrecoverable error: could not recover path index (%s)
%s:%d: Unrecoverable error: could not recover groups file (%s)
%s:%d: Unrecoverable error: could not open shadow head file (%s) %d
%s:%d: Unrecoverable error: could not read shadow head file (%s) %d, %d
%s:%d: Unrecoverable error: could not open index head file (%s) %d
%s:%d: Unrecoverable error: could not write index head file (%s) %d
*warn* recover canceled (%s)
close requested
%s:%d: trying to set to invalid index %s/%s
setDocumentAttributes canceled
%s:%d: trying to add to read only index
%s:%d: TermUpdateSetCreate failed
%s:%d: indexMarkDirty failed
%s:%d: %s setDocumentAttributes error - bad oid/docid mapping oid: %lld, docId: %d, old oid: %lld 
%s:%d: Got error %d
%s:%d: trying to delete from invalid index %s/%s
%s:%d: trying to modify read only index %s/%s
%s:%d: deleteDocument error - docId (%lld) >= max (%d) 
*warn* deleteDocument error: mismatch oid: %ld docId: %ld idxOid: %ld
%s:%d: reassignDocument error - docId (%lld) >= max (%d) 
*warn* reassignDocument error: oid mismatch oldOid: %ld newOid: %ld docId: %ld idxOid: %ld
%s:%d: invalid index: %s
%s:%d: index alreay compact: %s
%s:%d: cant compact writable index: %s
computer new term ids time (%f)
%s:%d: Failed compacting postings
compact_trie time (%f)
index_compact time (%f) - %d
%s:%d: open file error: %d, %s
%s:%d: bad file size: %d, min size %d, %s
%s:%d: map error: %d, size: %lld, %s
%s:%d: ftruncate error: %d, size: %lld, %s
%s:%d: open err: %d, %s
%s:%d: stat err: %d
%s:%d: bad file size: %lldd, min size %lldd, %s
%s:%d: invalid term length: %d
%s:%d: invalid termID: %d, max: %d
%s:%d: invalid posting offset: %lld, max: %lld
Post counts at %lld
Post bv1 at %lld
Post bv3 at %lld
Post bv4 at %lld
should exit
should cancel
Got unexpected 0 payloadCount. Attempting repair.
should flush, tc:%d, limit:%d
Terms + Postings exceed limit, used:%ld, limit:%ld
should flush term info (global), used:%ld, max:%ld
should flush, all:%ld, used:%ld, limit:%ld, total limit:%ld
Flush for high delete count
Out of space growing payloads.
Mark index needs flush
%s:%d: Got exception on %s %s addr:%p start:%p map end:%p sres:%d file_size:%lld dev:%d ino:%lld
%s:%d: Got exception on %s %s addr:%p %s sres:%d file_size:%lld dev:%d ino:%lld
%s:%d: Invalid version (%d) expected (%d)
%s:%d: invalid file (%d, %d, %d)
%s:%d: fstatfs(%d) err:%d
%s:%d: not enought space to compact index - needed: %lld, avail: %lld, device: %lld
%s:%d: NULL payload fd obj
Payloads: %lluKB %f
%s:%d: ftruncate(%s, %lld) err: %d
%s:%d: open error; %ld
%s:%d: pwrite error; %ld
resolve term id offsets: %f
make hot: %f
write postings: %f
update term id offsets: %f
Memsize: %luKB %f%% used
%s:%d: ftruncate err: %d
%s watchdog for %s
%s:%d: Indexing watchdog fired, thread:%p delta:%llus, startTime:%.3f, itemCount:%lu, perItemCost:%lu resumeTime:%.3f endtime:%lld protectionClass:%u
Starting the indexing watchdog, timer:%p, delta:%llus, startTime:%.3f, itemCount:%lu, bundleID:%@
Stopping the indexing watchdog, timer:%p, delta:%llus, time:%.3f, itemCount:%lu, bundleId:%@
%s:%d: invalid storage data
%s:%d: storageInit - inFdPtr == NULL
Memsize: %uKB %f%% used
%s:%d: mmap(%d, %lld) err:%d, %s
sync pages (%d, %d) took %f seconds
%s:%d: ftruncate error %d
%s:%d: head:0x%llx, freeRegion: 0x%llx
mmap (%p) %llx-%llx
%s:%d: mmap(%p, offset: %llx, size: %ld) error:%d, fSize:%lld
mmap (%p) %llx-%llx (%llx-%llx)
%s:%d: offset(%lld) < freeRegion (%lld)
%s:%d: _storageExpand %s error:%d
%s:%d: ftruncate(%lld) error:%d
Store Update Set (t %d, d %d, p %d) took %f seconds
%s:%d: invalid store version %d, expected %d or %d
%s:%d: Failed restoring update set for paths
%s:%d: invalid termLen %d
%s:%d: invalid  postingCount %u > %u
%s:%d: storeStream error %d
%s:%d: lastPosting==0
%s:%d: invalid doc id %d exceeded (%d, %d)
Restore Update Set (t %d, d %d, p %d) took %f seconds
invalid type for %d %@
%s:%d: invalid content token (%d) for %s
createForwardStore:%s
recoverForwardStore:%s
openForwardStore:%s
%s:%d: Failed to open dir store
%s:%d: no path for shadow
Move %llx/%llx
%s:%d: Move would loop in reverse directory store, skipping %lld to %lld
completed flushReverseStore
skip flushReverseStore; %x
completed commitSyncReverseStore: %d
%s:%d: shadowReverseStore fail. metadata = %d
shadowReverseStore: %d
%s:%d: copyFile error, src: reverseDirectoryStore, dst: reverseDirectoryStore.shadow
Completed shadowReverseStore
%s:%d: Failed shadowReverseStore
Completed commitShadowReverseStore
Recovering reverse store on open
Shadowing reverse store on open
Successfully opened from reverse store
Failed open for reverse store
%s:%d: update state (%d) failed err:%d at %d
%s:%d: init storage failed %s
%s:%d: init storage failed %s; could not read header got %ld bytes
leafPageOffset: %llx
_directoryStoreGetParent failed. leafPageOffset: %llx
Set %llx/%llx
Tree page:%p level: %d depth: %d origin: %d size: %d
page:%p depth: %d idx: %d offset: 0x%8.8llx
Flat page:%p level: %d depth: %d origin: %d size: %d
*warn* Flat page: 0x%8.8llx depth: %d exected: %d
oid: %lld parent: %lld
recoverReverseStore
%s:%d: Copy file failed for %s
%s:%d: Failed to read reverse store file %s
%s:%d: Failed to write reverse store header %s
%s:%d: Unexpected state in shadow header %x
Successfully recovered from %s to %s with state %x
skip dbo:%lld %p
live query nodes: %@
Passing up deletion
Attempt to append to queue failed. Releasing result batch
*warn* failed to parse %s
Computed time (%lld) %s from %s
Passing up out of results
Index Should Merge id:%d %p %s
enqueue at qos 0x%x
at qos 0x%x
bitCount: %ld
QueryId=%{signpost.description:attribute}lld CurrentQoS=%{signpost.description:attribute}x
Preiterate
Pack match bits %llx
No permission for %llx
Query detected merge is needed
Result count: %lld
Encoded results in %f seconds!
%p found %ld results
Enter %s
Batch size: %ld. Timeout: %f. Waiting: %d
Refilled oids. More: %s
Not enough data yet. More to collect: %s
Count: %ld
Real Count: %ld
Available at %ld loops: %ld (%ld) keep going:%d
Canceled; leaving with: %ld
Available after %ld loops: %ld (%ld)
(Full)Available: %ld
(Full)Count: %ld
Timeout
keepGoing: %d
Couldn't gather.
Abandoning %ld %ld %d
(Loop end)Available: %ld
Extracted %ld oids in %f seconds! bad batch:%s batch full:%s timeout:%s keepgoing:%s iterator:%s check needed:%s
QueryRefillOids
Early exit %llx%016llx %d
Scope checked %ld dbos in %f seconds!
Permission for %ld items!
Read/evaluated %ld oids in %f seconds!
readSDBForOids %p item count: %ld
categoryCount:%ld
readSDBForOids early exit %p
Created iterator for %ld oids in %f seconds!
Iterator out of results after %ld items
duplicate oid 0x%llx
Query was canceled
Read/evaluated %ld dbos in %f seconds!
QueryReadSDB
readSDBForOids exit %p
Set match bits %llx
%s:%d: Assertion caught during query
Get doc set!
alloc %ld cinodes for %ld noded
Got NULL context from processNodes
Computed doc set in %f seconds!
Couldn't create raw sdb iterator
1 - count: %ld
2 - count: %ld
QueryGatherIndexInfo
Looping %ld
No data for uniqued string %u
%s:%d: Bad string id for %d
No data for uniqued array %u
Clipping at 1.0 for %llx
Clipping at 0.0 for %llx
No last opened date for %llx
No useful date for %llx
%d start, end:%d
Skip at %ld
Updates from %d to %d
1 Disk from %d to %d
Got (%d to %d) Squashed (%d to %d)
Range %d to %d
Finished iterator. Squashed (0 to %d) end:  %d
OID Range %d to %d
Found: %ld
%s:%d: Caught assertion
%s:%d: Caught assertion for iterator %p %s
%s %d %llx%016llx %d
adding oid %ld (%ld %ld)
%s:%d: Expected valid doc set type for %p. Got %d
%s:%d: Date too distant while restting sentinel
%s:%d: Failed reseting sentinel date
%s:%d: Beyond max entries in counts or tried adding out of order
%s:%d: Beyond max entries in counts or tried adding out of order in adding new
%s:%d: Incorrect data size in counts code
%s:%d: Failed updating render/engagement data
%s:%d: unexpected db signature %x
%s:%d: Error unliking store.updates: %d
%s:%d: Error opening store.updates: %d
%s:%d: Error storing dirty sdb pages: %d
%s:%d: err:%d num_chunks:%d > max_chunks:%d
*warn* Restore error: %d, recovering from shadow
%s:%d: fstatfs err:%d
crash data for %s in volume %s?!?
%s:%d: Detected recurring crashes 3 hour window
%s:%d: Detected recurring crashes during compacting
%s:%d: crash count: %d
%s:%d: invalid crash state file (%s) deleting
%s:%d: Retry operation on address %p (%p) %f %d
%s:%d: Repeated error on address %p
%s:%d: state)Got some sort of signal!
%s:%d: state identity)Got some sort of signal!
exception handler not resolved for thread 0x%x
Allocating threads and such.
Creating exception handler thread
Done allocating threads and such.
Adding handler slot:%u port:%d
%s:%d: thread_get_state: %s
%s:%d: thread_set_state: %s
Dropped handler slot:%u port:%d
starting exc_thread loop in task %d
*warn* Got exception on %s addr:%p start:%p map end:%p sres:%d file_size:%lld dev:%d ino:%lld
Merging started (%s) count:%d
%s:%d: open termIdFile error: %d
%s:%d: pwrite error: %d
%s:%d: ftruncate error: %d
%s:%d: Exception raised during merging
Merging %s (%s)
Had to take slow path, items out of order. Inserted at index %d of %d
Mismatched changed count for %lld, count %d
Creating CI mergeIndexDataTrampoline thread
%s:%d: Exception on new index merging
%s:%d: Caught exception  on merge postings %p
start %lld
%p offset %lld
%s:%d: Nextlink out of bounds %lld %lld
%s:%d: %lld %lld %lld
%s:%d: Element outside legal range %lld>=%lld type %d (starting max %lld)
merging lat id %d
Bad doc id %lld (adjusted:%d) encountered during checking (current = %lld)
Mismatched changed count %d for %lld
fd limit %d
%s:%d: fd_open failed, path:%s, name:%s, flags:0x%x, parent_fd:%d, errno:%d
fd_open failed, path:%s, name:%s, flags:0x%x, parent_fd:%d, errno:%d
%s:%d: Open failed on %s child of %d with error %d
%s:%d: lseek(%d %s, o:%lx, w:%d) err:%d
%s:%d: pread(%d %s, o:%lx, s:%d) err:%d
%s:%d: pwrite(%d %s, o:%lx, s:%d) err:%d
%s:%d: write(%d %s, s:%d) err:%d
%s:%d: rename(%s, %s) err:%d
%s:%d: fd_ptr instance was invalidated
open error NULL obj
%s:%d: faccurate_realpath() failed, parent_fd:%d, path:%s, flags:0x%lx, errno:%d
%s:%d: Invalid parent path, currentPath:%s, path:%s, flags:0x%lx
*warn* too many open files, err: %d, closing inactive and trying again
*warn* (%d) - %@
%s:%d: Read depth %d in serialized value set
%s:%d: Read duplicate child entry at %d(%d) in serialized value set
%s:%d: missing end marker
FindTermIDsContext %p empty bucket %x %s %s
FindTermIDsContext %p fuzzy sort %d flat pages: %f seconds
FindTermIDsContext %p, fuzzy bc: %d -> %d
sort %d flat pages: %f seconds
FindTermIDsContext %p invalidate fuzzy pages bc: %u fc: %u gc: %u mc:%u lc: %u s: %f took %f seconds
FUZZY MATCH BEGIN, string:"%s", pattern:"%s", word_match:%s, word_start:%s, threshold:%d
%s match!
no match!
string: %s 
prefix matched against pattern 
normally matched against pattern 
FUZZY MATCH END: %s
%s:%d: Unexpected index base id order, recycling
%s:%d: Overlapping doc ids (%lld>%lld) between indexes %d and %d out of %d. Recycling
new loc field(%d): %@
ctx:%p idx:%p
%s:%d: db_add_field(_kMDItemGroupId) failed, oid:0x%llx(%lld), rc:%d
%s:%d: computePath error: %d oid: %lld parent: %lld
limit:%llu, used:%lld - using live index
DocID<->OID mapping out of sync. Had to do a brute force search. (Expected docId:%lld. Actual docID: %lld. OID: %llu
DocID<->OID mapping out of sync. Orphaned oid. (DocId:%lld. OID: %llu
sdb only update docId: %lld oid: %llu
%s:%d: ContentIndexUpdateContent failed (%d)
%s:%d: ContentIndexUpdateContent failed  (%d)
Update date to %d for oid %llx docId %llx
bad data in dbo (%lld) reimporting flags:%d
%s:%d: si_writeBackDBO failed, oid:0x%llx(%lld), rc:%d
Skipped swapindex
Starting flush
Failed index flush
Completed index flush
Merge slow at %f
force split; index size %lld
force split used:%lld, count:%d, deletes: %ld
force split; disk free %lld less than index size %lld
Flush took %f seconds, split state %d
Finished flush
Skipped flush
Skipped flushing
Transfer from %lld to %lld
Origin exists for %lld to %lld
Target does not exists for %lld to %lld
Reassigning %lld to %lld
Target exists for %lld to %lld
Target needs reimport for %lld to %lld
Target good for %lld to %lld
Store failed during attribute transfer on safe-save (%d)
No origin dbo exists for %lld to %lld
No target dbo exists for %lld to %lld
Target dbo exists for %lld to %lld
New last used date was not in the previous array: %f != %f
Failed adding used date
Failed adding ranking used date
New last used date was not in the previous array: %f
Failed adding used dates
Failed adding use count
ctx:%p %s
repair%s oid: %lld orphan parent: %lld
repair oid: %lld parent oid: %lld skipped
repair oid: %lld skipped
%s:%d: error: %d oid: %lld parent: %lld
%s:%d: SIPersistentIDStoreGetOidPathForOid error:%d at:%d oid:%lld parent:%lld
%s:%d: si_directoryStoreEnsurePath error:%d at:%d oid:%lld parent:%lld
%s:%d: db_cas_obj error: %d oid: %lld
lookupPathByDBO enter oid: %lld  parent: %lld
lookupPathByDBO oid: %lld p1: %lld p2: %lld
lookupPathByDBO error: %d oid: %lld  parent: %lld
*warn* forceToOrphanParent oid: %lld dbo parent oid: %lld parent: %lld original: %d
%s:%d: SIPersistentIDStoreGetParentForOid error:%d at:%d oid:%lld parent:%lld
Skipped compacting
skipping CFNull
no type conversion for %@
Waited %f seconds on scheduler
Running query at priority %d
Current QOS %d
*warn* Invalid query paramater version %d
Adding filter %@ to query %@
%s:%d: Failed adding filter: %@
Passing up change to not match
Stalling query because the task has data in the set queue
check (%s) %@ old:%@ new:%@
siquery_addactivetime %g seconds to %g seconds 0x%x
Factor.
Metadata or Content.
Range query.
Found *=* query
Invalid property name %s
No string for %s = %s
Range query: %@ < %s < %@
Matched factor %s = %@ in %f seconds
*warn* Too few arguments for query: %d
%d: %s
This node is always false.
This node is always true.
And.
%s:%d: scopePath: %@ / %s %f
Unpalatable ranking query: %@
%p: Query completely done
live filter query nodes: %@
no tags
long defer query for %@
defer query for %@
do defer query for %@
don't defer query for %@
_queryGoCracked
Segmenting %s %s
Started normal (grouping) query threadlet.
Started normal query threadlet.
Could not execute query for %p (!)
Couldn't make query string
Sanitized to %@
initWithQuery %@ for fields:%@ and scopes:%@
*warn* queryFromCFString failed for %@
*warn* grouping queryFromCFString failed for %@
*warn* Error creating ranking query for %@
*warn* rulecount %ld bitCount: %ld error
*warn* lifting queryFromCFString failed for %@
*warn* dboFilter queryFromCFString failed for %@
*warn* no fields for CoalescingCollectingQuery
*warn* No primary query
Query is limited to one group; turn off server side grouping
*warn* no or false _completeQuery
Failed creating query
msync(%p) err %d
fsync time %f - %s
ftruncate(%d %s, %lld) error:%d
%s:%d: fstat error (%d)
%s:%d: error (%d) opening %s
%s:%d: ftruncate error (%d)
%s:%d: read error (%d)
canceled
%s:%d: write error (%d)
%s:%d: write failed
%s:%d: write failed - expected:%lld, actual: %lld
copy file %s to %s
%s:%d: copy file error(%d) (%s) (%s)
%s:%d: copy file error(%d) resolving dest fd %d for %s
%s:%d: copy file error(%d) resolving source fd %d for %s
%s:%d: Tried to create index when index already existed %s
%s:%d: flock err: %d,  %s
*warn* flock err: %d,  %s
*warn* Couldn't statfs the CIMetaInfo. errno:%d
*warn* Failed to acquire lock on SMB CIMetaInfo; it might already be open by another machine's mds_stores.
*warn* Trying to acquire lock on CIMetaInfo again fd:%d
*warn* Failed to acquire lock on CIMetaInfo object: errno=%d
%s:%d: invalid generation file, resetting %s
*warn* indexSet:%p count:%d current:%d
*warn* 
%s id:%d flags:%x
%s:%d: sync err: %d
*warn* Failed writing remapping data. Will cause index corruption if remapping fails.
%s(%d) [%d] %s
%s(%d) %s%s
%s(%d) %s
%s%s%s%s
%s fd:%d, error:%d
%s:%d: EFAULT: Retry operation
Couldn't make psid store at %s
%s:%d: getattrlist returned parent id %lld for %lld (%s)
%s:%d: stat succeeded, getattrlist returned error  %d for %lld (%s = %s)
%s:%d: Error (%d) for 0x%llx
Squashed update %u (%llu) from %p
Add %lld to change holder %p
*warn* Failed to map postings: %d
*warn* Failed to allocated guard page error %d
range: %llu %u (%p)
rMin:%lld, uMax:%lld, 
rMax:%lld, uMin:%lld, 
la_transition_context_for_state, current_state: %llu %d: transition_ctx.default_state: %llu %d
### %supdateset processing - %d ###
Compacting %s payloads 
Reorder time (%f)
Compact iteration:%d, src cnt:%d, new cnt:%d, time (%f) ERROR: %d
Compact iteration:%d, src cnt:%d, new cnt:%d, time (%f)
%s:%d: expected term id 1%d
Compacted payloads (%f)
%s:%d: Error %d compacting, retrying
%s:%d: open err: %d
%s:%d: open err:%d
%s:%d: pwrite err:%d
%s:%d: compact missing termID %u
Merge (offset: %llx, length: %llx) (offset: %llx, length: %llx)
Merge (offset: %llx, length: %llx)
Merge time (%f)
%s:%d: Failed to fetch the field for index:%d, nameId:%lu, dst->flags:0x%lx, dst->name:%s
DB Raw
*warn* could not resolve unique dbf value for field %d
DB_FIELD_LOCALIZED_STR: %@. 
DB_VAL: %@. 
db_utf8str: %@. 
Scalar array: %@. 
%s:%d: Invalid string_id:%lu, map_count:%lu, index:%d, dst->name:%s, dst->flags:0x%x valid:%s
%s:%d: marking invalid %s flags:0x%x
%s:%d: Failed to fetch the field for index:%d, nameId:%lu, type:%d, flags:0x%lx(0x%lx), dst->flags:0x%lx, dst->name:%s
Got the wrong field for index:%d, nameId:%lu, type:%d, flags:0x%lx(0x%lx), dst->flags:0x%lx, dst->name:%s
String: %@
C String: %s
%s:%d: Lock failed with error %d
%s:%d: %s : read_query: page at offset 0x%llx not valid (skipping %d)! (0x%x %d %d 0x%x)
%s:%d: %s:%d : %s : %s
%s:%d: db2_page_uncompress_swap: invalid page size, flags:0x%lx, used_bytes:%lu, size:%ld
%s:%d: db2_page_uncompress_swap: invalid page, flags:0x%lx, used_bytes:%lu, uncompressed_used_bytes:%ld
%s:%d: db2_page_uncompress_swap: invalid page, flags:0x%lx, uncompressed_size:%lu, uncompressed_used_bytes:%lu, compression_size_estimate:%lu
%s:%d: db2_page_uncompress_swap: invalid page, flags:0x%lx, uncompressed_size:%lu, uncompressed_used_bytes:%lu
%s:%d: db2_page_uncompress_swap: uncompress(%s) failed, status:%d, flags:0x%lx, src_size:%lu, out_size:%lu, uncompressed_used_bytes:%lu
%s:%d: db2_page_uncompress_swap: uncompressed size mismatch (%lu/%lu)
%s:%d: db2_create_datastore: ERR: Can't create file (%s : %s)
%s:%d: %s : ERR: can't init the map! (%s)
%s:%d: %s : ERR: can't init the string table! (%s)
%s:%d: %s : ERR: Can't write DST header (%s)
%s:%d: %s : ERR: Can't write shadow DST header (%s)
%s:%d: update state (%d) failed err:%d
%s:%d: db2_check_datastore: ERR: could not get parent fdp
%s:%d: db2_check_datastore: ERR: could not open parent
%s:%d: db2_check_datastore: ERR:%d could not get shadow fdp
%s:%d: db2_check_datastore: ERR:%d could not open shadow
%s:%d: %s : db2_check_datastore: ERR: could not read %d bytes
%s:%d: %s : db2_check_datastore: ERR: signature 0x%x != 0x%x. bailing out.
%s:%d: %s : db2_check_datastore: ERR: DST_BUSY
%s : db2_check_datastore:%d (s_flags:%x m_flags:%x)
%s:%d: %s : db2_get_datastore: ERR: could not read %d bytes
%s:%d: %s : db2_get_datastore: ERR: signature 0x%x != 0x%x. bailing out.
%s:%d: %s : db2_get_datastore: ERR: bad page size %d bailing out.
%s:%d: bad shadow. recover.
%s : db2_get_datastore opening - clean needs shadow
%s:%d: %s : db2_get_datastore: ERR: requested recovery from dirty master.
%s : db2_get_datastore open - shadow to master
%s:%d: %s : db2_get_datastore copyFile or copy_datastore err:%d
%s:%d: %s : db2_get_datastore: ERR: both shadow and master are dirty!  no recovery possible.
%s:%d: Invalid string table version (%d %d)
%s:%d: Upgrading string flag data
Flush starting at %f
%s:%d: %s : db2_sync_datastore: !WARNING! write-errors flushing cache. %d
%s:%d: %s : db2_sync_datastore: !WARNING! write-errors writing map. %d
Push dirty string page %d to disk (%d). %d strings
No dirty string page for %d. %d strings
Flush ending at %f
Defragging index...
%s:%d: copyFile: ERR:%d (%s)
%s:%d: sync_dirty_chunks: ERR:%d (%s)
%s:%d: %s : ERR: Can't write DST master header (2: %d)
%s:%d: %s : ERR: Can't write DST header (2: %d)
%s:%d: %s : db2_sync_datastore: !WARNING! prior write-errors invalidate sync.
Push dirty string page %d to disk (%d)
%s:%d: %s : db2_sync_datastore: !WARNING! write-errors flushing cache/writing map.
%s:%d: %s : db2_sync_datastore: ERR: Can't write DST header (%s)
%s:%d: %s : ERR: Can't write DST header (2: %s)
%s:%d: Failed syncing db
Read page:%d sig:0x%4.4x sz:0x%4.4x used:0x%4.4x flags:0x%4.4x
%s:%d: invalid entry oid: 0x%llx type:%d, map[%d] oid:0x%llx type:%d, map[%d] oid:0x%llx type:%d
%s:%d: Delete failed
Expected %ld, found %ld
Missing item: %lld page:%d type %d. Lookup %ld of %ld. startIndex %ld of %ld
%s:%d: Field type %d out of bounds
%s:%d: Field name %s out of bounds
%s:%d: types don't match dbf_flags:%x dfb_type:%d flags:%x type:%d
original field not an array, dbf_flags:%x dfb_type:%d flags:%x type:%d
db_add_field: ERR: dbf is not valid! (dbf %p dbo %p size 0x%x)
%s : ERR: XXXdbg - whoa dude... can't get name ptr for name id %d
%s:%d: invalid sdb page in cache %d
%s:%d: update_db_header failed err:%d at %d for %s
%s:%d: sdb: ERR: copy_datastore: source is not a valid fd
%s:%d: sdb: ERR: copy_datastore: destination is not a valid fd
%s:%d: sdb: ERR: invalid master datastore! (%s)
%s:%d: %s : ERR: 2: failed to write %d bytes at %lld to to_fdp
%s:%d: %s : copy_datastore: ERR: failed to update the header! (%s)
%s:%d: %s : copy_datastore: ERR: failed to update the header 2! (%s)
%s:%d: sdb: copy_datastore: ERR: %d %s: error restoring from master datastore.
%s:%d: %s : copy_datastore:2: ERR: failed to update the header! (%s)
sdb: validate_datastore: ERR: invalid datastore header size
sdb: validate_datastore: ERR: invalid datastore signature: 0x%x
sdb: validate_datastore: ERR: invalid page @ 0x%llx (sig: 0x%x)
sdb: validate_datastore: ERR: failed to read %d bytes at offset 0x%llx
%s:%d: Invalid header ms: %u hs: %u fs: %lld
%s:%d: %s : load_map, invalid entry at %ld, oid:0x%.16llx/0x%.16llx, type:0x%lx/0x%lx, pgnum:%ld/%ld
%s:%d: %s : free: ERR: Danger! page num 0x%x looks bad (signature 0x%x expected 0x%x flags 0x%x)
%s:%d: page_free: ERR: error moving page from %lld to %d (%s)
Skipping string page move from %d to %d -- no string table!
Object page move from %d to %d
%s:%d: page_free: ERR: failed to change the map page offset from %lld to %d
%s:%d: ftruncate(%s, %lld) error: %d
page_free: ERR: tried to free the first & only page of the file (pgnum 0x%x).
Moving string page from %d to %d
Change dirty string page %d to %d (%d)
Change first string page %d to %d (%d)
Push chain string page %d to disk (%d)
%s : ERR: map_change_pgnum: BAD NEWS! pgnum 0x%x not found
%s:%d: %s: ERR: Can't add dirty chunks to a read-only db!
%s:%d: Bad sdb in db_updateset_iterate at page %d
%s:%d: Failed page allocation, oid:0x%llx(%lld), type:%ld, pgnum:%ld, rc:%d
%s:%d: Failed insert, oid:0x%llx(%lld), type:%ld, pgnum:%ld, rc:%d
%s:%d: Failed update, oid:0x%llx(%lld), type:%ld, pgnum:%ld, rc:%d
%s:%d: Failed %s, oid:0x%llx(%lld), type:%ld, pgnum:%ld, rc:%d
Failed delete after failed add/update, oid:0x%llx(%lld), type:%ld, pgnum:%ld, pageRc:%d updateSetRc:%d
%s:%d: Bad sdb in db_updateset_iterate (delete) at page %d
%s:%d: Failed delete, oid:0x%llx(%lld), type:%ld, pgnum:%ld, rc:%d
%s:%d: Failed compressing/splitting page %d error %d
%s:%d: Failed compressing/splitting page %d
%s:%d: ERR: page compression error %d with page %d used_bytes %d disk page size %d
%s:%d: ERR: db_split_page error %d with page %d used_bytes %d disk page size %d
page_compress: ERR: page is already compressed!
Zip Compression ratio: %f good:%lld bad:%lld
Zip Failed compressing %ld bytes
Compression ratio: %f good:%lld bad:%lld
Failed compressing %d bytes
%s:%d: Failed splitting compressed page %d
%s:%d: should not need to split a compressed cache
%s:%d: Failed page_alloc for %d
%s:%d: Failed page_fetch for %d
Nothing found on page %d used_bytes %d
%s:%d: ERR: page_resize error %d with page %d used_bytes %d new page size %d
Forced to split page %d used_bytes %d into pieces of size %d
%s:%d: Page compress failed with error %d at %d/%d
Failure to split page %d used_bytes %d into pieces of size %d
splitting map page %x, new page %x max_oid %llx type %d
%s:%d: Failed releasing dity compressed cache page %d with error %d
%s : ERR: map_split_page: BAD NEWS! pgnum 0x%x not found
%s:%d: %s : map_check_size: ERR FATAL: too many entries! %d / %ld
%s:%d: Failed releasing null page
%s:%d: Failed writing page
%s:%d: Failed writing map
%s:%d: page_release: ERROR: page_fetch caller responsible for making sure compressed page fits after changes.
%s:%d: page_release: page %d used_bytes %d disk page size %d
%s:%d: page_release: ERR: compress error %d with page %d used_bytes %d disk page size %d
%s:%d: Failed writing pgnum %d
%s:%d: sync_dirty_chunks: ERR: Can't determine the shadow file size! (%s)
sync_dirty_chunks: ERR: Failed to map shadow
sync_dirty_chunks: ERR: Failed to map master
sync_dirty_chunks: ERR: Failed to truncate master fd to %lld
%s:%d: sync_dirty_chunks: ERR:%d count:%d expected %d! (%s)
%s:%d: sync_dirty_chunks: ERR: Can't determine the master file size! (%s)
%s:%d: dirty callback returned non-zero
%s:%d: %s : db2_dirty_datastore: ERR: Can't write DST header (%s)
*warn* sdb not page-size aligned. Extending.
%s:%d: Failed allocating page
%s:%d: pwrite(%s, %d, %lld) error: %d
%s:%d: load_string_table: circular string table (pgnum %d)
sdb: load_string_table: ERR: failed to load page @ 0x%x
%s:%d: load_string_table: unexpected page flags (%x %x)
%s:%d: load_string_table: read past bound: dstr (%tx) str_index (%d)
%s:%d: load_string_table: hash_insert: string %s (id %d) already exists (id %p)!
Loaded %d strings for %d
%s:%d: load_string_table: string id mismatch: dstr (%tx) str_id (%d) str_index (%d)
Grow string table %p (%d)
Inserted field name %s with id %d for %d
Push empty string page %d to disk (%d)
Push old dirty string page %p %d to disk (%d)
New string table page %d (%d)
%s:%d: dbo too small
%s:%d: Error %d, oid %llx
%s:%d: Previous write error
test_compress_obj: ERR %d: compressing %d dbo with oid 0x%llx (%d bytes)
%s:%d: Error %d from db_updateset_insert_object
%s:%d: Error %d from flush_updateset_locked
%s:%d: page_update_obj: ERR: tried to read attr name table data! pgnum 0x%x
%s:%d: page_update_obj: ERR: page is still compressed! pgnum 0x%x
%s : update pgnum %d
%s : page_update_obj: ERR: page at num 0x%x has a bad object pgnum %p
%s:%d: page_split: ERR: tried to read attr name table data! pgnum 0x%x
%s : no map update for split at pgnum %d oid (%.16llx) to(%.16llx) dbo:%p end:%p next:%p dbp:%p
dbo %p beyond end of page at %p. Resetting to last at %p
%s : ERR: try_push_insert_obj: BAD NEWS! pgnum 0x%x not found
try_push_right: weird! end %p first %p but num_bytes %d
try_push_left: issshhhn't dat strange? decrease %d num_bytes %d
%s:%d: %s : ERR: map_update: page offset doesn't match! 0x%x != 0x%x
%s : ERR: map_update: did not find old oid %.16llx (%.16llx) dropping update to (%.16llx)
%s : map_update: update pgnum %d oid (%.16llx) to(%.16llx)
%s:%d: page_insert_obj: ERR: tried to read attr name table data! pgnum 0x%x
%s:%d: page_insert_obj: ERR: page is still compressed! pgnum 0x%x
%s : no map update for inserting at pgnum %d (%.16llx)
%s:%d: %s: page_insert_obj, page pgnum:%ld has a bad object at offset:%p
%s : ERR: map_insert: key already present! idx %d %.16llx
%s:%d: page_delete_obj: ERR: tried to read attr name table data! pgnum 0x%x
%s:%d: page_delete_obj: ERR: page is still compressed! pgnum 0x%x
%s : no map update for deleting at pgnum %d (%.16llx)
%s : ERR: map_delete: trying to delete non-existent oid %.16llx (%.16llx), (%d, %d)
Prefetch pages from %ld
(nextpage)Skip prefetch of %ld cache:%d
Failed to find %lld (%d) (offset:%lu first:%llu)
Already found %lld
Wrong next page in db iterator 0x%x %p
%s:%d: obj_iter_fetch_page: ERR: page came back compressed! pgnum 0x%x
%s:%d: Failed reading pgnum %d
%s:%d: db2_page_uncompress_swap failed, error:%d, pgnum:%lu, pgoff:0x%llx, signature:0x%x, size:%d, used_bytes:%d, flags:0x%x, name:%s
%s:%d: page_fetch found an invalid page, pgnum:%lu, pgoff:0x%llx, signature:0x%x, size:%d, used_bytes:%d, flags:0x%x, name:%s
%s:%d: page_fetch marking the dst as corrupted, pgnum:%lu, pgoff:0x%llx, flags:0x%x, name:%s
Prefetch page %d(%d) for db %p
1) Skipping oid %lld at index %ld
2) Skipping oid %lld at index %ld
%s:%d: page_find_oid: ERR: tried to read attr name table data! pgnum 0x%x
%s:%d: page_find_oid: ERR: page is still compressed! pgnum 0x%x
convert_value_to_type: unknown data type 0x%x (val 0x%p)
%s:%d: nil str_val converted_bits: 0x%x field: %s string: %s
NULL
-------------------------------------------------------------------------------------------
%s : node @ 0x%p looks trashed
%s : failed to convert qp @ 0x%p to type 0x%x
Growing hash table %d %d
%s:%d: Large page cache fetch fail for pgnum:%ld, ret:%d
Cache add %d %p %d %p %d %d %d
Forcing Cache Cleanup
%s:%d: Unexpected EOF in page cache preload; got %ld bytes at offset %lld
%s:%d: Missing signature in page cache preload %llx
Pre-loaded %ld cache pages
Cache remove %p %d
QOS executeSearchCtx: %d
Scopes: %@
Entering
File without dbo
File with dbo: ignored for search during initial indexing
File failed primary query
File failed secondary query
PQR had nothing!
Appended datum: %@
Encoding %ld items from set %p for field %s
Setting locale to %s
QOS executeSearchCtx_Start: %d
Search canceled while waiting on scheduler
Search waited %f seconds on the scheduler at qos 0x%x
Search was active (preIterate) for %f seconds on the scheduler at qos 0x%x
Search was active for %f seconds on the scheduler at qos 0x%x
QOS executeSearchContextCracked_2: %d
Search was active (performSearch) for %f seconds on the scheduler at qos 0x%x
Got %ld results
Coalesced result set: %p
Result queue overflowed. Not rescheduling
Query canceled
Low water routine triggered
resumeQuery triggered
QOS executeSearchCtx2: %d
Suspending root query scheduler(%d)
Passing up %ld results for mode %d (removed %ld duplicates)
%s:%d: _data_map_rdlock error %d
%s:%d: _data_map_unlock error %d
%s:%d: param error
found allocated size %lld for %lld %s
%s:%d: offsets fd_mmap error
%s:%d: fd_truncate error
%s:%d: hash fd_mmap error
%s:%d: invalid header size %ld
%s:%d: header fd_mmap error
%s:%d: storage fd_mmap error
%s:%d: offset fd_mmap error
%s:%d: invalid offset size 1 - %ld %d
%s:%d: invalid offset signature
%s:%d: invalid version %d
%s:%d: invalid extra_size %d %d
%s:%d: invalid header size
%s:%d: invalid storage size 1
%s:%d: re-build hash error
%s:%d: invalid hash size 1
%s:%d: exception processing %s
Opened map %s with counts: %d
%s complete %s map with count: %d
%s complete %s header with count: %d
rename %p %s to %s
Deleted %d items from %p[%d]
*warn* Delete strings canceled
rehash %p max id: %d deletes: %d count: %d hash_size: %d
%s:%d: re-build hash error %p
%s complete %s with count: %d
%s:%d: invalid data id %d max %d %p %s
%s:%d: invalid data offset 0x%lx 0x%lx %p %s
added %d to %p
*warn* Got exception on %s addr:%p start:%p map end:%p file end:%d sres:%d dev:%d ino:%lld
%s:%d: _data_map_wrlock error %d
Delete data for id:%d size:%d %s from %p
Delete data for id:%d size:%d from %p
Found %d deleted strings from %p
Deleting id: %d size: %d %s from %p
Deleting id: %d size: %d from %p
333?
333?
333?
333?
333?
333?
333?
333?
333?
fff?
?333333
@@5^
