com.apple.corespeech.cat.xpc
v8@?0
-[CSGestureMonitor isTriggerHandheld]
wakeGestureTimestamp
TQ,N,V_wakeGestureTimestamp
dismissalTimestamp
TQ,N,V_dismissalTimestamp
[SplitterEnabled(%d)]
[Device%d(%@) DoAP(%d)]
[SplitterState:%d]
splitterEnabled
TB,N,V_splitterEnabled
shouldDisableSpeakerVerificationInSplitterMode
TB,R,N
CSAudioInjectionBuiltInEngine
-[CSAudioInjectionBuiltInEngine dealloc]
SampleCount
HostTime
-[CSAudioInjectionBuiltInEngine getBestSampleCountWithOption:]
trigger-time
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
queue
T@"NSObject<OS_dispatch_queue>",&,N,V_queue
delegate
T@"<CSAudioInjectionEngineDelegate>",W,N,V_delegate
keywordAnalyzer
T@"CSKeywordAnalyzerNDEAPI",&,N,V_keywordAnalyzer
circularBuffer
T@"CSAudioCircularBuffer",&,N,V_circularBuffer
lastForwardedSampleCount
TQ,N,V_lastForwardedSampleCount
hostTimeBuffer
T@"NSMutableArray",&,N,V_hostTimeBuffer
uuid
T@"NSUUID",&,N,V_uuid
voiceTriggerEnabled
TB,N,V_voiceTriggerEnabled
connectedDevice
T@"CSAudioInjectionDevice",W,N,V_connectedDevice
isForwarding
TB,N,V_isForwarding
voiceTriggerSampleCount
TQ,N,V_voiceTriggerSampleCount
-[NviDataLogger logData:]
-[NviDataLogger stream:handleEvent:]
oStream
T@"NSOutputStream",&,N,V_oStream
CSVoiceTriggerAssetHandler
-[CSVoiceTriggerAssetHandler getVoiceTriggerAsset:]
/Library/Caches/com.apple.xbs/Sources/CoreSpeech_Sim/CoreSpeech-441.5/CoreSpeech/CSVoiceTriggerAssetHandler.m
observers
T@"NSHashTable",&,N,V_observers
CSAudioSessionController Queue
-[CSAudioSessionController dealloc]
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]_block_invoke
-[CSAudioSessionController _createXPCClientConnectionIfNeeded]
-[CSAudioSessionController _getLocalAudioSessionID]
-[CSAudioSessionController _startMonitoring]
-[CSAudioSessionController _stopMonitoring]
-[CSAudioSessionController _registerInterruptionNotification]
-[CSAudioSessionController _registerAudioRouteChangeNotification]
-[CSAudioSessionController _handleInterruption:]_block_invoke
-[CSAudioSessionController _mediaServicesWereLost:]_block_invoke
-[CSAudioSessionController _mediaServicesWereReset:]_block_invoke
-[CSAudioSessionController _audioRouteChanged:]_block_invoke
-[CSAudioSessionController _teardownXPCClientIfNeeded]
-[CSAudioSessionController CSXPCClient:didDisconnect:]_block_invoke
-[CSAudioSessionController coreSpeechDaemonStateMonitor:didReceiveStateChanged:]_block_invoke
sessionInfoProvider
T@"<CSAudioSessionInfoProviding>",&,N,V_sessionInfoProvider
xpcClient
T@"CSXPCClient",&,N,V_xpcClient
shouldKeepConnection
TB,V_shouldKeepConnection
com.apple.siri.SiriDebug.SpeakerVoiceGradingTrigger
com.apple.siri.SiriDebug.RemoteNearMissGradingTrigger
com.apple.siri.SiriDebug.VoiceProfileAddedTrigger
com.apple.siri.SiriDebug.VoiceProfileSyncTrigger
com.apple.siri.SiriDebug
+[CSSiriDebugConnection launchSiriDebugAppWithMessage:]_block_invoke
v24@?0@"AFSiriResponse"8@"NSError"16
CSMediaPlayingMonitor queue
-[CSMediaPlayingMonitor initializeMediaPlayingState]_block_invoke_2
v16@?0@8
v12@?0I8
-[CSMediaPlayingMonitor _startMonitoringWithQueue:]
-[CSMediaPlayingMonitor _stopMonitoring]
-[CSMediaPlayingMonitor _notePossiblePlayPausedStateChange:]
PLAYING
NOT PLAYING
audioURL : %@, numberOfChannels : %lu, scaleFactor: %f
audioURL
T@"NSURL",R,N,V_audioURL
outASBD
T{AudioStreamBasicDescription=dIIIIIIII},N,V_outASBD
fFile
T^{OpaqueExtAudioFile=},N,V_fFile
scaleFactor
Tf,R,N,V_scaleFactor
announcemessage
Audio/Video
Alarm
CSVolumeMonitor queue
-[CSVolumeMonitor _startMonitoringWithQueue:]
-[CSVolumeMonitor fetchVolumeFromAVSystemControllerForAudioCategory:]_block_invoke
-[CSVolumeMonitor systemControllerDied:]
-[CSVolumeMonitor startObservingSystemVolumes]
-[CSVolumeMonitor _startObservingSystemControllerLifecycle]
CSTimerMonitor queue
-[CSTimerMonitor _startMonitoringWithQueue:]
-[CSTimerMonitor _stopMonitoring]
CSAlarmMonitor queue
-[CSAlarmMonitor _startMonitoringWithQueue:]
-[CSAlarmMonitor _stopMonitoring]
-[CSAudioStreamHolding dealloc]
name
T@"NSString",&,N,V_name
T@"<CSBiometricMatchMonitorDelegate>",W,N,V_delegate
CSAudioInjectionHearstEngine
-[CSAudioInjectionHearstEngine dealloc]
v20@?0B8@"NSError"12
T@"CSKeywordAnalyzerNDAPI",&,N,V_keywordAnalyzer
lastDetectedVoiceTriggerBeginSampleCount
TQ,N,V_lastDetectedVoiceTriggerBeginSampleCount
-[CSAudioZeroCounter getZeroStatisticsFromBuffer:entireSamples:]
-[CSAudioZeroCounter stopReportZeroStatistics]
smartSiriVolume
noiseLevelChannelBitset
LKFSChannelBitset
DistanceChannelBitset
energyBufferSize
noiseLowerPercentile
noiseUpperPercentile
LKFSLowerPercentile
LKFSUpperPercentile
noiseTimeConstant
noiseMicSensitivityOffset
noiseMicSensitivityOffsetDeviceSimple
LKFSTimeConstant
LKFSMicSensitivityOffset
noiseTTSMappingInputRangeLow
noiseTTSMappingInputRangeHigh
noiseTTSMappingOutputRangeLow
noiseTTSMappingOutputRangeHigh
LKFSTTSMappingInputRangeLow
LKFSTTSMappingInputRangeHigh
LKFSTTSMappingOutputRangeLow
LKFSTTSMappingOutputRangeHigh
userOffsetInputRangeLow
userOffsetInputRangeHigh
userOffsetOutputRangeLow
userOffsetOutputRangeHigh
TTSVolumeLowerLimitDB
TTSVolumeUpperLimitDB
noiseWeight
SSVNoiseLevelChannelBitset
TQ,R,N
SSVLKFSChannelBitset
SSVDistanceChannelBitset
SSVEnergyBufferSize
TI,R,N
SSVNoiseLowerPercentile
SSVNoiseUpperPercentile
SSVLKFSLowerPercentile
SSVLKFSUpperPercentile
SSVNoiseTimeConstant
Tf,R,N
SSVNoiseMicSensitivityOffset
SSVNoiseMicSensitivityOffsetDeviceSimple
SSVLKFSTimeConstant
SSVLKFSMicSensitivityOffset
SSVNoiseTTSMappingInputRangeLow
SSVNoiseTTSMappingInputRangeHigh
SSVNoiseTTSMappingOutputRangeLow
SSVNoiseTTSMappingOutputRangeHigh
SSVLKFSTTSMappingInputRangeLow
SSVLKFSTTSMappingInputRangeHigh
SSVLKFSTTSMappingOutputRangeLow
SSVLKFSTTSMappingOutputRangeHigh
SSVUserOffsetInputRangeLow
SSVUserOffsetInputRangeHigh
SSVUserOffsetOutputRangeLow
SSVUserOffsetOutputRangeHigh
SSVTTSVolumeLowerLimitDB
SSVTTSVolumeUpperLimitDB
SSVNoiseWeight
SSVParameterDirectionary
T@"NSDictionary",R,N
CSVoiceTriggerXPCService Queue
-[CSVoiceTriggerXPCService enableVoiceTrigger:withAssertion:xpcClient:]_block_invoke
-[CSVoiceTriggerXPCService setPhraseSpotterBypassing:timeout:xpcClient:]_block_invoke
-[CSVoiceTriggerXPCService setRaiseToSpeakBypassing:timeout:xpcClient:]_block_invoke
-[CSVoiceTriggerXPCService notifyVoiceTriggeredSiriSessionCancelledWithXpcClient:]_block_invoke
-[CSVoiceTriggerXPCService fetchVoiceTriggerDailyStats]_block_invoke
-[CSVoiceTriggerXPCService _createXPCClientConnectionIfNeeded:]
-[CSVoiceTriggerXPCService voiceTriggerXPCClient:didDisconnect:]_block_invoke
-[CSVoiceTriggerXPCService _teardownXPCClientIfNeeded]
T@"CSVoiceTriggerXPCClient",&,N,V_xpcClient
OPP-
PCM-
OPUS_
Ads-
PHS-
-synced
com.apple.CoreSpeech.AudioLogging
+[CSAudioFileManager generateDeviceAudioLogging:speechId:]_block_invoke
FLLR
+[CSAudioFileManager _readDataFromFileHandle:toFileHandle:]
%@%@.wav
%@/%@%@.wav
+[CSAudioFileManager _createAudioFileWriterForAdBlockerWithLoggingDir:inputFormat:outputFormat:]
+[CSAudioFileManager _createAudioFileWriterForOpportuneSpeakListenerWithLoggingDir:inputFormat:outputFormat:]
+[CSAudioFileManager _createAudioFileWriterWithLoggingDir:withLoggingUUID:inputFormat:outputFormat:]
+[CSAudioFileManager _createAudioFileWriterForPHSTrainingWithLoggingDir:inputFormat:outputFormat:]
en_US_POSIX
yyyy_MM_dd-HHmmss.SSS
^%@*
%@(%@)?.wav$
+[CSAudioFileManager cleanupOrphanedGradingFiles]
+[CSAudioFileManager cleanupOrphanedGradingFiles]_block_invoke
v32@?0@"NSString"8@"NSURL"16^B24
attsiri
+[CSAudioFileManager audioFileWriterForAttentiveSiri]
%@.wav
v12@?0i8
-[CSVoiceTriggerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetDownloadMonitor _stopMonitoring]
-[CSVoiceTriggerAssetDownloadMonitor _didInstalledNewVoiceTriggerAsset]
com.apple.MobileAsset.VoiceTriggerAssets.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsIPad.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.new-asset-installed
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.new-asset-installed
Dispose Log Queue
+[CSUtils(Directory) removeLogFilesInDirectory:matchingPattern:beforeDays:]_block_invoke
v24@?0@"NSArray"8^@16
+[CSUtils(Directory) clearLogFilesInDirectory:matchingPattern:exceedNumber:]_block_invoke_2
+[CSUtils(Directory) clearLogFilesInDirectory:matchingPattern:exceedNumber:]_block_invoke
Unable to get %@ for file at %@: %@
q24@?0@"NSURL"8@"NSURL"16
B24@?0@"NSURL"8@"NSDictionary"16
+[CSUtils(Directory) _contentsOfDirectoryAtURL:matchingPattern:includingPropertiesForKeys:error:]
Languages
Footprint
Premium
-[CSAudioPreprocessor resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
-[CSAudioPreprocessor flush]
-[CSAudioPreprocessor _isHeadphoneDeviceWithRecordRoute:playbackRoute:]
sampleRate
Tf,N,V_sampleRate
upsampler
T@"CSAudioSampleRateConverter",&,N,V_upsampler
zeroFilter
T@"CSVoiceTriggerAwareZeroFilter",&,N,V_zeroFilter
beepCanceller
T@"CSBeepCanceller",&,N,V_beepCanceller
zeroCounter
T@"CSAudioZeroCounter",&,N,V_zeroCounter
T@"<CSAudioPreprocessorDelegate>",W,N,V_delegate
set option : allowVoiceTriggerAssetsDownload ? %@;           allowEndpointAssetDownload ? %@;           allowLanguageDetectorAssetDownload ? %@;           allowAdBlockerAssetDownload ? %@;           allowSpeakerRecognitionAssetDownload ? %@
allowVoiceTriggerAssetDownloading
TB,N,V_allowVoiceTriggerAssetDownloading
allowEndpointAssetDownloading
TB,N,V_allowEndpointAssetDownloading
allowLanguageDetectorAssetDownloading
TB,N,V_allowLanguageDetectorAssetDownloading
allowAdBlockerAssetDownloading
TB,N,V_allowAdBlockerAssetDownloading
allowSpeakerRecognitionAssetDownloading
TB,N,V_allowSpeakerRecognitionAssetDownloading
com.apple.assistant
Siri Global
 - %@
CSKeychainValueForAccountAndKey
CSBluetoothManager Queue
-[CSBluetoothManager getBTLocalDeviceWithCompletion:]
-[CSBluetoothManager getBTLocalDeviceWithCompletion:]_block_invoke
v16@?0^{BTLocalDeviceImpl=}8
-[CSBluetoothManager _getWirelessSplitterInfoFromLocalDevice:]
-[CSBluetoothManager _detachBluetoothSession]
-[CSBluetoothManager _attachBluetoothSession]
CSBluetoothManager
-[CSBluetoothManager _sessionAttached:result:]
-[CSBluetoothManager _sessionDetached:]
-[CSBluetoothManager _sessionTerminated:]
-[CSBluetoothManager _setUpLocalDevice]
bluetoothSession
T^{BTSessionImpl=},N,V_bluetoothSession
isAttachingBluetoothSession
TB,N,V_isAttachingBluetoothSession
localDevice
T^{BTLocalDeviceImpl=},N,V_localDevice
pairedDeviceAddresses
T@"NSArray",&,N,V_pairedDeviceAddresses
connectedDeviceAddresses
T@"NSArray",&,N,V_connectedDeviceAddresses
bluetoothSessionSetupGroup
T@"NSObject<OS_dispatch_group>",&,N,V_bluetoothSessionSetupGroup
CSSiriAssertionMonitor queue
-[CSSiriAssertionMonitor init]
-[CSSiriAssertionMonitor _stopMonitoring]
-[CSSiriAssertionMonitor enableAssertionReceived]_block_invoke
-[CSSiriAssertionMonitor disableAssertionReceived]_block_invoke
-[CSSpeakerRecognitionAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSSpeakerRecognitionAssetDownloadMonitor _stopMonitoring]
-[CSSpeakerRecognitionAssetDownloadMonitor _didInstalledNewAsset]
-[CSSpeakerRecognitionAssetDownloadMonitor trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
trialAssetMonitor
T@"CSTrialAssetDownloadMonitor",&,N,V_trialAssetMonitor
com.apple.MobileAsset.SpeakerRecognitionAssets.ma.new-asset-installed
CSAudioFileReader Queue
-[CSAudioFileReader initWithURL:]
-[CSAudioFileReader prepareRecording:]
-[CSAudioFileReader startRecording]
-[CSAudioFileReader _readAudioBufferAndFeed]
-[CSAudioFileReader stopRecording]
T@"<CSAudioFileReaderDelegate>",W,N,V_delegate
nohash
((?:[a-z]|[0-9])*)\.asset
+[CSUtils(ResourcePathHash) assetHashInResourcePath:]
-[CSAdBlockerAssetDownloadMonitor _startMonitoringWithQueue:]
-[CSAdBlockerAssetDownloadMonitor _stopMonitoring]
-[CSAdBlockerAssetDownloadMonitor _didInstalledNewAdBlockerAsset]
-[CSAdBlockerAssetDownloadMonitor trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:]
monitor
T@"CSTrialAssetDownloadMonitor",&,N,V_monitor
com.apple.MobileAsset.AdBlockerAssets.ma.new-asset-installed
CSAudioRouteChangeMonitorImplWatch queue
-[CSAudioRouteChangeMonitorImplWatch activeAudioRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImplWatch _stopMonitoring]
-[CSAudioRouteChangeMonitorImplWatch _notifyHearstConnectionState:]
-[CSAudioSampleRateConverter _createSampleRateConverterWithInASBD:outASBD:]
CSAudioSampleRateConverter.m
Too many buffers
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
-[CSAudioSampleRateConverter convertSampleRateOfBuffer:]
CSLanguageDetectorAssetMonitor
v24@?0@"NSArray"8@"NSError"16
-[CSLanguageDetectorAssetMonitor startMonitor]_block_invoke
en-US
-[CSLanguageDetectorAssetMonitor _supportedLocale:]_block_invoke
v24@?0@"CSAsset"8@"NSError"16
notifyToken
Ti,N,V_notifyToken
T@"<CSLanguageDetectorAssetMonitorDelegate>",W,N,V_delegate
com.apple.MobileAsset.LanguageDetectorAssets.ma.new-asset-installed
com.apple.CoreSpeech.Connection.Listener
-[CSSmartSiriVolumeClient init]
-[CSSmartSiriVolumeClient getVolumeForTTSType:withContext:]_block_invoke
v24@?0@"NSError"8@"CSSmartSiriVolumeEstimate"16
-[CSSmartSiriVolumeClient didTTSVolumeChangeForReason:]_block_invoke
v16@?0@"NSError"8
-[CSSmartSiriVolumeClient _getRemoteServiceProxyObject]_block_invoke
-[CSSmartSiriVolumeClient _getRemoteServiceProxyObject]
com.apple.corespeech.corespeechd.ssv.service
-[CSSmartSiriVolumeClient _createClientConnection]_block_invoke
ssvConnection
T@"NSXPCConnection",&,N,V_ssvConnection
T@"<CSSmartSiriVolumeClientDelegate>",W,N,V_delegate
CSAudioInjectionProvider
ATVRemoteInput
BuiltInMic
-[CSAudioInjectionProvider dealloc]
-[CSAudioInjectionProvider stop]
-[CSAudioInjectionProvider startAudioStreamWithOption:streamHandleId:error:]
-[CSAudioInjectionProvider stopAudioStreamWithStreamHandleId:error:]
BuiltInSpeaker
connectedDevices
T@"NSMutableArray",&,N,V_connectedDevices
builtInDevice
T@"CSAudioInjectionDevice",&,N,V_builtInDevice
bundleTvRemote
T@"CSAudioInjectionDevice",&,N,V_bundleTvRemote
builtInAudioInjectionEngine
T@"CSAudioInjectionEngine",&,N,V_builtInAudioInjectionEngine
audioInjectionEngines
T@"NSMutableDictionary",&,N,V_audioInjectionEngines
latestPluginStreamId
TQ,N,V_latestPluginStreamId
didStartDelayInSeconds
Tf,N,V_didStartDelayInSeconds
-[NSString(XPCObject) _cs_initWithXPCObject:]
RemoteVAD Align Queue
-[CSOpportuneSpeakListener startListenWithOption:completion:]
-[CSOpportuneSpeakListener _startRequestWithCompletion:]_block_invoke
-[CSOpportuneSpeakListener _startRequestWithCompletion:]
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]_block_invoke
-[CSOpportuneSpeakListener stopListenWithStateReset:completion:]
-[CSOpportuneSpeakListener audioStreamProvider:audioBufferAvailable:]
-[CSOpportuneSpeakListener spgEndpointAnalyzer:hasSilenceScoreEstimate:]
audioStream
T@"CSAudioStream",&,N,V_audioStream
spgEndpointAnalyzer
T@"CSSPGEndpointAnalyzer",&,N,V_spgEndpointAnalyzer
remoteVADSPGRatio
Ti,N,V_remoteVADSPGRatio
audioStreamProvider
T@"<CSAudioStreamProviding>",&,N,V_audioStreamProvider
audioSessionProvider
T@"<CSAudioSessionProviding>",&,N,V_audioSessionProvider
latestContext
T@"CSAudioRecordContext",&,N,V_latestContext
isMediaPlayingNow
TB,V_isMediaPlayingNow
remoteVADAlignBuffer
T@"NSMutableArray",&,N,V_remoteVADAlignBuffer
remoteVADAlignCount
TQ,N,V_remoteVADAlignCount
alignBufferQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_alignBufferQueue
audioFileWriter
T@"CSPlainAudioFileWriter",&,N,V_audioFileWriter
T@"<CSOpportuneSpeakListenerDelegate>",W,N,V_delegate
com.apple.corespeech.corespeechd.voiceid.xpc
v16@?0@"NSObject<OS_xpc_object>"8
-[CSVoiceIdXPCClient _handleListenerEvent:]
-[CSVoiceIdXPCClient _handleListenerError:]
utterencePath
audioDevice
audioRecord
voiceTriggerEventInfo
otherCtxt
type
body
result
resultErrorDomain
resultErrorCode
xpcConnection
T@"NSObject<OS_xpc_object>",&,N,V_xpcConnection
NviError
-[CSNNVADEndpointAnalyzer init]
-[CSNNVADEndpointAnalyzer preheat]
-[CSNNVADEndpointAnalyzer reset]
-[CSNNVADEndpointAnalyzer processAudioSamplesAsynchronously:]
-[CSNNVADEndpointAnalyzer recordingStoppedForReason:]
-[CSNNVADEndpointAnalyzer stopEndpointer]
-[CSNNVADEndpointAnalyzer resetForNewRequestWithSampleRate:recordContext:recordSettings:]
endpointStyle
Tq,N
delay
Td,N
startWaitTime
automaticEndpointingSuspensionEndTime
minimumDurationForEndpointer
lastEndOfVoiceActivityTime
Td,R,N
lastStartOfVoiceActivityTime
bypassSamples
endpointMode
interspeechWaitTime
endWaitTime
saveSamplesSeenInReset
TB,N
T@"<CSEndpointAnalyzerDelegate>",W,N
implDelegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N
canProcessCurrentRequest
activeChannel
TQ,N
endpointerModelVersion
T@"NSString",R,N
elapsedTimeWithNoSpeech
T@"<CSEndpointAnalyzerDelegate>",W,N,Vdelegate
T@"<CSEndpointAnalyzerImplDelegate>",W,N,VimplDelegate
TB,R,N,VcanProcessCurrentRequest
TQ,N,VactiveChannel
Tq,N,VendpointStyle
Td,N,Vdelay
Td,N,VstartWaitTime
Td,N,VautomaticEndpointingSuspensionEndTime
Td,N,VminimumDurationForEndpointer
Td,R,N,VlastEndOfVoiceActivityTime
Td,R,N,VlastStartOfVoiceActivityTime
com.apple.corespeech.corespeechd.activation.xpc
-[CSActivationXPCClient dealloc]
-[CSActivationXPCClient _handleListenerEvent:]
-[CSActivationXPCClient _handleListenerError:]
-[CSActivationXPCClient notifyActivationEvent:completion:]
event
T@"<CSLanguageDetectorDelegate>",W,N,V_delegate
+[CSAudioRecordContext defaultContext]
CSAudioRecordTypeUnspecified
CSAudioRecordTypeHomePress
CSAudioRecordTypeWiredHeadsetButtonPress
CSAudioRecordTypeBluetoothHeadSetButtonPress
CSAudioRecordTypeUIButtonPress
CSAudioRecordTypeServerInvoke
CSAudioRecordTypeVoiceTrigger
CSAudioRecordTypeStark
CSAudioRecordTypeTVRemote
CSAudioRecordTypeRaiseToSpeak
CSAudioRecordTypeHearstDoubleTap
CSAudioRecordTypeHearstVoice
CSAudioRecordTypeJarvis
CSAudioRecordTypePost
CSAudioRecordTypeDictation
CSAudioRecordTypeVoiceTriggerTraining
CSAudioRecordTypeOpportuneSpeaker
CSAudioRecordTypeRemoraVoice
CSAudioRecordTypeUnknown
recordType[%@] deviceId[%@] alwaysUseBuiltInMic[%d]
Tq,N,V_type
T@"NSString",&,N,V_deviceId
TB,N,V_alwaysUseRemoteBuiltInMic
xpcObject
T@"NSObject<OS_xpc_object>",R,N
alwaysUseRemoteBuiltInMic
deviceId
+[CSUtils(LanguageCode) getSiriLanguageWithFallback:]
CSStopRecordingReasonDefault
CSStopRecordingForClientEndpoint
CSStopRecordingForServerEndpoint
CSStopRecordingForReleaseAudioSession
CSStopRecordingForRequestCancellation
, %llu}
stopRecordingReason
TQ,N,V_stopRecordingReason
expectedStopHostTime
TQ,N,V_expectedStopHostTime
triggerEndMachTime
-[CSMyriadSelfTriggerCoordinator selfTriggerDetector:didDetectSelfTrigger:]
com.apple.siri.corespeech.selftrigger
T@"<CSMyriadSelfTriggerCoordinatorDelegate>",W,N,V_delegate
-[CSCommandControlStreamEventMonitor isStreaming]
numOfAVVCRecordingClients
TQ,R,N,V_numOfAVVCRecordingClients
-[CSSelectiveChannelAudioFileWriter initWithURL:inputFormat:outputFormat:channelBitset:]
v16@?0Q8
-[CSSelectiveChannelAudioFileWriter addSamples:numSamples:]
fileURL
T@"NSURL",R,N,V_fileURL
numberOfChannels
TI,R,N,V_numberOfChannels
audioSessionState
TQ,N,GgetAudioSessionState,V_audioSessionState
com.apple.corespeech.corespeechservices
com.apple.corespeech.xpc
+[CSCoreSpeechServices installedVoiceTriggerAssetForLanguageCode:completion:]_block_invoke
reason
CoreSpeechXPC service invalidated
+[CSCoreSpeechServices fetchRemoteVoiceTriggerAssetForLanguageCode:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:]
+[CSCoreSpeechServices voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]_block_invoke
+[CSCoreSpeechServices voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]
+[CSCoreSpeechServices requestUpdatedSATAudio]_block_invoke
v12@?0B8
+[CSCoreSpeechServices getFirstPassRunningMode]_block_invoke
v16@?0q8
T@"NSString",C,N,V_deviceId
CSSpeechManager Asset Query Queue
-[CSSpeechManager startManager]
-[CSSpeechManager registerSpeechController:]
-[CSSpeechManager registerSiriClientProxy:]
v32@?0@"NSNumber"8@"CSAudioProvider"16^B24
-[CSSpeechManager audioProviderWithContext:error:]
-[CSSpeechManager audioProviderWithContext:error:]_block_invoke
-[CSSpeechManager audioProviderWithStreamID:]_block_invoke
-[CSSpeechManager _getAudioRecorderWithError:]
-[CSSpeechManager audioProviderInvalidated:streamHandleId:]_block_invoke
-[CSSpeechManager audioRecorderWillBeDestroyed:]_block_invoke
-[CSSpeechManager voiceTriggerAssetHandler:didChangeCachedAsset:]
-[CSSpeechManager _createClearLoggingFileTimer]
-[CSSpeechManager _createClearLoggingFileTimer]_block_invoke
-[CSSpeechManager _startClearLoggingFilesTimer]
assetQueryQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_assetQueryQueue
audioRecorder
T@"CSAudioRecorder",&,N,V_audioRecorder
audioProviders
T@"NSMutableDictionary",&,N,V_audioProviders
fallbackAudioSessionReleaseProvider
T@"CSFallbackAudioSessionReleaseProvider",&,N,V_fallbackAudioSessionReleaseProvider
clientController
T@"<CSSpeechManagerDelegate>",W,N,V_clientController
clearLoggingFileTimer
T@"NSObject<OS_dispatch_source>",&,N,V_clearLoggingFileTimer
clearLoggingFileTimerCount
Tq,N,V_clearLoggingFileTimerCount
opportuneSpeakListnerTestService
T@"CSOpportuneSpeakListnerTestService",&,N,V_opportuneSpeakListnerTestService
postBuildInstallService
T@"CSPostBuildInstallService",&,N,V_postBuildInstallService
ssvManager
T@"CSSmartSiriVolumeManager",&,N,V_ssvManager
-[CSSpeechEndHostTimeEstimator notifyTrailingSilenceDurationAtEndpoint:]
-[CSSpeechEndHostTimeEstimator estimatedSpeechEndHostTime]
numAudioSampleForwarded
TQ,N,V_numAudioSampleForwarded
lastAudioChunkHostTime
TQ,N,V_lastAudioChunkHostTime
endPointNotified
TB,N,V_endPointNotified
trailingSilenceDurationAtEndpoint
Td,N,V_trailingSilenceDurationAtEndpoint
hybridendpointer_searchfield_dictation.json
CSCommandControlListener
-[CSCommandControlListener startListenWithOption:completion:]
-[CSCommandControlListener _startRequestWithCompletion:]_block_invoke
-[CSCommandControlListener _startRequestWithCompletion:]
-[CSCommandControlListener stopListenWithCompletion:]
-[CSCommandControlListener stopListenWithCompletion:]_block_invoke
-[CSCommandControlListener audioStreamProvider:didStopStreamUnexpectly:]_block_invoke
-[CSCommandControlListener CSXPCClient:didDisconnect:]_block_invoke
T@"<CSCommandControlListenerDelegate>",W,N,V_delegate
Serial CSAssetManager queue
-[CSAssetManager initWithDownloadOption:]
-[CSAssetManager initWithDownloadOption:]_block_invoke
ENABLED
DISABLED
v20@?0B8Q12
-[CSAssetManager setAssetDownloadingOption:]_block_invoke
-[CSAssetManager _fetchRemoteMetaData]
-[CSAssetManager _canFetchRemoteAsset:]
-[CSAssetManager CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSAssetManager _createPeriodicalDownloadTimer]
-[CSAssetManager _createPeriodicalDownloadTimer]_block_invoke
-[CSAssetManager _startPeriodicalDownload]
-[CSAssetManager _stopPeriodicalDownload]
currentLanguageCode
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
deque
-[NviDirectionalitySignalProvider initWithDataSource:assetsProvider:]
-[NviDirectionalitySignalProvider addDelegate:]
-[NviDirectionalitySignalProvider removeDelegate:]
-[NviDirectionalitySignalProvider startWithNviContext:didStartHandler:]
-[NviDirectionalitySignalProvider reset]
-[NviDirectionalitySignalProvider stopWithDidStopHandler:]
sigType
+[CSAudioRecorderFactory audioRecorderWithQueue:error:]
samples_fed
best_start
best_end
best_score
is_secondchance
isEarlyDetect
samplesFed
TQ,N,V_samplesFed
bestStart
TQ,N,V_bestStart
bestEnd
TQ,N,V_bestEnd
bestScore
Tf,N,V_bestScore
isSecondChance
TB,N,V_isSecondChance
TB,N,V_isEarlyDetect
dictionary
TQ,N,V_activeChannel
T@"<CSKeywordAnalyzerNDEAPIScoreDelegate>",W,N,V_delegate
triggerStartSampleCount
clientStartSampleCount
triggerFireMachTime
twoShotAudibleFeedbackDelay
musicVolume
mediaPlayState
CSSpeechRecordSettingsKey_AudioSessionActiveDelay
CSSpeechRecordSettingsKey_AudioSessionActiveReason
CSSpeechRecordSettingsKey_LanguageDetectorLocales
CSSpeechRecordSettingsKey_LanguageDetectorDictationLanguages
CSSpeechRecordSettingsKey_LanguageDetectorCurrentKeyboard
CSSpeechRecordSettingsKey_LanguageDetectorWasLanguageToggled
CSSpeechRecordSettingsKey_LanguageDetectorMultilingualKeyboardLanguages
CSSpeechRecordSettingsKey_LanguageDetectorKeyboardConvoLanguagePriors
CSSpeechRecordSettingsKey_LanguageDetectorKeyboardGlobalLanguagePriors
CSSpeechRecordSettingsKey_LanguageDetectorPreviousMessageLanguage
CSSpeechRecordSettingsKey_LanguageDetectorGlobalLastKeyboardUsed
CSSpeechRecordSettingsKey_LanguageDetectorDictationLanguagePriors
CSSpeechRecordSettingsKey_LanguageDetectorConversationalMessages
CSSpeechRecordSettingsKey_disableEndpointer
CSSpeechRecordSettingsKey_DictationRequestOrigin
CSSpeechRecordSettingsKey_DictationRequestAppName
CSSpeechRecordSettingsKey_DictationRequestAppBundleID
CSSpeechRecordSettingsKey_isDucking
spIdAudioProcessedDuration
spIdUnknownUserScore
spIdKnownUserScores
spIdKnownUserRawScores
spIdUserScoresVersion
spIdKnownUserProfileVersions
spIdScoreThresholdingType
spIdVTInvocationScoreThresholdingType
spIdNonVTInvocationScoreThresholdingType
SpIdScoreThreshold
spIdAssetVersion
spIdDirectionSigsArr
shouldRecordUserAudio
shouldRecordPayload
userIdentityClassification
userClassified
CSSpeechController ContextReset
com.apple.corespeech.twoShotAudibleFeedback
-[CSSpeechController initializeRecordSessionWithContext:]
-[CSSpeechController prepareRecordWithSettings:error:]
-[CSSpeechController _fetchLastTriggerInfo]
-[CSSpeechController _fetchLastTriggerInfo]_block_invoke_2
v24@?0@"NSDictionary"8@"NSDictionary"16
-[CSSpeechController _activateAudioSessionWithReason:delay:error:]_block_invoke
-[CSSpeechController _activateAudioSessionWithReason:delay:error:]
com.apple.corespeech.ducking
B8@?0
-[CSSpeechController _scheduleActivateAudioSessionWithDelay:sessionActivateReason:scheduleReason:validator:completion:]_block_invoke
-[CSSpeechController _scheduleActivateAudioSessionWithDelay:sessionActivateReason:scheduleReason:validator:completion:]
-[CSSpeechController _cancelPendingAudioSessionActivateForReason:]
-[CSSpeechController _performPendingAudioSessionActivateForReason:]
-[CSSpeechController _lazyActivateAudioSessionWithReason:error:]
-[CSSpeechController _lazyActivateAudioSessionWithReason:error:]_block_invoke
-[CSSpeechController _activateAudioSessionWithReason:error:]
-[CSSpeechController _doActivateAudioSessionWithReason:error:]
-[CSSpeechController setCurrentContext:error:]
-[CSSpeechController preheat]
-[CSSpeechController prewarmAudioSession]
-[CSSpeechController resetAudioSession]
-[CSSpeechController reset]
-[CSSpeechController releaseAudioSession]
-[CSSpeechController releaseAudioSession:]
v32@?0@8#16@?<v@?>24
-[CSSpeechController startRecordingWithSettings:error:]
-[CSSpeechController startRecordingWithSettings:error:]_block_invoke
-[CSSpeechController startRecordingWithSettings:error:]_block_invoke_2
-[CSSpeechController _startPhaticDecision]
-[CSSpeechController _startPhaticDecision]_block_invoke
-[CSSpeechController stopRecording]
-[CSSpeechController stopRecordingWithOptions:]
-[CSSpeechController recordRoute]
-[CSSpeechController recordDeviceInfo]
-[CSSpeechController playbackRoute]
-[CSSpeechController _didStopForReason:]
-[CSSpeechController audioStreamProvider:didStopStreamUnexpectly:]
-[CSSpeechController _audioStreamProvdider:audioBufferAvailable:]
-[CSSpeechController audioStreamProvider:audioChunkForTVAvailable:]_block_invoke
-[CSSpeechController audioStreamProvider:didHardwareConfigurationChange:]
-[CSSpeechController audioStreamProvider:didHardwareConfigurationChange:]_block_invoke
-[CSSpeechController audioSessionProvider:providerInvalidated:]_block_invoke_2
-[CSSpeechController audioSessionProvider:didChangeContext:]
-[CSSpeechController audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:]
-[CSSpeechController audioAlertProvidingDidFinishAlertPlayback:ofType:error:]
-[CSSpeechController audioAlertProvidingDidFinishAlertPlayback:ofType:error:]_block_invoke
-[CSSpeechController audioSessionProviderBeginInterruption:]
-[CSSpeechController audioSessionProviderBeginInterruption:]_block_invoke
-[CSSpeechController audioSessionProviderBeginInterruption:withContext:]
-[CSSpeechController audioSessionProviderBeginInterruption:withContext:]_block_invoke
-[CSSpeechController audioSessionProviderEndInterruption:]
-[CSSpeechController audioSessionProviderEndInterruption:]_block_invoke
-[CSSpeechController audioSessionProvider:willSetAudioSessionActive:]
-[CSSpeechController audioSessionProvider:willSetAudioSessionActive:]_block_invoke
-[CSSpeechController audioSessionProvider:didSetAudioSessionActive:]
-[CSSpeechController audioSessionProvider:didSetAudioSessionActive:]_block_invoke
-[CSSpeechController didTTSVolumeChange:forReason:]
-[CSSpeechController didTTSVolumeChange:forReason:]_block_invoke
-[CSSpeechController audioConverterDidConvertPackets:packets:durationInSec:timestamp:]
-[CSSpeechController setAlertSoundFromURL:forType:]
-[CSSpeechController playAlertSoundForType:]
-[CSSpeechController playRecordStartingAlertAndResetEndpointer]
-[CSSpeechController stopEndpointer]
-[CSSpeechController setMeteringEnabled:]
-[CSSpeechController _createAudioPowerMeterIfNeeded]
-[CSSpeechController outputReferenceChannel]
-[CSSpeechController voiceTriggerInfo]
-[CSSpeechController keywordDetectorDidDetectKeyword]_block_invoke
-[CSSpeechController _fetchAudioDecoderForTV:]
-[CSSpeechController _createAudioProviderFromXPCWithContext:]
Accounts
Speech Identifier
%c%c%c%c
none
-[CSSpeechController endpointerModelVersion]
-[CSSpeechController cancelCurrentLanguageDetectorRequest]_block_invoke
-[CSSpeechController beginWaitingForMyriad]
-[CSSpeechController endWaitingForMyriadWithDecision:]
-[CSSpeechController CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:]_block_invoke
-[CSSpeechController CSAlarmMonitor:didReceiveAlarmChanged:]_block_invoke
-[CSSpeechController CSTimerMonitor:didReceiveTimerChanged:]_block_invoke
-[CSSpeechController _setSoundPlayingState]
 NOT
-[CSSpeechController CSXPCClient:didDisconnect:]_block_invoke
-[CSSpeechController _teardownAudioProviderIfNeeded]
endpointerProxy
T@"CSEndpointerProxy",&,N,V_endpointerProxy
audioRecordContext
T@"CSAudioRecordContext",&,N,V_audioRecordContext
streamProvider
T@"<CSAudioStreamProviding>",&,N,V_streamProvider
sessionProvider
T@"<CSAudioSessionProviding>",&,N,V_sessionProvider
alertProvider
T@"<CSAudioAlertProviding>",&,N,V_alertProvider
audioMeterProvider
T@"<CSAudioMeterProviding>",&,N,V_audioMeterProvider
audioMetricProvider
T@"<CSAudioMetricProviding>",&,N,V_audioMetricProvider
isOpus
TB,N,V_isOpus
isSiriClientListening
TB,N,V_isSiriClientListening
isNarrowBand
TB,N,V_isNarrowBand
serverLoggingWriter
T@"CSSelectiveChannelAudioFileWriter",&,N,V_serverLoggingWriter
volumeController
T@"CSSmartSiriVolumeController",&,N,V_volumeController
recordEventUUID
T@"NSString",&,N,V_recordEventUUID
isAudioSessionActivated
TB,N,V_isAudioSessionActivated
deviceRoleIsStereo
TB,N,V_deviceRoleIsStereo
speakerRecognitionScores
T@"NSDictionary",&,N,V_speakerRecognitionScores
twoShotNotificationEnabled
TB,N,V_twoShotNotificationEnabled
isMediaPlaying
TB,N,V_isMediaPlaying
isAlarmPlaying
TB,N,V_isAlarmPlaying
isTimerPlaying
TB,N,V_isTimerPlaying
isSoundPlaying
TB,N,V_isSoundPlaying
isRemoteVADAvailableStream
TB,N,V_isRemoteVADAvailableStream
myriadPreventingTwoShotFeedback
TB,N,V_myriadPreventingTwoShotFeedback
needsPostGain
TB,N,V_needsPostGain
speechEndHostTimeEstimator
T@"CSSpeechEndHostTimeEstimator",&,N,V_speechEndHostTimeEstimator
bundleIdFromDictation
T@"NSString",&,N,V_bundleIdFromDictation
languageDetector
T@"CSLanguageDetector",&,N,V_languageDetector
shouldUseLanguageDetectorForCurrentRequest
TB,N,V_shouldUseLanguageDetectorForCurrentRequest
pendingAudioSessionActivationToken
T@"NSUUID",&,N,V_pendingAudioSessionActivationToken
pendingAudioSessionActivationCompletion
T@?,C,N,V_pendingAudioSessionActivationCompletion
pendingAudioSessionActivationReason
TQ,N,V_pendingAudioSessionActivationReason
audioSessionActivationDelay
Td,N,V_audioSessionActivationDelay
cachedAvgPower
Tf,N,V_cachedAvgPower
cachedPeakPower
Tf,N,V_cachedPeakPower
powerMeter
T@"CSAudioPowerMeter",&,N,V_powerMeter
didDeliverLastBuffer
TB,N,V_didDeliverLastBuffer
didDeliverFirstSpeechPacket
TB,N,V_didDeliverFirstSpeechPacket
canPerformDelayedStop
TB,N,V_canPerformDelayedStop
requestedStopRecordingOptions
T@"CSStopRecordingOptions",&,N,V_requestedStopRecordingOptions
numTrailingSamplesAfterSchedulingStop
TQ,N,V_numTrailingSamplesAfterSchedulingStop
maxAllowedTrailingSamplesAfterSchedulingStop
TQ,N,V_maxAllowedTrailingSamplesAfterSchedulingStop
decodersForTV
T@"NSMutableDictionary",&,N,V_decodersForTV
decoderProcessedSampleCountForTV
TQ,N,V_decoderProcessedSampleCountForTV
logEventUUID
T@"NSString",&,N,V_logEventUUID
ssvLogFilePath
T@"NSString",&,N,V_ssvLogFilePath
mediaPlayingMonitor
T@"CSMediaPlayingMonitor",&,N,V_mediaPlayingMonitor
volumeMonitor
T@"CSVolumeMonitor",&,N,V_volumeMonitor
T@"<CSSpeechControllerDelegate>",W,N,V_delegate
languageDetectorDelegate
T@"<CSLanguageDetectorDelegate>",W,N,V_languageDetectorDelegate
speakerIdDelegate
T@"<CSSpeakerIdentificationDelegate>",W,N,V_speakerIdDelegate
duckOthersOption
endpointAnalyzer
T@"<CSEndpointAnalyzer>",R,N
rtblobs
blob
majorVersion
minorVersion
signature
cert
rtlocalemap
jarvislocalemap
-[CSAsset(RTModel) createRTModelWithLocale:]
-[CSAsset(RTModel) latestHearstRTModelForLocale:]
-[CSAsset(RTModel) hearstRTModelWithMajorVersion:minorVersion:locale:]
-[CSAsset(RTModel) localeMapWithName:]
%02x
com.apple.siri.speechmodeltraining
com.apple.corespeech.speechmodeltraining.xpc
com.apple.speech.speechmodeltraining
SpeechModelTrainingClient
v24@?0@"NSString"8@"NSError"16
v16@?0@"NSString"8
v24@?0@"NSDictionary"8@"NSError"16
Assistant/SpeechPersonalizedLM
Assistant/SpeechPersonalizedLM_Fides
Received Error %@
Input directory path(%@) does not match expected path
com.apple.voicetrigger
com.apple.voicetrigger.notbackedup
kCSPreferencesJarvisTriggerModeDidChangeDarwinNotification
Phrase Detector Enabled
AttentiveSiri Enabled
AttentiveSiri AudioLogging Enabled
VoiceTrigger CoreSpeech Enabled
-[CSPreferences voiceTriggerInCoreSpeech]_block_invoke
Enable Two Shot Notification
com.apple.demo-settings
StoreDemoMode
File Logging Level
Library
Logs/CrashReporter/VoiceTrigger/audio/
/Logs/CrashReporter/Assistant/smartSiriVolumeContextAwareLogs/
Logs/CrashReporter/Assistant/smartSiriVolumeContextAwareLogs/
-[CSPreferences getSSVLogFilePathWithSessionIdentifier:]
/tmp
%@/SSV_%@.json
VoiceTrigger/TrialAssetData
VoiceTrigger/adBlocker
/Logs/CrashReporter/Assistant/
SpeechLogs
-[CSPreferences assistantAudioFileLogDirectory]
VoiceTrigger
siriBC
Second Pass Audio Logging Enabled
Jarvis Audio Logging Enabled
Jarvis Trigger Mode
Enable SoS Audio Logging
Force VoiceTrigger AP Mode
-[CSPreferences forceVoiceTriggerAPMode]_block_invoke
Force VoiceTrigger AOP Mode
-[CSPreferences forceVoiceTriggerAOPMode]_block_invoke
mobile
Logs/CrashReporter/CoreSpeech/sos/
-[CSPreferences getStartOfSpeechAudioLogFilePath]
yyyyMMdd_HHmmss.SSS
%@/%@
Remote VoiceTrigger Delay
Remote VoiceTrigger Endpoint Timeout
VoiceTrigger/interstitial
Myriad File Logging Enabled
Audio Injection Enabled
Programmable Audio Injection Enabled
-[CSPreferences enableAudioInjection:withKey:]
-[CSPreferences setAudioInjectionFilePath:]
Audio Injection File Path
-[CSPreferences audioInjectionFilePath]
-[CSPreferences audioInjectionFilePath]_block_invoke
v32@?0@8Q16^B24
SpeakerId Enabled
SpeakerId Score Type
SmartSiriVolume SoftVolume Enabled
Audio Session Activation Delay
Max Number Logging Files
Max Number Grading Files
Enable SiriActivation HomePod
Enable SiriActivation watchOS
IOS Support Barge-in
-[CSPreferences iOSBargeInSupportEnabled]_block_invoke
enabled
disabled
-[CSPreferences iOSBargeInSupportEnabled]
Overwrite Remote VAD Score
Hearst First Pass Model Version
Hearst Second Pass Model Version
Hearst Fake Model Path
VoiceTrigger Companion Sync Enabled
Enable OpportuneSpeakListener Bypass
Bypass Personalized HeySiri
MultiPhraseVTEnabled
MultiChannelAudioLoggingEnabled
Enable AdBlocker Audio Logging
Enable Self Trigger Audio Logging
CSSampleCountHostTimeConverter
anchorSampleCount
TQ,N,V_anchorSampleCount
anchorHostTime
TQ,N,V_anchorHostTime
-[CSAudioStartStreamOption(AVVC) avvcStartRecordSettingsWithAudioStreamHandleId:]
-[NviSignalProvidersController initWithAssetsProvider:dataSourceMap:signalProviderToDataSourceMap:]
-[NviSignalProvidersController dealloc]
NviSignalProvidersController.m
No DataSource found for SignalType: %@
-[NviSignalProvidersController _setupSignalProviders:]
-[NviSignalProvidersController _startDataSourcesWithContext:]
-[NviSignalProvidersController _startDataSourcesWithContext:]_block_invoke
-[NviSignalProvidersController _startSignalProvidersWithContext:]
-[NviSignalProvidersController _startSignalProvidersWithContext:]_block_invoke
-[NviSignalProvidersController _stopDataSources]_block_invoke
-[NviSignalProvidersController _stopDataSources]
-[NviSignalProvidersController _stopCurrentlyRunningSignalProviders]_block_invoke
-[NviSignalProvidersController _stopCurrentlyRunningSignalProviders]
-[NviSignalProvidersController _iterateSignalMask:withHandler:]
v16@?0@"<NviSignalProvider>"8
assetsProvider
T@"<NviAssetsProvider>",&,N,V_assetsProvider
dataSrcMap
T@"NSDictionary",&,N,V_dataSrcMap
sigProvidersMap
T@"NSMapTable",&,N,V_sigProvidersMap
currActiveSigProvTypes
T@"NSHashTable",&,N,V_currActiveSigProvTypes
currActiveDataSourceTypes
T@"NSHashTable",&,N,V_currActiveDataSourceTypes
T@"<CSVoiceTriggerDelegate>",W,N,V_delegate
com.apple.corespeech.corespeechd.xpc
-[CSXPCClient sendXPCClientType]
xpcClientType
-[CSXPCClient prepareAudioProviderWithContext:clientType:error:]
context
clientType
activateReason
dynamicAttribute
dictationRequestBundleId
deactivateOption
setDuckOthersOption
enableSmartRoutingConsideration
enableMiniDucking
alertType
soundPath
alertStartTime
-[CSXPCClient alertStartTime]
alertBehavior
setMeterEnable
channelNumber
power
-[CSXPCClient peakPowerForChannel:]
-[CSXPCClient averagePowerForChannel:]
-[CSXPCClient audioMetric]
audioMetric
audioStreamRequest
-[CSXPCClient audioStreamWithRequest:streamName:error:]
v24@?0@"CSAudioStream"8@"NSError"16
-[CSXPCClient audioStreamWithRequest:streamName:completion:]
-[CSXPCClient prepareAudioStreamSync:request:error:]
-[CSXPCClient prepareAudioStream:request:completion:]
startAudioStreamOption
-[CSXPCClient triggerInfoForContext:completion:]
voiceTriggerInfo
rtsTriggerInfo
recordRoute
recordDeviceInfo
recordSettings
playbackRoute
-[CSXPCClient audioChunkFrom:to:]
-[CSXPCClient audioChunkToEndFrom:]
-[CSXPCClient saveRecordingBufferFrom:to:toURL:]
-[CSXPCClient saveRecordingBufferToEndFrom:toURL:]
-[CSXPCClient holdAudioStreamWithDescription:timeout:]
-[CSXPCClient cancelAudioStreamHold:]
-[CSXPCClient isRecording]
sessionID
-[CSXPCClient audioSessionID]
sampleCount
replyHostTime
-[CSXPCClient hostTimeFromSampleCount:]
hostTime
replySampleCount
-[CSXPCClient sampleCountFromHostTime:]
option
-[CSXPCClient _handleListenerEvent:]
-[CSXPCClient _handleListenerMessage:]
-[CSXPCClient _handleListenerError:]
-[CSXPCClient _handleAlertProvidingDelegateMessageBody:]
didFinishAlertPlayback
errorDomain
errorCode
-[CSXPCClient _handleSessionProvidingDelegateMessageBody:]
interruptionContext
-[CSXPCClient _handleSessionProvidingDelegateBeginInterruptionWithContext:]
willSetAudioSessionActive
didSetAudioSessionActive
streamHandleIdInvalidationflag
didChangeContextFlag
-[CSXPCClient _handleSessionInfoProvidingDelegateMessageBody:]
notificationInfo
-[CSXPCClient _handleSessionInfoProvidingDelegateInterruptionNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateRouteChangeNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:]
-[CSXPCClient _handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:]
-[CSXPCClient _handleStreamProvidingDelegateMessageBody:]
stopReason
chunk
hardwareConfig
activationAssertions
T@"NSMutableSet",&,N,V_activationAssertions
audioSessionInfoObservers
T@"NSHashTable",&,N,V_audioSessionInfoObservers
TQ,N,V_xpcClientType
audioSessionProvidingDelegate
T@"<CSAudioSessionProvidingDelegate>",W,N,V_audioSessionProvidingDelegate
audioStreamProvidingDelegate
T@"<CSAudioStreamProvidingDelegate>",W,N,V_audioStreamProvidingDelegate
audioAlertProvidingDelegate
T@"<CSAudioAlertProvidingDelegate>",W,N,V_audioAlertProvidingDelegate
T@"<CSXPCClientDelegate>",W,N,V_delegate
UUID
T@"NSString",R,N,V_UUID
initialState
Tq,N,V_initialState
transitions
T@"NSMutableDictionary",&,N,V_transitions
T@"<CSStateMachineDelegate>",W,N,V_delegate
currentState
Tq,R,N,V_currentState
-[CSPlainAudioFileWriter initWithURL:inputFormat:outputFormat:]
-[CSPlainAudioFileWriter addSamples:numSamples:]
json
productType
productVersion
buildVersion
timeStamp
-[CSPlainAudioFileWriter addContextKey:withContext:]
-[CSPlainAudioFileWriter addContextKey:fromMetaFile:]
+[CSPlainAudioFileWriter saveAudioChunck:toURL:]
Serial CSEventMonitor queue
-[CSEventMonitor _startMonitoringWithQueue:]
/Library/Caches/com.apple.xbs/Sources/CoreSpeech_Sim/CoreSpeech-441.5/CoreSpeech/CSEventMonitor.m
-[CSEventMonitor _stopMonitoring]
-[CSAudioChunkForTV initWithXPCObject:]
T@"NSArray",&,N,V_packets
Tf,N,V_avgPower
Tf,N,V_peakPower
TQ,N,V_timeStamp
TI,N,V_numChannels
TI,N,V_audioFormat
TQ,N,V_streamHandleID
avgPower
peakPower
numChannels
audioFormat
streamHandleID
packets
-[CSSmartSiriVolumeManager initWithSamplingRate:withAsset:]
-[CSSmartSiriVolumeManager CSAlarmMonitor:didReceiveAlarmChanged:]
-[CSSmartSiriVolumeManager CSTimerMonitor:didReceiveTimerChanged:]
-[CSSmartSiriVolumeManager CSVolumeMonitor:didReceiveMusicVolumeChanged:]
-[CSSmartSiriVolumeManager CSVolumeMonitor:didReceiveAlarmVolumeChanged:]
T@"<CSSmartSiriVolumeProcessor>",&,N,V_smartSiriVolume
T@"<CSConnectionServiceDelegate>",W,N,V_delegate
numImplicitUtt
numExplicitUtt
numFirstPassTriggersPerDay
-[CSAudioFileLog _closeAudioFile]
-[CSAudioFileLog startRecording]_block_invoke
-input.wav
-[CSAudioFileLog appendAudioData:]_block_invoke
-[CSAudioFileLog stopRecording]_block_invoke
+[CSAudioStreamRequest defaultRequestWithContext:]
+[CSAudioStreamRequest requestForLpcmRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForOpusRecordSettingsWithContext:]
+[CSAudioStreamRequest requestForSpeexRecordSettingsWithContext:]
T@"CSAudioRecordContext",&,N,V_recordContext
TB,N,V_requiresHistoricalBuffer
TB,N,V_useCustomizedRecordSettings
Tq,N,V_audioFormat
Td,N,V_sampleRate
TI,N,V_lpcmBitDepth
TB,N,V_lpcmIsFloat
TI,N,V_numberOfChannels
TI,N,V_encoderBitRate
TB,N,V_isSiri
requiresHistoricalBuffer
useCustomizedRecordSettings
lpcmBitDepth
lpcmIsFloat
NumberOfChannels
encoderBitRate
isSiri
recordContext
[%@]
[%llu]
[%f]
BuiltInAOPVoiceTrigger
RemoteMicVoiceTrigger
RemoteMicVAD
JarvisVoiceTrigger
mediaserverdLaunched
RemoraVoiceTrigger
Unknown
TQ,N,V_type
T@"NSDictionary",&,N,V_activationInfo
TQ,N,V_hosttime
Tf,N,V_vadScore
localizedDescription
activationInfo
vadScore
hosttime
-[CSAssetController init]
Serial CSAssetController queue
V1 Assets Clean-up queue
-[CSAssetController _cleanUpMobileAssetV1Directory]
-[CSAssetController assetOfType:language:]
-[CSAssetController allInstalledAssetsOfType:language:]
q24@?0@"MAAsset"8@"MAAsset"16
v32@?0@"MAAsset"8Q16^B24
-[CSAssetController assetOfType:language:completion:]
-[CSAssetController installedAssetOfType:language:]
-[CSAssetController installedAssetOfType:language:completion:]
v24@?0@"MAAsset"8@"NSError"16
-[CSAssetController _installedAssetOfType:withLanguage:]
-[CSAssetController _installedAssetOfType:withLanguage:completion:]_block_invoke
-[CSAssetController _findLatestInstalledAsset:]
-[CSAssetController _assetQueryForAssetType:]
-[CSAssetController _runAssetQuery:completion:]
-[CSAssetController _runAssetQuery:completion:]_block_invoke
-[CSAssetController fetchRemoteMetaOfType:allowRetry:]
-[CSAssetController fetchRemoteMetaOfType:allowRetry:]_block_invoke
v20@?0@"NSError"8B16
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:completion:]
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:completion:]_block_invoke_2
-[CSAssetController _fetchRemoteAssetOfType:withLanguage:completion:]_block_invoke
-[CSAssetController _downloadAssetCatalogForAssetType:complete:]_block_invoke
-[CSAssetController _updateFromRemoteToLocalAssets:forAssetType:completion:]
-[CSAssetController _downloadAsset:withComplete:]
v16@?0d8
-[CSAssetController _downloadAsset:withComplete:]_block_invoke
-[CSAssetController _startDownloadingAsset:progress:completion:]
v16@?0@"MAProgressNotification"8
assetsMigrationQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_assetsMigrationQueue
csAssetsDictionary
T@"NSDictionary",&,N,V_csAssetsDictionary
T@"NSMutableDictionary",&,N,V_observers
+[CSAssetController(Utils) addKeyValuePairForQuery:assetType:]
com.apple.MobileAsset.VoiceTriggerAssets
com.apple.MobileAsset.VoiceTriggerAssetsIPad
com.apple.MobileAsset.VoiceTriggerAssetsWatch
com.apple.MobileAsset.VoiceTriggerAssetsMarsh
com.apple.MobileAsset.VoiceTriggerAssetsMac
com.apple.MobileAsset.SpeechEndpointAssetsWatch
com.apple.MobileAsset.LanguageDetectorAssets
com.apple.MobileAsset.AdBlockerAssets
com.apple.MobileAsset.SpeakerRecognitionAssets
-[CSSyncKeywordAnalyzerQuasar initWithConfigPath:triggerTokens:useKeywordSpotting:]
triggerConfidence
Td,N,V_triggerConfidence
ctcKwdToPhraseIdMap
T@"NSDictionary",&,N,V_ctcKwdToPhraseIdMap
phraseIdScores
T@"NSDictionary",R,N,V_phraseIdScores
T@"<CSAudioDecoderDelegate>",W,V_delegate
CSAudioInjectionTvRemoteEngine
opusEncoder
T@"CSAudioConverter",&,N,V_opusEncoder
v16@?0@"<AFMyriadContextMutating>"8
-[CSSiriLauncher notifyBuiltInVoiceTrigger:myriadPHash:completion:]_block_invoke
-[CSSiriLauncher notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:]_block_invoke_2
-[CSSiriLauncher notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:]_block_invoke
-[CSSiriLauncher notifyBluetoothDeviceVoiceTrigger:deviceId:completion:]_block_invoke
-[CSSiriLauncher deactivateSiriActivationConnectionWithReason:withOptions:]_block_invoke
v16@?0@"AFSiriActivationResult"8
-[CSAudioRouteChangeMonitor _startMonitoringWithQueue:]
/Library/Caches/com.apple.xbs/Sources/CoreSpeech_Sim/CoreSpeech-441.5/CoreSpeech/CSAudioRouteChangeMonitor.m
-[CSAudioRouteChangeMonitor _stopMonitoring]
-[CSAudioRouteChangeMonitor getHearstConnected:]
-[CSAudioRouteChangeMonitor hearstConnected]
-[CSAudioRouteChangeMonitor getJarvisConnected:]
-[CSAudioRouteChangeMonitor jarvisConnected]
CSSmartSiriVolumeEnablePolicy queue
-[CSSmartSiriVolumeEnablePolicy _addSmartSiriVolumeEnabledConditions]_block_invoke
CSAudioInjectionRemoraEngine
-[CSAudioInjectionRemoraEngine dealloc]
CSAudioInjectionEngine
-[CSAudioInjectionEngine _createDeInterleaverIfNeeded]
-[CSAudioInjectionEngine stop]_block_invoke
-[CSAudioInjectionEngine _readAudioBufferAndFeed]
-[CSAudioInjectionEngine injectAudio:withScaleFactor:outASBD:playbackStarted:completion:]
-[CSAudioInjectionEngine stopAudioStream]_block_invoke
-[CSAudioInjectionEngine _deinterleaveBufferIfNeeded:]
-[CSAudioInjectionEngine _compensateChannelDataIfNeeded:receivedNumChannels:]
audioStreamHandleId
TQ,N,V_audioStreamHandleId
fileOption
T@"CSAudioInjectionFileOption",&,N,V_fileOption
audioFeedTimer
T@"NSObject<OS_dispatch_source>",&,N,V_audioFeedTimer
isRecording
TB,N,V_isRecording
bufferDuration
Td,N,V_bufferDuration
injectionAudioFileList
T@"NSMutableArray",&,N,V_injectionAudioFileList
injectionStartNotifyBlocks
T@"NSMutableArray",&,N,V_injectionStartNotifyBlocks
injectionCompletionNotifyBlocks
T@"NSMutableArray",&,N,V_injectionCompletionNotifyBlocks
deinterleaver
T^{OpaqueAudioConverter=},N,V_deinterleaver
pNonInterleavedABL
T^{AudioBufferList=I[1{AudioBuffer=II^v}]},N,V_pNonInterleavedABL
didSetScaleFactor
TB,N,V_didSetScaleFactor
Tf,N,V_scaleFactor
VoiceTrigger Asset Change Monitor
T@"<CSVoiceTriggerAssetChangeDelegate>",W,N,V_delegate
com.apple.corespeech.voicetriggerassetchange
-[NviAudioFileWriter initWithURL:inputFormat:outputFormat:]
-[NviAudioFileWriter addSamples:numSamples:]
-[CSVoiceTriggerEnabledPolicyNonAOP _addVoiceTriggerEnabledConditions]_block_invoke
CSSiriClientBehaviorMonitor
-[CSSiriClientBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSSiriClientBehaviorMonitor notifyDidStopStream:withEventUUID:]_block_invoke
isStreaming
TB,N,V_isStreaming
-[CSSpeechEndpointAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeechEndpointAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeechEndpointAssetMetaUpdateMonitor _didReceiveNewSpeechEndpointAssetMetaData]
com.apple.MobileAsset.SpeechEndpointAssetsWatch.ma.cached-metadata-updated
estimatedTTSVolume
debugLogPath
supportsSecureCoding
TB,R
T@"NSString",R,N,V_debugLogPath
volumeEstimate
Tf,R,N,V_volumeEstimate
-[CSVoiceTriggerAssetHandlerMac _getVoiceTriggerAssetFromAssetManager:]_block_invoke
-[CSVoiceTriggerAssetHandlerMac _checkNewAssetAvailablity]_block_invoke
-[CSVoiceTriggerAssetHandlerMac CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:]
-[CSVoiceTriggerAssetHandlerMac CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:]
-[CSVoiceTriggerAssetHandlerMac CSFirstUnlockMonitor:didReceiveFirstUnlock:]
cachedAsset
T@"CSAsset",&,V_cachedAsset
CSVoiceTriggerAOPModeEnabledPolicyIOS RecordState queue
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSBargeIn]_block_invoke
BTDetails_IsHFPRoute
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _addConditionsForIOSAOP]_block_invoke
-[CSVoiceTriggerAOPModeEnabledPolicyIOS _isSpeechDetectionDevicePresent]
-[CSVoiceTriggerAOPModeEnabledPolicyIOS siriClientBehaviorMonitor:didChangedRecordState:withEventUUID:withContext:]_block_invoke
isSiriClientConsideredAsRecord
TB,N,V_isSiriClientConsideredAsRecord
pendingRecordingStopUUID
T@"NSString",&,N,V_pendingRecordingStopUUID
triggerScore
configVersion
firstPassTriggerSource
languageCode
start
stop
com.apple.corespeech.aopFirstPassTriggerWakeupLatency
latency
device
@"NSDictionary"8@?0
com.apple.corespeech.SecondPassWakeUp
unknown
modelVersion
firstPassSource
triggerAPWakeup
-[CSVoiceTriggerStatAggregator logFalseWakeUp:]
-[CSVoiceTriggerStatAggregator logTriggerLengthSampleCountStatistics:withFirstPassDeterministicTriggerLengthSampleCount:]
com.apple.exprAOPSecondPass
newTriggerLengthSampleCount
oldTriggerLengthSampleCount
sampleCountDelta
com.apple.corespeech.AudioZeroRun
duration
numFalseWakeUp
TQ,N,V_numFalseWakeUp
lastAggTimeFalseWakeUp
TQ,N,V_lastAggTimeFalseWakeUp
CSOpportuneSpeakBehaviorMonitor
-[CSOpportuneSpeakBehaviorMonitor notifyWillStartStreamWithContext:audioProviderUUID:option:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyDidStartStreamWithContext:audioProviderUUID:successfully:option:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSOpportuneSpeakBehaviorMonitor notifyDidStopStream:]_block_invoke
lastHash
T@"NSData",C
signalEstimate
Ts,N,V_signalEstimate
signalFractional
TC,N,V_signalFractional
Library/nvi
T@"NSDictionary",C,N,V_voiceTriggerInfo
T@"NSDictionary",C,N,V_rtsTriggerInfo
triggerNotifiedMachTime
TQ,N,V_triggerNotifiedMachTime
triggerEndSampleCount
triggerEndSeconds
com.apple.nvi
IsNviEnabled
InternalBuild
NviVADSignalType
NviKwdSignalType
NviDirectionalitySignalType
NviAsdAnchorSignalType
NviAsdPayloadSignalType
+[NviUtils strRepForNviSignalType:]
NviUtils.m
Unknown NviSignalTypeString: <%@>
NviAudioDataSrcType
+[NviUtils strRepForNviDataSourceType:]
NviDataSource_END_MARKER
+[NviUtils nviDataSourceTypeForStr:]
+[NviUtils _createDirAtPath:]
Unexpected!! Received dir for NviConfig: %@
+[NviUtils readJsonDictionaryAt:]
+[NviUtils getValueFromDictionaryOfDictionaries:keypath:]
+[NviUtils createDirAtPath:]
[requestHistoricalAudioDataWithHostTime = %@]
[requestHistoricalAudioDataSampleCount = %@]
[useOpportunisticZLL = %@]
[startRecordingHostTime = %llu]
[startRecordingSampleCount = %llu]
[alertBehavior = %llu %llu %llu]
[skipAlertBehavior = %@]
TB,N,V_requestHistoricalAudioDataWithHostTime
TB,N,V_requestHistoricalAudioDataSampleCount
TQ,N,V_startRecordingHostTime
TQ,N,V_startRecordingSampleCount
TB,N,V_useOpportunisticZLL
Tq,N,V_startAlertBehavior
Tq,N,V_stopAlertBehavior
Tq,N,V_errorAlertBehavior
TB,N,V_skipAlertBehavior
requestHistoricalAudioDataWithHostTime
requestHistoricalAudioDataSampleCount
startRecordingHostTime
startRecordingSampleCount
useOpportunisticZLL
startAlertBehavior
stopAlertBehavior
errorAlertBehavior
skipAlertBehavior
-[CSVoiceTriggerXPCServiceProxy enableVoiceTrigger:withAssertion:timestamp:]
voicetrigger assertion queue
-[CSVoiceTriggerXPCServiceProxy enableVoiceTrigger:withAssertion:timestamp:]_block_invoke
Enabled
Disabled
phrasespotter assertion queue
-[CSVoiceTriggerXPCServiceProxy setPhraseSpotterBypassing:timeout:]_block_invoke_2
bypassed
NOT bypassed
-[CSVoiceTriggerXPCServiceProxy setPhraseSpotterBypassing:timeout:]_block_invoke
raise-to-speak assertion queue
-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing:timeout:]_block_invoke_2
-[CSVoiceTriggerXPCServiceProxy setRaiseToSpeakBypassing:timeout:]_block_invoke
-[CSVoiceTriggerXPCServiceProxy notifyVoiceTriggeredSiriSessionCancelled]
-[CSVoiceTriggerXPCServiceProxy notifyServiceConnectionLost]
isPhraseSpotterBypassed
TB,N,V_isPhraseSpotterBypassed
isRaiseToSpeakBypassed
TB,N,V_isRaiseToSpeakBypassed
-[CSDispatchGroup leave]
smartSiriVolumeOverrideMediaVolume
com.apple.ssv.clientq
-[CSSmartSiriVolumeController getVolumeForTTSType:withContext:]_block_invoke
-[CSSmartSiriVolumeController _createSSVClientConnectionIfNeeded]
-[CSSmartSiriVolumeController didSmartSiriVolumeChangeForReason:]
ssvClient
T@"CSSmartSiriVolumeClient",&,N,V_ssvClient
T@"<CSSmartSiriVolumeControllerDelegate>",W,N,V_delegate
speakerRecognition
satThreshold
combinationWeight
implicitProfileThreshold
implicitProfileDeltaThreshold
implicitVTThreshold
pruningExplicitSATThreshold
pruningExplicitPSRThreshold
pruningSATThreshold
pruningPSRThreshold
numPruningRetentionUtt
maxEnrollmentUtterances
pruningCookie
configFileRecognizer
configFileNDAPI
voiceTriggerSecondPassAOP
implicit_training_enabled
multiUserHighScoreThreshold
multiUserLowScoreThreshold
multiUserConfidentScoreThreshold
multiUserDeltaScoreThreshold
recognizer.json
config.txt
containsSpeakerRecognitionCategory
satScoreThreshold
Tq,R,N
psrCombinationWeight
satImplicitProfileThreshold
satImplicitProfileDeltaThreshold
satVTImplicitThreshold
satImplicitTrainingEnabled
pruningExplicitUttThresholdSAT
pruningExplicitUttThresholdPSR
pruningThresholdSAT
pruningThresholdPSR
pruningNumRetentionUtterance
maxAllowedEnrollmentUtterances
voiceProfilePruningCookie
keywordDetectorNDAPIConfigFilePath
keywordDetectorQuasarConfigFilePath
address
T@"NSString",C,N,V_address
supportDoAP
TB,N,V_supportDoAP
isTemporaryPairedNotInContacts
TB,N,V_isTemporaryPairedNotInContacts
meta_version.json
enrollment_version.json
CSP2P_CommandType_Key
CSP2P_CommandDict_Key
corespeech
com.apple.siridebug.request.generic
com.apple.siridebug.command.remote.heysiri
com.apple.siridebug.command.parallel.recording
com.apple.siridebug.command.transfer.voiceprofile
com.apple.siridebug.command.query.voiceprofile
com.apple.siridebug.command.reverse.transfer.voiceprofile
com.apple.siridebug.command.fetch.voiceprofile
com.apple.siridebug.command.voiceprofile.update.trigger
com.apple.siridebug.command.fetch.parallelrecording
com.apple.siridebug.command.transfer.parallelrecording
com.apple.siridebug.command.fetch.voicegradingdata
com.apple.siridebug.command.transfer.voicegradingdata
com.apple.siridebug.command.delete.voiceprofile
CSP2P_RemoteHeySiriEnable_Key
CSP2P_RemoteHeySiriStatus_Key
CSP2P_RemoteRecordingStart_Key
CSP2P_RemoteRecordingStatus_Key
CSP2P_VoiceProfileData_Key
CSP2P_VoiceProfileFileName_Key
CSP2P_VoiceProfileSpeakerName_Key
CSP2P_VoiceProfileLocale_Key
CSP2P_VoiceProfileDataType_Key
CSP2P_VoiceProfileSegment_Key
CSP2P_VoiceProfileTotalSegments_Key
CSP2P_VoiceProfileStatus_Key
CSP2P_VoiceProfileProfileId_Key
CSP2P_VoiceProfileHomeUserId_Key
CSP2P_VoiceProfileRelativeFilePath_Key
CSP2P_VoiceProfileSiriProfileId_Key
CSP2P_VoiceProfileAppDomain_Key
CSP2P_VoiceProfileOnboardTimeStamp_Key
CSP2P_VoiceProfileTransferCompleted_Key
CSP2P_VoiceProfileRecordedData_Key
CSP2P_VoiceProfileRemoteFileName_Key
CSP2P_VoiceDataToBeGraded_Key
CSP2P_VoiceFileNameToBeGraded_Key
CSP2P_GradingDataTransferStatus_Key
CSP2P_PeerIdentifier_Key
CSP2P_VoiceProfilePeerName_Key
CSP2P_IsDataCompressed_Key
CSP2P_UncompressedDataSize_Key
CSP2P_GradingBatchTransferID_Key
CSP2P_VoiceProfileiTunesUserID_Key
CSP2P_VoiceProfileiTunesPassword_Key
remote
-triggered
-almost
-rejected
-activation
ssrmeta
ssvmeta
vtei
multiuser
com.apple.corespeech.p2psvc
-[CSP2PService processRemoteCommandWithPayload:fromPeer:withReply:]_block_invoke
CoreSpeech
-[CSP2PService sendCoreSpeechGradingDataToNearbyPeer]_block_invoke
-[CSP2PService sendVTNearMissGradingDataToCompanion]_block_invoke
-[CSP2PService sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:]_block_invoke
-[CSP2PService _processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _compressFilesInDirectory:matchingPredicate:compressedFileAvailable:]
-[CSP2PService _sendVoiceTriggerGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendVoiceTriggerGradingDataToPeerId:]_block_invoke
v52@?0@"NSString"8@"NSData"16Q24Q32B40@"NSError"44
.wav
.json
-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke_2
-[CSP2PService _sendCoreSpeechGradingDataToPeerId:]_block_invoke
-[CSP2PService _sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:]
fileData
fileName
peerId
-[CSP2PService _sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:]_block_invoke
-[CSP2PService _receiveParallelRecordingFromPeerId:recordingInfo:withReply:]
%@_%@
-[CSP2PService _receiveVoiceGradingDataFromPeerId:requestInfo:withReply:]
%@.%@.%@
suppressnotification
%@.%@
-[CSP2PService _receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:]
CoreSpeechCache
audio
tdti
com.apple.siri.corespeech.voiceprofilelist.change
-[CSP2PService _processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:]_block_invoke
CSP2PService.m
Invalid parameter not satisfying: %@
-[CSP2PService _processGradingDataFetchCommandWithRequest:fromSenderID:withReply:]
-[CSP2PService _processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:]
yyyyMMddHHmmss
voiceprofiles
-[CSP2PService _getHomeUserIdForSharedSiriId:withCompletion:]
-[CSP2PService _getHomeUserIdForSharedSiriId:withCompletion:]_block_invoke
homeUserId query for siriProfileId %@ timedout !
-[CSP2PService _processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:]
Caches/VoiceTrigger/SATUpdate
_%d_%d_%@
-[CSP2PService _sendVoiceProfile:toPeerId:]
td/audio
tdti/audio
ti/audio
-[CSP2PService _sendVoiceProfile:toPeerId:]_block_invoke
-[CSP2PService _processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:]
-[CSP2PService _processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:]
-[CSP2PService _sendVoiceProfileUpdateTriggerToPeerId:forLocale:]_block_invoke
Logs/CoreSpeech/spid/grading
-[CSP2PService _createDirectoryIfDoesNotExist:]
SiriDebugVT
RemoteGradingData
VoiceProfileStore
trained_users.json
Caches
-[CSP2PService _getContentsOfDirectory:]
lastCommunicatedPeer
T@"NSString",&,N,V_lastCommunicatedPeer
voiceTriggerBatchId
T@"NSString",&,N,V_voiceTriggerBatchId
voiceIdentificationBatchId
T@"NSString",&,N,V_voiceIdentificationBatchId
adCompanionServiceProvider
T@"<CSADCompanionServiceProvider>",W,N,V_adCompanionServiceProvider
com.apple.corespeech
-[CSVoiceTriggerAwareZeroFilter resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:]
vtEndInSampleCount
TQ,N,V_vtEndInSampleCount
numSamplesProcessed
TQ,N,V_numSamplesProcessed
T@"CSAudioZeroFilter",&,N,V_zeroFilter
T@"<CSVoiceTriggerAwareZeroFilterDelegate>",W,N,V_delegate
com.apple.da
liveOnHomePod
U+73bmG4kBGj6kpreQXUTQ
CSSafeSetOutErrorWithNSError
+N9mZUAHooNvMiQnjeTJ8g
+[CSUtils supportHybridEndpointer]
PTQ+ABwag03BwO/CKvIK/A
4D8XW4YwJI7QvyPhv1TEdw
+[CSUtils isIOSDeviceSupportingBargeIn]_block_invoke
BuildVersion
IOPlatformExpertDevice
+[CSUtils deviceHwRevision]
config-number
yyyyMMdd
-[CSPostBuildInstallService registerPostBuildInstallService]
-[CSPostBuildInstallService registerPostBuildInstallService]_block_invoke
com.apple.cs.postinstall
Trial
assetDownloadfailed
assetFetchfailed
VoiceId
satinitfailed
satmodelfilefailed
satvectorfailed
tdsrfailed
tdsrtimeout
retrainsatfailed
explicituttrejected
toolessaudiofiles
unrecognizedmetadata
delayedscores
missinghomeidforclouduser
voiceidstaleprofiledetected
Audio
didStartWatchDogFire
didStopWatchDogFire
streamDeallocDuringStreaming
resourceNotAvailable
recordStoppedBySessionInterruption
InsufficientPriority
secondPassCompleteWatchDogFire
APLeak
Endpointer
endpointerModelVersionIsNil
CSContinuousAudioFingerprintProvider
-[CSContinuousAudioFingerprintProvider startWithUUID:]
-[CSContinuousAudioFingerprintProvider startWithUUID:]_block_invoke
-[CSContinuousAudioFingerprintProvider stopWithUUID:]
-[CSContinuousAudioFingerprintProvider stopWithUUID:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenPollingWithInterval:completion:]
-[CSContinuousAudioFingerprintProvider _startListenPollingWithInterval:completion:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke_2
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]_block_invoke
-[CSContinuousAudioFingerprintProvider _startListenWithCompletion:]
-[CSContinuousAudioFingerprintProvider _startListenPolling]
-[CSContinuousAudioFingerprintProvider _stopListening]
-[CSContinuousAudioFingerprintProvider _stopListening]_block_invoke
-[CSContinuousAudioFingerprintProvider CSSiriEnabledMonitor:didReceiveEnabled:]
-[CSContinuousAudioFingerprintProvider audioStreamProvider:didStopStreamUnexpectly:]
-[CSContinuousAudioFingerprintProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
isListenPollingStarting
TB,N,V_isListenPollingStarting
audioLoggingBuffer
T@"CSAudioCircularBuffer",&,N,V_audioLoggingBuffer
inUseServices
T@"NSMutableSet",&,N,V_inUseServices
best_phrase
early_warning
is_rescoring
samples_at_fire
start_sample_count
phraseId
TQ,N,V_phraseId
bestPhrase
TQ,N,V_bestPhrase
isEarlyWarning
TB,N,V_isEarlyWarning
isRescoring
TB,N,V_isRescoring
samplesAtFire
TQ,N,V_samplesAtFire
startSampleCount
TQ,N,V_startSampleCount
-[CSKeywordAnalyzerNDAPI initWithConfigPath:resourcePath:]
-[CSKeywordAnalyzerNDAPI _setStartAnalyzeTime:]
threshold_normal
-[CSKeywordAnalyzerNDAPI getThreshold]
threshold_logging
-[CSKeywordAnalyzerNDAPI getLoggingThreshold]
threshold_reject_logging
-[CSKeywordAnalyzerNDAPI getRejectLoggingThreshold]
activePhraseId
TI,N,V_activePhraseId
T@"<CSKeywordAnalyzerNDAPIScoreDelegate>",W,N,V_delegate
Framework
Logs/CrashReporter/CoreSpeech/
Logs/CrashReporter/CoreSpeech/audio/
%@/%@%@%@
::: Initializing CoreSpeech logging...
yyyyMMdd-HHmmss
CSLogInitIfNeeded_block_invoke
gitrelno_unavailable
_CSGetOrCreateAudioLogDirectory
SignalTs, ProcessedAudioMs, StartSample, EndSample, Azimuth, EmaAzimuth, Confidence, SpatialSpreadSpectrum
%llu,%f,%lu,%lu,%f,%f,%f,
{%@, {start=%lu, end=%lu, conf=%f, az=%f, estAz=%fdist=%@}
,%d, 
%f, 
startSample
TQ,N,V_startSample
endSample
TQ,N,V_endSample
confidence
Tf,N,V_confidence
azimuth
Tf,N,V_azimuth
estimatedAzimuth
Tf,N,V_estimatedAzimuth
processedAudioDurMs
Td,N,V_processedAudioDurMs
spatialSpectrumData
T@"NSArray",&,N,V_spatialSpectrumData
azDistribution
T@"NSDictionary",&,N,V_azDistribution
mostSampledAzimuth
totalAudioRecorded
Td,N,V_totalAudioRecorded
featuresAtEndpoint
T@"NSArray",&,N,V_featuresAtEndpoint
endpointerType
Tq,N,V_endpointerType
serverFeatureLatencyDistribution
T@"NSDictionary",&,N,V_serverFeatureLatencyDistribution
additionalMetrics
T@"NSDictionary",&,N,V_additionalMetrics
noiseLevelDB
musicLevelDB
musicPlaybackVolumeDB
alarmVolume
finalTTSVolume
isLKFSProcessPaused
removeVoiceTriggerSamples
-[CSSmartSiriVolume initWithSamplingRate:asset:]
-[CSSmartSiriVolume startSmartSiriVolume]_block_invoke
RUNNING
PAUSED
-[CSSmartSiriVolume _startListenPolling]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]
-[CSSmartSiriVolume _startListenPollingWithInterval:completion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke_2
-[CSSmartSiriVolume _startListenWithCompletion:]_block_invoke
-[CSSmartSiriVolume _startListenWithCompletion:]
-[CSSmartSiriVolume _stopListening]
-[CSSmartSiriVolume _stopListening]_block_invoke
-[CSSmartSiriVolume initializeMediaPlayingState]_block_invoke
playing
NOT playing
-[CSSmartSiriVolume initializeMediaPlayingState]
-[CSSmartSiriVolume initializeAlarmState]_block_invoke
firing
NOT firing
-[CSSmartSiriVolume initializeTimerState]_block_invoke
-[CSSmartSiriVolume _setAsset:]
-[CSSmartSiriVolume _processAudioChunk:soundType:]
-[CSSmartSiriVolume estimateSoundLevelbySoundType:]_block_invoke
-[CSSmartSiriVolume _pauseSSVProcessing]_block_invoke
-[CSSmartSiriVolume _resumeSSVProcessing]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:audioBufferAvailable:]_block_invoke
-[CSSmartSiriVolume audioStreamProvider:didStopStreamUnexpectly:]
-[CSSmartSiriVolume didDetectKeywordWithResult:]
-[CSSmartSiriVolume didDetectKeywordWithResult:]_block_invoke
-[CSSmartSiriVolume estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:]_block_invoke
-[CSSmartSiriVolume _combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:]
-[CSSmartSiriVolume CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:]_block_invoke
-[CSSmartSiriVolume didReceiveAlarmChanged:]_block_invoke
-[CSSmartSiriVolume didReceiveTimerChanged:]_block_invoke
-[CSSmartSiriVolume CSSiriEnabledMonitor:didReceiveEnabled:]
-[CSSmartSiriVolume CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSSmartSiriVolume siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:]_block_invoke
-[CSSmartSiriVolume _setStartAnalyzeTime:]
-[CSSmartSiriVolume getVolumeForTTSType:withOverrideMediaVolume:WithRequestTime:]
listenPollingTimer
T@"NSObject<OS_dispatch_source>",&,N,V_listenPollingTimer
listenPollingTimerCount
Tq,N,V_listenPollingTimerCount
CSSACInfoMonitor queue
-[CSSACInfoMonitor _startMonitoringWithQueue:]
-[CSSACInfoMonitor _stopMonitoring]
-[CSSACInfoMonitor isDeviceRoleStereo]
CSRemoteControlClient
-[CSRemoteControlClient dealloc]
T@"<CSRemoteControlClientDelegate>",W,N,V_delegate
RTModelData
RTModelHash
RTModelLocale
RTModelDigest
RTModelSignature
RTModelCertificate
RT Model for 
 from asset 
CorealisRTModel
CorealisRTModelVersion
dataSize(%d), hash(%@), locale(%@), digest(%@), cert(%@), signature(%@)
modelData
T@"NSData",R,N,V_modelData
modelLocale
T@"NSString",R,N,V_modelLocale
modelHash
T@"NSString",R,N,V_modelHash
digest
T@"NSData",R,N,V_digest
T@"NSData",R,N,V_signature
certificate
T@"NSData",R,N,V_certificate
::: Initializing NVI logging...
InitNviLogging_block_invoke
CSAudioRouteChangeMonitorImpl queue
-[CSAudioRouteChangeMonitorImpl preferredExternalRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl carPlayAudioRouteDidChange:]_block_invoke
-[CSAudioRouteChangeMonitorImpl _stopMonitoring]
-[CSAudioRouteChangeMonitorImpl _notifyHearstConnectionState:]
-[CSAudioRouteChangeMonitorImpl _notifyJarvisConnectionState:]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _stopMonitoring]
-[CSSpeakerRecognitionAssetMetaUpdateMonitor _didReceiveSpeakerRecognitionAssetMetaData]
com.apple.MobileAsset.SpeakerRecognitionAssets.ma.cached-metadata-updated
com.apple.coreaudio.BorealisToggled
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]_block_invoke
-[CSVoiceTriggerEnabledMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerEnabledMonitor _stopMonitoring]
-[CSVoiceTriggerEnabledMonitor _checkVoiceTriggerEnabled]
Borealis Input
com.apple.VoiceTriggerUI.RecordSessionQueue
-[CSVTUIAudioSessionRecorder init]
-[CSVTUIAudioSessionRecorder _audioRecorder]
-[CSVTUIAudioSessionRecorder prepareRecord]
-[CSVTUIAudioSessionRecorder startRecording]
-[CSVTUIAudioSessionRecorder stopRecording]
-[CSVTUIAudioSessionRecorder _hasCorrectInputAudioRoute]
-[CSVTUIAudioSessionRecorder _hasCorrectOutputAudioRoute]
T@"<CSVTUIAudioSessionDelegate>",W,N,V_delegate
CSRemoteRecordClient Queue
T@"<CSRemoteRecordClientDelegate>",W,N,V_delegate
-[CSSiriEnabledMonitor _startMonitoringWithQueue:]
-[CSSiriEnabledMonitor _stopMonitoring]
_AssistantPrefsChangedNotification
com.apple.nvi.csaudiosrc
-[NviCSAudioDataSource startWithNviContext:didStartHandler:]_block_invoke_2
-[NviCSAudioDataSource stopWithDidStopHandler:]_block_invoke_2
-[NviCSAudioDataSource _createAudioStreamWithCurrentNviContext]
-[NviCSAudioDataSource audioStreamProvider:avBufferAvailable:]
-[NviCSAudioDataSource audioStreamProvider:didStopStreamUnexpectly:]
-[NviCSAudioDataSource audioStreamProvider:audioChunkForTVAvailable:]
numBytesPerSample
nviCtx
T@"NviContext",&,N,V_nviCtx
receivers
T@"NSHashTable",&,N,V_receivers
beepLocation
statsComputed
beepPower
signalPower
originalPower
absMaxVal
above95pcOfMax
totalInputSamples
totalOutputSamples
jbl_begin.bin
-[CSBeepCanceller init]
-[CSBeepCanceller willBeep]
-[CSBeepCanceller reset]
T@"<CSBeepCancellerDelegate>",W,N,V_delegate
metrics
RMSScore
Td,N,V_RMSScore
lastSampleCount
TQ,N,V_lastSampleCount
-[CSShadowMicScoreCreator calculateShadowMicScore]
rmsSamplesForEntireAudio
T@"NSMutableArray",&,N,V_rmsSamplesForEntireAudio
audioBuffer
T@"NSMutableData",&,N,V_audioBuffer
speechVoiceLevel
Td,N,V_speechVoiceLevel
numberOfVoicingFrames
TQ,N,V_numberOfVoicingFrames
numberOfTotalFramesETFT
Tq,N,V_numberOfTotalFramesETFT
bestStartDetectSample
TQ,N,V_bestStartDetectSample
bestEarlyDetectSample
TQ,N,V_bestEarlyDetectSample
bestEndDetectSample
TQ,N,V_bestEndDetectSample
shadowMicScore
Td,N,V_shadowMicScore
CSActivationEventNotifier
-[CSActivationEventNotifier notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotifier notifyActivationEvent:deviceId:activationInfo:completion:]_block_invoke
-[CSActivationEventNotifier _createXPCClientConnection]
-[CSGestureMonitorWatch _startMonitoringWithQueue:]
-[CSGestureMonitorWatch wakeGestureRecognized:]
CSLSWakeGestureMonitor
Class getCSLSWakeGestureMonitorClass(void)_block_invoke
CSGestureMonitorWatch.m
Unable to find class %s
void *CarouselServicesLibrary(void)
/System/Library/PrivateFrameworks/CarouselServices.framework/CarouselServices
/System/Library/PrivateFrameworks/CarouselServices.framework/Contents/MacOS/CarouselServices
CSInitialContinousZeros
CSMaxContinousZeros
CSMidSegmentContinousZeros
+[CSUtils(AudioFile) readAudioChunksFrom:block:]
-[CSSoftwareUpdateCheckingMonitor _startMonitoringWithQueue:]
-[CSSoftwareUpdateCheckingMonitor _stopMonitoring]
-[CSSoftwareUpdateCheckingMonitor _checkSoftwareUpdateCheckingState]
com.apple.duetscheduler.restartCheckNotification
-[CSAssetManagerEnablePolicy _addAssetManagerEnabledConditions]_block_invoke
-[CSAudioCircularBuffer initWithNumChannels:recordingDuration:samplingRate:]
-[CSAudioCircularBuffer copySamplesFromHostTime:]
-[CSAudioCircularBuffer copySamplesFrom:to:]
-[CSAudioCircularBuffer copybufferFrom:to:]
-[CSAudioCircularBuffer copyBufferWithNumSamplesCopiedIn:]
-[CSAudioCircularBuffer reset]
bufferLength
TQ,N,V_bufferLength
copySamples
+[SSREnrollmentDataManager saveRawUtteranceAndMetadata:to:isExplicitEnrollment:]
+[SSREnrollmentDataManager saveUtteranceAndMetadata:atDirectory:isExplicitEnrollment:]
+[SSREnrollmentDataManager saveUtterance:utteranceAudioPath:numSamplesToWrite:isExplicitEnrollment:]
+[SSREnrollmentDataManager saveMetadata:isExplicitEnrollment:]
+[SSREnrollmentDataManager _getBaseMetaDictionaryForUtterancePath:]
+[SSREnrollmentDataManager writeMetaDict:atMetaPath:]
-[CSVoiceTriggerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSVoiceTriggerAssetMetaUpdateMonitor _stopMonitoring]
-[CSVoiceTriggerAssetMetaUpdateMonitor _didReceiveNewVoiceTriggerAssetMetaData]
com.apple.MobileAsset.VoiceTriggerAssets.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsIPad.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsWatch.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMarsh.ma.cached-metadata-updated
com.apple.MobileAsset.VoiceTriggerAssetsMac.ma.cached-metadata-updated
-[CSRemoteVADCircularBuffer copySamplesFrom:to:]
capacity
TQ,R,N,V_capacity
size
TQ,R,N,V_size
beginSampleCount
TQ,R,N,V_beginSampleCount
-[CSAdBlockerAssetMetaUpdateMonitor _startMonitoringWithQueue:]
-[CSAdBlockerAssetMetaUpdateMonitor _stopMonitoring]
-[CSAdBlockerAssetMetaUpdateMonitor _didReceiveNewAdBlockerAssetMetaData]
com.apple.MobileAsset.AdBlockerAssets.ma.cached-metadata-updated
-[CSAudioStream initWithAudioStreamProvider:streamName:streamRequest:]
-[CSAudioStream dealloc]
-[CSAudioStream startAudioStreamWithOption:completion:]
-[CSAudioStream isStreaming]
-[CSAudioStream audioStreamProvider:didStopStreamUnexpectly:]
-[CSAudioStream audioStreamProvider:didHardwareConfigurationChange:]
streaming
TB,V_streaming
streamingUUID
T@"NSUUID",&,V_streamingUUID
T@"<CSAudioStreamProviding>",W,N,V_streamProvider
T@"<CSAudioStreamProvidingDelegate>",W,N,V_delegate
scheduledFutureSample
TB,N,V_scheduledFutureSample
streamRequest
T@"CSAudioStreamRequest",&,N,V_streamRequest
startStreamOption
T@"CSAudioStartStreamOption",&,N,V_startStreamOption
{wordCount: %ld, trailingSilDuration: %ld, eosLikelihood: %f, pauseCounts: (%@), silencePosterior: %f, taskName: %@, processedAudioDurationInMilliseconds: %ld}
WordCount
TrailingSilDuration
EOSLikelihood
PauseCounts
SilencePosterior
ProcessedAudioDurationInMilliseconds
wordCount
Tq,N,V_wordCount
trailingSilenceDuration
Tq,N,V_trailingSilenceDuration
eosLikelihood
Td,N,V_eosLikelihood
pauseCounts
T@"NSArray",C,N,V_pauseCounts
silencePosterior
Td,N,V_silencePosterior
processedAudioDurationInMilliseconds
Tq,N,V_processedAudioDurationInMilliseconds
taskName
T@"NSString",C,N,V_taskName
CSActivationEventNotificationHandler Queue
-[CSActivationEventNotificationHandler setDelegate:forType:]_block_invoke
-[CSActivationEventNotificationHandler notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotificationHandler _notifyActivationEvent:completion:]
-[CSActivationEventNotificationHandler _notifyActivationEvent:completion:]_block_invoke
-[CSActivationEventNotificationHandler _startMonitoring]
-[CSActivationEventNotificationHandler _stopMonitoring]
-[CSActivationEventNotificationHandler _didReceiveAOPFirstPassTrigger:completion:]
-[CSActivationEventNotificationHandler _didReceiveAOPFirstPassTrigger:completion:]_block_invoke
delegates
T@"NSMapTable",&,N,V_delegates
pendingActivationEvent
T@"CSActivationEvent",&,N,V_pendingActivationEvent
pendingCompletion
T@?,C,N,V_pendingCompletion
-[CoreSpeechXPC installedVoiceTriggerAssetForLanguageCode:completion:]
-[CoreSpeechXPC fetchRemoteVoiceTriggerAssetForLanguageCode:completion:]
-[CoreSpeechXPC _handleFakeHearstModelRequest:majorVersion:minorVersion:downloadedModels:preinstalledModels:completion:]
fakeModel.json
fakeModel
-[CoreSpeechXPC voiceTriggerRTModelForVersion:minorVersion:locale:downloadedModels:preinstalledModels:completion:]
v40@?0@"CSVoiceTriggerRTModel"8@"CSVoiceTriggerRTModel"16@"NSString"24@"NSError"32
-[CoreSpeechXPC voiceTriggerRTModelForVersion:minorVersion:locale:downloadedModels:preinstalledModels:completion:]_block_invoke
-[CoreSpeechXPC voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]_block_invoke
-[CoreSpeechXPC voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:]
de-AT
de-DE
de-CH
en-AU
en-CA
en-GB
en-SG
en-IE
en-IN
en-ZA
en-NZ
it-IT
it-CH
ja-JP
zh-CN
zh-TW
nb-NO
nl-BE
nl-NL
sv-SE
tr-TR
fi-FI
he-IL
es-ES
es-US
es-CL
es-MX
fr-FR
fr-BE
fr-CA
fr-CH
ko-KR
zh-HK
yue-CN
da-DK
ms-MY
pt-BR
ru-RU
th-TH
ar-AE
ar-SA
-[CSSiriRestrictionOnLockScreenMonitor _startMonitoringWithQueue:]
-[CSSiriRestrictionOnLockScreenMonitor _stopMonitoring]
-[CSSiriRestrictionOnLockScreenMonitor _checkSiriRestrictedOnLockScreen]
-[CSSpringboardStartMonitor _startMonitoringWithQueue:]
-[CSSpringboardStartMonitor _stopMonitoring]
-[CSSpringboardStartMonitor _checkSpringBoardStarted]
com.apple.springboard.finishedstartup
CSAudioProvider
CSAudioProvider logging
-[CSAudioProvider dealloc]
-[CSAudioProvider setStreamState:]
-[CSAudioProvider setAudioRecorder:]_block_invoke
-[CSAudioProvider setCurrentContext:error:]
-[CSAudioProvider setCurrentContext:error:]_block_invoke
-[CSAudioProvider _audioStreamWithRequest:streamName:error:]
-[CSAudioProvider _prepareAudioStreamSync:request:error:]
-[CSAudioProvider _createCircularBufferIfNeeded]
-[CSAudioProvider _tearDownCircularBufferIfNeeded]
-[CSAudioProvider startAudioStream:option:completion:]
-[CSAudioProvider startAudioStream:option:completion:]_block_invoke
-[CSAudioProvider prepareAudioStreamSync:request:error:]
-[CSAudioProvider prepareAudioStream:request:completion:]
-[CSAudioProvider _startAudioStream:option:completion:]
-[CSAudioProvider _switchToRecordingMode]
-[CSAudioProvider _switchToListeningMode]
-[CSAudioProvider _handleDidStartAudioStreamWithResult:error:]
-[CSAudioProvider _handleDidStopAudioStreamWithReason:]
-[CSAudioProvider _stopAudioStream:option:completion:]
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke
-[CSAudioProvider _stopAudioStream:option:completion:]_block_invoke_2
/Library/Caches/com.apple.xbs/Sources/CoreSpeech_Sim/CoreSpeech-441.5/CoreSpeech/CSAudioProvider.m
-[CSAudioProvider _saveRecordingBufferFrom:to:toURL:]_block_invoke
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke_2
-[CSAudioProvider holdAudioStreamWithDescription:timeout:]_block_invoke
-[CSAudioProvider cancelAudioStreamHold:]
-[CSAudioProvider cancelAudioStreamHold:]_block_invoke
-[CSAudioProvider prewarmAudioSessionWithError:]
-[CSAudioProvider activateAudioSessionWithReason:dynamicAttribute:bundleID:error:]
-[CSAudioProvider _activateAudioSessionWithReason:error:]
-[CSAudioProvider deactivateAudioSession:error:]
-[CSAudioProvider _deactivateAudioSession:error:]
-[CSAudioProvider setAlertSoundFromURL:forType:]
-[CSAudioProvider playAlertSoundForType:]
-[CSAudioProvider playRecordStartingAlertAndResetEndpointer]
-[CSAudioProvider alertStartTime]
-[CSAudioProvider triggerInfoForContext:completion:]_block_invoke
-[CSAudioProvider _shouldStopRecording]
-[CSAudioProvider audioRecorderStreamHandleIdInvalidated:]
-[CSAudioProvider audioRecorderWillBeDestroyed:]_block_invoke
-[CSAudioProvider _fetchHistoricalAudioAndForwardToStream:remoteVAD:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]
-[CSAudioProvider _scheduleAlertFinishTimeout:]_block_invoke
-[CSAudioProvider _didReceiveFinishStartAlertPlaybackAt:]
-[CSAudioProvider audioRecorderBuiltInAudioStreamInvalidated:error:]_block_invoke
-[CSAudioProvider audioRecorderDisconnected:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]
-[CSAudioProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]
-[CSAudioProvider _handleAudioSystemFailure]
StreamInit
StreamPrepared
StreamStarting
StreamSteaming
StreamStopping
StreamStoppingWithScheduledStart
unknown(%tu)
Recording transaction
-[CSAudioProvider _releaseRecordingTransactionIfNeeded]
%@-%@
-[CSAudioProvider _scheduleDidStartRecordingDelegateWatchDog]
-[CSAudioProvider _schduleDidStartRecordingDelegateWatchDogWithToken:]
-[CSAudioProvider _clearDidStartRecordingDelegateWatchDog]
-[CSAudioProvider _scheduleDidStopRecordingDelegateWatchDog]
-[CSAudioProvider _scheduleDidStopRecordingDelegateWatchDog:]
-[CSAudioProvider _clearDidStopRecordingDelegateWatchDog]
recordQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_recordQueue
loggingQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_loggingQueue
streamState
TQ,N,V_streamState
startPendingStreams
T@"NSHashTable",&,N,V_startPendingStreams
startPendingOnStoppingStreams
T@"NSHashTable",&,N,V_startPendingOnStoppingStreams
alertPlaybackFinishWaitingStreams
T@"NSHashTable",&,N,V_alertPlaybackFinishWaitingStreams
streams
T@"NSHashTable",&,N,V_streams
stopPendingStreams
T@"NSHashTable",&,N,V_stopPendingStreams
pendingStartCompletions
T@"NSMutableArray",&,N,V_pendingStartCompletions
alertPlaybackFinishWaitingCompletions
T@"NSMutableArray",&,N,V_alertPlaybackFinishWaitingCompletions
pendingStopCompletions
T@"NSMutableArray",&,N,V_pendingStopCompletions
startPendingOnStoppingStreamToCompletionDict
T@"NSMutableDictionary",&,N,V_startPendingOnStoppingStreamToCompletionDict
providerDelegate
T@"<CSAudioProviderDelegate>",W,N,V_providerDelegate
sessionDelegate
T@"<CSAudioSessionProvidingDelegate>",W,N,V_sessionDelegate
streamHolders
T@"NSMutableArray",&,N,V_streamHolders
historicalBufferRequestStreams
T@"NSHashTable",&,N,V_historicalBufferRequestStreams
alertDelegate
T@"<CSAudioAlertProvidingDelegate>",W,N,V_alertDelegate
lastAudioRecorderContext
T@"CSAudioRecordContext",&,N,V_lastAudioRecorderContext
audioSystemRecovering
TB,N,V_audioSystemRecovering
audioPreprocessor
T@"CSAudioPreprocessor",&,N,V_audioPreprocessor
recordingTransaction
T@"CSOSTransaction",&,N,V_recordingTransaction
recordingWillStartGroup
T@"NSObject<OS_dispatch_group>",&,N,V_recordingWillStartGroup
waitingForAlertFinish
TB,N,V_waitingForAlertFinish
alertPlaybackFinishTimeoutToken
T@"NSUUID",&,N,V_alertPlaybackFinishTimeoutToken
startRecordingWatchDogToken
T@"NSUUID",&,N,V_startRecordingWatchDogToken
stopRecordingWatchDogToken
T@"NSUUID",&,N,V_stopRecordingWatchDogToken
circularBufferStartHostTime
TQ,N,V_circularBufferStartHostTime
circularBufferStartSampleCount
TQ,N,V_circularBufferStartSampleCount
-[CSListeningEnabledPolicyWatch _addListeningEnabledConditions]_block_invoke
-[NSArray(XPCObject) _cs_initWithXPCObject:]
-[NSArray(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0Q8@"NSObject<OS_xpc_object>"16
-[NSArray(XPCObject) _cs_xpcObject]_block_invoke
-[CSAlwaysOnProcessorStateMonitor _didReceiveAOPListeningStateChange:]
+[CSAdBlockerAssetDecoderFactory adBlockerAssetDecoderWithVersion:]
-[CSAudioChunk subChunkFrom:numSamples:forChannel:]
-[CSAudioChunk subChunkFrom:numSamples:]
-[CSAudioChunk splitAudioChunkSuchThatNumSamplesReceivedSoFar:reachesACountOf:completionHandler:]
T@"NSData",R,N,V_data
TQ,R,N,V_numChannels
TQ,R,N,V_numSamples
TQ,R,N,V_sampleByteDepth
TQ,R,N,V_startSampleCount
TQ,R,N,V_hostTime
remoteVADAvailable
T@"NSData",&,N,V_remoteVAD
numSamples
sampleByteDepth
data
remoteVAD
sampleFed
TQ,N,V_sampleFed
earlyWarning
TB,N,V_earlyWarning
payloadData
T@"NSData",&,N,V_payloadData
T@"NSString",&,N,V_endpointerModelVersion
TB,R,N,V_canProcessCurrentRequest
deviceType
Tq,R,N,V_deviceType
deviceName
T@"NSString",R,N,V_deviceName
deviceID
T@"NSString",R,N,V_deviceID
deviceUID
T@"NSUUID",R,N,V_deviceUID
productIdentifier
T@"NSString",R,N,V_productIdentifier
isConnected
TB,N,V_isConnected
isPluginDevice
enableAlwaysOnVoiceTrigger
TB,N,V_enableAlwaysOnVoiceTrigger
injectionEngine
T@"CSAudioInjectionEngine",W,N,V_injectionEngine
+[CSUtils(Time) hostTimeFromSampleCount:anchorHostTime:anchorSampleCount:]
+[CSUtils(Time) sampleCountFromHostTime:anchorHostTime:anchorSampleCount:]
+[CSUtils(Time) macHostTimeFromBridgeHostTime:]
CSAudioSessionInfoProvider
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerCrash:]_block_invoke
-[CSAudioSessionInfoProvider CSAudioServerCrashMonitorDidReceiveServerRestart:]_block_invoke
-[CSAudioSessionInfoProvider _registerInterruptionNotification]
-[CSAudioSessionInfoProvider _registerAudioRouteChangeNotification]
-[CSAudioSessionInfoProvider _handleInterruption:]_block_invoke
-[CSAudioSessionInfoProvider _audioRouteChanged:]_block_invoke
-[CSAudioSessionInfoProvider _deregisterAudioSessionNotifications]
sessionInfoQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_sessionInfoQueue
-[CSEndpointerProxy resetForNewRequestWithSampleRate:recordContext:recordSettings:voiceTriggerInfo:]
-[CSEndpointerProxy resetForVoiceTriggerTwoShotWithSampleRate:]
-[CSEndpointerProxy preheat]
-[CSEndpointerProxy endpointer:didDetectStartpointAtTime:]
-[CSEndpointerProxy endpointer:didDetectHardEndpointAtTime:withMetrics:]
-[CSEndpointerProxy endpointer:detectedTwoShotAtTime:]
-[CSEndpointerProxy endpointerModelVersion]
-[CSEndpointerProxy logHybridEndpointFeaturesWithEvent:locale:]
hybridEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_hybridEndpointer
nnvadEndpointer
T@"<CSEndpointAnalyzerImpl>",&,N,V_nnvadEndpointer
activeEndpointer
T@"<CSEndpointAnalyzerImpl>",W,N,V_activeEndpointer
T@"NSDictionary",&,N,V_recordContext
recordingDidStop
TB,N,V_recordingDidStop
endpointerDelegate
T@"<CSEndpointAnalyzerDelegate>",W,N,V_endpointerDelegate
Serial CSCATAssetManager queue
-[CSCATAssetManager downloadForManifest:withAssetName:]_block_invoke_2
v32@?0@"NSString"8@"NSString"16@"NSError"24
-[CSCATAssetManager fetchRemoteCATAssetForResource:withNameOfFile:completion:]_block_invoke
CATXPC service invalidated
T@"<CSCATAssetManagerDelegate>",W,N,V_delegate
-[NSNumber(XPCObject) _cs_initWithXPCObject:]
-[NSNumber(XPCObject) _cs_xpcObject]
-[CSFirstUnlockMonitor _stopMonitoring]
kVTPreferencesPhraseSpotterEnabledDidChangeDarwinNotification
-[CSPhraseSpotterEnabledMonitor _checkPhraseSpotterEnabled]
-[CSPhraseSpotterEnabledMonitor _phraseSpotterEnabledDidChange]
corespeechd speaker xpc connection client queue
-[CSVoiceIdXPCConnection _handleClientEvent:]
-[CSVoiceIdXPCConnection _handleClientMessage:client:]
-[CSVoiceIdXPCConnection _handleClientError:client:]
connection
T@"NSObject<OS_xpc_object>",&,N,V_connection
com.apple.
com.apple.private.
CSFallbackAudioSessionReleaseProvider
-[CSFallbackAudioSessionReleaseProvider fallbackDeactivateAudioSession:error:]_block_invoke
-[CSFallbackAudioSessionReleaseProvider fallbackDeactivateAudioSession:error:]
T@"<CSSPGEndpointAnalyzerDelegate>",W,N,V_delegate
samplingRate
Tf,N,V_samplingRate
dictationLanguages
T@"NSSet",&,N,V_dictationLanguages
currentKeyboard
T@"NSString",&,N,V_currentKeyboard
wasLanguageToggled
TB,N,V_wasLanguageToggled
multilingualKeyboardLanguages
T@"NSArray",&,N,V_multilingualKeyboardLanguages
keyboardConvoLanguagePriors
T@"NSDictionary",&,N,V_keyboardConvoLanguagePriors
keyboardGlobalLanguagePriors
T@"NSDictionary",&,N,V_keyboardGlobalLanguagePriors
previousMessageLanguage
T@"NSString",&,N,V_previousMessageLanguage
globalLastKeyboardUsed
T@"NSString",&,N,V_globalLastKeyboardUsed
dictationLanguagePriors
T@"NSDictionary",&,N,V_dictationLanguagePriors
conversationalMessages
T@"NSArray",&,N,V_conversationalMessages
-[CSStartOfSpeechDetector initWithConfig:samplingRate:minSpeechFrames:numLeadingFrames:delegate:]
T@"<CSStartOfSpeechDetectorDelegate>",W,N,V_delegate
-[CSAudioServerCrashMonitor _startMonitoringWithQueue:]
serverState
TQ,N,V_serverState
com.apple.corespeech.voicetriggerservice
-[CSVoiceTriggerXPCClient dealloc]
-[CSVoiceTriggerXPCClient _handleListenerEvent:]
-[CSVoiceTriggerXPCClient _handleListenerError:]
enable
assertion
timestamp
phraseSpotterBypass
bypassTimeout
raiseToSpeakBypass
triggerStats
-[CSVoiceTriggerXPCClient fetchVoiceTriggerStats]
T@"<CSVoiceTriggerXPCClientDelegate>",W,N,V_delegate
-[CSCoreSpeechDaemonStateMonitor notifyDaemonStateChanged:]
com.apple.corespeech.corespeechd.launch
-[CSCoreSpeechDaemonStateMonitor _startMonitoringWithQueue:]
-[CSCoreSpeechDaemonStateMonitor _stopMonitoring]
-[CSCoreSpeechDaemonStateMonitor _didReceiveDaemonStateChanged:]
-[CSKeywordAnalyzerQuasar dealloc]
-[CSKeywordAnalyzerQuasar runRecognition]
-[CSKeywordAnalyzerQuasar endAudio]
Td,R,N,V_triggerConfidence
T@"<CSKeywordAnalyzerQuasarScoreDelegate>",W,N,V_delegate
-[CSNetworkAvailabilityMonitor _startMonitoringWithQueue:]
-[CSNetworkAvailabilityMonitor _stopMonitoring]
-[CSNetworkAvailabilityMonitor _availabilityChanged]
-[CSSpeechDetectionDevicePresentMonitor handleSpeechDetectionVADPresentChange:]
-[CSSpeechDetectionDevicePresentMonitor _systemControllerDied:]
route
isRemoteDevice
remoteDeviceUID
remoteDeviceProductIdentifier
%@ {route = %@, isRemoteDevice = %d, remoteDeviceUID = %@, remoteDeviceProductIdentifier = %@}
T@"NSString",R,C,N,V_route
TB,R,N,V_isRemoteDevice
T@"NSUUID",R,C,N,V_remoteDeviceUID
T@"NSString",R,C,N,V_remoteDeviceProductIdentifier
CSOpportuneSpeakListnerTestService
com.apple.corespeech.opportunelistner.start
com.apple.corespeech.opportunelistner.stop
A945B95D-69F6-FC77-4FAE-91F50A039CD8
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStart]_block_invoke
-[CSOpportuneSpeakListnerTestService receiveOpportuneSpeakListenerStop]_block_invoke
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasRemoteVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:hasVADAvailable:]
-[CSOpportuneSpeakListnerTestService opportuneSpeakListener:didStopUnexpectly:]
corespeech.json
assets.json
speakerRecognition.json
adBlockerPayload.bin
hybridendpointer.json
hybridendpointer_marsh.json
CSAsset.m
ERR: Unknown assetType: %lu
/System/Library/PrivateFrameworks/CoreSpeech.framework
+[CSAsset fallBackAssetResourcePath]
defaultFallbackHearst
defaultFallbackAdBlocker
-[CSAsset initWithResourcePath:configFile:configVersion:assetProvderType:]
-[CSAsset _decodeJson:]
-[CSAsset getNumberForKey:category:default:]
-[CSAsset getStringForKey:category:default:]
configVersion:%@ resourcePath:%@ path:%@
MobileAssets
path
T@"NSString",R,N,V_path
resourcePath
T@"NSString",R,N,V_resourcePath
hashFromResourcePath
T@"NSString",R,N,V_configVersion
assetProvider
TQ,R,N,V_assetProvider
-[CSAudioConverter _convertBufferedLPCM:allowPartial:timestamp:]
CSAudioConverter.m
Cannot produce ASPD for PCM
-[CSAudioConverter reset]
-[CSAudioConverter _configureAudioConverter:]
T@"<CSAudioConverterDelegate>",W,V_delegate
CreateAudioConverter
-[CSLanguageCodeUpdateMonitor _startMonitoringWithQueue:]
-[CSLanguageCodeUpdateMonitor _stopMonitoring]
-[CSLanguageCodeUpdateMonitor _didReceiveLanguageCodeUpdate]
Serial CSPolicy queue
-[NSData(Nvi) splitAudioDataToReachSampleCount:currSampleCount:numBytesPerSample:completionHandler:]
com.apple.corespeech.audioinjection.xpc
+[CSAudioInjectionServices setAudioInjectionMode:]
+[CSAudioInjectionServices audioInjectionEnabled]
+[CSAudioInjectionServices pingpong:completion:]_block_invoke
TEST
+[CSAudioInjectionServices pingpong:completion:]
v28@?0B8@"NSError"12@"NSUUID"20
+[CSAudioInjectionServices createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:]_block_invoke
+[CSAudioInjectionServices createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:]
v36@?0B8@"NSError"12Q20Q28
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:]_block_invoke
+[CSAudioInjectionServices injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:]
+[CSAudioInjectionServices connectDeviceWithUUID:completion:]_block_invoke
+[CSAudioInjectionServices connectDeviceWithUUID:completion:]
+[CSAudioInjectionServices disconnectDeviceWithUUID:completion:]_block_invoke_2
+[CSAudioInjectionServices disconnectDeviceWithUUID:completion:]_block_invoke
+[CSAudioInjectionServices disconnectDeviceWithUUID:completion:]
+[CSAudioInjectionServices primaryInputDeviceUUIDWithCompletion:]_block_invoke_2
+[CSAudioInjectionServices primaryInputDeviceUUIDWithCompletion:]_block_invoke
+[CSAudioInjectionServices primaryInputDeviceUUIDWithCompletion:]
Dpg:%.3f Dpd:%.3f T:%.3f
Td,R,N,V_droppingPrediction
Td,R,N,V_droppedPrediction
Td,R,N,V_timestamp
droppingPrediction
droppedPrediction
voic
carplay
hearst
raisetospeak
auto
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]
-[NSDictionary(XPCObject) _cs_initWithXPCObject:]_block_invoke
B24@?0r*8@"NSObject<OS_xpc_object>"16
-[NSDictionary(XPCObject) _cs_xpcObject]_block_invoke
v32@?0@8@16^B24
+[CSUserIdentityClassifier pickTopScoringProfileIdFromScores:]
+[CSUserIdentityClassifier classifyUserIdentityFor:withScores:withAsset:]
Confident
Known
Unsure1
UnsureN
+[CSUserIdentityClassifier stringFromClassificationCategory:]
effectiveThreshold
recognizerScore
recognizerThresholdOffset
threshold
supportedPhrases
mpvt2ndPassTriggeredPhraseId
phraseStr
ndapiScore
2ndChanceThreshold
loggingThreshold
recognizerScoreScaleFactor
tdsrSatCombinedSATThreshold
%lu:%@:ndapi=%f:ctc=%f:comb=%f:thr=%f:maxd=%d:
%lu:%@:ndapi=%f:ctc=%f:comb=%f:thr=%f:maxd=%d:res=%@
phId
TQ,N,V_phId
phStr
T@"NSString",&,N,V_phStr
Tf,N,V_threshold
secondChanceThreshold
Tf,N,V_secondChanceThreshold
Tf,N,V_loggingThreshold
useKwdSpotting
TB,N,V_useKwdSpotting
Tf,N,V_recognizerScoreScaleFactor
Tf,N,V_recognizerThresholdOffset
Tf,N,V_satThreshold
Tf,N,V_tdsrSatCombinedSATThreshold
Tf,N,V_ndapiScore
ctcCheckerScore
Tf,N,V_ctcCheckerScore
combinedScore
Tf,N,V_combinedScore
isMaximized
TB,N,V_isMaximized
ndapiResult
T@"CSKeywordAnalyzerNDAPIResult",&,N,V_ndapiResult
-[CSVTSecondPassScorer initWithAsset:firstPassSource:]
-[CSVTSecondPassScorer updateWithCtcCheckerResults:]
-[CSVTSecondPassScorer getTriggeredPhraseWithSecondChanceEnabled:]
%@, 
triggeredPhrase
T@"CSVTSecondPassPhraseScore",&,N,V_triggeredPhrase
phraseMap
T@"NSDictionary",&,N,V_phraseMap
detector-config
supported-locales
detector.json
sos-options.json
SPG.json
languageDetectorSupportedLocale
T@"NSArray",R,N
languageDetectorConfigFile
startOfSpeechDetectorConfigFile
spgConfigFile
[streamHandleId = %d]
[startHostTime = %llu]
[startAlert = %d]
[stopAlert = %d]
[stopOnErrorAlert = %d]
[skipAlert = %@]
VoiceControllerCreationQueue
-[CSAudioRecorder initWithQueue:error:]
-[CSAudioRecorder willDestroy]
-[CSAudioRecorder dealloc]
-[CSAudioRecorder _destroyVoiceController]
-[CSAudioRecorder _voiceControllerWithError:]_block_invoke
-[CSAudioRecorder _voiceControllerWithError:]
-[CSAudioRecorder setContext:error:]
-[CSAudioRecorder setCurrentContext:streamHandleId:error:]
-[CSAudioRecorder prepareAudioStreamRecord:streamHandleId:error:]
-[CSAudioRecorder _startAudioStreamForAudioInjection]
-[CSAudioRecorder startAudioStreamWithOption:streamHandleId:error:]
-[CSAudioRecorder stopAudioStreamWithStreamHandleId:error:]
-[CSAudioRecorder isSessionCurrentlyActivated]
Builtin Microphone
-[CSAudioRecorder recordingSampleRateWithStreamHandleId:]
-[CSAudioRecorder isNarrowBandWithStreamHandleId:]
-[CSAudioRecorder prewarmAudioSessionWithStreamHandleId:error:]
-[CSAudioRecorder setRecordMode:streamHandleId:error:]
-[CSAudioRecorder activateAudioSessionWithReason:streamHandleId:error:]
-[CSAudioRecorder deactivateAudioSession:error:]
+[CSAudioRecorder createSharedAudioSession]
-[CSAudioRecorder enableSmartRoutingConsiderationForStream:enable:]
-[CSAudioRecorder setDuckOthersOption:]
-[CSAudioRecorder enableMiniDucking:]
Enable
Disable
-[CSAudioRecorder configureAlertBehavior:audioStreamHandleId:]
-[CSAudioRecorder voiceTriggerInfo]
-[CSAudioRecorder _updateLanguageCodeForRemoteVTEIResult:]
useRemoteBuiltInMic
-[CSAudioRecorder _processAudioBuffer:audioStreamHandleId:]
-[CSAudioRecorder _compensateChannelDataIfNeeded:receivedNumChannels:]
-[CSAudioRecorder playAlertSoundForType:]
-[CSAudioRecorder voiceControllerDidStartRecording:forStream:successfully:error:]
-[CSAudioRecorder voiceControllerAudioCallback:forStream:buffer:]
-[CSAudioRecorder voiceControllerDidStopRecording:forStream:forReason:]
-[CSAudioRecorder voiceControllerStreamInvalidated:forStream:]
-[CSAudioRecorder voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:]
-[CSAudioRecorder voiceControllerDidFinishAlertPlayback:ofType:error:]
-[CSAudioRecorder voiceControllerEncoderErrorDidOccur:error:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:]
-[CSAudioRecorder voiceControllerBeginRecordInterruption:withContext:]
-[CSAudioRecorder voiceControllerEndRecordInterruption:]
-[CSAudioRecorder voiceControllerWillSetAudioSessionActive:willActivate:]
-[CSAudioRecorder voiceControllerDidSetAudioSessionActive:isActivated:]
-[CSAudioRecorder voiceControllerMediaServicesWereLost:]
-[CSAudioRecorder voiceControllerMediaServicesWereReset:]
-[CSAudioRecorder _deinterleaveBufferIfNeeded:]
-[CSAudioRecorder _createDeInterleaverIfNeeded]
-[CSAudioRecorder _getRecordSettingsWithRequest:]
voiceControllerCreationQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_voiceControllerCreationQueue
crashEventDelegate
T@"<CSAudioServerCrashEventProvidingDelegate>",W,N,V_crashEventDelegate
sessionEventDelegate
T@"<CSAudioSessionEventProvidingDelegate>",W,N,V_sessionEventDelegate
CSCommandControlBehaviorMonitor
-[CSCommandControlBehaviorMonitor notifyWillStartStreamWithContext:option:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyDidStartStreamWithContext:successfully:option:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyWillStopStream:]_block_invoke
-[CSCommandControlBehaviorMonitor notifyDidStopStream:]_block_invoke
[profileId: %@, language: %@, product: %@, version: %@, homeId: %@, name: %@]
profileId
T@"NSString",&,N,V_profileId
T@"NSString",&,N,V_languageCode
productCategory
T@"NSString",&,N,V_productCategory
version
T@"NSNumber",&,N,V_version
onboardType
TQ,N,V_onboardType
homeId
T@"NSString",&,N,V_homeId
userName
T@"NSString",&,N,V_userName
{isVT=%d, requestHistoricalAudio=%d, reqStartAudioSampleId=%lu, reqStartMachAbsTime=%llu}
T@"NSDictionary",&,N,V_voiceTriggerInfo
requestHistoricalAudio
TB,N,V_requestHistoricalAudio
reqStartAudioSampleId
TQ,N,V_reqStartAudioSampleId
reqStartMachAbsTime
TQ,N,V_reqStartMachAbsTime
shouldLogRawSensorData
TB,N,V_shouldLogRawSensorData
rootLogDir
T@"NSString",&,N,V_rootLogDir
-[NSData(XPCObject) _cs_initWithXPCObject:]
CSOpportuneSpeakEventMonitor
-[CSOpportuneSpeakEventMonitor isStreaming]
isOpportuneSpeakListening
TB,N,V_isOpportuneSpeakListening
audioProviderUUID
T@"NSString",&,N,V_audioProviderUUID
token
T@"NSUUID",&,N,V_token
-[CSOSTransaction initWithDescription:]
-[CSOSTransaction dealloc]
+[NviSignalData headerString]
-[NviSignalData stringForLogging]
{%@:ts=%lld}
TQ,N,V_sigType
sigGenTs
TQ,N,V_sigGenTs
A(knN
?pbhw
pbtb
pbiu
otua
ciov
bhev
eltb
siar
tdtb
cvdh
cvpc
tcid
tsop
rtsh
tvps
cvdh
@fff?
ffffff
@mcpl
mcplsupoxeps
%s Tagging as handheld as user interacted in last %f secs
%s Tagging as farfield as last user interaction %f secs back
%s Tagging as FarField as user dismissed
%s Dealloc CSAudioInjectionEngine : %@
%s Looking up audio diff:%llu sampleCount:%llu %@
%s Unable to write to o/p stream ! 
%s Got event! %lu
%s Got unhandled evt code %lu 
%s %{public}@ deallocated
%s audioProvider not exist
%s Fetched audio session ID %lu
%s Start Monitoring : AudioSession notification from corespeechd
%s Stop Monitoring : AudioSession notification from corespeechd
%s reset sessionInfoProvider since xpcClient disconnected
%s CoreSpeech Daemon reset notification
%s %@ task delivered.
%s %@ completed with response %@ and error %@.
%s Get initial state from MediaRemote: media is on playing state %{public}ld.
%s Start monitoring MediaRemote: media playback
%s Stop monitoring MediaRemote: media playback
%s MediaRemote reported the now playing app playback state changed to %s (state %d)
%s Celestial is not available on this platform.
%s notification = %{public}@
%s MobileTimer is not available on this platform.
%s Dealloc audioStreamHolding : %{public}@
%s In %@: Continuous digital zero detected, lasting %{public}u samples per channel
%s In %@: Continuous digital zero in this audio chunk detected, lasting %{public}u samples per channel
%s Requesting RTS %{public}@ bypass for %{public}lf seconds
%s voiceTriggerXPC client not exist
%s reset xpcClient since it disconnected
%s Plan removing the temp file %{public}@
%s Failed to remove temp file %{public}@ reason: %{public}@
%s Start copying %{public}u bytes of data to crashreporter with wav file header offset %{public}llu
%s Failed to read data from %{public}@
%s Finished copying data to crashreporter.
%s Logging audio file into : %{public}@
%s ERR: reading contents of gradingDir: %{public}@ with error %{public}@
%s Deleting orphaned grading file %{public}@
%s ERR: Failed to delete %{public}@ with error %{public}@
%s Removing non-dir at AttentiveSiri AudioLog dir: %@
%s Error removing %@: err: %@
%s Failed to create AudioLogging directory for AttentiveSiri: %@
%s Created AudioLogging dir for AttentiveSiri at: %@
%s Start monitoring : VoiceTrigger Asset Download
%s Stop monitoring : VoiceTrigger Asset Download
%s New VoiceTrigger is now installed
%s CS logging files under %{public}@ created before %{public}@ will be removed.
%s Couldn't get creation date: %{public}@
%s Could not remove %{public}@: %{public}@
%s CS logging files number %{public}lu with pattern %{public}@ under %{public}@ exceeding limit, only keep the latest %{public}lu ones
%s Regular expression is nil!
%s Resetting audio preprocessor : %{public}f, containsVoiceTrigger:%{public}d
%s Flushing audio preprocessor
%s Record route = %{public}@, playback route = %{public}@
%s Device endpointType = %{public}lu
%s Couldn't find keychain value %@ for account %@ %{public}d
%s Trying to access BTLocalDevice
%s Accessing BTLocalDevice
%s BTLocalDevice %{public}p
%s Failed to get sharing enable flag : %d
%s Failed getting sharing device addresses %d
%s Failed converting address from BTDeviceAddress (result = %d).
%s Device is temporary paired and not in contacts
%s Detaching bluetooth session : %{public}p
%s Already Attaching Bluetooth Session
%s Start attaching bluetooth session
%s session = %{public}p, result = %{public}d
%s session = %p
%s detached session is different from currently attached session, ignore
%s terminated session is different from currently attached session, ignore
%s Bluetooth Session is NULL
%s Failed to get default local device from session %{public}p, (result = %{public}d)
%s Failed to add local device callback from session %{public}p, (result = %{public}d
%s Start monitoring: siri assertion enable/disable
%s Stop monitoring: siri assertion enable/disable
%s did receive enable assertion
%s did receive disable assertion
%s Start monitoring : SpeakerRecognition Asset Download
%s Stop monitoring : SpeakerRecognition Assets Download
%s New SpeakerRecognition Assets is now installed
%s ERR: Delegate received for invalid Trial assetType:%lu
%s ::: Error reading file %@, err: %d
%s CSAudioFileReader requires prepare recording settings to feed audio
%s CSAudioFileReader only support LinearPCM to feed
%s Setting ExtAudioFileSetProperty failed : %d
%s Starting audio file feed timer, bufferDuration = %f sampleRate = %f, bytesPerFrame = %d, channelsPerFrame = %d
%s ::: Error reading data from audio file : %d
%s Reach to EOF, chunkSize = %d
%s Stopping audio file feed timer
%s Failed to create regular expression : %{public}@
%s Start monitoring : AdBlocker Asset Download
%s Stop monitoring : AdBlocker Asset Download
%s New AdBlockerAsset is now installed
%s Received active route change notification
%s Stop monitoring : AudioRouteChangeMonitor
%s Notifying Hearst Connection State : %{public}d
%s Cannot create SampleRateConverter using AudioConverterNew : %{public}d
%s Cannot set Quality property to audioConverter
%s Cannot set Complexity property to audioConverter
%s Audio resampling done : %lu
%s AudioConverter is sad: 0x%{public}xd
%s Cannot start monitoring language detector asset, since we already registered
%s LanguageDetector supported locale is nil : %{public}@
%s Creating SmartSiriVolume connection
%s SmartSiriVolume Remote Object Proxy is nil
%s SmartSiriVolume Failed to get estimate with %{public}@
%s SmartSiriVolume didChangeForReason: %{public}d
%s ERR: SmartSiriVolume Remote Object Proxy returned error : %{public}ld (%{public}@)
%s ERR: SmartSiriVolume ssvConnection is nil
%s Client Interruption Handler: %{public}@, client PID: %{public}d)
%s Client Invalidation Handler: %{public}@, client PID: %{public}d exited
%s Dealloc CSAudioInjectionProvider : %@
%s Stopping Audio Injection Provider : %@
%s Calling start audio stream : %@ %@
%s Calling stop audio stream : %@
%s xpc object string return nil
%s xpc object should be XPC_TYPE_STRING
%s Start Listening request with deviceId : %{public}@
%s CSOpportuneSpeakListener received didStart : %{public}d, %{public}@
%s remoteVADDuration = %{public}d, spgDuration = %{public}d, _remoteVADSPGRatio = %{public}d
%s AudioStreamRequest has failed : %{public}@
%s CSOpportuneSpeakListener received didStop : %{public}d, %{public}@
%s Request stop CSOpportuneSpeakListener
%s Audio coming from DoAP should contains RemoteVAD
%s boronScore : %{public}d, reportBoron : %{public}d, slienceScore : %{public}lf
%s cannot handle nil event 
%s ignore unknown types of message: %{public}@
%s cannot handle nil error
%s Listener connection disconnected
%s connection error: %{public}s
%s Not supported on this platform
%s disconnect activationXPCClient
%s cannot handle event : event = %{public}p
%s ignore unknown types of message 
%s cannot handle error : error = %{public}p
%s default to recordContext : %{public}@
%s Siri language is nil, falling back to %@
%s Advert data: %{public}@
%s advert data write failed
%s Fetching CommandControl Listening State: %d
%s ::: Error creating output file %{public}@, err: %{public}d
%s ::: Error writing to output wave file. : %{public}ld
%s getCoreSpeechXPCConnection Invalidated
%s Asking current VoiceTrigger aset for %{public}d.%{public}d
%s Asking keyword language given Jarvis language list %{public}@, jarvis-selected language: %{public}@
%s CSCoreSpeechServices Invalidated
%s Request updated SAT audio succeed.
%s Request updated SAT audio failed.
%s speechController = %{public}p
%s xpcListener = %{public}p
%s context = %{public}@
%s Failed to create audio recorder : %{public}@
%s For Context : %{public}@, audioStreamId(%llu) has allocated
%s Failed to get audio stream handle ID : %{publid}@
%s has match with audio stream handle id : %llu
%s does not match with audio stream handle id(%llu), creating new audio provider
%s have matched audioProvider with stream handle id : %llu
%s don't have matched audioProvider with stream handle id : %llu, need to create one later
%s audioProvider[%{public}@] invalidated with streamHandleId : %{public}llu
%s No matched audioProvider found for streamHandleId : %{public}llu
%s Received VoiceTrigger cached asset change notification, let's reinitialize VoiceTrigger
%s Trying to start clear logging files
%s Clear logging file timer is already started, ignore startClearLoggingFilesTimer request.
%s SpeechEndEstimation: trailingSilenceDuration = %{public}f
%s SpeechEndEstimation: TrailingSilenceDuration at endpointer(%{public}f) is longer than threshold(%{public}f), force to make 0
%s SpeechEndEstimation: _lastAudioChunkHostTime = %{public}llu, estimatedSpeechEndHostTime = %{public}llu
%s Start Listening for Command Control
%s Calling didStart of CSCommandControlListener
%s Stopping stopListenWithCompletion
%s Calling didStop of CSCommandControlListener
%s Calling didStopUnexpectly
%s Received xpc disconnection, audioStream is streaming = %{public}d
%s init-_currentLanguageCode: %{public}@
%s Asset Manager Policy has been %{public}@
%s Asset Manager Policy has been enabled, start fetching meta data now
%s %@
%s Need to fetch remote meta now, since we have new asset need to be downloaded
%s Does not need to fetch remote meta now
%s Cannot fetch VoiceTrigger asset meta data
%s Undefined assetType : %{public}u
%s _currentLanguageCode changed: %{public}@
%s Trying to start download meta data
%s Periodical downloading is already scheduled, ignore request.
%s No periodical downloading is scheduled, ignore request.
%s Not supported on this platform.
%s Using audioInjectionProvider as recorder
%s Context : %{public}@
%s settings : %{public}@
%s Session Provider does not exist
%s Received special error code that corespeech needs to setContext and activate audio session again
%s CSSpeechController is already streaming audio.., we don't need to create another audio stream here
%s Prepare audio stream succeeded ? %{public}@, error - %{public}@
%s audioStreamWithRequest succeeded ? %{public}@, error - %{public}@
%s Failed to get audioStream : %{public}@
%s AudioStreamProvider is not existing?
%s We need to apply 12dB post gain for this Siri audio session
%s We don't need to apply post gain
%s Done prepareRecord with result: %{public}@.
%s xpcClient not existing
%s received lastVoiceTriggerInfo %{public}@, lastRTSTriggerInfo %{public}@
%s Activating Audio Session Now.
%s StreamProvider is already recording
%s duckingDelayedTime = %{public}f, timeIntervalSinceLastTriggerEnd = %{public}lf
%s Failed activate audio session with %{public}f seconds delay from prepareRecordWithSettings due to error %{public}@.
%s Finished activate audio session with %{public}f seconds delay from prepareRecordWithSettings.
%s Cancelled activate audio session with %{public}f seconds delay from prepareRecordWithSettings.
%s Scheduled SetRecordModeToRecording with %{public}f seconds delay in prepareRecordWithSettings.
%s Delayed active audio session: Consumed token %{public}@ with %{public}f seconds delay for reason %{public}@.
%s Delayed active audio session: Activating audio session for reason %{public}@.
%s Delayed active audio session: Failed to activate audio session for reason %{public}@ due to error %@.
%s Delayed active audio session: Successfully activate audio session for reason %{public}@.
%s Delayed active audio session: Ignored activating audio session for reason %{public}@ because the validator rejected.
%s Delayed active audio session: Ignored activate audio session for reason %{public}@ because the scheduled token %{public}@ does not match the current token %{public}@.
%s Delayed SetRecordModeToRecording: Scheduled new token %{public}@ with %{public}f seconds delay for reason %{public}@.
%s Delayed SetRecordModeToRecording: Cancelled token %{public}@ for reason %{public}@.
%s Delayed audio session activate: Consumed token %{public}@ in advance for reason %{public}@.
%s Delayed SetRecordModeToRecording: Setting record mode to recording for reason %{public}@.
%s Delayed SetRecordModeToRecording: Failed to set record mode to recording for reason %{public}@ due to error %@.
%s Delayed SetRecordModeToRecording: Successfully set record mode to recording for reason %{public}@.
%s Creating fake session activation notification for session activation now
%s Scheduling Lazy Audio Session activation with %f timeout
%s Lazy session activate success
%s Lazy Audio Session is not configured.
%s Creating fake session activation notification for session activation failure : %{public}@
%s Activating audio session now
%s AudioSession activated successfully ? %{public}@
%s AudioSession Provider not available
%s context : %{public}@
%s Resetting CoreSpeech frameworks
%s Ask start recording from: %{public}tu
%s Voice trigger to use the current voice triggered channel: %{public}tu
%s Auto prompt to use the last voice triggered channel: %{public}tu
%s SpeechController to receive data from default channel
%s SpeechController to receive data from channel %{public}tu
%s Ask delay audio session active by %{public}f seconds
%s Sending client speechControllerDidStartRecording successfully? %{pubic}@
%s audioStream not existing
%s _activateAudoiSessionWithDelay has failed. startRecordWithSettings has failed
%s Start recording invoked too late (%{public}.3f seconds), override scheduledCheckTime: %{public}llu to currentTime: %{public}llu
%s Scheduled audible feedback decision after %{public}.3fseconds (vtEndMachTime: %{public}llu currentMachTime: %{public}llu)
%s Two shot audible feedback decision not needed since we already stopped recording
%s Two shot audible feedback decision (%{public}.3fs later than the scheduled time), elapsedTimeWithNoSpeech: %{public}.3f
%s Two shot audible feedback is needed, should notify? [%{public}@]
%s Two shot audible feedback decision timed out while waiting for Myriad decision
%s Phatic not needed since we already stopped recording
%s Phatic decision elapsedTimeWithNoSpeech: %{public}.3f
%s Notifying scheduled phatic playback...
%s Failed to playback phatic, error: %{public}@
%s Asking stopRecording when audio stream is not existing
%s Options: %{public}@ at: %{public}llu
%s Reporting didDeliverLastPacket at: %{public}llu
%s SpeechEndEstimation: %{public}llu
%s Scheduling StopRecording After HostTime=%{public}llu
%s Reason : %{public}ld
%s SpeechEndEstimation: Should Estimate SpeechEndHostTime
%s Sending client speechControllerDidStopRecording for reason : %{public}d, at: %{public}llu
%s SpeechEndEstimation: Reporting didStop with estimated speech end : %{public}llu, at: %{public}llu
%s _didDeliverLastPacket=%d. Dropping Audio packets of size=%lu
%s chunk.hostTime=%{public}llu, chunkSz=%{public}lu, stopOptions=%{public}@, _numTrailingSamplesAfterSchedulingStop=%{public}lu, maxAllowedSamples=%{public}lu
%s STOPRECORDING: Reached MAX allowed trailing samples AFTER stopRecording was scheduled!
%s STOPRECORDING: chunk.hostTime=%{public}llu >= stopOptions=%{public}@
%s SpeechManager still forwarding audio after didStopForwarding, we shouldn't have this
%s STOPRECORDING: chunk.endHostTime=%{public}llu >= stopOptions=%{public}@
%s AudioProvider is invalidated, teardown connection to audioprovider
%s Ignore session active notification
%s SmartSiriVolume update reason: %lu
%s SpeechController is trying to forward encoded audio after didStopForwarding, we shouldn't have this
%s first speech packets count: %{public}lu
%s Setting Alert Sounds From : %{public}@ for AlertType : %{public}d
%s Creating Audio Power Meter with record route %{public}@
%s We don't need Audio Power Meter with record route %{public}@
%s Not available
%s Requesting QuickStop operation upon detecting keyword
%s Unexpected audioFormat for ATV : %{public}u
%s Create audioDecoder for audioFormat %{public}u
%s Unable to prepareAudioProvider in _xpcClient, teardown XPC connection again
%s Queried endpointerModelVersion: %{public}@
%s Cancelling current language detector request !
%s Received Myriad started
%s Received Myriad finished with decision: %tu
%s Received unknown media playing state, ignoring
%s Received unknown alarm playing state, ignoring
%s Received unknown timer playing state, ignoring
%s Detected sound is%{public}@ playing: media(%d) alarm(%d) timer(%d)
%s XPCConnection disconnected
%s reset audioProvider since xpcClient disconnected
%s CS doesn't have ndblobbuilder!
%s latestMajorVersion = %d, LatestMinorVersion = %d
%s corespeech.json doesn't contains rtblobs
%s blob file name is not exists
%s blob file is not exists at %{public}@
%s Reading blob from : %{public}@
%s Blob is nil : %{public}@
%s Locale map for %{public}@ is not available on asset
%@ Interrupted
%@ Invalidated
Dealloc-ing
personalizedLMPath=%@ fidesPersonalizedLMPath=%@
Client is 24-hour job
Client is DictationPersonalizationFidesPlugin
Client is PersonalizedLmFidesPlugin
Received an error while accessing %@ service: %@
Invalidating
%s value = %{public}d
%s Couldn't create SSV log directory at path %{public}@ %{public}@
%s Couldn't create speech log directory at path %{public}@ %{public}@
%s Force enabling VoiceTrigger AP mode ? %{public}@
%s Force enabling VoiceTrigger AOP mode ? %{public}@
%s Couldn't create SoS log directory at path %{public}@ %{public}@
%s enableAudioInection: is only available on internal builds
%s setAudioInjectionFilePath: is only available on internal builds
%s kCSAudioInjectionFilePathKey is not array type
%s kCSAudioInjectionFilePathKey array size = %d
%s kCSAudioInjectionFilePathKey doesn't have NSString as an array entry
%s Override iOS barge-in support key to: %{public}@
%s Shouldn't be called on non-iOS platform
%s Start Recording Host Time = %{public}llu
%s %p created
%s %p dealloced
%s sp=%p
%s %@ not supported yet.
%s Failed to create: %@
%s SigPrvdrs: %@
%s Starting datasrc: %@
%s Failed to start %@. Err=%@
%s >>> All DataSources Started within timeout of 2secs: timeTaken=%f ms
%s WARN: DataSources Start timedout. timeout=2secs
%s Starting signal provider: %@
%s Failed to start %@: Err=%@
%s >>> All SignalProviders didStart within timeout of 2secs: timeTaken=%f ms
%s WARN: SignalProviders timedout didStart. timeout=2secs
%s >>> All DataSources Stopped within timeout of 2secs: timeTaken=%f ms
%s WARN: DataSources timedout stopping. timeout=2secs
%s Failed to stop %@: Err=%@
%s >>> All SignalProviders didStop within timeout of 2secs: timeTaken=%f ms
%s WARN: SignalProviders timedout didStop. timeout=2secs
%s WARN: Cannot find SignalProvider for %@. Skipping
%s Sending XPCClientType : %{public}d
%s Prepare Audio Provider with Context : %{public}@
%s Failed to get reply result correctly
%s Received alertStartTime = %{public}llu
%s Received peakPower = %{public}f
%s Received averagePower = %{public}f
%s Sending audioMetric request
%s Failed to get audioMetric reply
%s audioMetric : %{public}@
%s Received invalid audioMetric
%s Error creating message
%s audioStreamWithRequest for stream %{public}@
%s Invalid message: stream is nil or request is nil
%s PrepareAudioStream %{public}@
%s Sending VoiceTriggerInfo request
%s Failed to get VoiceTriggerInfo request
%s Received VoiceTriggerInfo %{public}@
%s Failed to parse VoiceTriggerInfo from raw data
%s Received rtsTriggerInfo %{public}@
%s Failed to parse rtsTriggerInfo from raw data
%s Message not valid
%s Not implemented
%s NO reply!!!
%s No message!!
%s No reply for hostTimeFromSampleCount request with sampleCount %{public}llu
%s No message for hostTimeFromSampleCount request with sampleCount %{public}llu
%s No reply for sampleCountFromHostTime request with hostTime %{public}llu
%s No message for sampleCountFromHostTime request with hostTime %{public}llu
%s Cannot handle nil message
%s Unexpected message type : %{public}lld
%s AlertProvidingDelegate messageType : %{public}lld
%s Unexpected type : %{public}lld
%s SessionProvidingDelegate messageType : %{public}lld
%s invalid context
%s SessionInfoProvidingDelegate messageType : %{public}lld
%s Received notificationInfo %{public}@
%s Failed to parse notificationInfo from raw data
%s metaInfo passed is nil - Bailing out
%s Unable to read data from file: %@
%s Could not read existing %@ file: err: %@
%s ERR: Failed to create json %{public}@ with %{public}@
%s saveAudioChunk toURL: %{public}@
%s Invalid request: nothing to write to file
%s invalid packets
%s Smart Siri Volume not supported on this platform - Bailing out
%s ERR: Failed to initialize Smart Siri Volume with sampling %{public}f and %{public}@
%s AlarmState changed to %{public}d
%s TimerState changed to %{public}d
%s MusicVolume changed to %{public}f
%s AlarmVolume changed to %{public}f
%s Failure disposing audio file %{public}d
%s Audio file already configured, closing first
%s Creating audio file at URL %{public}@
%s Failed creating audio file at url %{public}@ %{public}d
%s Error setting input format %{public}d
%s No audio file to append data
%s Failed writing audio file %{public}d
%s Closing file at URL %{public}@, audio size: %{public}u
%s _csAssetsDictionary = %{public}@
%s CSAssetController cannot query for nil language
%s ::: found %{public}lu installed assets for assetType=%{public}lu, matching query: %{public}@
%s Error running asset-query for assetType:%{public}lu, query: %{public}@, error: %{public}lu
%s ::: found %{public}lu assets for assetType=%{public}lu, matching query: %{public}@
%s Asset state : %{public}ld
%s ::: %{public}s
%s ::: %{public}s; query: %{public}@
%s Found %{public}lu assets
%s Error running asset query: error %{public}lu, or result is empty
%s ::: Request Fetching RemoteMetaData : assetType : %{public}d
%s Fetching remote meta data failed, scheduled retry after %{public}f seconds
%s ::: Request fetching remote asset
%s ::: found %{public}lu assets for assetType %{public}lu
%s Failed to finish query for assetType %{public}lu with error %{public}lu
%s Meta data downloaded successfully for assetType %{public}lu
%s Failed to download meta data for assetType %{public}lu with error %{public}lu
%s ::: Fetching remote asset
%s ::: Purging installed asset : %{public}@
%s ::: Request downloading remote asset for assetType %{public}lu
%s ::: Start downloading asset
%s ::: download progress: %{public}3.0f%%
%s ::: Error downloading from %{public}@ with error %{public}@
%s ::: download completed successfully from %{public}@.
%s Attempting to download asset %{public}@, asset state : %{public}ld
%s ERR: Unknown AssetType: %{public}lu
%s Not supported in this platform
%s Invoked Siri client
%s Cannot invoke Siri client : %{public}@
%s Invoked Siri client for voice trigger from Jarvis
%s Cannot invoke Siri client for voice trigger from Jarvis : %{public}@
%s SiriActivationConnection deactivated due to %ld
%s SmartSiriVolume cannot be resumed since Siri is speaking
%s Dealloc CSAudioInjectionEngineRemoraEngine : %@
%s Cannot create de-interleaver using AudioConverterNew: %{public}d
%s Created de-interleaver
%s Stopping AudioInjectionEngine : %@
%s Failed to open audio file %@, error : %d
%s Streaming from %@
%s Cannot speak nil Audio URL
%s Cannot speak since audio file does not exists : %@
%s Calling stopAudioStream
%s Failed to deinterleave the data: %{public}d
%s Compensating %{public}u channel(s), heartbeat = %{public}lld
%s VoiceTrigger cannot be turned on since SpeechDetectionVAD is not present
%s VoiceTrigger cannot be turned on since voiceTriggerInCoreSpeech is NO
%s VoiceTrigger cannot be turned on since VoiceTrigger is disabled
%s VoiceTrigger cannot be turned on since Siri is disabled
%s VoiceTrigger cannot be turned on since SpringBoard is not started yet
%s VoiceTrigger cannot be turned on since device is not unlocked after restart
%s VoiceTrigger cannot be turned on since device is on battery
%s VoiceTrigger cannot be turned on since Siri is restricted on lock screen
%s VoiceTrigger cannot be turned on since Software Update Checking is running
%s Start monitoring : speech endpoint asset meta update
%s Stop monitoring : speech endpoint asset meta update
%s New speech endpoint asset is available
%s Cannot get a VoiceTrigger asset : %{public}@
%s CSVoiceTriggerAsset found: %{public}@
%s Asset Query failed : %{public}@
%s cached asset:%{public}@, new asset:%{public}@
%s New asset is same as cached asset, ignore notification
%s New asset is different from cached one. Updating cached asset
%s new VoiceTrigger asset downloaded
%s Language Code Changed : %{public}@
%s First unlock notification received : %{public}d
%s Turn on AP mode since device is hands free state
%s CommandControl Streaming = %{public}d
%s Turn on AP mode since command control is streaming
%s VoiceTrigger AOP mode cannot be turned on since builtIn speaker is active
%s AudioRecordContext = %{public}@, recordState = RECORDING
%s hypotheticalRoute = %{public}@
%s Audio route changing to HFP is expected
%s VoiceTrigger AOP mode cannot be turned on since Siri client is recording
%s AOP Listening is disabled
%s Turn on AP mode since device is on the phone(or ringtone) call state
%s Speech Detection VAD is not available, we will still running in AOP mode
%s Will notify Siri Client record state change to STOPPED in %{public}f seconds, eventUUID = %{public}@
%s Notifying Siri Client record state change to STOPPED, eventUUID = %{public}@
%s There is no pending event to timeout : pendingRecordingStopUUID = %{public}@, timeoutTargetUUID = %{public}@
%s ::: incrementing false wakeup to %{public}llu
%s ::: accumulated false wakeup count is %{public}llu so far, not reporting yet because it has been only %{public}.2f seconds since last report
%s Sending event with non determenistic triggerLengthSampleCount %llu, triggerLengthSampleCountDetermenisticFromFirstPass %llu, and delta of %lld samples
%s WARN: Invalid sigType: %lu
%s Unknown DataSrc Type: %{public}lu
%s Unknown DataSrcTypeStr(%{public}@)
%s Failed to create dir at: %{public}@
%s Json file doesnt exist at: %{public}@
%s Could not read Json file at: %{public}@, err: %{public}@
%s Failed to parse json at: %{public}@, err: %{public}@
%s Could not find <%{public}@> in Keypath=%{public}@
%s ::: %{public}s enable: %{public}d reason: %{public}@ timestamp : %{public}lf
%s Ignoring request to enable/disable voice trigger with nil reason.
%s ::: Asserting that VoiceTrigger should be %{public}@ with reason: %{public}@. Existing assertions (%{public}lu): %{public}@; times: %{public}@ vs %{public}f
%s Ignoring request to enable/disable voice trigger - time order violation.
%s ::: Ignore request as phraseSpotter already %{public}@
%s ::: Asserting that PhraseSpotter should be %{public}@, timeout: %{public}f
%s ::: Timeout!! PhraseSpotter should be NOT bypassed
%s ::: Ignore request as raiseToSpeak already %{public}@
%s ::: Asserting that raiseToSpeak should be %{public}@, timeout: %{public}f
%s ::: Timeout!! raiseToSpeak should be NOT bypassed
%s HandleDisconnect
%s unbalanced dispatch_group_enter and leave : ignore we are ignore dispatch_group_leave
%s ERR: Failed to get TTS Volume
%s Estimated TTS volume : %{public}f
%s SmartSiriVolume not available
%s Notifying SSV Client on Volume change for reason - %{public}d
%s Dropped SSV Client notification for Volume change with reason - %{public}d
%s Non internal build, Ignoring command %@ from peerId %@ - Bailing out!
%s Received Malformed command %@ from peerId %@ - Bailing out!
%s Command %@ received from peerId %@
%s Unknown Command: (%@) - Ignoring
%s Triggering sync with peer - %@
%s Triggering nearmiss sync with peer - %@
%s Triggering voice profile sync with peer - %@
%s CSP2P_RemoteHeySiriCmd: ENABLE HeySiri: Not Implemented Yet: 
%s CSP2P_RemoteHeySiriCmd: DISABLE HeySiri: Not Implemented Yet: 
%s Cannot read contents of directory: %@, err: %@
%s Could not determine if [%@] is a directory or not. Err=%@
%s Found dir: %@. Skipping compression
%s _compressFilesInDirectory: Malloc failed for file %@ (%lu) - Discarding
%s _compressFilesInDirectory: Compression failed for file %@ (%lu) - Sending Uncompressed
%s _compressFilesInDirectory: File %@ compressed from %ld to %ld 
%s Failed in compressing %{public}@ with errror %{public}@ - Bailing out
%s Transfering NearMiss file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s Transfering grading file %@ withCompression %{public}@ and size %ld in batch %{public}@
%s %@ is nil - Bailing out
%s Failed in transporting Voice file %@ with reponse: %@, error %@
%s Failed to remove the file %@ with error %@
%s Failed to move the file %@ to %@ with error %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: unknown IDS peer with passed Identifier %@, %@ %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: received malformed command - %@
%s CSP2P_VoiceProfileParallelRecordingTransferCmd: Creating directory failed with error %@
%s Ignoring sync of existing file %@ from %@
%s Syncing parallel recorded audio file - %@ from %@
%s Uncompressed file %@ sent by peer %@
%s ERR: Failed to allocate buffer of size %zu, bailing out
%s Writing to file(%@) failed!. Err=%@
%s received malformed command - %@ %@ %@
%s unknown IDS peer with passed Identifier %@, %@ %@
%s received malformed command - %@
%s Syncing audio file - %@ from %@
%s CSP2P_VoiceProfileTransferCmd: received malformed command - %@ %@ %@
%s CSP2P_VoiceProfileTransferCmd: received malformed command: CSP2P_VoiceProfileData_Key: %@CSP2P_VoiceProfileFileName_Key: %@CSP2P_VoiceProfileSpeakerName_Key: %@CSP2P_VoiceProfileLocale_Key: %@CSP2P_VoiceProfileDataType_Key: %@CSP2P_VoiceProfileTotalSegments_Key: %@CSP2P_VoiceProfileSegment_Key: %@
%s CSP2P_VoiceProfileTransferCmd: Received VoiceProfile Segment (%@/%@) from peerId %@
%s CSP2P_VoiceProfileTransferCmd: Failed to delete the directory %@ with error %@
%s CSP2P_VoiceProfileTransferCmd: received VoiceProfileSegment %@, expected %d
%s CSP2P_VoiceProfileTransferCmd: Creating directory failed with error %@
%s CSP2P_VoiceProfileTransferCmd: Writing to file failed!!!
%s Received request to delete VoiceProfile %@ from peerId %@
%s Cannot send data across when _adCompanionServiceProvider is nil - returning
%s ERR: Rejecting command %@ sent to non Horseman device
%s ERR: received malformed command - %@ %@
%s ERR: unknown IDS peer with passed Identifier %@, %@ %@
%s ERR: received malformed command with locale nil - %@
%s Fetching homeUserId for siriProfileId %{public}@
%s siriProfileId %{public}@ maps to homeUserId %{public}@
%s ERR: Home User Id erred %{public}@ for Siri Profile Id %{private}@
%s ERR: %@
%s ERR: received malformed command with profileId nil - %@
%s ERR: Failed to find voice profile with identifier - %@
%s CSP2P_VoiceProfileFetchCmd: Transferring voice profile %{public}@
%s CSP2P_VoiceProfileFetchCmd: File %@ isCompressed: %d, compressedSize: %ld, err: %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed VoiceProfileTransfer: %@, error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred %@
%s CSP2P_VoiceProfileReverseTransferCmd: Failed transferring voice profile %@ with error %@
%s CSP2P_VoiceProfileReverseTransferCmd: Successfully transferred voice profile %@
%s ERR: Rejecting command %@ sent to Horseman device
%s ERR: received malformed command with relative path nil - %@
%s Failed in sending trigger for Voice profile update to peer %@ with error %@
%s SpkrId:: path is nil - Bailing out
%s SpkrId:: Direntry with same name exists, this will be removed: %@
%s SpkrId:: Creating Directory : %@
%s SpkrId:: Creating Directory failed : %@
%s Error reading directory at %@: err: %@
%s %@ is empty
%s zeroFilterWinSz: %{public}tu, numHostTicksPerAudioSample: %{public}f
%s _vtEndInSampleCount:%{public}ld, _numSamplesProcessed: %{public}ld, voiceTriggerInfo: %{public}@
%s ERR: %{public}@
%s HEP enabled=%d
%s Device supporting barge-in ? %{public}@
%s Failed to find matching service to IOPlatformExpertDevice
%s Fetched hardware revision : %{public}@
%s Failed to find property "config-number"
%s Registering for post build install/first unlock activity - %s
%s Received event for XPC activity: %@ in state: %ld
%s XPC activity: %@ deferred: %@ firstUnlock: %@
%s Registered XPC activity got triggered...
%s VT is disabled, skipping post build activity !
%s Post build install/first unlock tasks got completed with error - %{public}@
%s Registered XPC activity complete. State: %@.
%s UUID was nil will not start fingerprint provider
%s Updated in use services for fingerprintProvider. %lu services in use
%s Starting continuousFingerprintProvider
%s UUID was nil will not stop fingerprint provider
%s Updated in use services for fingerprintProvider. %lu services remaining
%s Stopping continuousFingerprintProvider
%s listen polling has failed : %{public}@
%s Skip listen polling since audio is streaming / Siri disabled
%s Start audio stream successfully ? %{public}@, error : %{public}@
%s Received didStartRecording when Siri is off
%s Failed in requesting audio stream : %{public}@
%s Already started listen polling, skip
%s Failed to stop audio stream : %{public}@
%s No audio stream to stop, we shouldn't hit this
%s Siri enabled : %{public}d
%s stream stopped unexpectedly : %{public}ld
%s Mediaserverd/bridgeaudiod recovered from crash
%s NDAPI initialization failed
%s set StartAnalyzeSampleCount = %{public}lld
%s NDAPI config doesn't contain threshold_normal
%s NDAPI config doesn't contain threshold_logging
%s NDAPI config doesn't contain threshold_reject_logging
%s ::: CoreSpeech logging initialized (%s)
%s Couldn't create CoreSpeech log directory at path %{public}@ %{public}@
%s SmartSiriVolume: deleted %{public}u elements in energy buffer.
%s SmartSiriVolume: number of elements to delete exceeds energy buffer size, ignore.
%s SmartSiriVolume init value for noise estimation %{public}f
%s SmartSiriVolume init value for LKFS estimation %{public}f
%s SmartSiriVolume enable policy changed : %{public}@
%s SmartSiriVolume received MediaRemote initial state as %{public}@
%s SmartSiriVolume haven't got MediaRemote callback yet, let's assume media is playing.
%s SmartSiriVolume received alarm initial state as %{public}@
%s SmartSiriVolume received timer initial state as %{public}@
%s asset is nil, use default parameters(this should not happen).
%s SmartSiriVolume configure: %{public}@
%s SmartSiriVolume heartbeat = %{public}lld
%s SmartSiriVolume: estimated noise level %{public}f
%s SmartSiriVolume: estimated LKFS %{public}f
%s SmartSiriVolume: pause SSV calculation.
%s SmartSiriVolume: resume SSV calculation.
%s Siri is disabled, we shouldn't receive audio here, heartbeat = %{public}lld
%s SmartSiriVolume received VT event!
%s SmartSiriVolume remove samples from VT utterances by %{public}llu, with startAnalyzeSampleCount = %{public}llu, samplesFed = %{public}llu, triggerStartSampleCount = %{public}llu
%s SmartSiriVolume trying to delete too many VT samples, set triggerDurationToDelete to be limited max: %{public}llu
%s SmartSiriVolume got empty VT event!
%s SmartSiriVolume dismiss alarm firing as VoiceTrigger detected.
%s SmartSiriVolume dismiss timer firing as VoiceTrigger detected.
%s SmartSiriVolume: final estimated TTS volume in dB %{public}f
%s SmartSiriVolume: adjust TTS volume since alarm/timer is firing.
%s SmartSiriVolume: TTS volume in dB from noise %{public}f, from LKFS %{public}f, with user offset %{public}f
%s SmartSiriVolume: soft volume algorithm in use
%s SmartSiriVolume: pause LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume: resume LKFS calculation according to MediaRemote notification.
%s SmartSiriVolume received unknown media playing state, let's assume media is playing.
%s SmartSiriVolume received unknown alarm state, let's reset alarm state.
%s SmartSiriVolume: alarm firing status = %@ according to MobileTimer notification.
%s SmartSiriVolume received unknown timer state, let's reset timer state.
%s SmartSiriVolume: timer firing status = %@ according to MobileTimer notification.
%s SmartSiriVolume dismiss alarm firing as Siri client is recording.
%s SmartSiriVolume dismiss timer firing as Siri client is recording.
%s SmartSiriVolume: set StartAnalyzeSampleCount = %{public}lld
%s SmartSiriVolume: final estimated TTS volume %{public}f with music volume %{public}f
%s Start monitoring : SACInfo
%s Stop monitoring : SACInfo
%s Device is in stereo mode : %{public}@
%s Dealloc of CSRemoteControlClient, it should close connection
%s ::: NVI logging initialized
%s Received external route change notification
%s Received CarPlay route change notification
%s Notifying Jarvis Connection State : %{public}d
%s Start monitoring : SpeakerRecognition Asset meta update
%s Stop monitoring : SpeakerRecognition Asset meta update
%s New Speaker Recognition asset metadata is available
%s VoiceTrigger is already %{public}@, received duplicated notification!
%s Start monitring : VoiceTrigger setting switch
%s Cannot start monitoring VoiceTrigger setting switch because it was already started
%s Stop monitring : VoiceTrigger setting switch
%s VoiceTrigger enabled = %{public}@
%s Creating audioRecorder has failed
%s AudioRecorder creation failed : %@
%s AudioStream Handle ID is invalid : %{public}@
%s audioRecorder %p created
%s Cannot prepare since audio recorder does not exist
%s Failed to activate audio session, error : %{public}@
%s AudioRecorder is already recording, do not prepare anymore
%s Failed to prepareAudioStreamRecord : %{public}@
%s Failed to startAudioStream : %{public}@
%s failed to stopRecording : %{public}@
%s audioInput:[%@]
%s audioOutput:[%@]
%s Start monitoring : Siri setting switch, Siri is %{public}@
%s Stop monitoring : Siri setting switch
%s Siri Enabled = %{public}@
%s Start audio stream successfully ? %{public}@, error : %{public}@, startRecordingSampleCount=%lu
%s Stopped audioStream with result=%d, err=%@
%s audioProvider == nil, error : %{public}@
%s provider: %{public}@, unexpectedStop: %{public}ld
%s BeepCanceller asset file loading from : %{public}@
%s Could not read beep file: %@
%s beepVector Size = %{public}lu
%s Cannot initialize beep canceller
%s Beep canceller initialized with maxNumSamples = %{public}d
%s It will beep now
%s Reset beep cancellation
%s _bestStartDetectSample %lu was greater than _bestEarlyDetectSample %lu or _bestEndDetectSample %lu
%s _bestEarlyDetectSample %lu was greater than _bestEndDetectSample %lu
%s _speechVoiceLevel %lu is 0
%s _numberOfTotalFramesETFT %lu is 0
%s Received Activation Event : %{public}@
%s Cannot handle activation event : %{public}@
%s activation client not exist
%s Start monitoring: wake Gesture
%s ::: Received Gesture: %@
%s Wake Gesture: currDate=%@, wakeGestureTimeStamp=%@, 
currMachAbsTime=%llu, timeDelta=%f, 
timeDeltaInTicks=%llu, possWakeGesture=%llu
%s Error reading audio file: %{public}d, skipping...
%s Start monitoring : Software update checking state
%s Cannot start monitoring software update checking state because it was already started
%s Stop monitoring : Software update checking state
%s Software update checking running : %{public}@
%s AssetManager cannot be turned on since isFirstUnlocked is NO
%s AssetManager cannot be turned on since network is not available
%s numChannels: %{public}lu, recordingDuration: %{public}f, sampleRate: %{public}f
%s Cannot copy samples since this is empty
%s Could NOT copyFrom: %{public}lu to: %{public}lu, retSampleCount: %{public}lu
%s copyBuffer: oldestSample: %{public}lu latestSample: %{public}lu, numSamplesCopied: %{public}lu
%s CSAudioCircularBuffer.reset
%s Invalid request: reqStartSample=%{public}lu, reqEndSample=%{public}lu, oldestSampleInBuffer: %{public}lu, latestSampleInBuffer=%{public}lu
%s Saving utterance and meta as %{public}@ training.
%s Failed to write utterance into %{public}@
%s Saving %{public}@ at %{public}@ as %{public}@ training.
%s numSamplesToWrite %{public}lu
%s Failed to get CSAudioFileWriter:
%s Failed to addSamples to CSAudioFileWriter: %{public}@
%s Failed to endAudio on CSAudioFileWriter: %{public}@
%s ERR: called with nil metaPath
%s ERR: called with nil uttPath
%s ERR: called with nil uttMeta
%s Cannot create json file : %{public}@
%s Start monitoring : VoiceTrigger Asset meta update
%s Stop monitoring : VoiceTrigger Asset meta update
%s New VoiceTrigger asset metadata is available
%s Start monitoring : AdBlocker Asset meta update
%s Stop monitoring : AdBlocker Asset meta update
%s New AdBlocker asset metadata is available
%s stream %{public}@ initialized
%s stream %{public}@ is deallocated
%s Creating UUID for start audio stream request : %{public}@
%s AudioStream<%{public}@> is streaming : %{public}d
%s AudioStream<%{public}@> has received didStopStreamUnexpectly
%s AudioStream<%{public}@> has received didHardwareConfigurationChange
%s Found pending activation : %{public}@, handle pending activation immediately
%s Received Activation Event in CoreSpeechDaemon: %{public}@
%s Returning error for already existing pending activation event : %{public}@
%s No delegate registered : Postpone activation event handling until we have delegate registered
%s Pending Timeout fired for %{public}@ returning error for timeout
%s There is no pending activation event to timeout
%s corespeechd received mediaserverd launched event
%s Start monitoring : AOP First Pass trigger
%s Stop monitoring : AOP First Pass trigger
%s AOP First Pass trigger detected
%s Received a request for VoiceTrigger Asset for language code : %{public}@
%s Fake Model Path does not exist : %{public}@
%s fake model meta json does not exist : %{public}@
%s Unable to read fake model meta json : %{public}@
%s Unable to parse fake model meta json : %{public}@
%s Loading FakeModel : %{public}@
%s Cannot create RTModel from %{public}@
%s fake model number(%{public}d) is less than minimum fake model number((%{public}d)
%s %{public}@ fake model is selected for download
%s %{public}@ model is selected for fallback
%s Received a request for VoiceTriggerRTModel for Firmware Version : %{public}d.%{public}d
%s Asking mobile asset with currentLanguageCode = %{public}@
%s DownloadModel : 
%s preinstalledModels : 
%s Hearst Fake Model request switch turned on, executing stress test mode with fakeModelPath : %{public}@
%s VoiceTriggerAsset is not available : %{public}@
%s rtLocaleMap is nil fallback to embedded locale map
%s accessoryRTBlobs are not available for the version(%{public}d.%{public}d) and locale:%{public}@, returning fallback model : %{public}@
%s Hash matched with downloadedModel : %{public}@, accessory will select this model
%s Hash matched with preinstalledModel : %{public}@, accessory will select this model
%s Ask for download : %{public}@, and use %{public}@ as fallback
%s Select keyword language as %{public}@, error : %{public}@
%s Language list and jarvis language not provided
%s current Siri language code : %{public}@
%s Jarvis locale map is nil, fallback to embedded locale map
%s Start monitoring : Setting preference change
%s Stop monitoring : Setting preference change
%s Siri restricted on lock screen : %{public}@
%s Start monitoring : Springboard start
%s Cannot start monitoring Springboard start because it was already started
%s Stop monitoring : Springboard start
%s SpringBoard started = %{public}@
%s CSAudioProvider is deallocated
%s CSAudioProvider[%{public}@]:StreamState changed from : %{public}@ to : %{public}@
%s CSAudioProvider[%{public}@]:Setting audioRecorder : %{public}p
%s CSAudioProvider[%{public}@]:setCurrentContext : %{public}@
%s CSAudioProvider[%{public}@]:Cannot change context since audio recorder is currently recording
%s CSAudioProvider[%{public}@]:audioStreamWithRequest for stream <%{public}@>
%s Failed to _prepareAudioStreamSync : %{public}@
%s CSAudioProvider[%{public}@]:Prepare audio stream reuqested while state is %{public}@
%s CSAudioProvider[%{public}@]:Cannot prepare, audio system is recovering
%s CSAudioProvider[%{public}@]:Asking AudioRecorder prepareAudioStreamRecord
%s CSAudioProvider[%{public}@]:prepareAudioStreamRecord failed : %{public}@
%s CSAudioProvider[%{public}@]:Create circular buffer
%s CSAudioProvider[%{public}@]:Tear down circular buffer
%s CSAudioProvider[%{public}@]:startAudioStream with stream : %{public}@ with stream state : %{public}@, option : %{public}@, streamId : %{public}llu
%s CSAudioProvider[%{public}@]:state was %{public}@, prepareAudioStream first
%s CSAudioProvider[%{public}@]:prepareAudioStreamSync with stream : %{public}@ with stream state : %{public}@
%s CSAudioProvider[%{public}@]:prepareAudioStream with stream : %{public}@ with stream state : %{public}@
%s CSAudioProvider[%{public}@]:Cannot handle start audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:Cannot startAudioStream, audio system is recovering
%s CSAudioProvider[%{public}@]:Requested startHostTime = %{public}llu, _clientStartSampleCount = %{public}tu
%s CSAudioProvider[%{public}@]:%{public}@ is requesting earlier audio than asked, we can't deliver earlier audio
%s CSAudioProvider[%{public}@]:Set circularBufferStartHostTime = %{public}llu, circularBufferStartSampleCount = %{public}lu
%s CSAudioProvider[%{public}@]:Entering dispatch group for recordingWillStartGroup
%s CSAudioProvider[%{public}@]:Failed to fetch historical audio since _clientStartSampleCount is newer than audioBuffer sample count(%{public}llu)
%s Failed to switch to record mode : %{public}@
%s CSAudioProvider[%{public}@]:Leaving dispatch group for recordingWillStartGroup
%s CSAudioProvider[%{public}@]:Received didStartRecording while %{public}@
%s CSAudioProvider[%{public}@]:Received didStopRecording reason : %{public}d, streamState : %{public}@
%s CSAudioProvider[%{public}@]:Received didStopRecording while %{public}@
%s CSAudioProvider[%{public}@]:Waiting for recordingWillStartGroup before scheduling stopAudioStream
%s CSAudioProvider[%{public}@]:Scheduled stopAudioStream after waiting for recordingWillStartGroup - stopAudioStream %{public}@ with streamState : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stoppingWithScheduledStart, take out audio stream from schedule
%s CSAudioProvider[%{public}@]:Stream %{public}@ is not streaming on stream state : %{public}@, ignore the stopAudioStream request
%s CSAudioProvider[%{public}@]:Cannot handle stop audio stream on : %{public}@
%s CSAudioProvider[%{public}@]:requested stop audio stream while stopping, adding audio stream into stop pending
%s CSAudioProvider[%{public}@]:Stop all recordings, moving stream state to %{public}@
%s CSAudioProvider[%{public}@]:Failed to stop audioStream : %{public}@
%s Saving circular buffer from %{public}lu to %{public}lu
%s CSAudioProvider[%{public}@]:%{public}@ ask for audio hold stream for %{public}f
%s CSAudioProvider[%{public}@]:Timeout for %{public}@ has fired
%s CSAudioProvider[%{public}@]:Removing %{public}@ from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ stream holder was already removed from stream holders
%s CSAudioProvider[%{public}@]:%{public}@ ask for cancel hold stream
%s Failed to prewarmAudioSessionWithError : %{public}@
%s Failed to activateAudioSessionWithReason: %{public}@
%s CSAudioProvider[%{public}@]:Activating Audio Session under : %{public}@
%s Failed to activateAudioSession : %{public}@
%s Failed to deactivate audio session : %{public}@
%s CSAudioProvider[%{public}@]:Deactivating Audio Session under : %{public}@
%s Failed to deactivateAudioSession : %{public}@
%s CSAudioProvider[%{public}@]:AVVC is recovering, ignore command...
%s Fetching voiceTriggerInfo locally for context type : %{public}lld
%s Fetching voiceTriggerInfo from audioRecorder
%s CSAudioProvider[%{public}@]:Cannot stopRecording as there are %{public}tu streamHolders
%s CSAudioProvider[%{public}@]:Shouldn't stop AVVC recording as there are %{public}tu streams
%s CSAudioProvider[%{public}@]:
%s CSAudioProvider[%{public}@]:Buffer underrun!!!!, lastForwardedSampleTime:%{public}lu, oldestSampleTimeInBuffer:%{public}lu, stream:%{public}@
%s CSAudioProvider[%{public}@]:Ignore forwarding stream %{public}@                                        the audio packets until sampleCount == %{public}lu (theMostRecentSampleCount:%{public}lu)
%s CSAudioProvider[%{public}@]:Buffer overrun!!! lastForwardedSampleTime:%{public}lu,                                    theMostRecentSampleCount:%{public}lu, stream:%{public}@
%s ScheduleAlertFinishTimeout : %{public}@
%s ScheduleAlertFinishTimeout will be ignored : %{public}@, %{public}@
%s Received finishStartAlertPlaybackAt:%{public}llu streamState : %{public}@
%s CSAudioProvider[%{public}@]:Requested alertFinishHostTime = %{public}llu, _clientStartSampleCount = %{public}tu, circularBufferSampleCount = %{public}tu
%s Audio Streaming already stopped
%s Will invalidate current builtIn audio stream : %{public}@
%s failed to stopAudioStream : %{public}@
%s CSAudioProvider[%{public}@]:Audio Recorder Disconnected
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod crashed
%s CSAudioProvider[%{public}@]:Mediaserverd/bridgeaudiod recovered from crash
%s CSAudioProvider[%{public}@]:AudioRecorder will be destroyed
%s CSAudioProvider[%{public}@]:recordingTransaction already released
%s CSAudioProvider[%{public}@]:Release recording transaction at streamState : %{public}@
%s Schedule didStart WDT %{public}@ for %{public}lf seconds
%s startRecordingWatchDogDidFire : %{public}@, currentToken : %{public}@
%s startRecordingWatchDogToken doesn't match. Ignore this WDT fire
%s Clearing didStartRecordingDelegate WatchDogTimer : %{public}@
%s Schedule didStop WDT %{public}@ for %{public}lf seconds
%s stopRecordingWatchDogDidFire : %{public}@, currentToken : %{public}@
%s stopRecordingWatchDogToken doesn't match. Ignore this WDT fire
%s Clearing didStopRecordingDelegate WatchDogTimer : %{public}@
%s Listening on watch cannot be turned on since speech detection VAD is disabled
%s Listening on watch cannot be turned on since Siri is disabled
%s Listening on watch cannot be turned on since SpringBoard is not started
%s Listening on watch cannot be turned on since device is not unlocked after restart
%s Listening on watch cannot be turned on since Siri assertion is disabled
%s Listening on watch cannot be turned on since audioInjection is enabled
%s xpc object should be XPC_TYPE_ARRAY
%s xpcObject value is NULL
%s Cannot decode non-plist types of XPC object
%s Cannot encode non-plist types into XPC object : %{public}@
%s Received AOP Listening state change notification : %{public}d
%s Error reading file
%s Version of AdBlockerAsset: %d
%s Cannot generate subChunk since channel(%{public}tu) is larger than number of channels(%{public}tu)
%s Cannot generate subChunk if it reuqest more than it has : %{public}tu %{public}tu %{public}tu
%s SpkrId:: Processing ended at: numSamplesProcessed=%lu, totalSampleCountToReach=%lu
%s Delta is larger than anchorHostTime: anchorSampleCount = %{public}lld, sampleTime = %{public}lld, anchorHostTime = %{public}lld
%s Delta is larger than anchorSampleCount
%s Mediaserverd/bridgeaudiod crashed
%s Start monitoring : AudioSessionInterruption
%s Start monitoring : AudioSessionRouteChangeNotification
%s Stop monitoring AudioSession activities
%s Endpointer is disabled in RecordSettings: %@
%s CSHybridEndpointer canProcessCurrentRequest
%s CSHybridEndpointer can-NOT-ProcessCurrentRequest, fallback  to NNVAD
%s _activeEndpointer=%{public}@
%s shouldUseCVT2ShotDecision: %{public}d, isWatchRTSTriggered=%{public}d
%s preheat
%s endpointer: %{public}@: didDetectStartpointAtTime: %{public}f
%s %{public}@: Endpointer didDetectHardEndpointAtTime:withMetrics: %{public}f, CallingDelegate: %{public}@
%s Reported 2-shot at: %{public}f secs
%s speechcontroller.delegate doesnt respond to speechControllerDidDetectVoiceTriggerTwoShot
%s WARN: endpointerModelVersion called when CSHybridEndpointer is not available
%s WARN: logEndpointFeatures called when CSHybridEndpointer is not available
%s Asset available from CAT from: %{public}@
%s getCATXPCConnection Invalidated
%s Cannot create NSNumber if xpcObject is NULL
%s XPC object type should be BOOL, DOUBLE, INT64, or UINT64
%s Cannot create xpcObject if objcType is NULL
%s Cannot create xpcObject since there is no matching type
%s Stop monitoring : First unlock
%s PhraseSpotter enabled = %{public}@
%s PhraseSpotter is already %{public}@, received duplicated notification!
%s event = %{public}p client = %{public}p cannot handle event
%s ignore unknown types of message
%s message = %{public}p, client = %{public}p, cannot handle message
%s MessageType = %{public}lld
%s Received error %{public}@ from client %{public}@
%s Client %{public}p connection disconnected, noticing xpc listener
%s Cannot deactivateAudioSession since audio recorder doesn't exist
%s Cannot deactivateAudioSession with %{public}@
%s Start Of Speech Detector not supported !
%s Start monitoring : Mediaserverd crash / recover event
%s disconnect VoiceTriggerXPCClient
%s ERR: failed to get response !
%s Notifying CoreSpeechDaemon launched
%s Start monitoring : corespeechd state
%s Cannot start monitoring corespeechd state because it was already started
%s Stop monitoring : corespeechd state
%s CoreSpeechDaemon state changed to %{public}u
%s network state notify key : %s
%s Start monitoring : network availability
%s Stop monitoring : network availability
%s Network availability changed
%s startListenWithOption : %{public}d, %{public}@
%s stopListenWithCompletion : %{public}d, %{public}@
%s hasRemoteVADAvailable : %d
%s hasVADAvailable : %d
%s didStopUnexpectly : %d
%s Fallback asset resource path : %{public}@
%s Cannot find corespeech asset from resourcePath : %{public}@
%s Configuration file is not exists : %{public}@
%s Cannot read configuration file : %{public}@
%s Cannot decode configuration json file : %{public}@
%s Configuration json file is not expected format
%s Cannot access to %{public}@ %{public}@ using default value=%{public}@
%s There is not audio buffer to convert. Skip this.
%s MachTime of sending first speech packet: %{public}llu
%s Resetting AudioConverter buffer
%s createAudioConverter : initial frames per buffer = dur %{public}.2f * sr %{public}.2f = %{public}u
%s Failed to get audioConverter property (kAudioConverterCurrentOutputStreamDescription) : %{public}d
%s _configureAudioConverter: encoded audio needs minimum of %{public}u bytes per output buffer
%s _configureAudioConverter: AudioConverterGetProperty(kAudioConverterPropertyMinimumOutputBufferSize) returned status %{public}d
%s _configureAudioConverter: final framesPerBuffer: %{public}u
%s _configureAudioConverter: _convertPacketCount: %{public}u
%s _configureAudioConverter: AudioConverterGetProperty(MaximumOutputPacketSize): returned status %{public}d
%s createAudioConverter: outputSizePerPacket: %{public}u
%s _configureAudioConverter: _convertAudioCapacity %{public}u bytes
%s Cannot create AudioConverter using AudioConverterNew : %{public}u
%s Cannot set encoder bit rate : %{public}u
%s Cannot set codecQuality : %{public}u
%s Start monitoring : Siri language code
%s Stop monitoring : Siri language code
%s Siri language changed to : %{public}@
%s Ignore notifying change of language code, since it is nil
%s RequiredSampleCount reached: currSampleCount=%{public}lu, endingSampleCount=%{public}lu
%s Setting audio injection enabled : %d
%s Fetched audio injection enabled : %d
%s CSAudioInjectionServices Interrupted
%s CSAudioInjectionServices Invalidated
%s XPC connection not exist?
%s Request to create audio injection device type : %ld, deviceName : %@, deviceId : %@, productId : %@
%s Fetching primary device timed-out!!
%s Request to inject audio %@ to deviceUUID %@
%s Request to connect device with UUID %@
%s Connect device timed-out!!
%s Request to disconnect device with UUID %@
%s Disconnect device timed-out!!
%s Request to fetch primary device
%s xpc object should be XPC_TYPE_DICTIONARY
%s xpcObject key or value is NULL
%s Cannot encode key into xpcobject since the key is not NSString class type
%s ERR: topScoringUser is nil from %{public}@
%s ERR: invalid arguments passed %{public}@ %{public}@
%s ERR: Incorrect category %{public}d passed
%s MpVT: supportedPhrasesInfo: %@
%s MpVT: ctcResults=%@
%s OldTrigPh: %@, NewTrigPh: %@
%s Failed to create AVVC : %{public}@
%s Create new CSAudioRecorder = %{public}p
%s CSAudioRecorder %{public}p deallocated
%s AVVC initialization failed
%s Successfully create AVVC : %{public}p
%s Calling AVVC setContext
%s Failed to get handle id : %{public}@
%s setContext elapsed time = %{public}lf
%s Calling AVVC setContextForStream : %{public}@
%s setCurrentContext elapsed time = %{public}lf
%s Calling AVVC prepareRecordForStream(%{public}llu) : %{public}@
%s AVVC prepareRecordForStream failed : %{public}@
%s prepareRecordForStream elapsed time = %{public}lf
%s ::: CSAudioRecord will inject audio file instead of recording
%s Resetting AudioFilePathIndex
%s Increase AudioFilePathIndex = %d
%s AudioFilePathIndex is out-of-boundary _audioFilePathIndex:%d injectAudioFilePaths:%d
%s AudioFilePathIndex:%d accessing:%@
%s Unable to find injectAudioFilePath = %@
%s Calling AVVC startRecordForStream : %{public}@
%s startRecordForStream failed : %{public}@
%s startRecordForStream elapsed time = %{public}lf
%s Calling AVVC stopRecordForStream
%s Failed to stopRecordForStream : %{public}@
%s stopRecordForStream elapsed time = %{public}lf
%s Session State = %d
%s AudioSessionState = YES
%s AudioSessionState = NO
%s AVVC sampling rate = %{public}f
%s AVVC doesn't return sampleRate, assume it is default sample rate
%s isNarrowBand = NO for streamHandleId = %{public}lu
%s isNarrowBand = %{public}@ for streamHandleId = %{public}lu
%s Calling AVVC setSessionActive for Prewarm
%s Prewarm AudioSession has failed : %{public}@
%s Calling AVVC setRecordMode to mode : %{public}d
%s AVVC successfully setRecordMode
%s setRecordMode elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for activation
%s AVVC setSessionActivate has failed : %{public}@
%s AVVC successfully activated audioSession
%s setSessionActivate elapsed time = %{public}lf
%s Calling AVVC setSessionActivate for deactivation : %{public}tu
%s Failed to setIamTheAssistant : %{public}@
%s Creating audio session with allow mixable audio while recording to YES
%s Failed to setAllowMixableAudioWhileRecording : %{public}@
%s Calling AVVC : Enable Smart Routing Consideration
%s Calling AVVC : Disable Smart Routing Consideration
%s enableSmartRoutingConsiderationForStream elapsed time = %{public}lf
%s Fail to setSmartRoutingConsideration : %{public}@
%s Should not call setDuckOthersOptions with NO in B238
%s %{public}@ miniDucking now
%s enableMiniDucking elapsed time = %{public}lf
%s %{public}@
%s configureAlertBehavior elapsed time = %{public}lf
%s VoiceTriggerInfo is nil from AVVC
%s Updated languageCode to: %{public}@ in VTEI received from remote
%s Peak : %f, Avg : %f
%s AVVCAudioBuffer contains %{public}d packet descriptions, size %{public}d, channels %{public}d. Ignoring
%s packetCount %{public}d
%s Bad packet length %{public}d. Skipping rest of record buffer.
%s Cannot handle audio buffer : unexpected format(%{public}u)
%s Calling AVVC playAlertSoundsForType : %{public}ld
%s Received didStartRecording : %{public}p, forStream:%{public}llu, successfully:%{public}d, error:%{public}@
%s Received audio buffer %{public}d, heartbeat = %{public}llu, streamID (%{public}lu)
%s Received didStopRecording : %{public}p forStream:%{public}llu forReason:%{public}ld
%s Received Stream Invalidated : %{public}llu
%s toConfiguration : %{public}d
%s type : %{public}d, error : %{public}@
%s Encoder error : %{public}@
%s withContext : %{public}@
%s activate : %{public}d
%s AVVC lost mediaserverd connection
%s AVVC informed mediaserverd reset, no further action required
%s Unsupported audio format!
%s Cannot create NSData with size 0
%s xpc object should be XPC_TYPE_DATA
%s Creating OS Transaction for %{public}@
%s Release OS Transaction for %{public}@
%s Abstract Impl. Returning nil
softlink:r:path:/System/Library/PrivateFrameworks/CarouselServices.framework/CarouselServices
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
zPLR
CSCATXPCProtocol
CSGestureMonitor
CSBluetoothWirelessSplitterInfo
CSAudioInjectionBuiltInEngine
CSAudioInjectionEngineDelegate
NSObject
NviDataLogger
NSStreamDelegate
CSVoiceTriggerAssetHandler
CSAudioSessionController
CSAudioSessionInfoProvidingDelegate
CSXPCClientDelegate
CSCoreSpeechDaemonStateMonitorDelegate
CSSiriDebugConnection
CSPhoneCallStateMonitor
CSCommandControlListenerOption
CSMediaPlayingMonitor
CSAudioInjectionFileOption
CSMSNExceptionManager
CSVolumeMonitor
CSTimerMonitor
CSAlarmMonitor
CSAudioStreamHolding
CSAssetManagerEnablePolicyFactory
CSBiometricMatchMonitor
CSAudioInjectionHearstEngine
AVVC
CSAudioZeroCounter
SmartSiriVolume
CSVoiceTriggerXPCService
CSVoiceTriggerXPCClientDelegate
CSAudioFileManager
CSVoiceTriggerAssetDownloadMonitor
Directory
CSAsset
CSAudioPreprocessor
CSVoiceTriggerAwareZeroFilterDelegate
CSBeepCancellerDelegate
CSAssetDownloadingOption
CSBluetoothManager
CSSiriAssertionMonitor
CSXPCConnectionDelegate
CSSpeakerRecognitionAssetDownloadMonitor
CSTrialAssetDownloadMonitorDelegate
CSPowerAssertionMac
CSAudioFileReader
ResourcePathHash
CSAdBlockerAssetDownloadMonitor
CSAudioRouteChangeMonitorImplWatch
CSAudioSampleRateConverter
CSLanguageDetectorAssetMonitor
CSSmartSiriVolumeService
CSSmartSiriVolumeServiceDelegate
CSSmartSiriVolumeClient
isPluginContext
CSAudioInjectionProvider
XPCObject
CSOpportuneSpeakListener
CSAudioStreamProvidingDelegate
CSSPGEndpointAnalyzerDelegate
CSVoiceIdXPCClient
AudioInjectionXPCProtocol
CSVoiceTriggerHeartBeatMetricsProvider
CSNNVADEndpointAnalyzer
CSEndpointAnalyzerImpl
CSEndpointAnalyzer
CSActivationXPCClient
CSLanguageDetector
CSAudioRecordContext
NSCopying
LanguageCode
CSStopRecordingOptions
CSMacWakeSleepMonitor
CSMyriadSelfTriggerCoordinator
CSSelfTriggerDetectorDelegate
LPCMTypeConversion
CSCommandControlStreamEventMonitor
CSCommandControlBehaviorMonitorDelegate
CSAVVCRecordingClientMonitor
CSSelectiveChannelAudioFileWriter
CSAudioFileWriter
CSAudioSessionMonitor
CSAudioSessionEventProvidingDelegate
Indexing
CSCoreSpeechServices
CSOpportuneSpeakListenerDeviceManager
CSAVVoiceTriggerClientManager
CSConfig
CSSpeechManager
CSAudioServerCrashMonitorDelegate
CSVoiceTriggerAssetHandlerDelegate
CSActivationEventNotificationHandlerDelegate
CSAudioRecorderDelegate
CSAudioProviderDelegate
CSOpportuneSpeakEventMonitorDelegate
CSSpeechEndHostTimeEstimator
CSClamshellStateMonitor
HybridEndpointer
CSCommandControlListener
CSAssetManager
CSVoiceTriggerAssetMetaUpdateMonitorDelegate
CSSpeechEndpointAssetMetaUpdateMonitorDelegate
CSAdBlockerMetaUpdateMonitorDelegate
CSAssetControllerDelegate
CSSpeakerRecognitionAssetMetaUpdateMonitorDelegate
CSLanguageCodeUpdateMonitorDelegate
NviDirectionalitySignalProvider
NviSignalProvider
SSRTriggerPhraseDetectorNDAPI
CSAudioRecorderFactory
CSKeywordAnalyzerNDEAPIResult
CSKeywordAnalyzerNDEAPI
CSSpeechController
CSAudioConverterDelegate
CSSmartSiriVolumeControllerDelegate
CSAudioSessionProvidingDelegate
CSAudioAlertProvidingDelegate
CSAudioSessionControllerDelegate
CSAudioDecoderDelegate
CSSpeechManagerDelegate
CSContinuousVoiceTriggerDelegate
RTModel
SpeechModelTrainingClient
CSPreferences
CSAudioTimeConverter
SSRAESKeyManager
SpeechModelTrainingProtocol
NviSignalProvidersController
CSVoiceTriggerFirstPassHearstAP
CSXPCClient
CSAudioSessionProviding
CSFallbackAudioSessionReleaseProviding
CSAudioStreamProviding
CSAudioAlertProviding
CSAudioSessionInfoProviding
CSAudioMeterProviding
CSAudioMetricProviding
CSAudioTimeConversionProviding
CSTriggerInfoProviding
CSStateMachine
CSPlainAudioFileWriter
CSEventMonitor
CSAudioChunkForTV
CSSmartSiriVolumeManager
CSVoiceTriggerDelegate
CSAlarmMonitorDelegate
CSTimerMonitorDelegate
CSVolumeMonitorDelegate
CSVoiceTriggerDataCollector
CSAudioFileLog
CSAudioStreamRequest
CSActivationEvent
CSScreenLockMonitor
CSAssetController
CSEventMonitorDelegate
Utils
CSSyncKeywordAnalyzerQuasar
CSAudioDecoder
CSAudioInjectionTvRemoteEngine
CSSiriLauncher
CSAudioRouteChangeMonitor
CSSmartSiriVolumeEnablePolicy
CSAudioInjectionRemoraEngine
CSAudioInjectionEngine
AudioHardware
CSVoiceTriggerAssetChangeMonitor
NviAudioFileWriter
CSVoiceTriggerEnabledPolicyNonAOP
CSBluetoothWirelessSplitterMonitor
CSSiriClientBehaviorMonitor
CSSpeechEndpointAssetMetaUpdateMonitor
VoiceTriggerRecord
CSSmartSiriVolumeEstimate
NSSecureCoding
NSCoding
CSVoiceTriggerAssetHandlerMac
CSVoiceTriggerAssetDownloadMonitorDelegate
CSFirstUnlockMonitorDelegate
CSVoiceTriggerAOPModeEnabledPolicyIOS
CSSiriClientBehaviorMonitorDelegate
CSVoiceTriggerStatAggregator
CSOpportuneSpeakBehaviorMonitor
CSMyriadPHash
NviConstants
CSVoiceTriggerEventInfoProvider
NviUtils
CSHostPowerSourceMonitor
CSAudioStartStreamOption
CSAssetControllerFactory
CSVoiceTriggerXPCServiceProxy
CSDispatchGroup
CSSmartSiriVolumeController
CSSmartSiriVolumeClientDelegate
SpeakerRecognition
CSBluetoothDeviceInfo
CSP2PService
CSVoiceTriggerAwareZeroFilter
CSAlwaysDisabledPolicy
CSUtils
CSPostBuildInstallService
CSDiagnosticReporter
CSContinuousAudioFingerprintProvider
CSKeywordAnalyzerNDAPIResult
CSKeywordAnalyzerNDAPI
CSBuiltinSpeakerStateMonitor
NviDirectionalitySignalData
CSEndpointerMetrics
CSSmartSiriVolume
CSMediaPlayingMonitorDelegate
CSSiriEnabledMonitorDelegate
CSSmartSiriVolumeProcessor
CSSACInfoMonitor
CSRemoteControlClient
CSVoiceTriggerRTModel
CSAudioRouteChangeMonitorImpl
AudioStreamBasicDescription
CSSpeakerRecognitionAssetMetaUpdateMonitor
CSVoiceProfileRetrainManager
CSVoiceTriggerEnabledMonitor
CSVTUIAudioSessionRecorder
CSVTUIAudioSession
CSRemoteRecordClient
CSSiriEnabledMonitor
NviCSAudioDataSource
NviAudioDataSource
NviDataSource
CSAlertBehaviorPredictor
CSBeepCanceller
CSAudioInjectionEngineFactory
RMSSample
CSShadowMicScoreCreator
CoreSpeechXPCProtocol
CSActivationEventNotifier
CSGestureMonitorWatch
CSLSWakeGestureObserver
CSAudioZeroFilter
AudioFile
CSSoftwareUpdateCheckingMonitor
CSAssetManagerEnablePolicy
CSCoreSpeechServiceListenerDelegate
CSVoiceTriggerAOPModeEnabledPolicyFactory
CSBatteryMonitor
CSAudioCircularBuffer
SSREnrollmentDataManager
CSVoiceTriggerAssetMetaUpdateMonitor
CSDarkWakePowerAssertionMac
CSAlwaysEnabledPolicy
CSRemoteVADCircularBuffer
CSAdBlockerAssetMetaUpdateMonitor
CSAudioStream
CSServerEndpointFeatures
CSActivationEventNotificationHandler
CoreSpeechXPC
CSSiriRestrictionOnLockScreenMonitor
MCProfileConnectionObserver
CSSpringboardStartMonitor
CSAudioProvider
CSAudioPreprocessorDelegate
CSListeningEnabledPolicyWatch
CSAlwaysOnProcessorStateMonitor
CSAdBlockerAssetDecoderFactory
CSAudioChunk
CSNovDetectorResult
CSNovDetector
CSAdBlockerAssetDecoderV1
CSUserSessionActiveMonitor
CSTrialAssetDownloadMonitor
Bitset
CSHybridEndpointAnalyzer
CSOpportuneSpeakListenerOption
CSAudioInjectionDevice
Time
CSAudioSessionInfoProvider
CSEndpointerProxy
CSEndpointAnalyzerDelegate
CSEndpointAnalyzerImplDelegate
CSCATAssetManager
CSFirstUnlockMonitor
CSAudioPowerMeter
CSPhraseSpotterEnabledMonitor
CSVoiceIdXPCConnection
NSXPC
CSFallbackAudioSessionReleaseProvider
CSSPGEndpointAnalyzer
CSLanguageDetectorOption
CSTrialAssetManager
CSStartOfSpeechDetector
CSAudioServerCrashMonitor
CSAudioServerCrashEventProvidingDelegate
CSVoiceTriggerXPCClient
CSCoreSpeechDaemonStateMonitor
CSKeywordAnalyzerQuasar
CSNetworkAvailabilityMonitor
CSSpeechDetectionDevicePresentMonitor
CSAudioRecordDeviceInfo
CSOpportuneSpeakListnerTestService
CSOpportuneSpeakListenerDelegate
CSAudioConverter
CSLanguageCodeUpdateMonitor
CSPolicy
CSAudioInjectionServices
Trial
CSGestureDropEvent
RecordContext
CSUserIdentityClassifier
CSVTSecondPassPhraseScore
CSVTSecondPassScorer
LanguageDetector
debugDescription
remoteVoiceActivityVADBuffer
CSAudioRecorder
AVVoiceControllerRecordDelegate
CSAudioFileReaderDelegate
CSAudioServerCrashEventProviding
CSAudioSessionEventProviding
CSCommandControlBehaviorMonitor
CSVoiceProfileContext
NviContext
CSJarvisTriggerModeMonitor
CSOpportuneSpeakEventMonitor
CSOpportuneSpeakBehaviorMonitorDelegate
CSOSTransaction
NviSignalData
CSSRFUserSettingMonitor
fetchRemoteCATAssetForResource:withNameOfFile:completion:
interfaceWithProtocol:
arrayWithObjects:count:
setWithArray:
setClasses:forSelector:argumentIndex:ofReply:
sharedInstance
wakeGestureTimestamp
dismissalTimestamp
hostTimeToSeconds:
_startMonitoringWithQueue:
_stopMonitoring
isTriggerHandheld
setWakeGestureTimestamp:
setDismissalTimestamp:
_wakeGestureTimestamp
_dismissalTimestamp
init
array
string
appendFormat:
countByEnumeratingWithState:objects:count:
address
supportDoAP
splitterState
copy
addObject:
_hasDeviceTemporaryPairedNotInContacts
isTemporaryPairedNotInContacts
description
splitterDeviceList
addDeviceIntoSplitterDeviceList:
shouldDisableSpeakerVerificationInSplitterMode
splitterEnabled
setSplitterEnabled:
.cxx_destruct
_splitterDeviceList
_splitterEnabled
initWithStreamHandleId:
inputRecordingNumberOfChannels
inputRecordingSampleRate
initWithNumChannels:recordingDuration:samplingRate:
UUID
setConnectedDevice:
enableAlwaysOnVoiceTrigger
isAlwaysOnVoiceTriggerAvailable
setAlwaysOnVoiceTriggerEnabled:
setDelegate:
dealloc
start
noAlertOption
startAudioStreamWithOption:
stopAudioStream
stop
reset
injectAudio:
injectAudio:withScaleFactor:playbackStarted:completion:
sampleCount
requestHistoricalAudioDataWithHostTime
startRecordingHostTime
count
objectAtIndex:
objectForKeyedSubscript:
unsignedIntValue
unsignedLongLongValue
getBestSampleCountWithOption:
audioEngineDidStartRecord:audioStreamHandleId:successfully:error:
audioStreamHandleId
audioEngineDidStopRecord:audioStreamHandleId:reason:
length
inputRecordingSampleByteDepth
numberWithUnsignedInteger:
numberWithUnsignedLongLong:
dictionaryWithObjects:forKeys:count:
removeObjectAtIndex:
bytes
addSamples:numSamples:
applyNegative12dBGain:
initWithData:numChannels:numSamples:sampleByteDepth:startSampleCount:hostTime:remoteVAD:
processAudioChunk:
isEarlyDetect
bestEnd
bestStart
secondsToHostTime:
sharedManagerForCoreSpeechDaemon
builtInMicVoiceTriggerEvent:hostTime:
notifyActivationEvent:completion:
inputRecordingBufferDuration
copybufferFrom:to:
audioEngineBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
debugDescription
audioEngineAudioChunkForTvAvailable:audioChunk:
alwaysOnVoiceTriggerEnabled
attachDevice:
isRecording
queue
setQueue:
delegate
keywordAnalyzer
setKeywordAnalyzer:
circularBuffer
setCircularBuffer:
lastForwardedSampleCount
setLastForwardedSampleCount:
hostTimeBuffer
setHostTimeBuffer:
uuid
setUuid:
voiceTriggerEnabled
setVoiceTriggerEnabled:
connectedDevice
isForwarding
setIsForwarding:
voiceTriggerSampleCount
setVoiceTriggerSampleCount:
_voiceTriggerEnabled
_isForwarding
_queue
_delegate
_keywordAnalyzer
_circularBuffer
_lastForwardedSampleCount
_hostTimeBuffer
_uuid
_connectedDevice
_voiceTriggerSampleCount
outputStreamToFileAtPath:append:
currentRunLoop
scheduleInRunLoop:forMode:
open
hasSpaceAvailable
stringWithFormat:
lengthOfBytesUsingEncoding:
cStringUsingEncoding:
write:maxLength:
close
removeFromRunLoop:forMode:
stream:handleEvent:
initWithFilePath:appendHdr:
logData:
endRequest
oStream
setOStream:
_oStream
weakObjectsHashTable
removeObject:
voiceTriggerAssetHandler:didChangeCachedAsset:
sharedHandler
getVoiceTriggerAsset:
defaultFallbackModelIfNil:
registerObserver:
unregisterObserver:
notifyObservers:
observers
setObservers:
_observers
_startMonitoring
_getAudioSessionID
_createXPCClientConnectionIfNeeded
sessionInfoProvider
audioSessionID
audioSessionController:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
audioSessionController:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
initWithType:
setSessionInfoProvider:
connect
opaqueSessionID
setShouldKeepConnection:
addObserver:
userInfo
_registerInterruptionNotification
_registerAudioRouteChangeNotification
audioSessionController:didReceiveAudioSessionOwnerLostNotification:
_teardownXPCClientIfNeeded
audioSessionController:didReceiveAudioSessionOwnerResetNotification:
audioSessionInfoProvider:didReceiveAudioSessionInterruptionNotificationWithUserInfo:
audioSessionInfoProvider:didReceiveAudioSessionRouteChangeNotificationWithUserInfo:
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereLostNotificationWithUserInfo:
audioSessionInfoProvider:didReceiveAudioSessionMediaServicesWereResetNotificationWithUserInfo:
CSXPCClient:didDisconnect:
coreSpeechDaemonStateMonitor:didReceiveStateChanged:
getAudioSessionIDWithCompletion:
getAudioSessionID
_getLocalAudioSessionID
_handleInterruption:
_mediaServicesWereLost:
_mediaServicesWereReset:
_audioRouteChanged:
xpcClient
setXpcClient:
shouldKeepConnection
_shouldKeepConnection
_sessionInfoProvider
_xpcClient
initWithAppBundleIdentifier:
initWithTaskDeliverer:
initWithMessage:makeAppFrontmost:
handleSiriRequest:deliveryHandler:completionHandler:
launchSiriDebugAppWithMessage:
isInPhoneCallState
defaultOption
_notifyObserver:mediaIsPlayingState:
enumerateObserversInQueue:
defaultCenter
_notePossiblePlayPausedStateChange:
addObserver:selector:name:object:
removeObserver:name:object:
objectForKey:
boolValue
notifyObserver:
CSMediaPlayingMonitor:didReceiveMediaPlayingChanged:
initializeMediaPlayingState
mediaPlayingState
mediaPlayingStateWithCompletion:
_mediaIsPlaying
initWithAudioURL:withScaleFactor:outASBD:
audioURL
outASBD
setOutASBD:
fFile
setFFile:
scaleFactor
_scaleFactor
_audioURL
_fFile
_outASBD
beginAnnounceMessageException:reason:
endAnnounceMessageException:reason:
fetchVolumeFromAVSystemControllerForAudioCategory:
_startObservingSystemControllerLifecycle
startObservingSystemVolumes
removeObserver:
isEqualToString:
musicVolume
musicVolumeWithCompletion:
alarmVolume
systemVolumeDidChange:
systemControllerDied:
_supportAVSystemVolumeFetch
_musicVolumeLevel
_alarmVolumeLevel
initializeTimerState
timerState
_timerFiringState
initializeAlarmState
alarmState
_alarmFiringState
name
setName:
_name
assetManagerEnabledPolicy
startObserving
getLastBiometricMatchEvent:atTime:
getBiometricMatchResultForTriggerTimeStamp:
getAnalyzedResult
bestScore
getThreshold
deviceID
remoteMicVoiceTriggerEvent:activationInfo:hostTime:
lastDetectedVoiceTriggerBeginSampleCount
setLastDetectedVoiceTriggerBeginSampleCount:
_lastDetectedVoiceTriggerBeginSampleCount
avvcContext
unsignedIntegerValue
initWithMode:deviceUID:
avvcContextSettings
zeroFilterWindowSizeInMs
zeroFilterWindowSizeInMsForReport
shouldDeinterleaveAudioOnCS
sharedAggregator
logAudioZeroRun:
initWithToken:sampleRate:numChannels:
resetWithSampleRate:
getZeroStatisticsFromBuffer:entireSamples:
stopReportZeroStatistics
_methodToken
_continuousZeroCounter
_zeroCounterWinSz
_zeroCounterWinSzForReport
_maxContinuousZeroCount
_numChannels
_analyzeStep
_sampleRate
_shouldDeinterleaveAudio
getNumberForKey:category:default:
floatValue
getNumElementInBitset:
SSVNoiseLevelChannelBitset
SSVLKFSChannelBitset
SSVEnergyBufferSize
numberWithUnsignedInt:
SSVNoiseLowerPercentile
SSVNoiseUpperPercentile
SSVLKFSLowerPercentile
SSVLKFSUpperPercentile
SSVNoiseTimeConstant
numberWithFloat:
SSVNoiseMicSensitivityOffset
SSVLKFSTimeConstant
SSVLKFSMicSensitivityOffset
SSVNoiseTTSMappingInputRangeLow
SSVNoiseTTSMappingInputRangeHigh
SSVNoiseTTSMappingOutputRangeLow
SSVNoiseTTSMappingOutputRangeHigh
SSVLKFSTTSMappingInputRangeLow
SSVLKFSTTSMappingInputRangeHigh
SSVLKFSTTSMappingOutputRangeLow
SSVLKFSTTSMappingOutputRangeHigh
SSVUserOffsetInputRangeLow
SSVUserOffsetInputRangeHigh
SSVUserOffsetOutputRangeLow
SSVUserOffsetOutputRangeHigh
SSVTTSVolumeLowerLimitDB
SSVTTSVolumeUpperLimitDB
SSVNoiseWeight
SSVDistanceChannelBitset
SSVNoiseMicSensitivityOffsetDeviceSimple
SSVParameterDirectionary
SSVDefaultNoiseChannelCount
SSVDefaultLKFSChannelCount
SSVDefaultDistanceChannelCount
getSSVDeviceType
_createXPCClientConnectionIfNeeded:
processInfo
systemUptime
enableVoiceTrigger:withAssertion:timestamp:
enableVoiceTrigger:withAssertion:xpcClient:
setPhraseSpotterBypassing:timeout:
setPhraseSpotterBypassing:timeout:xpcClient:
setRaiseToSpeakBypassing:timeout:
setRaiseToSpeakBypassing:timeout:xpcClient:
notifyVoiceTriggeredSiriSessionCancelled
fetchVoiceTriggerStats
notifyVoiceTriggeredSiriSessionCancelledWithXpcClient:
sharedService
voiceTriggerXPCClient:didDisconnect:
enableVoiceTrigger:withAssertion:
fetchVoiceTriggerDailyStats
_sharedAudioLoggingQueue
fileURL
URLByDeletingLastPathComponent
path
sharedPreferences
assistantAudioFileLogDirectory
containsString:
defaultManager
removeItemAtURL:error:
seekToEndOfFile
seekToFileOffset:
readDataOfLength:
getBytes:length:
initWithData:encoding:
offsetInFile
writeData:
fileLoggingIsEnabled
_createAudioFileWriterForOpportuneSpeakListenerWithLoggingDir:inputFormat:outputFormat:
_createAudioFileWriterForPHSTrainingWithLoggingDir:inputFormat:outputFormat:
_createAudioFileWriterWithLoggingDir:withLoggingUUID:inputFormat:outputFormat:
_getDateLabel
stringByAppendingPathComponent:
fileURLWithPath:
lpcmNonInterleavedASBDWithSampleRate:numberOfChannels:
lpcmInterleavedASBDWithSampleRate:numberOfChannels:
initWithURL:inputFormat:outputFormat:channelBitset:
isAdBlockerAudioLoggingEnabled
voiceTriggerAudioLogDirectory
_createAudioFileWriterForAdBlockerWithLoggingDir:inputFormat:outputFormat:
pruneLogFiles
URLWithString:
initWithURL:inputFormat:outputFormat:
localeWithLocaleIdentifier:
setLocale:
setDateFormat:
stringFromDate:
removeLogFilesInDirectory:matchingPattern:beforeDays:
maxNumGradingFiles
pruneNumberOfGradingFilesTo:
maxNumLoggingFiles
pruneNumberOfLogFilesTo:
arrayWithObjects:
clearLogFilesInDirectory:matchingPattern:exceedNumber:
cleanupOrphanedGradingFiles
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
dictionary
absoluteString
lastPathComponent
stringByDeletingPathExtension
setObject:forKeyedSubscript:
removeObjectForKey:
fileExistsAtPath:isDirectory:
removeItemAtPath:error:
enumerateKeysAndObjectsUsingBlock:
isAttentiveSiriAudioLoggingEnabled
assistantLogDirectory
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
utteranceFileASBD
generateDeviceAudioLogging:speechId:
_readDataFromFileHandle:toFileHandle:
createAudioFileWriterForOpportuneSpeakListenerWithInputFormat:outputFormat:
createAudioFileWriterForPHSTrainingWithInputFormat:outputFormat:
createAudioFileWriterForRemoteVADWithInputFormat:outputFormat:withLoggingUUID:
createAudioFileWriterWithInputFormat:outputFormat:withLoggingUUID:
createSelectiveChannelAudioFileWriterWithChannelBitset:
createAudioFileWriterForAdBlockerWithInputFormat:outputFormat:
removeLogFilesOlderThanNDays:
audioFileWriterForAttentiveSiri
_notificationKey
_didInstalledNewVoiceTriggerAsset
_notifyObserver:
enumerateObservers:
CSVoiceTriggerAssetDownloadMonitor:didInstallNewAsset:
_notifyToken
_sharedDisposeLoggingQueue
dateWithTimeIntervalSinceNow:
distantFuture
getResourceValue:forKey:error:
localizedDescription
compare:
URLsInDirectory:matchingPattern:completion:
_sortedURLsInDirectory:matchingPattern:completion:
_contentsOfDirectoryAtURL:matchingPattern:includingPropertiesForKeys:error:
sortedArrayUsingComparator:
regularExpressionWithPattern:options:error:
numberOfMatchesInString:options:range:
predicateWithBlock:
filteredArrayUsingPredicate:
getLocalUrl
_compatibilityVersion
stringValue
appendString:
_version
_footprint
assetForAssetType:resourcePath:configVersion:
attributes
state
integerValue
isPremium
getCSAssetOfType:
isDownloading
isCSAssetInstalled
canBePurged
isLatestCompareTo:
supportZeroFilter
supportBeepCanceller
resetWithSampleRate:containsVoiceTrigger:voiceTriggerInfo:
setSampleRate:
_isNarrowBand:
upsampler
setUpsampler:
zeroFilter
beepCanceller
convertSampleRateOfBuffer:
processBuffer:atTime:
cancelBeepFromSamples:timestamp:
audioPreprocessor:hasAvailableBuffer:atTime:
flush
_reportMetrics
_isHeadphoneDeviceWithRecordRoute:playbackRoute:
willBeep
currentRoute
outputs
endpointType
inputRecordingSampleRateNarrowBand
zeroFilter:zeroFilteredBufferAvailable:atHostTime:
beepCancellerDidCancelSamples:buffer:timestamp:
initWithSampleRate:
willBeepWithRecordRoute:playbackRoute:
sampleRate
setZeroFilter:
setBeepCanceller:
zeroCounter
setZeroCounter:
_upsampler
_zeroFilter
_beepCanceller
_zeroCounter
allowVoiceTriggerAssetDownloading
setAllowVoiceTriggerAssetDownloading:
allowEndpointAssetDownloading
setAllowEndpointAssetDownloading:
allowLanguageDetectorAssetDownloading
setAllowLanguageDetectorAssetDownloading:
allowAdBlockerAssetDownloading
setAllowAdBlockerAssetDownloading:
allowSpeakerRecognitionAssetDownloading
setAllowSpeakerRecognitionAssetDownloading:
_allowVoiceTriggerAssetDownloading
_allowEndpointAssetDownloading
_allowLanguageDetectorAssetDownloading
_allowAdBlockerAssetDownloading
_allowSpeakerRecognitionAssetDownloading
stringByAppendingFormat:
_attachBluetoothSession
_getWirelessSplitterInfoFromLocalDevice:
getBTLocalDeviceWithCompletion:
initWithCapacity:
initWithUTF8String:
setAddress:
setSupportDoAP:
setIsTemporaryPairedNotInContacts:
_tearDownLocalDevice
_detachBluetoothSession
_setUpLocalDevice
getWirelessSplitterInfoWithCompletion:
device:serviceMask:serviceEventType:serviceSpecificEvent:result:
_sessionAttached:result:
_sessionDetached:
_sessionTerminated:
localDevice:event:result:
bluetoothSession
setBluetoothSession:
isAttachingBluetoothSession
setIsAttachingBluetoothSession:
localDevice
setLocalDevice:
pairedDeviceAddresses
setPairedDeviceAddresses:
connectedDeviceAddresses
setConnectedDeviceAddresses:
bluetoothSessionSetupGroup
setBluetoothSessionSetupGroup:
_isAttachingBluetoothSession
_bluetoothSession
_localDevice
_pairedDeviceAddresses
_connectedDeviceAddresses
_bluetoothSessionSetupGroup
isEnabled
CSSiriAssertionMonitor:didReceiveEnabled:
handleXPCMessage:messageBody:client:
CSXPCConnectionReceivedClientError:clientError:client:
enableAssertionReceived
disableAssertionReceived
_assertionState
_didInstalledNewAsset
CSSpeakerRecognitionAssetDownloadMonitor:didInstallNewAsset:assetProviderType:
trialAssetDownloadMonitorDelegate:didInstallNewAsset:assetType:
trialAssetMonitor
setTrialAssetMonitor:
_lastUpdatedAssetType
_trialAssetMonitor
initWithTimeout:
invalidate
_readAudioBufferAndFeed
audioFileReaderDidStartRecording:successfully:error:
dataWithLength:
audioFileReaderBufferAvailable:buffer:atTime:
audioFileReaderDidStopRecording:forReason:
initWithURL:
setRecordBufferDuration:
prepareRecording:
startRecording
stopRecording
readSamplesFromChannelIdx:
_audioFeedTimer
_bufferDuration
firstMatchInString:options:range:
numberOfRanges
rangeAtIndex:
substringWithRange:
assetHashInResourcePath:
_didInstalledNewAdBlockerAsset
CSAdBlockerAssetDownloadMonitor:didInstallNewAsset:assetProviderType:
monitor
setMonitor:
_monitor
_fetchHearstConnectionState
_notifyHearstConnectionState:
CSAudioRouteChangeMonitor:didReceiveAudioRouteChangeEvent:
getHearstConnected:
hearstConnected
getJarvisConnected:
jarvisConnected
activeAudioRouteDidChange:
_isHearstConnected
lpcmNarrowBandASBD
lpcmASBD
initWithInASBD:outASBD:
_createSampleRateConverterWithInASBD:outASBD:
mutableBytes
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
setLength:
downsampler
_sampleRateConverter
_outBufferScaleFactor
_inASBD
languageDetectorAssetMonitor:didReceiveNewAssetWithSupportLocale:
_supportedLocale:
supportLanguageDetector
sharedManager
setAssetDownloadingOption:
languageDetectorSupportedLocale
assetOfType:language:completion:
errorWithDomain:code:userInfo:
startMonitor
supportedLocale:
notifyToken
setNotifyToken:
_getRemoteServiceProxyObject
getVolumeForTTSType:withContext:reply:
didSmartSiriVolumeChangeForReason:
_createClientConnection
code
synchronousRemoteObjectProxyWithErrorHandler:
initWithMachServiceName:options:
setRemoteObjectInterface:
didTTSVolumeChangeForReason:
setExportedInterface:
setExportedObject:
ssvConnection
processIdentifier
setSsvConnection:
setInterruptionHandler:
setInvalidationHandler:
resume
getVolumeForTTSType:withContext:
_ssvConnection
type
isPluginContext
UUIDString
initWithDeviceType:deviceName:deviceID:productID:
deviceType
_createSpeechDetectionVADIfNeeded
isPluginDevice
_connectPluginDevice:
_tearDownSpeechDetectionVADIfNeeded
engineWithDeviceType:streamHandleId:
setInjectionEngine:
setObject:forKey:
removeAllObjects
audioRecorderStreamHandleIdInvalidated:
audioRecorderWillBeDestroyed:
injectionEngine
deviceId
deviceName
deviceUID
productIdentifier
initWithRoute:isRemoteDevice:remoteDeviceUID:remoteDeviceProductIdentifier:
setActive:withOptions:error:
setActive:error:
audioRecorderDidStartRecord:audioStreamHandleId:successfully:error:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:remoteVAD:atTime:
audioRecorderDidStopRecord:audioStreamHandleId:reason:
audioRecorderBufferAvailable:audioStreamHandleId:buffer:
streamHandleID
defaultInjectionProvider
createSharedAudioSession
primaryInputDevice
connectDevice:
disconnectDevice:
willDestroy
setAudioServerCrashEventDelegate:
setAudioSessionEventDelegate:
setContext:error:
setCurrentContext:streamHandleId:error:
prepareAudioStreamRecord:streamHandleId:error:
startAudioStreamWithOption:streamHandleId:error:
stopAudioStreamWithStreamHandleId:error:
isRecordingWithStreamHandleId:
recordRouteWithStreamHandleId:
recordDeviceInfoWithStreamHandleId:
recordSettingsWithStreamHandleId:
recordingSampleRateWithStreamHandleId:
isNarrowBandWithStreamHandleId:
prewarmAudioSessionWithStreamHandleId:error:
activateAudioSessionWithReason:streamHandleId:error:
deactivateAudioSession:streamHandleId:error:
setRecordMode:streamHandleId:error:
setDuckOthersOption:
duckOthersOption
playbackRoute
setAlertSoundFromURL:forType:
playRecordStartingAlertAndResetEndpointerFromStream:
playAlertSoundForType:
alertStartTime
setMeteringEnabled:
updateMeters
peakPowerForChannel:
averagePowerForChannel:
isSessionCurrentlyActivated
voiceTriggerInfo
enableMiniDucking:
metrics
configureAlertBehavior:audioStreamHandleId:
didStartDelayInSeconds
setDidStartDelayInSeconds:
connectedDevices
setConnectedDevices:
builtInDevice
setBuiltInDevice:
bundleTvRemote
setBundleTvRemote:
builtInAudioInjectionEngine
setBuiltInAudioInjectionEngine:
audioInjectionEngines
setAudioInjectionEngines:
latestPluginStreamId
setLatestPluginStreamId:
_didStartDelayInSeconds
_connectedDevices
_builtInDevice
_bundleTvRemote
_builtInAudioInjectionEngine
_audioInjectionEngines
_latestPluginStreamId
UTF8String
_cs_initWithXPCObject:
_cs_xpcObject
initWithAnalyzeMode
lpcmNonInterleavedWithRemoteVADASBD
lpcmInterleavedWithRemoteVADASBD
setDeviceId:
contextForHearstVoiceTriggerWithDeviceId:
contextForOpportuneSpeakerListener
_resetAlignBuffer
prepareAudioProviderWithContext:clientType:error:
_startRequestWithCompletion:
defaultRequestWithContext:
setRequiresHistoricalBuffer:
audioStreamWithRequest:streamName:error:
setAudioStream:
getFrameDurationMs
remoteVADDuration
startAudioStreamWithOption:completion:
endAudio
audioStream
stopAudioStreamWithOption:completion:
stopListenWithStateReset:completion:
opportuneSpeakListener:didStopUnexpectly:
gainCompensatedChunk
channelForProcessedInput
dataForChannel:
numSamples
addAudio:numSamples:
remoteVAD
opportuneSpeakListenerBypassEnabled
_addRemoteVADSignal:
dataWithRemoteVADWithScaleFactor:numAudioSamplesPerRemoteVAD:
numberWithBool:
_shouldReportBoron
_popRemoteVADSignal
opportuneSpeakListener:hasRemoteVADAvailable:
opportuneSpeakListener:hasVADAvailable:
audioStreamProvider:didStopStreamUnexpectly:
audioStreamProvider:audioBufferAvailable:
audioStreamProvider:audioChunkForTVAvailable:
audioStreamProvider:didHardwareConfigurationChange:
startListenWithOption:completion:
stopListenWithCompletion:
spgEndpointAnalyzer:hasSilenceScoreEstimate:
spgEndpointAnalyzer
setSpgEndpointAnalyzer:
remoteVADSPGRatio
setRemoteVADSPGRatio:
audioStreamProvider
setAudioStreamProvider:
audioSessionProvider
setAudioSessionProvider:
latestContext
setLatestContext:
isMediaPlayingNow
setIsMediaPlayingNow:
remoteVADAlignBuffer
setRemoteVADAlignBuffer:
remoteVADAlignCount
setRemoteVADAlignCount:
alignBufferQueue
setAlignBufferQueue:
audioFileWriter
setAudioFileWriter:
_isMediaPlayingNow
_remoteVADSPGRatio
_audioStream
_spgEndpointAnalyzer
_audioStreamProvider
_audioSessionProvider
_latestContext
_remoteVADAlignBuffer
_remoteVADAlignCount
_alignBufferQueue
_audioFileWriter
_handleListenerEvent:
disconnect
_handleListenerError:
initWithDictionary:
_sendMessage:connection:completion:
_decodeError:
stringWithUTF8String:
notifyImplicitUtterance:audioDeviceType:audioRecordType:voiceTriggerEventInfo:otherCtxt:completion:
xpcConnection
setXpcConnection:
_xpcConnection
pingpong:completion:
createAudioInjectionDeviceWithType:deviceName:deviceID:productID:completion:
injectAudio:toDeviceWithUUID:withScaleFactor:completion:
connectDeviceWithUUID:completion:
disconnectDeviceWithUUID:completion:
primaryInputDeviceUUIDWithCompletion:
fetchVoiceTriggerHeartBeatMetrics
preheat
endpointStyle
setEndpointStyle:
delay
setDelay:
startWaitTime
setStartWaitTime:
automaticEndpointingSuspensionEndTime
setAutomaticEndpointingSuspensionEndTime:
minimumDurationForEndpointer
setMinimumDurationForEndpointer:
lastEndOfVoiceActivityTime
lastStartOfVoiceActivityTime
bypassSamples
setBypassSamples:
endpointMode
setEndpointMode:
interspeechWaitTime
setInterspeechWaitTime:
endWaitTime
setEndWaitTime:
saveSamplesSeenInReset
setSaveSamplesSeenInReset:
resetForNewRequestWithSampleRate:recordContext:recordSettings:
processAudioSamplesAsynchronously:
stopEndpointer
recordingStoppedForReason:
trailingSilenceDurationAtEndpoint
implDelegate
setImplDelegate:
canProcessCurrentRequest
activeChannel
setActiveChannel:
processServerEndpointFeatures:
updateEndpointerThreshold:
updateEndpointerDelayedTrigger:
shouldAcceptEagerResultForDuration:resultsCompletionHandler:
logFeaturesWithEvent:locale:
handleVoiceTriggerWithActivationInfo:
endpointerModelVersion
elapsedTimeWithNoSpeech
xpcObject
initWithModelURL:
recordRecognitionLanguage:
setMostRecentRecognitionLanguage:
setInteractionIDforCurrentRequest:
cancelCurrentRequest
resetForNewRequest:
initWithRecordType:deviceId:
setAlwaysUseRemoteBuiltInMic:
contextForServerInvoke
recordTypeFromAVVCActivationMode:
setType:
copyWithZone:
_createAVVCContextWithType:deviceId:
avvcActivationMode:
numberWithInteger:
isBuiltInVoiceTriggered
isHearstVoiceTriggered
isJarvisVoiceTriggered
isHearstDoubleTapTriggered
recordTypeString:
contextForRemoraVoiceTriggerWithDeviceId:
contextForBuiltInVoiceTrigger
contextForJarvisWithDeviceId:
contextForBTLEWithDeviceId:
contextForVoiceTriggerTraining
contextForHomeButton
defaultContext
initWithXPCObject:
initWithAVVCContext:
isVoiceTriggered
isTriggeredFromHearst
isRTSTriggered
isServerInvoked
isStarkTriggered
isDictation
alwaysUseRemoteBuiltInMic
_alwaysUseRemoteBuiltInMic
_type
_deviceId
getSiriLanguageWithFallback:
stringWithString:
stopRecordingReason
setStopRecordingReason:
expectedStopHostTime
setExpectedStopHostTime:
_stopRecordingReason
_expectedStopHostTime
deviceIsInSleep
dataWithCapacity:
appendBytes:length:
myriadHashFilePath
writeToFile:atomically:
CSMyriadSelfTriggerCoordinator:didGenerateMyriadPHashForSelfTrigger:
selfTriggerDetector:didDetectSelfTrigger:
initWithLength:
inputRecordingIsFloat
applyGain:toBuffer:
convertToFloatLPCMBufFromShortLPCMBuf:
convertToShortLPCMBufFromFloatLPCMBuf:
apply12dBGain:
_notifyStopCommandControl
commandControlBehaviorMonitor:willStartStreamWithContext:option:
commandControlBehaviorMonitor:didStartStreamWithContext:successfully:option:
commandControlBehaviorMonitor:willStopStream:
commandControlBehaviorMonitor:didStopStream:
isStreaming
_isCommandControlStreaming
numOfAVVCRecordingClients
_numOfAVVCRecordingClients
iterateBitset:block:
mutableCopy
numberOfChannels
isWriting
inASBD
selectedChannelList
_numberOfChannels
_fileURL
audioSessionEventProvidingWillSetAudioSessionActive:
audioSessionEventProvidingDidSetAudioSessionActive:
getAudioSessionState
setAudioSessionState:
_audioSessionState
enumerateObjects:
initWithServiceName:
getCoreSpeechXPCConnection
remoteObjectProxy
installedVoiceTriggerAssetForLanguageCode:completion:
fetchRemoteVoiceTriggerAssetForLanguageCode:completion:
voiceTriggerRTModelForVersion:minorVersion:locale:downloadedModels:preinstalledModels:completion:
voiceTriggerJarvisLanguageList:jarvisSelectedLanguage:completion:
getCoreSpeechServiceConnection
requestUpdatedSATAudio:
getFirstPassRunningMode:
voiceTriggerRTModelForVersion:minorVersion:downloadedModels:preinstalledModels:completion:
requestUpdatedSATAudio
getFirstPassRunningMode
sharedVoiceTriggerClient
inputRecordingFramesPerPacket
shouldRunVTOnCS
isIOSDeviceSupportingBargeIn
inputRecordingBytesPerFrame
inputRecordingBytesPerPacket
hearstNumberOfBytesPerChunk
hearstNumberOfSamplesPerChunk
inputRecordingDurationInSecs
inputRecordingSampleBitDepth
EncryptionAudioSampleByteDepth
inputRecordingEncoderAudioQuality
inputRecordingSampleRateConverterAlgorithm
audioConverterBitrate
channelForOutputReference
zeroFilterApproxAbsSpeechThreshold
csAudioProcessingQueuePriority
daysBeforeRemovingLogFiles
serverLoggingChannelBitset
continousFingerprintBufferDuration
startManager
_createClearLoggingFileTimer
registerPostBuildInstallService
_startClearLoggingFilesTimer
supportHearstVoiceTrigger
setDelegate:forType:
supportRemoraVoiceTrigger
supportJarvisVoiceTrigger
supportBluetoothDeviceVoiceTrigger
_getAudioRecorderWithError:
audioProviders
initWithAudioStreamHandleId:audioRecorder:
setAudioProviderDelegate:
initWithAudioRecorder:
audioRecorderWithQueue:error:
setAudioRecorder:
setAsset:
CSAudioServerCrashMonitorDidReceiveServerCrash:
CSAudioServerCrashMonitorDidReceiveServerRestart:
activationEventNotificationHandler:event:completion:
audioRecorderRecordHardwareConfigurationDidChange:toConfiguration:
audioRecorderDidFinishAlertPlayback:ofType:error:
audioRecorderBeginRecordInterruption:
audioRecorderBeginRecordInterruption:withContext:
audioRecorderEndRecordInterruption:
audioRecorder:willSetAudioSessionActive:
audioRecorder:didSetAudioSessionActive:
voiceTriggerDetectedOnAOP:
audioRecorderDisconnected:
audioRecorderLostMediaserverd:
audioRecorderBuiltInAudioStreamInvalidated:error:
audioProviderInvalidated:streamHandleId:
opportuneSpeakEventMonitor:didStreamStateChanged:
voiceTriggerEventNotifier
audioFingerprintProvider
_getVoiceTriggerAssetIfNeeded:
registerSpeechController:
registerSiriClientProxy:
audioProviderWithUUID:
audioProviderWithContext:error:
audioProviderWithStreamID:
fetchFallbackAudioSessionReleaseProvider
_reinitializeSmartSiriVolumeWithAsset:
assetQueryQueue
setAssetQueryQueue:
audioRecorder
setAudioProviders:
fallbackAudioSessionReleaseProvider
setFallbackAudioSessionReleaseProvider:
clientController
setClientController:
clearLoggingFileTimer
setClearLoggingFileTimer:
clearLoggingFileTimerCount
setClearLoggingFileTimerCount:
opportuneSpeakListnerTestService
setOpportuneSpeakListnerTestService:
postBuildInstallService
setPostBuildInstallService:
ssvManager
setSsvManager:
_assetQueryQueue
_audioRecorder
_audioProviders
_fallbackAudioSessionReleaseProvider
_clientController
_clearLoggingFileTimer
_clearLoggingFileTimerCount
_opportuneSpeakListnerTestService
_postBuildInstallService
_ssvManager
addNumSamples:hostTime:
notifyTrailingSilenceDurationAtEndpoint:
estimatedSpeechEndHostTime
numAudioSampleForwarded
setNumAudioSampleForwarded:
lastAudioChunkHostTime
setLastAudioChunkHostTime:
endPointNotified
setEndPointNotified:
setTrailingSilenceDurationAtEndpoint:
_endPointNotified
_numAudioSampleForwarded
_lastAudioChunkHostTime
_trailingSilenceDurationAtEndpoint
_notifyObserver:withClamshellState:
CSClamshellStateMonitor:didReceiveClamshellStateChange:
isClamshellClosed
_didReceiveClamshellStateChangeNotification:
resourcePath
configFilepathForDictationOrigin:
commandControlListener:didStopUnexpectly:
commandControlListener:hasLPCMBufferAvailable:
initWithDownloadOption:
defaultController
addObserver:forAssetType:
_createPeriodicalDownloadTimer
_startPeriodicalDownload
_stopPeriodicalDownload
setCallback:
_fetchRemoteMetaData
_canFetchRemoteAsset:
assetOfType:language:
installedAssetOfType:language:
allInstalledAssetsOfType:language:
installedAssetOfType:language:completion:
getInstalledAssetofType:completion:
fetchRemoteMetaOfType:
supportHybridEndpointer
supportAdBlocker
supportsSpeakerRecognitionAssets
assetForCurrentLanguageOfType:completion:
CSAssetManagerDidDownloadNewAsset:
CSVoiceTriggerAssetMetaUpdateMonitor:didReceiveNewVoiceTriggerAssetMetaData:
CSSpeechEndpointAssetMetaUpdateMonitor:didReceiveNewSpeechEndpointAssetMetaData:
CSAdBlockerMetaUpdateMonitor:didReceiveNewAdBlockerAssetMetaData:
CSAssetController:didDownloadNewAssetForType:
CSSpeakerRecognitionAssetMetaUpdateMonitor:didReceiveNewSpeakerRecognitionAssetMetaData:
CSLanguageCodeUpdateMonitor:didReceiveLanguageCodeChanged:
assetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:
installedAssetForCurrentLanguageOfType:completion:
assetOfType:providerType:language:completion:
currentLanguageCode
removeObserver:forAssetType:
_enablePolicy
_currentLanguageCode
_downloadingOption
_downloadTimer
_downloadTimerCount
initWithDataSource:assetsProvider:
addDelegate:
removeDelegate:
startWithNviContext:didStartHandler:
stopWithDidStopHandler:
sigType
initWithConfigPath:resourcePath:phraseId:
analyzeWavData:numSamples:
getSuperVectorWithEndPoint:
programmableAudioInjectionEnabled
initWithQueue:error:
initWithBlob:isEarlyDetected:
samplesFed
setSamplesFed:
setBestStart:
setBestEnd:
setBestScore:
isSecondChance
setIsSecondChance:
setIsEarlyDetect:
_isSecondChance
_isEarlyDetect
_bestScore
_samplesFed
_bestStart
_bestEnd
initWithBlob:
checkForTriggerWithBytes:withNumberOfSamples:
processAudioBytes:withNumberOfSamples:
_currentBlob
_activeChannel
startController
getFixedHighPrioritySerialQueueWithLabel:
twoShotNotificationEnabled
_currentAudioRecorderSampleRate
supportPhatic
_initializeMediaPlayingState
_initializeAlarmState
_initializeTimerState
_setSoundPlayingState
supportSmartVolume
audioSessionActivationDelay
_contextToString:
setCurrentContext:error:
supportLazySessionActivation
_refreshSpeakerRecognitionAssets
supportSessionActivateDelay
_shouldResetContextAtPrepare
audioRecordContext
_fetchAudioProviderWithContext:
sessionProvider
enableSmartRoutingConsideration:
_shouldFetchVoiceTriggerInfo
_shouldFetchRaiseToSpeakInfo
_fetchLastTriggerInfo
_activateAudioSessionWithReason:delay:error:
domain
_activateAudioSessionWithReason:error:
setIsSiri:
prepareAudioStreamSyncWithRequest:error:
streamProvider
isNarrowBand
_setupDownsamplerIfNeeded
_setupAudioConverter:isNarrowBand:
recordRoute
_createAudioPowerMeterIfNeeded
triggerInfoForContext:completion:
isDeviceRoleStereo
_isDelayedDuckingSupportedContext
hostTimeToTimeInterval:
logHybridEndpointFeaturesWithEvent:locale:
_scheduleActivateAudioSessionWithDelay:sessionActivateReason:scheduleReason:validator:completion:
_cancelPendingAudioSessionActivateForReason:
_lazyActivateAudioSessionWithReason:error:
_doActivateAudioSessionWithReason:error:
speechController:willSetAudioSessionActive:
speechController:didSetAudioSessionActive:
activateAudioSessionWithReason:dynamicAttribute:bundleID:error:
setAudioRecordContext:
prewarmAudioSessionWithError:
_teardownAudioProviderIfNeeded
deactivateAudioSession:error:
_fetchFallbackAudioSessionReleaseProviding
fallbackDeactivateAudioSession:error:
recordSettings
numberWithInt:
lpcmInt16NarrowBandASBD
lpcmInt16ASBD
setDictationLanguages:
setCurrentKeyboard:
setWasLanguageToggled:
setMultilingualKeyboardLanguages:
setKeyboardConvoLanguagePriors:
setKeyboardGlobalLanguagePriors:
setPreviousMessageLanguage:
setGlobalLastKeyboardUsed:
setDictationLanguagePriors:
setConversationalMessages:
_isRecordRouteBuiltinMic
setAVVCAlertBehavior:
supportOpportunisticZLL
setUseOpportunisticZLL:
setStartRecordingHostTime:
setRequestHistoricalAudioDataWithHostTime:
_shouldSetStartSampleCount
setRequestHistoricalAudioDataSampleCount:
setStartRecordingSampleCount:
_shouldSetStartSampleCountForRTS
_setupSpeakerRecognitionController
_startPhaticDecision
resetForNewRequestWithSampleRate:recordContext:recordSettings:voiceTriggerInfo:
isMultiChannelAudioLoggingEnabled
lpcmNonInterleavedASBD
lpcmInterleavedASBD
_shouldUseLanguageDetector:
_createLanguageDetectorIfNeeded
_languageDetectorOptionFromSettings:
setSamplingRate:
languageDetectorDelegate
doubleValue
notifyWillStartStreamWithContext:option:
speechControllerDidStartRecording:successfully:error:
notifyDidStartStreamWithContext:successfully:option:withEventUUID:
_canPlayPhaticDuringMediaPlayback
speechControllerDidDetectVoiceTriggerTwoShot:atTime:
shouldDelayPhaticForMyriadDecision
_shouldSchedulePhaticAtStartRecording
_scheduledPhaticDelay
speechControllerRequestsOperation:forReason:completion:
_phaticPlaybackReason
startRecordingWithSettings:error:
notifyWillStopStream:
_didStopForReason:
speechControllerDidDeliverLastBuffer:forReason:estimatedSpeechEndHostTime:
canPerformDelayedStop
recordDeviceInfo
speechControllerDidStopRecording:forReason:
speechControllerDidStopRecording:forReason:estimatedSpeechEndHostTime:
addContextKey:withContext:
addContextKey:fromMetaFile:
_deviceAudioLoggingWithFileWriter:
notifyDidStopStream:withEventUUID:
_logRecordingStopErrorIfNeeded:
subChunkFrom:numSamples:
_audioStreamProvdider:audioBufferAvailable:
hostTime
sampleByteDepth
processFloatBuffer:stride:inFrameToProcess:
processShortBuffer:stride:inFrameToProcess:
startSampleCount
addSamples:timestamp:
speechControllerLPCMRecordBufferAvailable:buffer:recordedAt:
speechControllerLPCMRecordBufferAvailable:buffer:
data
audioFormat
_fetchAudioDecoderForTV:
packets
timeStamp
numChannels
addPackets:audioStreamHandleId:remoteVAD:timestamp:receivedNumChannels:
avgPower
setCachedAvgPower:
peakPower
setCachedPeakPower:
speechControllerRecordBufferAvailable:buffers:recordedAt:
speechControllerRecordBufferAvailable:buffers:durationInSec:recordedAt:
processSampleCount:hostTime:
speechControllerRecordHardwareConfigurationDidChange:toConfiguration:
speechControllerDidFinishAlertPlayback:ofType:error:
speechControllerBeginRecordInterruption:
speechControllerBeginRecordInterruption:withContext:
speechControllerEndRecordInterruption:
speechControllerDidUpdateSmartSiriVolume:forReason:
narrowBandOpusConverter
opusConverter
alertProvider
playRecordStartingAlertAndResetEndpointer
audioMeterProvider
getPeakPowerDB
cachedPeakPower
getAveragePowerDB
cachedAvgPower
speechControllerRequestsOperation:forReason:
audioMetricProvider
audioMetric
setEndpointerDelegate:
submitAudioIssueReport:
speexDecoder
opusDecoder
_createAudioProviderFromXPCWithContext:
setStreamProvider:
setSessionProvider:
setAlertProvider:
setAudioMeterProvider:
setAudioMetricProvider:
setAudioSessionDelegate:
setAudioAlertDelegate:
allKeys
_getSpeechIdentifier
debugLogPath
volumeEstimate
sharedController
isSmartSiriVolumeAvailable
audioConverterDidConvertPackets:packets:durationInSec:timestamp:
didTTSVolumeChange:forReason:
audioSessionProviderBeginInterruption:
audioSessionProviderBeginInterruption:withContext:
audioSessionProviderEndInterruption:
audioSessionProvider:willSetAudioSessionActive:
audioSessionProvider:didSetAudioSessionActive:
audioSessionProvider:providerInvalidated:
audioSessionProvider:didChangeContext:
audioAlertProvidingDidFinishAlertPlayback:ofType:error:
audioDecoderDidDecodePackets:audioStreamHandleId:buffer:remoteVAD:timestamp:receivedNumChannels:
continuousVoiceTrigger:detectedVoiceTriggerResult:
continuousVoiceTrigger:detectedSilenceAfterVoiceTriggerAt:
initializeRecordSessionWithContext:
prepareRecordWithSettings:error:
_performPendingAudioSessionActivateForReason:
prewarmAudioSession
resetAudioSession
releaseAudioSession
releaseAudioSession:
getLPCMAudioStreamBasicDescription
setSynchronousCallbackEnabled:
getRecordBufferDuration
startRecording:
stopRecordingWithOptions:
peakPowerForOutputReference
averagePowerForOutputReference
outputReferenceChannel
keywordDetectorDidDetectKeyword
endpointAnalyzer
setEndpointAnalyzerDelegate:
resetEndpointer
getSmartSiriVolume
languageDetectorSetMostRecentRecognitionLanguage:
cancelCurrentLanguageDetectorRequest
setLanguageDetectorInteractionID:
beginWaitingForMyriad
endWaitingForMyriadWithDecision:
CSAlarmMonitor:didReceiveAlarmChanged:
CSTimerMonitor:didReceiveTimerChanged:
setLanguageDetectorDelegate:
speakerIdDelegate
setSpeakerIdDelegate:
endpointerProxy
setEndpointerProxy:
isOpus
setIsOpus:
isSiriClientListening
setIsSiriClientListening:
setIsNarrowBand:
serverLoggingWriter
setServerLoggingWriter:
volumeController
setVolumeController:
recordEventUUID
setRecordEventUUID:
isAudioSessionActivated
setIsAudioSessionActivated:
deviceRoleIsStereo
setDeviceRoleIsStereo:
speakerRecognitionScores
setSpeakerRecognitionScores:
setTwoShotNotificationEnabled:
isMediaPlaying
setIsMediaPlaying:
isAlarmPlaying
setIsAlarmPlaying:
isTimerPlaying
setIsTimerPlaying:
isSoundPlaying
setIsSoundPlaying:
isRemoteVADAvailableStream
setIsRemoteVADAvailableStream:
myriadPreventingTwoShotFeedback
setMyriadPreventingTwoShotFeedback:
needsPostGain
setNeedsPostGain:
speechEndHostTimeEstimator
setSpeechEndHostTimeEstimator:
bundleIdFromDictation
setBundleIdFromDictation:
languageDetector
setLanguageDetector:
shouldUseLanguageDetectorForCurrentRequest
setShouldUseLanguageDetectorForCurrentRequest:
pendingAudioSessionActivationToken
setPendingAudioSessionActivationToken:
pendingAudioSessionActivationCompletion
setPendingAudioSessionActivationCompletion:
pendingAudioSessionActivationReason
setPendingAudioSessionActivationReason:
setAudioSessionActivationDelay:
powerMeter
setPowerMeter:
didDeliverLastBuffer
setDidDeliverLastBuffer:
didDeliverFirstSpeechPacket
setDidDeliverFirstSpeechPacket:
setCanPerformDelayedStop:
requestedStopRecordingOptions
setRequestedStopRecordingOptions:
numTrailingSamplesAfterSchedulingStop
setNumTrailingSamplesAfterSchedulingStop:
maxAllowedTrailingSamplesAfterSchedulingStop
setMaxAllowedTrailingSamplesAfterSchedulingStop:
decodersForTV
setDecodersForTV:
decoderProcessedSampleCountForTV
setDecoderProcessedSampleCountForTV:
logEventUUID
setLogEventUUID:
ssvLogFilePath
setSsvLogFilePath:
mediaPlayingMonitor
setMediaPlayingMonitor:
volumeMonitor
setVolumeMonitor:
_contextResetQueue
_opusAudioConverter
_narrowBandOpusConverter
_audioConverter
_downsampler
_requestedRecordSettings
_lastVoiceTriggerInfo
_lastRTSTriggerInfo
_audibleFeedbackQueue
_twoShotAudibleFeedbackDecisionGroup
_isOpus
_isSiriClientListening
_isNarrowBand
_isAudioSessionActivated
_deviceRoleIsStereo
_twoShotNotificationEnabled
_isMediaPlaying
_isAlarmPlaying
_isTimerPlaying
_isSoundPlaying
_isRemoteVADAvailableStream
_myriadPreventingTwoShotFeedback
_needsPostGain
_shouldUseLanguageDetectorForCurrentRequest
_didDeliverLastBuffer
_didDeliverFirstSpeechPacket
_canPerformDelayedStop
_cachedAvgPower
_cachedPeakPower
_languageDetectorDelegate
_speakerIdDelegate
_endpointerProxy
_audioRecordContext
_streamProvider
_sessionProvider
_alertProvider
_audioMeterProvider
_audioMetricProvider
_serverLoggingWriter
_volumeController
_recordEventUUID
_speakerRecognitionScores
_speechEndHostTimeEstimator
_bundleIdFromDictation
_languageDetector
_pendingAudioSessionActivationToken
_pendingAudioSessionActivationCompletion
_pendingAudioSessionActivationReason
_audioSessionActivationDelay
_powerMeter
_requestedStopRecordingOptions
_numTrailingSamplesAfterSchedulingStop
_maxAllowedTrailingSamplesAfterSchedulingStop
_decodersForTV
_decoderProcessedSampleCountForTV
_logEventUUID
_ssvLogFilePath
_mediaPlayingMonitor
_volumeMonitor
createRTModelWithLocale:
hearstRTModelWithMajorVersion:minorVersion:locale:
fileExistsAtPath:
dataWithContentsOfFile:
_sha1:
_sha256:
initWithData:hash:locale:digest:signature:certificate:
localeMapWithName:
stringWithCapacity:
RTModelWithFallbackLanguage:
latestHearstRTModelForLocale:
hearstRTModelLocaleMap
jarvisRTModelLocaleMap
_serviceProxyWithErrorHandler:
upperCaseString:withReply:
firstObject
stringByStandardizingPath
trainPersonalizedLMWithLanguage:configuration:asset:fides:activity:completion:
trainPersonalizedLMWithLanguage:configuration:fides:write:completion:
initWithFormat:
trainPersonalizedLMWithLanguage:configuration:asset:directory:completion:
trainPersonalizedLMWithLanguage:configuration:fides:activity:completion:
trainGlobalNNLMwithFidesRecipe:attachments:completion:
trainGlobalNNLMwithFidesSessionURL:completion:
initialize
upperCaseString:completion:
trainPersonalizedLMWithLanguage:directory:completion:
_smtConnection
_storeModeEnabled
runningVoiceTriggerOnMac
setFileLoggingLevel:
fileLoggingLevel
intValue
baseDir
myriadHashDirectory
date
stringByReplacingOccurrencesOfString:withString:
interstitialRelativeDirForLevel:
enableAudioInjection:withKey:
audioInjectionEnabledWithKey:
enumerateObjectsUsingBlock:
smartSiriVolumeContextAwareEnabled
phraseSpotterEnabled
isAttentiveSiriEnabled
voiceTriggerInCoreSpeech
setFileLoggingIsEnabled:
ssvLogDirectory
getSSVLogFilePathWithSessionIdentifier:
trialBaseAssetDirectory
getCatAdBlockerAssetUpdateDirectory
secondPassAudioLoggingEnabled
jarvisAudioLoggingEnabled
setJarvisTriggerMode:
getJarvisTriggerMode
startOfSpeechAudioLoggingEnabled
forceVoiceTriggerAPMode
forceVoiceTriggerAOPMode
getStartOfSpeechAudioLogFilePath
_isDirectory:
remoteVoiceTriggerDelayTime
remoteVoiceTriggerEndpointTimeoutWithDefault:
interstitialAbsoluteDirForLevel:
myriadFileLoggingEnabled
enableAudioInjection:
audioInjectionEnabled
enableProgrammableAudioInjection:
setAudioInjectionFilePath:
audioInjectionFilePath
isPHSSupported
_isRemoteVoiceTriggerAvailable
isSpeakerRecognitionAvailable
speakerIdScoreReportingType
smartSiriVolumeSoftVolumeEnabled
smartSiriVolumeContextAwareLoggingEnabled
useSiriActivationSPIForHomePod
useSiriActivationSPIForwatchOS
iOSBargeInSupportEnabled
shouldOverwriteRemoteVADScore
overwritingRemoteVADScore
setHearstFirstPassModelVersion:
setHearstSecondPassModelVersion:
fakeHearstModelPath
companionSyncVoiceTriggerUtterancesEnabled
bypassPersonalizedHeySiri
isMultiPhraseVTEnabled
isSelfTriggerFileLoggingEnabled
hostTimeFromSampleCount:anchorHostTime:anchorSampleCount:
sampleCountFromHostTime:anchorHostTime:anchorSampleCount:
hostTimeFromSampleCount:
sampleCountFromHostTime:
anchorSampleCount
setAnchorSampleCount:
anchorHostTime
setAnchorHostTime:
_anchorSampleCount
_anchorHostTime
getVoiceTriggerProfilesAESKey
generateIfNecessaryVoiceTriggerProfilesAESKey
generateIfNecessaryAESKeyWithKeySizeInBits:applicationTag:keyLabel:shouldGenerateIfNecessary:
generateAESKeyWithKeySizeInBits:
storeAESKeyInKeychain:applicationTag:keyLabel:
getAESKeyFromKeychainWithApplicationTag:keyLabel:
deleteAESKeyWithApplicationTag:keyLabel:
getKeychainAttributesForAESKeyWithApplicationTag:keyLabel:
initWithStreamID:atStartHostTime:
avvcAlertBehavior
setStartAlert:
setStopAlert:
setStopOnErrorAlert:
skipAlertBehavior
setSkipAlert:
_alertBehaviorTypeFromAVVCOberrideType:
setStartAlertBehavior:
setStopAlertBehavior:
setErrorAlertBehavior:
startAlertBehavior
_avvcAlertOverrideType:
stopAlertBehavior
errorAlertBehavior
avvcStartRecordSettingsWithAudioStreamHandleId:
avvcSettings
_setupSignalProviders:
mapTableWithKeyOptions:valueOptions:
strRepForNviSignalType:
strRepForNviDataSourceType:
timeIntervalSinceDate:
signalProvidersMapForContext:
hashTableWithOptions:
_startSignalProvidersWithContext:
_startDataSourcesWithContext:
_stopDataSources
_stopCurrentlyRunningSignalProviders
_iterateSignalMask:withHandler:
initWithAssetsProvider:dataSourceMap:signalProviderToDataSourceMap:
startWithNviContext:
registerSignalProviderDelegate:forSignalTypes:
unregisterSignalProviderDelegate:forSignalType:
registerSignalProviderDelegateForAllSignalTypes:
unregisterSignalProviderDelegateForAllSignalTypes:
assetsProvider
setAssetsProvider:
dataSrcMap
setDataSrcMap:
sigProvidersMap
setSigProvidersMap:
currActiveSigProvTypes
setCurrActiveSigProvTypes:
currActiveDataSourceTypes
setCurrActiveDataSourceTypes:
_assetsProvider
_dataSrcMap
_sigProvidersMap
_currActiveSigProvTypes
_currActiveDataSourceTypes
sendXPCClientType
_sendMessageAndReplySync:connection:error:
setAudioSessionProvidingDelegate:
setAudioAlertProvidingDelegate:
initWithAudioStreamProvider:streamName:streamRequest:
createPrepareAudioStreamMessageWithRequest:
createStartAudioStreamMessageWithOption:
createStopAudioStreamMessage
_handleListenerMessage:
_handleSessionProvidingDelegateMessageBody:
_handleStreamProvidingDelegateMessageBody:
_handleAlertProvidingDelegateMessageBody:
_handleSessionInfoProvidingDelegateMessageBody:
_handleListenerDisconnectedError:
_handleAlertProvidingDelegateDidFinishAlertPlayback:
audioAlertProvidingDelegate
_handleSessionProvidingDelegateBeginInterruption:
_handleSessionProvidingDelegateBeginInterruptionWithContext:
_handleSessionProvidingDelegateEndInterruption:
_handleSessionProvidingDelegateWillSetAudioSession:
_handleSessionProvidingDelegateDidSetAudioSession:
_handleSessionProvidingDelegateStreamHandleIdInvalidation:
_handleSessionProvidingDelegateDidChangeContext:
audioSessionProvidingDelegate
_handleSessionInfoProvidingDelegateInterruptionNotification:
_handleSessionInfoProvidingDelegateRouteChangeNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereLostNotification:
_handleSessionInfoProvidingDelegateMediaServicesWereResetNotification:
_handleStreamProvidingDelegateDidStopUnexpectly:
_handleStreamProvidingDelegateChunkAvailable:
_handleStreamProvidingDelegateChunkForTVAvailable:
_handleStreamProvidingDelegateHardwareConfigChange:
createAudioStreamMessageWithRequest:
audioStreamWithRequest:streamName:completion:
prepareAudioStreamSync:request:error:
prepareAudioStream:request:completion:
startAudioStream:option:completion:
stopAudioStream:option:completion:
audioChunkFrom:to:
audioChunkToEndFrom:
saveRecordingBufferFrom:to:toURL:
saveRecordingBufferToEndFrom:toURL:
holdAudioStreamWithDescription:timeout:
cancelAudioStreamHold:
configureAlertBehavior:
pingpong:
audioStreamProvidingDelegate
setAudioStreamProvidingDelegate:
activationAssertions
setActivationAssertions:
audioSessionInfoObservers
setAudioSessionInfoObservers:
xpcClientType
setXpcClientType:
_audioSessionProvidingDelegate
_audioStreamProvidingDelegate
_audioAlertProvidingDelegate
_UUID
_activationAssertions
_audioSessionInfoObservers
_xpcClientType
didTransitFrom:to:by:
didIgnoreEvent:from:
initWithInitialState:
addTransitionFrom:to:for:
performTransitionForEvent:
currentState
initialState
setInitialState:
transitions
setTransitions:
_currentState
_initialState
_transitions
URLByDeletingPathExtension
URLByAppendingPathExtension:
deviceProductType
deviceProductVersion
deviceBuildVersion
dictionaryWithDictionary:
dataWithJSONObject:options:error:
JSONObjectWithData:options:error:
saveAudioChunck:toURL:
initWithFilepath:
CSEventMonitorDidReceiveEvent:
setPackets:
setAvgPower:
setPeakPower:
setTimeStamp:
setNumChannels:
setAudioFormat:
setStreamHandleID:
_avgPower
_peakPower
_audioFormat
_packets
_timeStamp
_streamHandleID
initWithSamplingRate:withAsset:
initWithSamplingRate:asset:
startSmartSiriVolume
getVolumeForTTSType:withOverrideMediaVolume:WithRequestTime:
didReceiveAlarmChanged:
notifyClientsWithBlock:
didReceiveTimerChanged:
didReceiveMusicVolumeChanged:
didReceiveAlarmVolumeChanged:
didDetectKeywordWithResult:
voiceTriggerDidDetectKeyword:deviceId:
voiceTriggerDidDetectKeyword:deviceId:completion:
voiceTriggerDidDetectNearMiss:
voiceTriggerDidDetectSpeakerReject:
voiceTriggerGotSuperVector:
raiseToSpeakDetected:
voiceTriggerDidRejected:
CSVolumeMonitor:didReceiveMusicVolumeChanged:
CSVolumeMonitor:didReceiveAlarmVolumeChanged:
smartSiriVolume
setSmartSiriVolume:
_smartSiriVolume
addVTRejectEntry:truncateData:
addVTAcceptEntryAndSubmit:
_closeAudioFile
fileURLWithPath:isDirectory:
appendAudioData:
_audioFile
_asbd
_url
_audioLength
setEncoderBitRate:
setNumberOfChannels:
setLpcmBitDepth:
setLpcmIsFloat:
setRecordContext:
setUseCustomizedRecordSettings:
requestForLpcmRecordSettingsWithContext:
requestForOpusRecordSettingsWithContext:
requestForSpeexRecordSettingsWithContext:
recordContext
requiresHistoricalBuffer
useCustomizedRecordSettings
lpcmBitDepth
lpcmIsFloat
encoderBitRate
isSiri
_requiresHistoricalBuffer
_useCustomizedRecordSettings
_lpcmIsFloat
_isSiri
_lpcmBitDepth
_encoderBitRate
_recordContext
initWithType:deviceId:activationInfo:vadScore:hosttime:
initWithType:deviceId:activationInfo:hosttime:
_activationTypeString
remoteMicVADEvent:vadScore:hostTime:
jarvisVoiceTriggerEvent:activationInfo:hostTime:
remoraVoiceTriggerEvent:hostTime:
mediaserverdLaunchedEvent:
activationInfo
setActivationInfo:
hosttime
setHosttime:
vadScore
setVadScore:
_vadScore
_activationInfo
_hosttime
componentsSeparatedByString:
shortFormForUUID
isScreenLocked
getVoiceTriggerAssetTypeString
getEndpointAssetTypeString
getLanguageDetectorAssetTypeString
getAdBlockerAssetTypeString
getSpeakerRecognitionAssetTypeString
_cleanUpMobileAssetV1Directory
_isReadyToUse
installedAssetOfType:withLanguage:
_fetchRemoteAssetOfType:withLanguage:completion:
_assetQueryForAssetType:
returnTypes:
queryMetaDataSync
results
filteredAssetsForAssets:assetType:language:
queryParams
installedAssetOfType:withLanguage:completion:
_installedAssetOfType:withLanguage:
_installedAssetOfType:withLanguage:completion:
_findLatestInstalledAsset:
queryMetaData:
addKeyValuePairForQuery:assetType:
isFirstUnlocked
fetchRemoteMetaOfType:allowRetry:
_runAssetQuery:completion:
_downloadAssetCatalogForAssetType:complete:
_updateFromRemoteToLocalAssets:forAssetType:completion:
_defaultDownloadOptions
_isRetryRecommendedWithResult:
startCatalogDownload:options:then:
cancelDownloadSync
purgeSync
_downloadAsset:withComplete:
setAllowsCellularAccess:
setCanUseLocalCacheServer:
setDiscretionary:
assetServerUrl
_startDownloadingAsset:progress:completion:
expectedTimeRemaining
totalWritten
totalExpected
attachProgressCallBack:
spaceCheck:
startDownload:then:
getAssetTypeStringForType:
assetsMigrationQueue
setAssetsMigrationQueue:
csAssetsDictionary
setCsAssetsDictionary:
_assetsMigrationQueue
_csAssetsDictionary
valueForKey:
containsObject:
supportPremiumAssets
getVoiceTriggerAssetCurrentCompatibilityVersion
getEndpointAssetCurrentCompatibilityVersion
getLanguageDetectorCurrentCompatibilityVersion
getAdBlockerCurrentCompatibilityVersion
getSpeakerRecognitionCurrentCompatibilityVersion
addKeyValuePair:with:
filteredAssetsForFetchRemoteMetaDataForAssets:assetType:
initWithConfigPath:triggerTokens:useKeywordSpotting:
resetWithLanguage:withFarField:withAudioSource:
flushAudio
triggerConfidence
setTriggerConfidence:
ctcKwdToPhraseIdMap
setCtcKwdToPhraseIdMap:
phraseIdScores
_triggerConfidence
_ctcKwdToPhraseIdMap
_phraseIdScores
opusASBD
speexASBD
objectAtIndexedSubscript:
dataWithBytes:length:
_decoder
opusEncoder
setOpusEncoder:
_opusEncoder
setTimestamp:
initWithData:
setPerceptualAudioHash:
newWithBuilder:
initWithServicePort:
deactivateForReason:options:context:completion:
sharedLauncher
notifyBuiltInVoiceTrigger:myriadPHash:completion:
notifyCarPlayVoiceTrigger:deviceId:myriadPHash:completion:
notifyBluetoothDeviceVoiceTrigger:deviceId:completion:
notifyRemoraVoiceTrigger:deviceId:completion:
deactivateSiriActivationConnectionWithReason:withOptions:
_addSmartSiriVolumeEnabledConditions
_subscribeEventMonitors
subscribeEventMonitor:
addConditions:
_createDeInterleaverIfNeeded
_startAudioFeedingTimer
_deinterleaveBufferIfNeeded:
_compensateChannelDataIfNeeded:receivedNumChannels:
setFileOption:
_defaultOutASBD
injectAudio:withScaleFactor:outASBD:playbackStarted:completion:
initWithBytes:length:
replaceBytesInRange:withBytes:
lpcmFloatASBD
setAudioStreamHandleId:
fileOption
audioFeedTimer
setAudioFeedTimer:
setIsRecording:
bufferDuration
setBufferDuration:
injectionAudioFileList
setInjectionAudioFileList:
injectionStartNotifyBlocks
setInjectionStartNotifyBlocks:
injectionCompletionNotifyBlocks
setInjectionCompletionNotifyBlocks:
deinterleaver
setDeinterleaver:
pNonInterleavedABL
setPNonInterleavedABL:
didSetScaleFactor
setDidSetScaleFactor:
setScaleFactor:
_isRecording
_didSetScaleFactor
_audioStreamHandleId
_fileOption
_injectionAudioFileList
_injectionStartNotifyBlocks
_injectionCompletionNotifyBlocks
_deinterleaver
_pNonInterleavedABL
hasRemoteBuiltInMic
assetChangeMonitorDidDetectAssetChange:
sharedMonitor
startMonitoring
notifyVoiceTriggerAssetChanged
_addVoiceTriggerEnabledConditions
isPresent
isSpringboardStarted
batteryState
isRestricted
isSoftwareUpdateCheckingRunning
splitterState:
siriClientBehaviorMonitor:willStartStreamWithContext:option:
siriClientBehaviorMonitor:didStartStreamWithContext:successfully:option:withEventUUID:
siriClientBehaviorMonitor:didChangedRecordState:withEventUUID:withContext:
siriClientBehaviorMonitor:willStopStream:
siriClientBehaviorMonitor:didStopStream:withEventUUID:
setIsStreaming:
_isStreaming
_didReceiveNewSpeechEndpointAssetMetaData
alertMuteBehaviorDict
voiceTriggerRecordContext
hearstVoiceTriggerRecordContext:
jarvisVoiceTriggerRecordContext:
lpcmRecordSettings
opusRecordSettings
speexRecordSettings
alertMuteSettings
decodeObjectOfClass:forKey:
encodeObject:forKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
initWithVolumeEstimate:debugLogFile:
_volumeEstimate
_debugLogPath
setCachedAsset:
cachedAsset
_getVoiceTriggerAssetFromAssetManager:
isEqualAsset:
_checkNewAssetAvailablity
CSFirstUnlockMonitor:didReceiveFirstUnlock:
_cachedAsset
_addVoiceTriggerAOPModeEnabledConditions
supportHandsFree
_addConditionsForIOSBargeIn
_addConditionsForIOSAOP
_isSpeechDetectionDevicePresent
currentBuiltinSpeakerState
isSiriClientConsideredAsRecord
pickedRoute
setIsSiriClientConsideredAsRecord:
setPendingRecordingStopUUID:
notifyCallbackWithOption:
pendingRecordingStopUUID
_recordStateQueue
_isSiriClientConsideredAsRecord
_pendingRecordingStopUUID
_borealisPowerlog:
systemUpTime
numberWithLongLong:
powerLogVoiceTriggerStart
powerLogVoiceTriggerStop
logAOPFirstPassTriggerWakeupLatency:
logSecondPassResult:eventInfo:triggerAPWakeUp:
logFalseWakeUp:
logTriggerLengthSampleCountStatistics:withFirstPassDeterministicTriggerLengthSampleCount:
numFalseWakeUp
setNumFalseWakeUp:
lastAggTimeFalseWakeUp
setLastAggTimeFalseWakeUp:
_numFalseWakeUp
_lastAggTimeFalseWakeUp
opportuneSpeakBehaviorMonitor:willStartStreamWithContext:audioProviderUUID:option:
opportuneSpeakBehaviorMonitor:didStartStreamWithContext:audioProviderUUID:successfully:option:
opportuneSpeakBehaviorMonitor:willStopStream:
opportuneSpeakBehaviorMonitor:didStopStream:
notifyWillStartStreamWithContext:audioProviderUUID:option:
notifyDidStartStreamWithContext:audioProviderUUID:successfully:option:
notifyDidStopStream:
generateEmptyPHash:writeFile:
notifyHashlessTrigger:
setLastHash:
lastHash
generatePHashFromVoiceTriggerInfo:writeFile:
pHash:length:
signalEstimate
setSignalEstimate:
signalFractional
setSignalFractional:
_signalFractional
_signalEstimate
numChannelsForNviDirectionality
nviDirectionalityStartingChannelId
nviDirectionalityEndingChannelId
monoChannelLpcmASBD
allChannelsLpcmInterleavedASBD
allChannelsLpcmNonInterleavedASBD
nviDirectionalityLpcmNonInterleavedASBD
nviDirectionalityLpcmInterleavedASBD
nviLogsRootDir
setVoiceTriggerInfo:
rtsTriggerInfo
setRtsTriggerInfo:
triggerNotifiedMachTime
setTriggerNotifiedMachTime:
_voiceTriggerInfo
_rtsTriggerInfo
_triggerNotifiedMachTime
dataWithContentsOfFile:options:error:
lastObject
isNviEnabled
strRepForNviSignalMask:
nviSignalTypeForStr:
nviDataSourceTypeForStr:
_createDirAtPath:
timeStampString
getVoiceTriggerEndSampleCountFromVTEI:
getVoiceTriggerEndSecsFromVTEI:
readJsonDictionaryAt:
getValueFromDictionaryOfDictionaries:keypath:
createDirAtPath:
currentPowerSource
setSkipAlertBehavior:
requestHistoricalAudioDataSampleCount
startRecordingSampleCount
useOpportunisticZLL
_requestHistoricalAudioDataWithHostTime
_requestHistoricalAudioDataSampleCount
_useOpportunisticZLL
_skipAlertBehavior
_startRecordingHostTime
_startRecordingSampleCount
_startAlertBehavior
_stopAlertBehavior
_errorAlertBehavior
numberWithDouble:
CSVoiceTriggerXPCServiceProxy:bypassPhraseSpotter:
CSVoiceTriggerXPCServiceProxy:bypassRaiseToSpeak:
notifyServiceConnectionLost
isPhraseSpotterBypassed
setIsPhraseSpotterBypassed:
isRaiseToSpeakBypassed
setIsRaiseToSpeakBypassed:
_isPhraseSpotterBypassed
_isRaiseToSpeakBypassed
enter
leave
waitWithTimeout:
_dispatchGroup
_dispatchGroupCounter
_createSSVClientConnectionIfNeeded
ssvClient
setSsvClient:
_ssvClient
containsCategory:
satScoreThreshold
getStringForKey:category:default:
getBoolForKey:category:default:
containsSpeakerRecognitionCategory
multiUserLowScoreThreshold
multiUserHighScoreThreshold
multiUserConfidentScoreThreshold
multiUserDeltaScoreThreshold
psrCombinationWeight
satImplicitProfileThreshold
satImplicitProfileDeltaThreshold
satVTImplicitThreshold
pruningExplicitUttThresholdSAT
pruningExplicitUttThresholdPSR
pruningThresholdSAT
pruningThresholdPSR
pruningNumRetentionUtterance
maxAllowedEnrollmentUtterances
voiceProfilePruningCookie
keywordDetectorQuasarConfigFilePath
keywordDetectorNDAPIConfigFilePath
satImplicitTrainingEnabled
_supportDoAP
_isTemporaryPairedNotInContacts
_address
_processRemoteHeySiriCommandWithRequest:fromSenderID:withReply:
_processParallelRecordingCommandWithRequest:fromSenderID:withReply:
_receiveParallelRecordingFromPeerId:recordingInfo:withReply:
_receiveVoiceProfileFromPeerId:voiceProfileInfo:withReply:
_processGradingDataFetchCommandWithRequest:fromSenderID:withReply:
_processVoiceProfileDeleteCommandWithRequest:fromSenderID:withReply:
_receiveVoiceGradingDataFromPeerId:requestInfo:withReply:
_processVoiceProfileListQueryCommandFromPeerId:requestInfo:withReply:
_processFetchVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processReverseTransferVoiceProfileCommandFromPeerId:requestInfo:withReply:
_processVoiceProfileUpdateTriggerFromPeerId:requestInfo:withReply:
_sendCoreSpeechGradingDataToPeerId:
_sendVoiceTriggerGradingDataToPeerId:
_sendVoiceProfileUpdateTriggerToPeerId:forLocale:
pathExtension
_sendGradingData:withFileName:toPeerId:withCompressedFlag:withUncompressedDataSize:withBatchId:withRetainFileFlag:
_compressFilesInDirectory:matchingPredicate:compressedFileAvailable:
stringByAppendingString:
numberWithUnsignedLong:
stringByAppendingPathExtension:
moveItemAtPath:toPath:error:
sendMessageWithPayload:toPeer:withReply:
_spIdSiriDebugVoiceProfileRootDirectoryForProfile:locale:
writeToFile:options:error:
_spIdSiriDebugGradingDataRootDirectory
temporaryDirectory
URLByAppendingPathComponent:
_createDirectoryIfDoesNotExist:
writeToURL:atomically:
newVoiceProfileWithLocale:withAppDomain:
initWithVoiceRetrainingContext:error:
_getContentsOfDirectory:
addUtterances:toProfile:withContext:withCompletion:
updateVoiceProfile:withUserName:
profileID
provisionedVoiceProfilesForLocale:
appDomain
profileId
voiceProfileForId:
deleteUserVoiceProfile:
sharedSiriId
dateAdded
homeId
_getHomeUserIdForSharedSiriId:withCompletion:
userName
languageCode
initWithObjectsAndKeys:
getHomeUserIdForSharedUserId:completion:
_sendVoiceProfile:toPeerId:
siriProfileId
locale
contentsOfDirectoryAtPath:error:
stringByDeletingLastPathComponent
_spIdSiriDebugVoiceProfileCacheDirectoryForProfile:locale:
URLsForDirectory:inDomains:
_spIdSiriDebugVTDataDirectory
_spIdSiriDebugVoiceProfileStoreRootDirectory
_spIdSiriDebugVoiceProfileStoreRootDirectoryForLocale:
processRemoteCommandWithPayload:fromPeer:withReply:
sendCoreSpeechGradingDataToNearbyPeer
sendVTNearMissGradingDataToCompanion
sendVoiceProfileUpdatedMessageToNearbyPeerForLocale:
_speakerRecognitionAudioLogsGradingDir
_spIdSiriDebugTrainedUsersFilePathForLocale:
adCompanionServiceProvider
setAdCompanionServiceProvider:
lastCommunicatedPeer
setLastCommunicatedPeer:
voiceTriggerBatchId
setVoiceTriggerBatchId:
voiceIdentificationBatchId
setVoiceIdentificationBatchId:
_adCompanionServiceProvider
_lastCommunicatedPeer
_voiceTriggerBatchId
_voiceIdentificationBatchId
getHostClockFrequency
initWithZeroWindowSize:approxAbsSpeechThreshold:numHostTicksPerAudioSample:
filterZerosInAudioPacket:atBufferHostTime:filteredPacket:
endAudioAndFetchAnyTrailingZerosPacket:
vtEndInSampleCount
setVtEndInSampleCount:
numSamplesProcessed
setNumSamplesProcessed:
_vtEndInSampleCount
_numSamplesProcessed
_addDisabledConditions
supportRaiseToSpeak
supportPremiumWatchAssets
supportTTS
rootQueueWithFixedPriority:
characterSetWithCharactersInString:
componentsSeparatedByCharactersInSet:
supportContinuousVoiceTrigger
supportKeywordDetector
supportSelfTriggerSuppression
supportCSTwoShotDecision
supportSAT
supportCompactPlus
supportContinuousAudioFingerprint
supportPremiumModel
shouldDownloadVTAssetsOnDaemon
hasRemoteCoreSpeech
supportCircularBuffer
getFixedPrioritySerialQueueWithLabel:fixedPriority:
deviceUserAssignedName
deviceHwRevision
timeStampWithSaltGrain
supportsVoiceTriggerFides
_performPostBuildInstallWithCompletion:
numberWithLong:
submitVoiceIdIssueReport:
submitVoiceTriggerIssueReport:
submitEndpointerIssueReport:
submitTrialIssueReport:
_reset
_startListenPolling
_stopListening
copyBufferWithNumSamplesCopiedIn:
_startListenPollingWithInterval:completion:
_startListenWithCompletion:
startWithUUID:
stopWithUUID:
CSSiriEnabledMonitor:didReceiveEnabled:
isListenPollingStarting
setIsListenPollingStarting:
audioLoggingBuffer
setAudioLoggingBuffer:
inUseServices
setInUseServices:
_isListenPollingStarting
_audioLoggingBuffer
_inUseServices
phraseId
setPhraseId:
bestPhrase
setBestPhrase:
isEarlyWarning
setIsEarlyWarning:
isRescoring
setIsRescoring:
samplesAtFire
setSamplesAtFire:
setStartSampleCount:
_isEarlyWarning
_isRescoring
_phraseId
_bestPhrase
_samplesAtFire
_startSampleCount
initWithConfigPath:resourcePath:
_resetStartAnalyzeTime
resetBest
_setStartAnalyzeTime:
analyzeWavFloatData:numSamples:
getAnalyzedResultForPhraseId:
sampleFed
getAnalyzedMpVtResults
keywordAnalyzerNDAPI:hasMpVtResultsAvailable:forChannel:
keywordAnalyzerNDAPI:hasResultAvailable:forChannel:
earlyWarning
_keywordAnalyzerNDAPIResultForPhraseId:withNovDetectorResult:
numResultsAvailable
arrayWithCapacity:
setObject:atIndexedSubscript:
getOptionValue:
getLoggingThreshold
getRejectLoggingThreshold
activePhraseId
setActivePhraseId:
_novDetector
_startAnalyzeSampleCount
_isStartSampleCountMarked
_lastSampleFed
_sampleFedWrapAroundOffset
_activePhraseId
isBuiltinSpeakerMuted
setBuiltInSpeakerState:
initWithSignalType:timestamp:
sigGenTs
headerString
initWithStartSample:endSample:confidence:azimuth:estimatedAzimuth:
mostSampledAzimuth
stringForLogging
_spatialSpectrumLogStr
startSample
setStartSample:
endSample
setEndSample:
confidence
setConfidence:
azimuth
setAzimuth:
estimatedAzimuth
setEstimatedAzimuth:
processedAudioDurMs
setProcessedAudioDurMs:
spatialSpectrumData
setSpatialSpectrumData:
azDistribution
setAzDistribution:
_confidence
_azimuth
_estimatedAzimuth
_startSample
_endSample
_processedAudioDurMs
_spatialSpectrumData
_azDistribution
initWithTotalAudioRecorded:featuresAtEndpoint:endpointerType:serverFeatureLatencyDistribution:additionalMetrics:
totalAudioRecorded
setTotalAudioRecorded:
featuresAtEndpoint
setFeaturesAtEndpoint:
endpointerType
setEndpointerType:
serverFeatureLatencyDistribution
setServerFeatureLatencyDistribution:
additionalMetrics
setAdditionalMetrics:
_totalAudioRecorded
_featuresAtEndpoint
_endpointerType
_serverFeatureLatencyDistribution
_additionalMetrics
_setDefaultParameters
_setAsset:
_convertDB2Mag:
fetchInitSystemVolumes
_resumeSSVProcessing
_pauseSSVProcessing
_getDevicedBFSForInputLinearVolume:
_getFloatBufferData:
_prepareSoundLevelBufferFromSamples:soundType:
_processAudioChunk:soundType:
_estimatedTTSVolume:lowerLimit:upperLimit:TTSmappingInputRangeLow:TTSmappingInputRangeHigh:TTSmappingOutputRangeLow:TTSmappingOutputRangeHigh:
_getUserOffsetFromMusicVolumeDB:
_combineResultsWithOptimalFromNoise:andOptimalFromLkfs:withUserOffset:
_getDeviceSimpleOutputLinearVolumeFordBFSValue:
_scaleInputWithInRangeOutRange:minIn:maxIn:minOut:maxOut:
sharedAnalytics
logEventWithType:context:
_getMusicVolumeDBCSSSVDeviceSimple:
_getMusicVolumeDBCSSSVDeviceDefault:
_deviceSpecificLinearVolumeToDBMappingCSSSVDeviceSimple:
_deviceSpecificDBToLinearVolumeMappingCSSSVDeviceSimple:
_getDeviceSimpledBFSForOutputLinearVolume:
estimateSoundLevelbySoundType:
estimatedTTSVolumeForNoiseLevelAndLKFS:LKFS:
prepareSoundLevelBufferFromSamples:soundType:firedVoiceTriggerEvent:triggerStartTimeSampleOffset:triggerEndTimeSampleOffset:
listenPollingTimer
setListenPollingTimer:
listenPollingTimerCount
setListenPollingTimerCount:
.cxx_construct
_smartSiriVolumeNoiseLevel
_smartSiriVolumeLKFS
_floatBuffer
_defaults
_ssvEnablePolicy
_processedSampleCount
_shouldPauseSSVProcess
_shouldPauseLKFSProcess
_alarmSoundIsFiring
_timerSoundIsFiring
_currentAsset
_musicVolumeDB
_alarmVolume
_noiseLevelChannelBitset
_LKFSChannelBitset
_energyBufferSize
_noiseLowerPercentile
_noiseUpperPercentile
_LKFSLowerPercentile
_LKFSUpperPercentile
_noiseTimeConstant
_noiseMicSensitivityOffset
_noiseMicSensitivityOffsetDeviceSimple
_LKFSTimeConstant
_LKFSMicSensitivityOffset
_noiseTTSMappingInputRangeLow
_noiseTTSMappingInputRangeHigh
_noiseTTSMappingOutputRangeLow
_noiseTTSMappingOutputRangeHigh
_LKFSTTSMappingInputRangeLow
_LKFSTTSMappingInputRangeHigh
_LKFSTTSMappingOutputRangeLow
_LKFSTTSMappingOutputRangeHigh
_userOffsetInputRangeLow
_userOffsetInputRangeHigh
_userOffsetOutputRangeLow
_userOffsetOutputRangeHigh
_TTSVolumeLowerLimitDB
_TTSVolumeUpperLimitDB
_noiseWeight
_listenPollingTimer
_listenPollingTimerCount
_isDeviceRoleStereo
waitingForConnection:error:
isConnected
containsValueForKey:
decodeObjectForKey:
base64EncodedStringWithOptions:
substringToIndex:
initWithHash:locale:
initWithData:hash:locale:
builtInRTModelDictionary
modelData
modelLocale
modelHash
digest
signature
certificate
_modelData
_modelLocale
_modelHash
_digest
_signature
_certificate
_fetchJarvisConnectionState
_notifyJarvisConnectionState:
preferredExternalRouteDidChange:
carPlayAudioRouteDidChange:
_isJarvisConnected
opusNarrowBandASBD
aiffFileASBD
_asssetMetaUpdatedKey
_didReceiveSpeakerRecognitionAssetMetaData
triggerVoiceProfileRetrainingWithAsset:
_checkVoiceTriggerEnabled
_didReceiveVoiceTriggerSettingChanged:
_notifyObserver:withEnabled:
CSVoiceTriggerEnabledMonitor:didReceiveEnabled:
_didReceiveVoiceTriggerSettingChangedInQueue:
_isVoiceTriggerEnabled
_hasCorrectInputAudioRoute
_hasCorrectOutputAudioRoute
audioSessionDidStopRecording:
subdataWithRange:
audioSessionRecordBufferAvailable:
audioSessionDidStartRecording:error:
convertStopReason:
_handleDidStopWithReason:
audioSessionErrorDidOccur:
audioSessionUnsupportedAudioRoute
prepareRecord
audioSource
resetEndPointer
hasAudioRoute
hasCorrectAudioRoute
averagePower
startRecordingWithOptions:error:
stopRecording:
didPlayEndpointBeep
voiceTriggerEventInfo
hasPendingTwoShotBeep
_didReceiveSiriSettingChanged:
fetchIsEnabled
_isSiriEnabled
_createAudioStreamWithCurrentNviContext
requestHistoricalAudio
reqStartAudioSampleId
receiveOnlyProcessedChannelData
audioChunkAvailable:numChannels:numSamplesPerChannel:startSampleId:atAbsMachTimestamp:
addReceiver:
removeReceiver:
numBytesPerSample
audioStreamProvider:avBufferAvailable:
nviCtx
setNviCtx:
receivers
setReceivers:
_nviCtx
_receivers
bundleForClass:
bundlePath
_beepFloatVec
_shortBuffer
_numTotalInputSamples
_numTotalOutputSamples
RMSScore
initWithRMSScore:lastSampleCount:
compareScoresDesc:
setRMSScore:
lastSampleCount
setLastSampleCount:
_RMSScore
_lastSampleCount
appendData:
getBytes:range:
_calculateRMSWithFrameData:
_calculateSpeechVoicingLevel
_calculateNumberOfVoicingFrames
numberOfVoicingFrames
sortUsingSelector:
addDataToBuffer:
calculateShadowMicScore
bestStartDetectSample
setBestStartDetectSample:
bestEarlyDetectSample
setBestEarlyDetectSample:
bestEndDetectSample
setBestEndDetectSample:
shadowMicScore
setShadowMicScore:
rmsSamplesForEntireAudio
setRmsSamplesForEntireAudio:
audioBuffer
setAudioBuffer:
speechVoiceLevel
setSpeechVoiceLevel:
setNumberOfVoicingFrames:
numberOfTotalFramesETFT
setNumberOfTotalFramesETFT:
_bestStartDetectSample
_bestEarlyDetectSample
_bestEndDetectSample
_shadowMicScore
_rmsSamplesForEntireAudio
_audioBuffer
_speechVoiceLevel
_numberOfVoicingFrames
_numberOfTotalFramesETFT
_createXPCClientConnection
sharedNotifier
notifyActivationEvent:deviceId:activationInfo:completion:
addObserver:observeFilteredGestures:includingWhenScreenOff:
gestureType
timestamp
_didReceiveWakeGesture
gestureMonitorDidReceiveWakeGesture:
wakeGestureRecognized:
wakeGestureRecognized:date:
_gestureMonitor
handleFailureInFunction:file:lineNumber:description:
_audioZeroFilterImpl
readAudioChunksFrom:block:
_checkSoftwareUpdateCheckingState
_didReceiveSoftwareUpdateCheckingStateChanged:
_softwareUpdateCheckingState
_notifyObserver:withSoftwareUpdateCheckingRunning:
CSSoftwareUpdateCheckingMonitor:didReceiveStateChanged:
_didReceiveSoftwareUpdateCheckingStateChangedInQueue:
_isSoftwareUpdateCheckingRunning
_addAssetManagerEnabledConditions
_shouldCheckNetworkAvailability
isAvailable
getTestResponse:
getCurrentVoiceTriggerLocale:
setDelayInterstitialSounds:level:completion:
getTriggerCount:
clearTriggerCount:
voiceTriggerAOPModeEnabledPolicy
addSamples:numSamples:atHostTime:
copySamplesFrom:to:
createAudioCircularBufferWithDefaultSettings
copySamplesFromHostTime:
bufferLength
setBufferLength:
_csAudioCircularBufferImpl
_bufferLength
saveMetadata:isExplicitEnrollment:
saveUtterance:utteranceAudioPath:numSamplesToWrite:isExplicitEnrollment:
_getBaseMetaDictionaryForUtterancePath:
writeMetaDict:atMetaPath:
saveRawUtteranceAndMetadata:to:isExplicitEnrollment:
saveUtteranceAndMetadata:atDirectory:isExplicitEnrollment:
_didReceiveNewVoiceTriggerAssetMetaData
initWithDescription:timeout:
_addAlwaysEnabledCondition
initWithRecordingDuration:audioSamplesPerRemoteVAD:audioSampleRate:
remoteVADSampleCount
copySamplesFromAudioSampleCount:toAudioSampleCount:
capacity
size
beginSampleCount
_remoteVADCircularBufferImpl
_audioSamplesPerRemoteVAD
_capacity
_size
_beginSampleCount
_didReceiveNewAdBlockerAssetMetaData
setStreaming:
setStreamRequest:
setStreamingUUID:
setStartStreamOption:
streamingUUID
streaming
prepareAudioStreamWithRequest:completion:
scheduledFutureSample
setScheduledFutureSample:
streamRequest
startStreamOption
_scheduledFutureSample
_streaming
_streamRequest
_startStreamOption
_streamingUUID
initWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:taskName:processedAudioDurationInMilliseconds:
componentsJoinedByString:
initWithWordCount:trailingSilenceFrames:endOfSilenceLikelihood:pauseCounts:silencePosterior:taskName:
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
eosLikelihood
setEosLikelihood:
pauseCounts
setPauseCounts:
silencePosterior
setSilencePosterior:
processedAudioDurationInMilliseconds
setProcessedAudioDurationInMilliseconds:
taskName
setTaskName:
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
_taskName
strongToWeakObjectsMapTable
_hasPendingActivationForType:
_notifyActivationEvent:completion:
_isVoiceTriggerEvent:
_didReceiveAOPFirstPassTrigger:completion:
delegates
setDelegates:
pendingActivationEvent
setPendingActivationEvent:
pendingCompletion
setPendingCompletion:
_delegates
_pendingActivationEvent
_pendingCompletion
_handleFakeHearstModelRequest:majorVersion:minorVersion:downloadedModels:preinstalledModels:completion:
getAccessoryFallbackLocalTable
selectFallbackModelForLocale:downloadedModels:preinstalledModels:rtLocaleMap:
setTriggerMode:
getAccessoryFallbackFamilyLocal:fromLocaleMap:
sharedConnection
_checkSiriRestrictedOnLockScreen
effectiveBoolValueForSetting:
_notifyObserver:withRestricted:
CSSiriRestrictionOnLockScreenMonitor:didReceiveRestrictionChanged:
_didReceiveRestrictionChanged:
profileConnectionDidReceiveRestrictionChangedNotification:userInfo:
profileConnectionDidReceivePasscodeChangedNotification:userInfo:
profileConnectionDidReceivePasscodePolicyChangedNotification:userInfo:
profileConnectionDidReceiveProfileListChangedNotification:userInfo:
profileConnectionDidReceiveEffectiveSettingsChangedNotification:userInfo:
profileConnectionDidReceiveDefaultsChangedNotification:userInfo:
profileConnectionDidReceiveAppWhitelistChangedNotification:userInfo:
_didReceiveRestrictionChangedInQueue:
_isRestricted
_checkSpringBoardStarted
_didReceiveSpringboardStarted:
_notifyObserver:withStarted:
CSSpringboardStartMonitor:didReceiveStarted:
_didReceiveSpringboardStartedInQueue:
_isSpringBoardStarted
setStreamState:
_holdRecordingExceptionIfNeeded:
_streamStateName:
setProviderDelegate:
_prepareAudioStreamSync:request:error:
historicalBufferRequestStreams
_createCircularBufferIfNeeded
_audioStreamWithRequest:streamName:error:
_handleAudioSystemFailure
_startAudioStream:option:completion:
_prepareAudioStream:request:completion:
startPendingOnStoppingStreams
startPendingOnStoppingStreamToCompletionDict
_didPlayStartAlertSoundForSiri:audioStream:
alertPlaybackFinishWaitingStreams
alertPlaybackFinishWaitingCompletions
_scheduleAlertFinishTimeout:
_switchToRecordingMode
circularBufferStartHostTime
circularBufferStartSampleCount
startPendingStreams
pendingStartCompletions
_holdRecordingTransactionIfNeeded
_scheduleDidStartRecordingDelegateWatchDog
_resetCircularBufferStartTime
setCircularBufferStartHostTime:
setCircularBufferStartSampleCount:
streams
_clearDidStartRecordingDelegateWatchDog
_releaseRecordingTransactionIfNeeded
_clearDidStopRecordingDelegateWatchDog
_preEpilogueAudioStream
stopPendingStreams
pendingStopCompletions
_postEpilogueAudioStream
_shouldHandleStartPendingOnStopping:withStopReason:
objectEnumerator
_stopAudioStream:option:completion:
_cs_isHashTableEmpty
_shouldStopRecording
_scheduleDidStopRecordingDelegateWatchDog
_switchToListeningMode
_audioChunkFrom:to:
_saveRecordingBufferFrom:to:toURL:
streamHolders
setSessionDelegate:
_deactivateAudioSession:error:
enableSmartRoutingConsiderationForStream:enable:
setAlertDelegate:
_isVoiceTriggerInfoAvailableLocally:
_processAudioBuffer:remoteVAD:atTime:
_handleDidStartAudioStreamWithResult:error:
_handleDidStopAudioStreamWithReason:
sessionDelegate
providerDelegate
setRemoteVAD:
_fetchHistoricalAudioAndForwardToStream:remoteVAD:
_didReceiveFinishStartAlertPlaybackAt:
alertDelegate
initWithDescription:
_schduleDidStartRecordingDelegateWatchDogWithToken:
_scheduleDidStopRecordingDelegateWatchDog:
_tearDownCircularBufferIfNeeded
notifyProviderContextChanged
recordQueue
setRecordQueue:
loggingQueue
setLoggingQueue:
streamState
setStartPendingStreams:
setStartPendingOnStoppingStreams:
setAlertPlaybackFinishWaitingStreams:
setStreams:
setStopPendingStreams:
setPendingStartCompletions:
setAlertPlaybackFinishWaitingCompletions:
setPendingStopCompletions:
setStartPendingOnStoppingStreamToCompletionDict:
setStreamHolders:
setHistoricalBufferRequestStreams:
lastAudioRecorderContext
setLastAudioRecorderContext:
audioSystemRecovering
setAudioSystemRecovering:
audioPreprocessor
setAudioPreprocessor:
recordingTransaction
setRecordingTransaction:
recordingWillStartGroup
setRecordingWillStartGroup:
waitingForAlertFinish
setWaitingForAlertFinish:
alertPlaybackFinishTimeoutToken
setAlertPlaybackFinishTimeoutToken:
startRecordingWatchDogToken
setStartRecordingWatchDogToken:
stopRecordingWatchDogToken
setStopRecordingWatchDogToken:
_audioSystemRecovering
_waitingForAlertFinish
_recordQueue
_loggingQueue
_streamState
_startPendingStreams
_startPendingOnStoppingStreams
_alertPlaybackFinishWaitingStreams
_streams
_stopPendingStreams
_pendingStartCompletions
_alertPlaybackFinishWaitingCompletions
_pendingStopCompletions
_startPendingOnStoppingStreamToCompletionDict
_providerDelegate
_sessionDelegate
_streamHolders
_historicalBufferRequestStreams
_alertDelegate
_lastAudioRecorderContext
_audioPreprocessor
_recordingTransaction
_recordingWillStartGroup
_alertPlaybackFinishTimeoutToken
_startRecordingWatchDogToken
_stopRecordingWatchDogToken
_circularBufferStartHostTime
_circularBufferStartSampleCount
_addListeningEnabledConditions
initWithArray:
CSAlwaysOnProcessorStateMonitor:didReceiveStateChange:
_didReceiveAOPListeningStateChange:
_isListeningEnabled
adBlockerAssetDecoderWithVersion:
remoteVADAvailable
subChunkFrom:numSamples:forChannel:
skipSamplesAtStartSuchThatNumSamplesReceivedSoFar:reachesACountOf:completionHandler:
splitAudioChunkSuchThatNumSamplesReceivedSoFar:reachesACountOf:completionHandler:
_data
_numSamples
_sampleByteDepth
_hostTime
_remoteVAD
initWithResult:
setSampleFed:
setEarlyWarning:
_earlyWarning
_sampleFed
payloadData
setPayloadData:
_payloadData
isUserActive
setEndpointerModelVersion:
_canProcessCurrentRequest
_endpointerModelVersion
speakAudio:
speakAudio:withScaleFactor:playbackStarted:completion:
speakAudio:withScaleFactor:outASBD:playbackStarted:completion:
setEnableAlwaysOnVoiceTrigger:
setIsConnected:
_isConnected
_enableAlwaysOnVoiceTrigger
_deviceType
_deviceName
_deviceID
_deviceUID
_productIdentifier
_injectionEngine
macHostTimeFromBridgeHostTime:
_deregisterAudioSessionNotifications
_registerAudioSessionNotifications
sessionInfoQueue
setSessionInfoQueue:
_sessionInfoQueue
_setupNNVADEndpointer
isRecordContextVoiceTrigger:
isRecordContextHearstVoiceTrigger:
isRecordContextJarvisVoiceTrigger:
isRecordContextRaiseToSpeak:
isWatchRTSTriggered
endpointer:didDetectStartpointAtTime:
endpointer:didDetectHardEndpointAtTime:withMetrics:
endpointer:detectedTwoShotAtTime:
resetForVoiceTriggerTwoShotWithSampleRate:
endPointAnalyzerType
endpointerDelegate
hybridEndpointer
setHybridEndpointer:
nnvadEndpointer
setNnvadEndpointer:
activeEndpointer
setActiveEndpointer:
recordingDidStop
setRecordingDidStop:
_recordingDidStop
_endpointerDelegate
_hybridEndpointer
_nnvadEndpointer
_activeEndpointer
catAssetManagerDelegate:withVersion:withError:
getCATXPCConnection
downloadForManifest:withAssetName:
initWithBool:
initWithDouble:
initWithLongLong:
initWithUnsignedLongLong:
objCType
longLongValue
_checkFirstUnlocked
_didReceiveFirstUnlock:
_notifyObserver:withUnlocked:
_firstUnlockNotified
_didReceiveFirstUnlockInQueue:
_firstUnlocked
_scaleDecayConstants:
_savePeaks:averagePower:maxSample:
peakValueSinceLastCall
setPeakValueSinceLastCall:
setSawNotANumber:
setSawInfinity:
_zapgremlins:
_linearToDB:
_ampToDB:
_averagePowerI
_averagePowerF
_instantaneousMode
_peak
_maxPeak
_decay
_peakDecay
_averagePowerPeak
_peakHoldCount
_previousBlockSize
_decay1
_peakDecay1
_clipping
_checkPhraseSpotterEnabled
CSPhraseSpotterEnabledMonitor:didReceiveEnabled:
_didReceivePhraseSpotterSettingChangedInQueue:
_phraseSpotterEnabledDidChange
_isPhraseSpotterEnabled
_handleClientEvent:
_handleClientMessage:client:
_handleClientError:client:
_sendReplyMessageWithResult:error:event:client:
initWithConnection:
activateConnection
connection
setConnection:
_connection
valueForEntitlement:
xpcConnection:hasEntitlement:
initWithEndpointThreshold:
samplingRate
dictationLanguages
currentKeyboard
wasLanguageToggled
multilingualKeyboardLanguages
keyboardConvoLanguagePriors
keyboardGlobalLanguagePriors
previousMessageLanguage
globalLastKeyboardUsed
dictationLanguagePriors
conversationalMessages
_wasLanguageToggled
_samplingRate
_dictationLanguages
_currentKeyboard
_multilingualKeyboardLanguages
_keyboardConvoLanguagePriors
_keyboardGlobalLanguagePriors
_previousMessageLanguage
_globalLastKeyboardUsed
_dictationLanguagePriors
_conversationalMessages
initWithConfig:samplingRate:minSpeechFrames:numLeadingFrames:delegate:
resetForNewRequest
_didReceiveMediaserverNotification:
_notifyObserver:withMediaserverState:
audioServerCrashEventProvidingLostMediaserverd
_mediaserverdDidRestart
serverState
setServerState:
_serverState
_didReceiveDaemonStateChanged:
_notifyObserver:withDaemonState:
notifyDaemonStateChanged:
runRecognition
_recognizeWavData:length:
_previousUtteranceTokens
_triggerTokenList
_useKeywordSpotting
_availabilityChanged
_didReceivedNetworkAvailabilityChangedNotification:
_notifyObserver:withNetworkAvailability:
CSNetworkAvailabilityMonitor:didReceiveNetworkAvailabilityChanged:
_startObservingSpeechDetectionVADPresence
handleSpeechDetectionVADPresentChange:
_systemControllerDied:
initWithUUIDString:
isRemoteDevice
remoteDeviceUID
remoteProductIdentifier
initWithAVVCRecordDeviceInfo:
route
remoteDeviceProductIdentifier
_isRemoteDevice
_route
_remoteDeviceUID
_remoteDeviceProductIdentifier
receiveOpportuneSpeakListenerStart
receiveOpportuneSpeakListenerStop
listener
assetForAssetType:resourcePath:configVersion:assetProvider:
hybridEndpointerAssetFilename
initWithResourcePath:configFile:configVersion:assetProvderType:
fallBackAssetResourcePath
_decodeJson:
getConfigFileNameForAssetType:
defaultFallBackAssetForSmartSiriVolume
defaultFallBackAssetForHearst
defaultFallBackAssetForAdBlocker
containsKey:category:
hashFromResourcePath
stringForCurrentAssetProviderType
configVersion
assetProvider
_decodedInfo
_path
_resourcePath
_configVersion
_assetProvider
_configureAudioConverter:
_convertBufferedLPCM:allowPartial:timestamp:
replaceBytesInRange:withBytes:length:
_opusConverter
_bufferedLPCM
_recordBasePacketsPerSecond
_opusOutASBD
_convertPacketCount
_convertAudioCapacity
_lastTimestamp
_outPacketSizeInSec
_didSendFirstPacket
_notifyObserver:withLanguageCode:
_didReceiveLanguageCodeUpdate
_checkAllConditionsEnabled
notifyCallback:option:
_monitors
_conditions
_callback
splitAudioDataToReachSampleCount:currSampleCount:numBytesPerSample:completionHandler:
rawMicChannelsDataWithNumSamplesPerChannel:
strRepForFloatData
getAudioInjectionXPCConnection
injectAudio:toDeviceWithUUID:withfadingTimeWindowLength:completion:
setAudioInjectionMode:
injectAudio:toDeviceWithUUID:completion:
getAssetTypeForNamespace:
getTrialIdsForAssetType:withCompletion:
initWithDroppingPrediction:droppedPrediction:timestamp:
toString
droppingPrediction
droppedPrediction
_droppingPrediction
_droppedPrediction
_timestamp
isRecordContextHearstDoubleTap:
isRecordContextAutoPrompt:
isRecordContextHomeButtonPress:
isRecordContextSpeakerIdTrainingTrigger:
isRecordContextJarvisButtonPress:
recordContextString:
pickTopScoringProfileIdFromScores:
classifyUserIdentityFor:withScores:withAsset:
stringFromClassificationCategory:
_update
didTriggerWithSecondChanceEnabled:
initWithPhraseInfoDict:useKeywordSpotting:
updateWithNdapiResult:
updateWithCtcScore:
effectiveThresholdWithSecondChanceEnabled:
hasNearMissTriggerWithSecondChanceEnabled:
dictionaryRepresentationWithSecondChanceEnabled:
phId
setPhId:
phStr
setPhStr:
threshold
setThreshold:
secondChanceThreshold
setSecondChanceThreshold:
loggingThreshold
setLoggingThreshold:
useKwdSpotting
setUseKwdSpotting:
recognizerScoreScaleFactor
setRecognizerScoreScaleFactor:
recognizerThresholdOffset
setRecognizerThresholdOffset:
satThreshold
setSatThreshold:
tdsrSatCombinedSATThreshold
setTdsrSatCombinedSATThreshold:
ndapiScore
setNdapiScore:
ctcCheckerScore
setCtcCheckerScore:
combinedScore
setCombinedScore:
isMaximized
setIsMaximized:
ndapiResult
setNdapiResult:
_useKwdSpotting
_isMaximized
_threshold
_secondChanceThreshold
_loggingThreshold
_recognizerScoreScaleFactor
_recognizerThresholdOffset
_satThreshold
_tdsrSatCombinedSATThreshold
_ndapiScore
_ctcCheckerScore
_combinedScore
_phId
_phStr
_ndapiResult
VTSecondPassCategoryForFirstPassSource:
supportedVTPhrasesInfoForCategory:
dictionaryWithCapacity:
VTSecondPassUseKeywordSpottingFrom:
initWithAsset:firstPassSource:
updateWithNdapiResults:
updateWithCtcCheckerResults:
getTriggeredPhraseWithSecondChanceEnabled:
getNearMissPhraseWithSecondChanceEnabled:
bestScoringPhrase
phraseMap
setPhraseMap:
triggeredPhrase
setTriggeredPhrase:
_phraseMap
_triggeredPhrase
languageDetectorConfigFile
startOfSpeechDetectorConfigFile
spgConfigFile
streamID
startHostTime
startAlert
stopAlert
stopOnErrorAlert
skipAlert
remoteVoiceActivityAvailable
remoteVoiceActivityVAD
remoteVoiceActivityVADBuffer
_voiceControllerWithError:
_destroyVoiceController
_audioRecorderDidStartRecordingSuccessfully:streamHandleID:error:
setRecordDelegate:
initWithError:
setContextForStream:forStream:error:
_getRecordSettingsWithRequest:
initWithStreamID:settings:bufferDuration:
prepareRecordForStream:error:
_logResourceNotAvailableErrorIfNeeded:
_shouldInjectAudio
_needResetAudioInjectionIndex:
_startAudioStreamForAudioInjection
startRecordForStream:error:
stopRecordForStream:error:
getCurrentSessionState
getCurrentStreamState:
getRecordDeviceInfoForStream:
getRecordSettingsForStream:
isUpsamplingSourceAudio
activateAudioSessionForStream:isPrewarm:error:
_shouldLogResourceNotAvailableError
activateAudioSessionForStream:isPrewarm:recordMode:error:
_convertDeactivateOption:
deactivateAudioSessionWithOptions:
setIAmTheAssistant:error:
setAllowMixableAudioWhileRecording:error:
enableSmartRoutingConsiderationForStream:enable:error:
_updateLanguageCodeForRemoteVTEIResult:
channels
packetDescriptionCount
bytesDataSize
packetDescriptions
updateMeterForStream:
getPeakPowerForStream:forChannel:
getAveragePowerForStream:forChannel:
streamDescription
_processAudioChain:audioStreamHandleId:remoteVAD:atTime:
playAlertSoundForType:overrideMode:
_processAudioBuffer:audioStreamHandleId:
_audioRecorderDidStopRecordingForReason:streamHandleID:
voiceControllerDidStartRecording:successfully:
voiceControllerDidStartRecording:successfully:error:
voiceControllerDidStopRecording:forReason:
voiceControllerDidDetectStartpoint:
voiceControllerDidDetectEndpoint:ofType:
voiceControllerDidDetectEndpoint:ofType:atTime:
voiceControllerEncoderErrorDidOccur:error:
voiceControllerDidFinishAlertPlayback:ofType:error:
voiceControllerDidFinishAlertPlayback:withSettings:error:
voiceControllerRecordHardwareConfigurationDidChange:toConfiguration:
voiceControllerBeginRecordInterruption:
voiceControllerBeginRecordInterruption:withContext:
voiceControllerEndRecordInterruption:
voiceControllerMediaServicesWereLost:
voiceControllerMediaServicesWereReset:
voiceControllerWillSetAudioSessionActive:willActivate:
voiceControllerDidSetAudioSessionActive:isActivated:
voiceControllerRecordBufferAvailable:buffer:
voiceControllerLPCMRecordBufferAvailable:buffer:
voiceControllerWirelessSplitterRouteAvailable:devices:
voiceControllerDidStartRecording:forStream:successfully:error:
voiceControllerDidStopRecording:forStream:forReason:
voiceControllerAudioCallback:forStream:buffer:
voiceControllerStreamInvalidated:forStream:
_shouldUseRemoteRecordForContext:
_shouldUseRemoteBuiltInMic:
voiceControllerCreationQueue
setVoiceControllerCreationQueue:
crashEventDelegate
setCrashEventDelegate:
sessionEventDelegate
setSessionEventDelegate:
_voiceController
_interleavedABL
_remoteRecordClient
_shouldUseRemoteRecord
_opusDecoders
_audioFileReader
_audioFilePathIndex
_waitingForDidStart
_pendingTwoShotVTToken
_voiceControllerCreationQueue
_crashEventDelegate
_sessionEventDelegate
notifyDidStartStreamWithContext:successfully:option:
initWithSharedSiriId:languageCode:productCategory:version:sharedHomeId:userName:
setProfileId:
setLanguageCode:
productCategory
setProductCategory:
version
setVersion:
onboardType
setOnboardType:
setHomeId:
setUserName:
_profileId
_languageCode
_productCategory
_onboardType
_homeId
_userName
setRequestHistoricalAudio:
setReqStartAudioSampleId:
reqStartMachAbsTime
setReqStartMachAbsTime:
shouldLogRawSensorData
setShouldLogRawSensorData:
rootLogDir
setRootLogDir:
_requestHistoricalAudio
_shouldLogRawSensorData
_reqStartAudioSampleId
_reqStartMachAbsTime
_rootLogDir
getTriggerMode
_notifyStopOpportuneSpeakWithDelay:
audioProviderUUID
isOpportuneSpeakListening
setIsOpportuneSpeakListening:
setAudioProviderUUID:
token
setToken:
_isOpportuneSpeakListening
_audioProviderUUID
_token
_transaction
_description
decodeIntegerForKey:
decodeInt64ForKey:
encodeInteger:forKey:
encodeInt64:forKey:
setSigType:
setSigGenTs:
_sigType
_sigGenTs
isSiriRestrictedOnLockScreen
v40@0:8@16@24@?32
v40@0:8@"NSURL"16@"NSString"24@?<v@?@"NSString"@"NSString"@"NSError">32
@16@0:8
v24@0:8@16
v16@0:8
B16@0:8
Q16@0:8
v24@0:8Q16
v20@0:8B16
@"NSMutableArray"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8#16
B24@0:8:16
Vv16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v44@0:8@16Q24B32@36
v40@0:8@16Q24Q32
v56@0:8@16Q24@32@40Q48
v32@0:8@16@24
v44@0:8@"CSAudioInjectionEngine"16Q24B32@"NSError"36
v40@0:8@"CSAudioInjectionEngine"16Q24Q32
v56@0:8@"CSAudioInjectionEngine"16Q24@"NSData"32@"NSData"40Q48
v32@0:8@"CSAudioInjectionEngine"16@"CSAudioChunkForTV"24
@24@0:8Q16
B44@0:8@16f24@?28@?36
q24@0:8@16
@"NSObject<OS_dispatch_queue>"
@"<CSAudioInjectionEngineDelegate>"
@"CSKeywordAnalyzerNDEAPI"
@"CSAudioCircularBuffer"
@"NSUUID"
@"CSAudioInjectionDevice"
v32@0:8@16Q24
v32@0:8@"NSStream"16Q24
@32@0:8@16@24
@"NSOutputStream"
v24@0:8@?16
@24@0:8@16
@"NSHashTable"
v32@0:8@"<CSAudioSessionInfoProviding>"16@"NSDictionary"24
v28@0:8@16B24
v28@0:8@"CSXPCClient"16B24
v32@0:8@"CSCoreSpeechDaemonStateMonitor"16Q24
I16@0:8
@"<CSAudioSessionInfoProviding>"
@"CSXPCClient"
v32@0:8@16q24
q16@0:8
@68@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
v56@0:8{AudioStreamBasicDescription=dIIIIIIII}16
^{OpaqueExtAudioFile=}16@0:8
v24@0:8^{OpaqueExtAudioFile=}16
f16@0:8
@"NSURL"
^{OpaqueExtAudioFile=}
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@"NSString"
B32@0:8^B16^Q24
Q24@0:8Q16
@"<CSBiometricMatchMonitorDelegate>"
@"CSKeywordAnalyzerNDAPI"
@32@0:8@16f24I28
v20@0:8f16
v28@0:8@16I24
v28@0:8@"CSVoiceTriggerXPCClient"16B24
v36@0:8B16@20@28
v28@0:8B16@20
v36@0:8B16d20@28
v28@0:8B16d20
@"CSVoiceTriggerXPCClient"
@96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
@104@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56@96
@104@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64
@112@0:8@16@24{AudioStreamBasicDescription=dIIIIIIII}32{AudioStreamBasicDescription=dIIIIIIII}72
r*16@0:8
v36@0:8@16@24f32
v40@0:8@16@24Q32
@48@0:8@16@24@32^@40
v40@0:8@"CSVoiceTriggerAwareZeroFilter"16@"NSData"24Q32
v40@0:8@"CSBeepCanceller"16@"NSData"24Q32
@20@0:8f16
v32@0:8f16B20@24
B32@0:8@16@24
B20@0:8f16
@"<CSAudioPreprocessorDelegate>"
@"CSAudioSampleRateConverter"
@"CSVoiceTriggerAwareZeroFilter"
@"CSBeepCanceller"
@"CSAudioZeroCounter"
@24@0:8^{BTLocalDeviceImpl=}16
v40@0:8^{BTDeviceImpl=}16I24i28I32i36
v28@0:8^{BTSessionImpl=}16i24
v24@0:8^{BTSessionImpl=}16
v32@0:8^{BTLocalDeviceImpl=}16i24i28
^{BTSessionImpl=}16@0:8
^{BTLocalDeviceImpl=}16@0:8
v24@0:8^{BTLocalDeviceImpl=}16
^{BTSessionImpl=}
^{BTLocalDeviceImpl=}
@"NSArray"
@"NSObject<OS_dispatch_group>"
v40@0:8@16@24@32
v40@0:8@"NSObject<OS_xpc_object>"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v40@0:8@"CSXPCConnection"16@"NSObject<OS_xpc_object>"24@"NSObject<OS_xpc_object>"32
v36@0:8@16B24Q28
@"CSTrialAssetDownloadMonitor"
@24@0:8d16
B24@0:8d16
@20@0:8I16
@"NSObject<OS_dispatch_source>"
@"<CSAudioFileReaderDelegate>"
^{OpaqueAudioConverter=}96@0:8{AudioStreamBasicDescription=dIIIIIIII}16{AudioStreamBasicDescription=dIIIIIIII}56
^{OpaqueAudioConverter=}
i16@0:8
v20@0:8i16
@"<CSLanguageDetectorAssetMonitorDelegate>"
v40@0:8Q16@24@?32
v40@0:8Q16@"NSDictionary"24@?<v@?@"NSError"@"CSSmartSiriVolumeEstimate">32
@32@0:8Q16@24
@"<CSSmartSiriVolumeClientDelegate>"
@"NSXPCConnection"
Q32@0:8@16^@24
B40@0:8@16Q24^@32
B32@0:8Q16^@24
B24@0:8Q16
f24@0:8Q16
B40@0:8Q16Q24^@32
B40@0:8q16Q24^@32
B32@0:8@16q24
B24@0:8q16
@"CSAudioInjectionEngine"
@"NSMutableDictionary"
v32@0:8@"<CSAudioStreamProviding>"16q24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunk"24
v32@0:8@"<CSAudioStreamProviding>"16@"CSAudioChunkForTV"24
v32@0:8@16@?24
v28@0:8B16@?20
v32@0:8@16d24
@"<CSOpportuneSpeakListenerDelegate>"
@"CSAudioStream"
@"CSSPGEndpointAnalyzer"
@"<CSAudioStreamProviding>"
@"<CSAudioSessionProviding>"
@"CSAudioRecordContext"
@"CSPlainAudioFileWriter"
v64@0:8@16@24@32@40@48@?56
@"NSObject<OS_xpc_object>"
v56@0:8q16@24@32@40@?48
v44@0:8@16@24f32@?36
v32@0:8@"NSString"16@?<v@?@"NSString">24
v56@0:8q16@"NSString"24@"NSString"32@"NSString"40@?<v@?B@"NSError"@"NSUUID">48
v44@0:8@"NSURL"16@"NSUUID"24f32@?<v@?B@"NSError"QQ>36
v32@0:8@"NSUUID"16@?<v@?B@"NSError">24
v24@0:8@?<v@?B@"NSError"@"NSUUID">16
v24@0:8q16
d16@0:8
v24@0:8d16
v40@0:8Q16@24@32
v32@0:8d16@?24
v40@0:8Q16@"NSDictionary"24@"NSDictionary"32
v24@0:8@"CSAudioChunk"16
@"<CSEndpointAnalyzerDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerDelegate>"16
@"<CSEndpointAnalyzerImplDelegate>"16@0:8
v24@0:8@"<CSEndpointAnalyzerImplDelegate>"16
v24@0:8@"CSServerEndpointFeatures"16
v32@0:8d16@?<v@?B@"NSArray">24
v32@0:8@"NSString"16@"NSString"24
v24@0:8@"NSDictionary"16
@"<CSEndpointAnalyzerDelegate>"
@"<CSEndpointAnalyzerImplDelegate>"
@"<CSLanguageDetectorDelegate>"
@24@0:8q16
@24@0:8^{_NSZone=}16
@32@0:8q16@24
q24@0:8q16
v32@0:8@"CSSelfTriggerDetector"16@"NSDictionary"24
@"<CSMyriadSelfTriggerCoordinatorDelegate>"
v28@0:8f16@20
v44@0:8@16@24B32@36
v40@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32
v44@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioRecordContext"24B32@"CSAudioStartStreamOption"36
v32@0:8@"CSCommandControlBehaviorMonitor"16@"CSAudioStopStreamOption"24
B32@0:8r^v16Q24
@112@0:8@16{AudioStreamBasicDescription=dIIIIIIII}24{AudioStreamBasicDescription=dIIIIIIII}64Q104
B32@0:8r^v16q24
v56@0:8Q16Q24@32@40@?48
S16@0:8
v24@0:8@"CSAudioServerCrashMonitor"16
v32@0:8@"CSVoiceTriggerAssetHandler"16@"CSAsset"24
v40@0:8@"CSActivationEventNotificationHandler"16@"CSActivationEvent"24@?<v@?B@"NSError">32
v40@0:8@16Q24@32
v40@0:8@16Q24q32
v40@0:8@16q24@32
v56@0:8@"CSAudioRecorder"16Q24@"NSData"32@"NSData"40Q48
v40@0:8@"CSAudioRecorder"16Q24@"CSAudioChunkForTV"32
v44@0:8@"CSAudioRecorder"16Q24B32@"NSError"36
v40@0:8@"CSAudioRecorder"16Q24q32
v32@0:8@"CSAudioRecorder"16q24
v40@0:8@"CSAudioRecorder"16q24@"NSError"32
v24@0:8@"CSAudioRecorder"16
v32@0:8@"CSAudioRecorder"16@"NSDictionary"24
v28@0:8@"CSAudioRecorder"16B24
v32@0:8@"CSAudioRecorder"16@"NSError"24
v32@0:8@"CSAudioProvider"16Q24
v28@0:8@"CSOpportuneSpeakEventMonitor"16B24
@32@0:8@16^@24
@24@0:8^@16
@"CSAudioRecorder"
@"CSFallbackAudioSessionReleaseProvider"
@"<CSSpeechManagerDelegate>"
@"CSOpportuneSpeakListnerTestService"
@"CSPostBuildInstallService"
@"CSSmartSiriVolumeManager"
v32@0:8Q16Q24
@"<CSCommandControlListenerDelegate>"
v32@0:8@"CSAssetController"16Q24
v32@0:8@16@"NSString"24
v32@0:8Q16@?24
v48@0:8Q16Q24@32@?40
@"CSPolicy"
@"CSAssetDownloadingOption"
@32@0:8@"<NviDataSource>"16@"<NviAssetsProvider>"24
v24@0:8@"<NviSignalProviderDelegate>"16
v32@0:8@"NviContext"16@?<v@?B@"NSError">24
v24@0:8@?<v@?B@"NSError">16
@40@0:8@16@24Q32
@32@0:8@16Q24
@28@0:8@16B24
@32@0:8r^s16q24
@32@0:8^v16q24
@"NSMutableData"
@"<CSKeywordAnalyzerNDEAPIScoreDelegate>"
v44@0:8@16@24f32Q36
v44@0:8@"CSAudioConverter"16@"NSArray"24f32Q36
v32@0:8@"CSSmartSiriVolumeController"16Q24
v24@0:8@"<CSAudioSessionProviding>"16
v32@0:8@"<CSAudioSessionProviding>"16@"NSDictionary"24
v28@0:8@"<CSAudioSessionProviding>"16B24
v40@0:8@"<CSAudioAlertProviding>"16q24@"NSError"32
v32@0:8@"CSAudioSessionController"16@"NSDictionary"24
v60@0:8@16Q24@32@40Q48I56
v60@0:8@"CSAudioDecoder"16Q24@"NSData"32@"NSData"40Q48I56
v32@0:8@"CSContinuousVoiceTrigger"16@"NSDictionary"24
v32@0:8@"CSContinuousVoiceTrigger"16d24
B32@0:8@16^@24
B40@0:8Q16d24^@32
v56@0:8d16Q24@32@?40@?48
B24@0:8^@16
B24@0:8B16B20
@?16@0:8
@"CSAudioConverter"
@"NSDictionary"
@"<CSSpeechControllerDelegate>"
@"<CSSpeakerIdentificationDelegate>"
@"CSEndpointerProxy"
@"<CSAudioAlertProviding>"
@"<CSAudioMeterProviding>"
@"<CSAudioMetricProviding>"
@"CSSelectiveChannelAudioFileWriter"
@"CSSmartSiriVolumeController"
@"CSSpeechEndHostTimeEstimator"
@"CSLanguageDetector"
@"CSAudioPowerMeter"
@"CSStopRecordingOptions"
@"CSMediaPlayingMonitor"
@"CSVolumeMonitor"
@40@0:8Q16Q24@32
@24@0:8@?16
v56@0:8@16@24@32@40@?48
v60@0:8@16@24@32B40@44@?52
v52@0:8@16@24B32@36@?44
d24@0:8d16
B20@0:8B16
B28@0:8B16^{__CFString=}20
B24@0:8^{__CFString=}16
@44@0:8Q16@24@32B40
B40@0:8@16@24@32
v48@0:8@16@24B32B36@?40
v48@0:8@"NSString"16@"NSString"24B32B36@?<v@?@"NSDictionary"@"NSError">40
v40@0:8@"NSDictionary"16@"NSArray"24@?<v@?@"NSDictionary"@"NSData"@"NSError">32
v32@0:8@"NSURL"16@?<v@?@"NSError">24
@40@0:8@16@24@32
@"<NviAssetsProvider>"
@"NSMapTable"
@"<CSVoiceTriggerDelegate>"
B48@0:8Q16Q24@32^@40
v24@0:8@"<CSAudioSessionProvidingDelegate>"16
B48@0:8Q16Q24@"NSString"32^@40
@40@0:8@16@24^@32
B40@0:8@16@24^@32
@32@0:8Q16Q24
v40@0:8Q16Q24@32
v32@0:8Q16@24
@32@0:8@16d24
B32@0:8@"CSAudioRecordContext"16^@24
@"CSAudioStream"40@0:8@"CSAudioStreamRequest"16@"NSString"24^@32
v40@0:8@"CSAudioStreamRequest"16@"NSString"24@?<v@?@"CSAudioStream"@"NSError">32
B40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24^@32
v40@0:8@"CSAudioStream"16@"CSAudioStreamRequest"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStartStreamOption"24@?<v@?B@"NSError">32
v40@0:8@"CSAudioStream"16@"CSAudioStopStreamOption"24@?<v@?B@"NSError">32
@"CSAudioChunk"32@0:8Q16Q24
@"CSAudioChunk"24@0:8Q16
v40@0:8Q16Q24@"NSURL"32
v32@0:8Q16@"NSURL"24
@"CSAudioStreamHolding"32@0:8@"NSString"16d24
v24@0:8@"CSAudioStreamHolding"16
@"CSAudioRecordDeviceInfo"16@0:8
@"NSDictionary"16@0:8
v24@0:8@"<CSAudioAlertProvidingDelegate>"16
B32@0:8@"NSURL"16q24
v24@0:8@"<CSAudioSessionInfoProvidingDelegate>"16
v32@0:8@"CSAudioRecordContext"16@?<v@?@"NSDictionary"@"NSDictionary">24
@"<CSAudioSessionProvidingDelegate>"
@"<CSAudioStreamProvidingDelegate>"
@"<CSAudioAlertProvidingDelegate>"
@"<CSXPCClientDelegate>"
@"NSMutableSet"
v40@0:8q16q24q32
@"<CSStateMachineDelegate>"
v20@0:8I16
v32@0:8@"NSDictionary"16@"NSString"24
v40@0:8@"NSDictionary"16@"NSString"24@?<v@?>32
v24@0:8@"NSData"16
v32@0:8@"CSAlarmMonitor"16q24
v32@0:8@"CSTimerMonitor"16q24
v28@0:8@16f24
v28@0:8@"CSVolumeMonitor"16f24
@28@0:8f16@20
@40@0:8Q16@24Q32
@"<CSConnectionServiceDelegate>"
@"<CSSmartSiriVolumeProcessor>"
@36@0:8@16f24Q28
@52@0:8Q16@24@32f40Q44
@48@0:8Q16@24@32Q40
v28@0:8Q16B24
v40@0:8@16Q24@?32
v40@0:8@16@?24@?32
@40@0:8@16Q24@32
v32@0:8^@16Q24
@36@0:8@16@24B32
v36@0:8@16C24@28
v52@0:8@16Q24@32Q40I48
@"<CSAudioDecoderDelegate>"
v48@0:8@16@24@32@?40
v32@0:8q16Q24
B84@0:8@16f24{AudioStreamBasicDescription=dIIIIIIII}28@?68@?76
@24@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16
@28@0:8@16I24
^{OpaqueAudioConverter=}16@0:8
v24@0:8^{OpaqueAudioConverter=}16
^{AudioBufferList=I[1{AudioBuffer=II^v}]}16@0:8
v24@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16
@"CSAudioInjectionFileOption"
^{AudioBufferList=I[1{AudioBuffer=II^v}]}
@"<CSVoiceTriggerAssetChangeDelegate>"
v32@0:8r^v16q24
v44@0:8@16B24@28@36
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
v28@0:8@"CSFirstUnlockMonitor"16B24
@"CSAsset"
v52@0:8@16@24B32@36@44
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioRecordContext"24@"CSAudioStartStreamOption"32
v52@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioRecordContext"24B32@"CSAudioStartStreamOption"36@"NSString"44
v32@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24
v40@0:8@"CSSiriClientBehaviorMonitor"16@"CSAudioStopStreamOption"24@"NSString"32
v44@0:8@"CSSiriClientBehaviorMonitor"16B24@"NSString"28@"CSAudioRecordContext"36
v32@0:8i16@20B28
@28@0:8Q16B24
S28@0:8^f16i24
s16@0:8
v20@0:8s16
C16@0:8
v20@0:8C16
Q24@0:8@16
d24@0:8@16
v36@0:8B16@20d28
q24@0:8Q16
@"<CSSmartSiriVolumeControllerDelegate>"
@"CSSmartSiriVolumeClient"
v64@0:8@16@24@32B40Q44@52B60
@"<CSADCompanionServiceProvider>"
@"<CSVoiceTriggerAwareZeroFilterDelegate>"
@"CSAudioZeroFilter"
@20@0:8i16
@28@0:8@16i24
@28@0:8I16@20
@"CSNovDetector"
@"<CSKeywordAnalyzerNDAPIScoreDelegate>"
@44@0:8Q16Q24f32f36f40
@56@0:8d16@24q32@40@48
v32@0:8@"CSMediaPlayingMonitor"16q24
v28@0:8@"CSSiriEnabledMonitor"16B24
@28@0:8f16@"CSAsset"20
v24@0:8@"CSAsset"16
@"CSSmartSiriVolumeEstimate"40@0:8Q16@"NSNumber"24Q32
v28@0:8I16q20
v52@0:8@16q24B32Q36Q44
f24@0:8q16
f24@0:8f16f20
f20@0:8f16
f36@0:8f16f20f24f28f32
f44@0:8f16f20f24f28f32f36f40
f28@0:8f16f20f24
^f24@0:8@16
{unique_ptr<SmartSiriVolume, std::__1::default_delete<SmartSiriVolume> >="__ptr_"{__compressed_pair<SmartSiriVolume *, std::__1::default_delete<SmartSiriVolume> >="__value_"^{SmartSiriVolume}}}
{vector<float, std::__1::allocator<float> >="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::__1::allocator<float> >="__value_"^f}}
@"NSUserDefaults"
@"CSSmartSiriVolumeEnablePolicy"
B32@0:8d16^@24
@"<CSRemoteControlClientDelegate>"
@64@0:8@16@24@32@40@48@56
@"NSData"
{AudioStreamBasicDescription=dIIIIIIII}24@0:8f16I20
v24@0:8@"<CSVTUIAudioSessionDelegate>"16
v24@0:8@"<Endpointer>"16
@"<CSVTUIAudioSessionDelegate>"
@"<CSRemoteRecordClientDelegate>"
v24@0:8@"<NviDataReceiver>"16
@"NviContext"
{unique_ptr<BatchBeepCanceller, std::__1::default_delete<BatchBeepCanceller> >="__ptr_"{__compressed_pair<BatchBeepCanceller *, std::__1::default_delete<BatchBeepCanceller> >="__value_"^{BatchBeepCanceller}}}
{vector<short, std::__1::allocator<short> >="__begin_"^s"__end_"^s"__end_cap_"{__compressed_pair<short *, std::__1::allocator<short> >="__value_"^s}}
@"<CSBeepCancellerDelegate>"
@32@0:8q16Q24
@32@0:8d16Q24
d24@0:8[80s]16
v64@0:8Q16Q24@32@40@48@?56
v32@0:8@"NSString"16@?<v@?@"NSString"@"NSString"@"NSError">24
v64@0:8Q16Q24@"NSString"32@"NSArray"40@"NSArray"48@?<v@?@"CSVoiceTriggerRTModel"@"CSVoiceTriggerRTModel"@"NSError">56
v40@0:8@"NSArray"16@"NSString"24@?<v@?@"NSString"@"NSError">32
v48@0:8Q16@24@32@?40
v24@0:8@"CSLSWakeGesture"16
v32@0:8Q16@"NSDate"24
@"CSLSWakeGestureMonitor"
@36@0:8Q16S24d28
Q40@0:8@16Q24^@32
Q24@0:8^@16
{unique_ptr<CSAudioZeroFilterImpl<unsigned short>, std::__1::default_delete<CSAudioZeroFilterImpl<unsigned short> > >="__ptr_"{__compressed_pair<CSAudioZeroFilterImpl<unsigned short> *, std::__1::default_delete<CSAudioZeroFilterImpl<unsigned short> > >="__value_"^{CSAudioZeroFilterImpl<unsigned short>}}}
B32@0:8@16@?24
Vv24@0:8@?16
Vv40@0:8@16q24@?32
Vv24@0:8@?<v@?@"NSString">16
Vv40@0:8@"NSArray"16q24@?<v@?@"NSError">32
Vv24@0:8@?<v@?Q>16
Vv24@0:8@?<v@?>16
Vv24@0:8@?<v@?B>16
Vv24@0:8@?<v@?q>16
@32@0:8Q16f24f28
v32@0:8r^v16Q24
v40@0:8r^v16Q24Q32
@24@0:8^Q16
{unique_ptr<corespeech::CSAudioCircularBufferImpl<unsigned short>, std::__1::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned short> > >="__ptr_"{__compressed_pair<corespeech::CSAudioCircularBufferImpl<unsigned short> *, std::__1::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned short> > >="__value_"^{CSAudioCircularBufferImpl<unsigned short>}}}
v36@0:8@16@24B32
B36@0:8@16@24B32
B44@0:8@16@24Q32B40
B28@0:8@16B24
@28@0:8f16i20f24
{unique_ptr<corespeech::CSAudioCircularBufferImpl<unsigned char>, std::__1::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned char> > >="__ptr_"{__compressed_pair<corespeech::CSAudioCircularBufferImpl<unsigned char> *, std::__1::default_delete<corespeech::CSAudioCircularBufferImpl<unsigned char> > >="__value_"^{CSAudioCircularBufferImpl<unsigned char>}}}
@"CSAudioStreamRequest"
@"CSAudioStartStreamOption"
@72@0:8q16q24d32@40d48@56q64
@64@0:8q16q24d32@40d48@56
@"CSActivationEvent"
v64@0:8@16Q24Q32@40@48@?56
@48@0:8@16@24@32@40
v32@0:8@"MCProfileConnection"16@"NSDictionary"24
v40@0:8@"CSAudioPreprocessor"16@"NSData"24Q32
B32@0:8Q16q24
@"<CSAudioProviderDelegate>"
@"CSAudioPreprocessor"
@"CSOSTransaction"
@72@0:8@16Q24Q32Q40Q48Q56@64
@28@0:8f16Q20
@40@0:8Q16Q24Q32
v40@0:8Q16Q24@?32
I24@0:8Q16
@48@0:8q16@24@32@40
Q20@0:8f16
d24@0:8Q16
Q40@0:8Q16Q24Q32
v40@0:8@16d24@32
v32@0:8@"<CSEndpointAnalyzer>"16d24
v40@0:8@"<CSEndpointAnalyzer>"16d24@"CSEndpointerMetrics"32
v32@0:8@"<CSEndpointAnalyzerImpl>"16d24
v48@0:8Q16@24@32@40
@"<CSEndpointAnalyzerImpl>"
@"<CSCATAssetManagerDelegate>"
v32@0:8r^s16i24i28
v32@0:8r^f16i24i28
v28@0:8i16i20i24
v24@0:8^d16
@"CSAudioUnitMeterClipping"
v44@0:8B16@20@28@36
@"<CSSPGEndpointAnalyzerDelegate>"
@"NSSet"
@56@0:8@16Q24Q32Q40@48
@"<CSStartOfSpeechDetectorDelegate>"
@"<CSVoiceTriggerXPCClientDelegate>"
v28@0:8r^s16i24
@"<CSKeywordAnalyzerQuasarScoreDelegate>"
@44@0:8@16B24@28@36
v28@0:8@"CSOpportuneSpeakListener"16B24
@"CSOpportuneSpeakListener"
@40@0:8Q16@24@32
@48@0:8@16@24@32Q40
@"<CSAudioConverterDelegate>"
v28@0:8B16Q20
v48@0:8Q16Q24Q32@?40
v48@0:8@16@24Q32@?40
@40@0:8d16d24d32
Q40@0:8@16@24@32
f20@0:8B16
@20@0:8B16
@"CSKeywordAnalyzerNDAPIResult"
@"CSVTSecondPassPhraseScore"
v36@0:8@16B24@28
v28@0:8@16i24
v36@0:8@16i24d28
v36@0:8@16i24@28
v28@0:8@"AVVoiceController"16B24
v36@0:8@"AVVoiceController"16B24@"NSError"28
v32@0:8@"AVVoiceController"16q24
v24@0:8@"AVVoiceController"16
v28@0:8@"AVVoiceController"16i24
v36@0:8@"AVVoiceController"16i24d28
v32@0:8@"AVVoiceController"16@"NSError"24
v36@0:8@"AVVoiceController"16i24@"NSError"28
v40@0:8@"AVVoiceController"16@"AVVCAlertInformation"24@"NSError"32
v32@0:8@"AVVoiceController"16@"NSDictionary"24
v32@0:8@"AVVoiceController"16@"AVVCAudioBuffer"24
v28@0:8B16@"NSArray"20
v44@0:8@"AVVoiceController"16Q24B32@"NSError"36
v40@0:8@"AVVoiceController"16Q24q32
v40@0:8@"AVVoiceController"16Q24@"AVVCAudioBuffer"32
v32@0:8@"AVVoiceController"16Q24
v40@0:8@"CSAudioFileReader"16@"NSData"24Q32
v36@0:8@"CSAudioFileReader"16B24@"NSError"28
v32@0:8@"CSAudioFileReader"16q24
v24@0:8@"<CSAudioServerCrashEventProvidingDelegate>"16
v24@0:8@"<CSAudioSessionEventProvidingDelegate>"16
v48@0:8@16Q24@32Q40
v36@0:8B16Q20@28
@"AVVoiceController"
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
@"CSRemoteRecordClient"
@"CSAudioFileReader"
@"<CSAudioServerCrashEventProvidingDelegate>"
@"<CSAudioSessionEventProvidingDelegate>"
@"NSNumber"
v48@0:8@16@24@32@40
v52@0:8@16@24@32B40@44
v48@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioRecordContext"24@"NSString"32@"CSAudioStartStreamOption"40
v52@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioRecordContext"24@"NSString"32B40@"CSAudioStartStreamOption"44
v32@0:8@"CSOpportuneSpeakBehaviorMonitor"16@"CSAudioStopStreamOption"24
@"NSObject<OS_os_transaction>"
supo
ciov
cvdh
cvpc
mcpl
supo
xeps
333333
333333
