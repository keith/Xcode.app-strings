@(#)PROGRAM:Translation  PROJECT:Translation-111.5
@mcpl
hash
TQ,R
superclass
T#,R
description
T@"NSString",R,C
debugDescription
delegate
T@"<_LTSpeechTranslationDelegate>",W,N,V_delegate
com.apple.translation.powerlog
sentence
singleParagraph
paragraphs
text-to-speech
speech
preheat
text-LID
v8@?0
loggerQueue
T@"NSObject<OS_dispatch_queue>",&,N,V_loggerQueue
requestTypeSet
T@"NSOrderedSet",&,V_requestTypeSet
__unknown__
localeDetectionCount
unsupportedLanguageCount
dominantLocale
LTTextLanguageDetectionResult.m
Invalid parameter not satisfying: %@
locales
languages
supportsSecureCoding
TB,R
T@"NSLocale",R,C,N,V_dominantLocale
T@"NSCountedSet",R,C,N,V_localeDetectionCount
unsupportedLanguageCounts
T@"NSCountedSet",R,C,N,V_unsupportedLanguageCounts
com.apple.translation.daemon.listener
DisambiguationEnabled
com.apple.translationd
uniqueID
sessionID
taskHint
localePair
autodetectLanguage
autoEndpoint
sensorSpeech
outputFileURL
asrModelURLs
mtModelURL
route
audioSessionID
lidThreshold
asrConfidenceThreshold
sourceURL
T@"NSString",C,N,V_uniqueID
T@"NSString",C,N,V_sessionID
Tq,N,V_taskHint
T@"_LTLocalePair",C,N,V_localePair
TB,N,V_autodetectLanguage
censorSpeech
TB,N,V_censorSpeech
T@"NSURL",C,N,V_outputFileURL
T@"NSArray",C,N,V_asrModelURLs
T@"NSURL",C,N,V_mtModelURL
T@"NSURL",C,N,V_sourceURL
TB,N,V_autoEndpoint
Tq,N,V_lidThreshold
Tq,N,V_route
TI,N,V_audioSessionID
Tq,N,V_asrConfidenceThreshold
clientIdentifier
T@"NSString",&,N,V_clientIdentifier
dataSharingOptInStatus
Tq,N,V_dataSharingOptInStatus
zh-Hant
zh_TW
zh-Hans
zh_CN
dominantLanguage
confidences
isConfident
isFinal
T@"NSLocale",C,N,V_dominantLanguage
T@"NSDictionary",C,N,V_confidences
TB,R,N,V_isConfident
TB,N,V_isFinal
com.apple.translation.lid.result
samplingRate
Td,R,N,V_samplingRate
audioBitDepth
Tq,R,N,V_audioBitDepth
TranslationErrorDomain
InternalTranslationErrorDomain
LTRemoteFailure
unknown error
Remote service failure
Online translation not implemented
Cannot force both online and offline
Failed to load LID model
Translation ongoing already
Speech translation already ongoing
Speech duration limit exceeded
Translation server did not respond in time.
Offline TTS failed
Translation from %@ to %@ is not supported.
completion
T@?,C,N,V_completion
paragraph
T@"_LTTranslationParagraph",&,N,V_paragraph
requestParagraph
T@"FTMutableBatchTranslationRequest_Paragraph",&,N,V_requestParagraph
request_id
hasFinalServerResponse
completionHandlerCalled
Missing Batch Translation Responses
request
T@"FTMutableBatchTranslationRequest",&,N,V_request
toLocale
T@"NSLocale",&,N,V_toLocale
metricEvent
T@"LTSchemaBatchTranslationEvent",&,N,V_metricEvent
batchedParagraphs
T@"NSMutableDictionary",&,N,V_batchedParagraphs
bufferSize
TQ,N,V_bufferSize
sourceLocale
T@"NSLocale",&,N,V_sourceLocale
targetLocale
T@"NSLocale",&,N,V_targetLocale
requestID
T@"NSString",&,N,V_requestID
T@"NSString",&,N,V_sessionID
startTime
T@"NSDate",&,N,V_startTime
T@"NSURL",&,N,V_sourceURL
TB,N,V_hasFinalServerResponse
TB,N,V_completionHandlerCalled
com.apple.Translation
OnlineTranslationEngine
com.apple.translation.online-queue
com.apple.translation.server-timer
v24@?0@"NSError"8q16
com.apple.Translate
com.apple.mobilesafari
v16@?0@"OspreyMutableRequest"8
v24@?0@"FTTextToSpeechResponse"8@"NSError"16
v24@?0@"FTTranslationResponse"8@"NSError"16
%@/%08ld
@"FTSpan"16@?0@"_LTTranslationSpan"8
v16@?0@"NSError"8
sentenceCount
v24@?0@"_LTTranslationResult"8@"NSError"16
Translation failed
Translation input was empty
v32@?0@"_LTTranslationParagraph"8Q16^B24
ttsCache
T@"_LTTextToSpeechCache",&,N,V_ttsCache
default
LastOfflineAssetCatalogUpdate
LastOfflineAssetUpdate
LastConfigAssetUpdate
OspreyEndpointURL
DeviceSessionID
BatchingMaxParagraphs
BatchingMaxParagraphBufferSize
BatchingMaxParagraphBufferTimeout
ASRConfidenceThresholds
ASRWordLevelConfidenceThreshold
LanguageDetectorConfidenceThreshold
EnableHybridEndpointer
HybridEndpointerThreshold
DisconnectedHybridEndpointerThreshold
HybridEndpointerClientLagThreshold
HybridEndpointerClampedLatencyForClientLag
HybridEndpointerUseDefaultFeaturesOnClientLag
LotteryNumber
ServerSpeechSessionInitialOnlineTimeout
ServerSpeechSessionOnlineTimeout
ServerSpeechSessionOnlineEndpointTimeout
Configuration
SupportedRegions
asr_languages
_all
@"NSLocale"16@?0@"NSString"8
LanguagePairs
web.online
mt_app.online
@"_LTLocalePair"16@?0@"NSString"8
AdditionalLanguages
WebTaskIsSupportedInCountry
https://guzzoni.apple.com
https://seed.siri.apple.com
https://carry.siri.apple.com
asbd
T{AudioStreamBasicDescription=dIIIIIIII},R,N,V_asbd
rawData
T@"NSData",R,N,V_rawData
packetCount
Tq,R,N,V_packetCount
packetDescriptions
T@"NSData",R,N,V_packetDescriptions
wordCount
trailingSilence
eosLikelihood
pauseCounts
silencePosterior
processedAudio
Tq,N,V_wordCount
trailingSilenceDuration
Tq,N,V_trailingSilenceDuration
Td,N,V_eosLikelihood
T@"NSArray",C,N,V_pauseCounts
Td,N,V_silencePosterior
processedAudioDurationInMilliseconds
Tq,N,V_processedAudioDurationInMilliseconds
com.apple.siri.translation.HEP
com.apple.siri.translation.HEP.features
endpointerThreshold
T@"NSDictionary",C,N,V_endpointerThreshold
Tq,R,N,V_samplingRate
clientLagThresholdMs
Td,N,V_clientLagThresholdMs
clampedSFLatencyMsForClientLag
Td,N,V_clampedSFLatencyMsForClientLag
useDefaultServerFeaturesOnClientLag
TB,N,V_useDefaultServerFeaturesOnClientLag
identifier
sourceRange
targetRange
text
T{_NSRange=QQ},N,V_sourceRange
T{_NSRange=QQ},N,V_targetRange
T@"NSString",C,N,V_identifier
T@"NSString",C,N,V_text
com.apple.translationd.playback
Translation
v24@?0@"_LTAudioData"8@"NSError"16
deviceOS
deviceType
appIdentifier
T@"NSString",R,C,N,V_sessionID
Tq,R,N,V_taskHint
T@"_LTLocalePair",R,C,N,V_localePair
T@"NSString",R,C,N,V_deviceOS
T@"NSString",R,C,N,V_deviceType
T@"NSString",R,C,N,V_appIdentifier
Languages
Footprint
Premium
hybridendpointer.json
hybridepAssetFile
T@"NSString",R,N,V_hybridepAssetFile
spgAssetFile
T@"NSString",R,N,V_spgAssetFile
T@"NSString",&,N,V_text
completionHandler
T@?,C,N,V_completionHandler
AssetVersion
_LTSpeechTranslationAssetInfo
%@ <-> %@ | %@ %@
config-lq
config
asset_list
AssetName
assets.json
mt-quasar-config.json
inputTokenCount
inputSubtokenCount
firstleg sentencepiece encoder input
sentencepiece encoder input
firstleg sentencepiece encoder output
sentencepiece encoder output
Tq,N,V_inputTokenCount
Tq,N,V_inputSubtokenCount
undefined
loggingType
T@"NSString",R,N
T@"_LTLocalePair",R,N,V_localePair
T@"NSURL",&,N,V_outputFileURL
forcedOfflineTranslation
TB,N,V_forcedOfflineTranslation
_forcedOnlineTranslation
TB,N,V__forcedOnlineTranslation
_offlineMTModelURL
T@"NSURL",&,N,V__offlineMTModelURL
_mtConfidenceThreshold
Tq,N,V__mtConfidenceThreshold
T@"NSString",C,N,V_sentence
textHandler
T@?,C,N,V_textHandler
translationHandler
T@?,C,N,V_translationHandler
batch
LTTranslationRequest.m
This is deprecated
T@"NSArray",C,N,V_paragraphs
TranslationRequest
com.apple.siri.translation.speechrequest
@"AVAudioBuffer"20@?0I8^q12
Could not drain converter %@
Could not run audio converter %@
_lidModelURL
T@"NSURL",&,N,V__lidModelURL
_offlineASRModelURLs
T@"NSArray",&,N,V__offlineASRModelURLs
_asrConfidenceThreshold
Tq,N,V__asrConfidenceThreshold
_lidThreshold
Tq,N,V__lidThreshold
textToSpeech
CMBlockBufferCopyDataBytes could not copy data: %d
SELF != ''
v40@?0{_NSRange=QQ}8Q24^B32
DeviceName
 Simulator
ProductName
ProductType
BuildVersion
ProductVersion
+N9mZUAHooNvMiQnjeTJ8g
siri
app_review
mt_app
InternalBuild
ar_AE
ar_SA
com.apple.translation.tts-cache
LTTextToSpeechCache.m
MISS
com.apple.MobileAsset.SpeechTranslationAssets
com.apple.MobileAsset.SpeechEndpointAssets
AssetManager
com.apple.Translator.EMTAssetManager
v16@?0q8
v12@?0B8
plist
mt_app.offline
q24@?0@"_LTLocalePair"8@"_LTLocalePair"16
@16@?0@"_LTLocalePair"8
TranslationAssetDownloadDomain
_DownloadSize
v16@?0@"MAProgressNotification"8
MADownLoadResult
Mobile asset failed to download.
Beta voice not found for %@:%@
Beta voice downloaded for %@:%@
Downloading beta voice %@:%@, progress: %.2f remainingTime: %.f
v20@?0d8f16
v16@?0@"NSArray"8
Assets
TranslationAssetQueryDomain
Type
RequiredCapabilityIdentifier
Configuration asset is missing.
The Configuration asset has not yet been downloaded.
Missing asset entitlement
LanguageDetectorDefaultAsset
profile_blob
profile_blob_version
profile_checksum
T@"NSData",C,N
T@"NSString",C,N
acoustic_profile_version
acoustic_profile_blob
token_text
start_milli_seconds
end_milli_seconds
silence_start_milli_seconds
confidence
add_space_after
phone_seq
ipa_phone_seq
Ti,N
TB,N
tokens
T@"NSArray",C,N
tok_phrases
has_unsuggested_alternatives
positional_tok_phrase_alt
alternative_index
itn_alignment
post_itn_choice_indices
pre_itn_token_to_post_itn_char_alignments
pre_itn
post_itn
pre_itn_nbest_choices
post_itn_nbest_choices
pre_itn_token_to_post_itn_char_alignment
choice_alignments
T@"FTRecognitionSausage",C,N
bool_stats
int32_stats
double_stats
language
speech_id
request_locale
name
value
Td,N
first_pre_itn_token_index
last_pre_itn_token_index
first_post_itn_char_pos
last_post_itn_char_pos
acoustic_feature_per_frame
frame_duration
Tf,N
speech_recognition_features
acoustic_features
T@"FTAcousticFeature",C,N
session_id
return_code
return_str
recognition_result
lang_profile_recreate_codes
audio_analytics
watermark_detection
watermark_peak_average
latnn_mitigator_result
has_result
T@"FTRecognitionResult",C,N
Tq,N
T@"FTAudioAnalytics",C,N
T@"FTLatnnMitigatorResult",C,N
recognition_text
is_stable_result
audio_duration_ms
task_name
codec
stream_results
enable_server_side_endpoint
device_type
device_os
mic_type
udm_host
udm_port
tandem_mode
store_audio
stream_unstable_results
end_point_mode
start_audio_bookmark
is_far_field
enable_utterance_detection
enable_endpoint_candidate
start_recognition_at
start_endpointing_at
enable_hybrid_endpoint
client_endpointer_model_version
keyboard_identifier
input_origin
initial_recognition_candidate_id
disable_auto_punctuation
keyboard_dictation
experiment_id
speech_request_source
fork_id
application_name
metadata
TQ,N
TI,N
start_speech_request
user_parameters
primary_speech_id
T@"FTStartSpeechRequest",C,N
product_id
vendor_id
contextual_text
pron_hints
left_context
right_context
context_with_pron_hints
user_language_profile
user_acoustic_profile
T@"FTUserLanguageProfile",C,N
T@"FTUserAcousticProfile",C,N
audio_bytes
packet_count
total_audio_recorded_seconds
features_at_endpoint
server_feature_latency_distribution
updated_acoustic_profile
orthography
pronunciations
frequency
attributes
category_name
category_data
user_data
error_code
error_str
incomplete_profile
recreate_apg_prons
reason
phonemes
blob
apg_id
voc_token
tts_pronunciations
human_readable_prons
T@"FTVocToken",C,N
apg_ids
recovery_return_codes
voc_tokens
num_of_requested
num_of_processed
num_of_succeeded
words_list
formatted_words_list
post_itn_string
nbest_variants_max
normalized_tokens
original_token
nbest_variants
pron_sequence
log_weight
token
pron_source
sanitized_sequences
prons
normalized_prons
sanitized_tokens
T@"FTContextWithPronHints",C,N
is_pron_guessed
g2p_version
g2p_model_version
phoneset_version
aot_token_prons
jit_token_prons
index
start_index
end_index
do_not_translate
span
raw_sausage
raw_nbest_choices
post_itn_tokens
post_itn_recognition
itn_alignments
translation_phrase
pre_itn_payload
post_itn_payload
pre_sausage_payload
spans
task
source_language
target_language
siri_translation_info
speech_translation_info
siri_payload_translation_info
sequence_id
web_translation_info
disable_log
opt_in_status
app_id
T@"FTSiriTranslationInfo",C,N
T@"FTSpeechTranslationInfo",C,N
T@"FTSiriPayloadTranslationInfo",C,N
T@"FTWebTranslationInfo",C,N
return_string
n_best_translated_phrases
engine_input
engine_output
mt_alignment
T@"FTAlignment",C,N
translated_tokens
meta_info
low_confidence
end_point_likelihood
processed_audio_duration_ms
latitude
longitude
enable_geo_location_features
speech_packet_count
processed
version
threshold
score
result_id
fingerprint_detection
start_speech_time
end_speech_time
speech_detected
audio_packets
ref_transcript
blamer_report
token_str
log10_score
ngram_used
transcript
enable_completion
max_results
max_expand_paths
max_tm_score
abs_pruning_threshold
rel_pruning_threshold
enable_word_boundary
max_path_num_at_boundary
parabolic_error_wide
parabolic_error_center
parabolic_error_bias
parabolic_error_min
max_latency
word_penalty
delimiter
matched_result
total_score
tm_score
match_ids
debug_information
matcher_id
query
target
T@"FTAStarFuzzyMatchingConfig",C,N
latency
expanded_path
results
keyword_orthography
posterior
keywords
enable_sanitization
corrected_sausage
n_best_list
num_of_words
trailing_silence_duration
eos_likelihood
pause_counts
silence_posterior
original_utterance
corrected_utterance
original_words
corrected_words
corrections
fe_feature
fe_feature_only
gender
quality
type
voice
resource
T@"FTTextToSpeechVoice",C,N
T@"FTTextToSpeechResource",C,N
channel_type
context_info
dialog_identifier
experiment_identifier
normalized_text
phoneme_sequence
audio_type
enable_word_timing_info
voice_name
preferred_voice_type
context
experiment
feature_flags
T@"FTTextToSpeechRequestMeta",C,N
T@"FTTextToSpeechRequestContext",C,N
T@"FTTextToSpeechRequestExperiment",C,N
T@"FTTTSRequestFeatureFlags",C,N
sample_rate
format_id
format_flags
bytes_per_packet
frames_per_packet
bytes_per_frame
channels_per_frame
bits_per_channel
reserved
word
sample_idx
offset
length
timestamp
audio
decoder_description
playback_description
word_timing_info
feature
T@"FTAudioDescription",C,N
T@"FTTextToSpeechMeta",C,N
T@"FTTextToSpeechFeature",C,N
stream_id
streaming_playback_buffer_size_in_seconds
current_pkt_number
total_pkt_number
audio_length
original_session_id
cache_meta_info
cache_object
T@"FTTextToSpeechCacheMetaInfo",C,N
endpoint_threshold
endpoint_extra_delay
audio_frames
source_locale
target_locale
conversation_id
translation_locale_pairs
translation_request
text_to_speech_requests
restricted_mode
T@"FTTranslationRequest",C,N
translation_locale_pair
detected_locale
user_selected_locale
senses
user_selected_sense
user_interacted_senses
T@"FTTranslationLocalePair",C,N
T@"FTLanguageDetected",C,N
text_to_speech_response
T@"FTTextToSpeechResponse",C,N
server_endpoint_features
T@"FTServerEndpointFeatures",C,N
saliency
tags
label
matchers
is_variable_match
is_user_vocabulary
is_app_vocabulary
is_entity_name_node
is_entity_reference_node
begin
match_type
speech_alternate
semantic
dbpedia_classes
matching_tokens
is_salient
is_derived
matched_token_index
utterance
interaction_id
locale
input
output
meta_infos
example_id
debug_info
T@"FTDebugInfo",C,N
predictions
ner_score
global_neu_score
nen_all_spans_aggregate_score
ner_alternative_index
entity_type
ner_entity_confidence_score
nen_title
nen_id
nen_entity_match_score
start_token_position
end_token_position
position
metrics_info
positional_features
global_features
span_feature_indices
word_embeddings
char_embeddings
raw_instance_str
neu_request
T@"FTMetricsInfo",C,N
T@"FTNeuRequest",C,N
features
indices
values
shortcuts
T@"FTShortcutFuzzyMatchRequest_StringTokenPair",C,N
raw_string
shortcut_score_pairs
shortcut
similarity_score
language_parameters_by_id
is_low_confidence
paragraph_id
translated_text
content_type
content
contentAsFTStartPronGuessRequest
T@"FTStartPronGuessRequest",C,N
contentAsFTAudioPacket
T@"FTAudioPacket",C,N
contentAsFTFinishAudio
T@"FTFinishAudio",C,N
contentAsFTCancelRequest
T@"FTCancelRequest",C,N
contentAsFTPronGuessResponse
T@"FTPronGuessResponse",C,N
contentAsFTStartBatchRecoverRequest
T@"FTStartBatchRecoverRequest",C,N
contentAsFTBatchRecoverFinalResponse
T@"FTBatchRecoverFinalResponse",C,N
contentAsFTStartSpeechRequest
contentAsFTUpdateAudioInfo
T@"FTUpdateAudioInfo",C,N
contentAsFTSetRequestOrigin
T@"FTSetRequestOrigin",C,N
contentAsFTSetSpeechContext
T@"FTSetSpeechContext",C,N
contentAsFTSetSpeechProfile
T@"FTSetSpeechProfile",C,N
contentAsFTSetEndpointerState
T@"FTSetEndpointerState",C,N
contentAsFTResetServerEndpointer
T@"FTResetServerEndpointer",C,N
contentAsFTCheckForSpeechRequest
T@"FTCheckForSpeechRequest",C,N
contentAsFTSetAlternateRecognitionSausage
T@"FTSetAlternateRecognitionSausage",C,N
contentAsFTFinalSpeechRecognitionResponse
T@"FTFinalSpeechRecognitionResponse",C,N
contentAsFTPartialSpeechRecognitionResponse
T@"FTPartialSpeechRecognitionResponse",C,N
contentAsFTUpdatedAcousticProfile
T@"FTUpdatedAcousticProfile",C,N
contentAsFTEndPointLikelihood
T@"FTEndPointLikelihood",C,N
contentAsFTEndPointCandidate
T@"FTEndPointCandidate",C,N
contentAsFTRecognitionProgress
T@"FTRecognitionProgress",C,N
contentAsFTCheckForSpeechResponse
T@"FTCheckForSpeechResponse",C,N
contentAsFTRecognitionCandidate
T@"FTRecognitionCandidate",C,N
contentAsFTRequestStatsResponse
T@"FTRequestStatsResponse",C,N
contentAsFTServerEndpointFeatures
contentAsFTClientSetupInfo
T@"FTClientSetupInfo",C,N
contentAsFTAudioLimitExceeded
T@"FTAudioLimitExceeded",C,N
contentAsFTMultiUserStartSpeechRequest
T@"FTMultiUserStartSpeechRequest",C,N
contentAsFTFinalBlazarResponse
T@"FTFinalBlazarResponse",C,N
contentAsFTStartMultilingualSpeechRequest
T@"FTStartMultilingualSpeechRequest",C,N
contentAsFTLanguageDetected
contentAsFTStartSpeechTranslationRequest
T@"FTStartSpeechTranslationRequest",C,N
contentAsFTSpeechTranslationAudioPacket
T@"FTSpeechTranslationAudioPacket",C,N
contentAsFTStartSpeechTranslationLoggingRequest
T@"FTStartSpeechTranslationLoggingRequest",C,N
contentAsFTSpeechTranslationPartialRecognitionResponse
T@"FTSpeechTranslationPartialRecognitionResponse",C,N
contentAsFTSpeechTranslationFinalRecognitionResponse
T@"FTSpeechTranslationFinalRecognitionResponse",C,N
contentAsFTSpeechTranslationMtResponse
T@"FTSpeechTranslationMtResponse",C,N
contentAsFTSpeechTranslationTextToSpeechResponse
T@"FTSpeechTranslationTextToSpeechResponse",C,N
contentAsFTSpeechTranslationServerEndpointFeatures
T@"FTSpeechTranslationServerEndpointFeatures",C,N
contentAsFTBatchTranslationRequest
T@"FTBatchTranslationRequest",C,N
contentAsFTBatchTranslationResponse
T@"FTBatchTranslationResponse",C,N
contentAsFTStartTextToSpeechStreamingRequest
T@"FTStartTextToSpeechStreamingRequest",C,N
contentAsFTBeginTextToSpeechStreamingResponse
T@"FTBeginTextToSpeechStreamingResponse",C,N
contentAsFTPartialTextToSpeechStreamingResponse
T@"FTPartialTextToSpeechStreamingResponse",C,N
contentAsFTFinalTextToSpeechStreamingResponse
T@"FTFinalTextToSpeechStreamingResponse",C,N
contentAsFTQssAckResponse
T@"FTQssAckResponse",C,N
contentAsFTStartLanguageDetectionRequest
T@"FTStartLanguageDetectionRequest",C,N
contentAsFTLanguageDetectionResponse
T@"FTLanguageDetectionResponse",C,N
Installed
Not Present
Downloading
Required by OS
Installed not in catalog
Installed with OS
Unknown
Unavailable
Unimplemented
%@ <-> %@ | pair: %@ MT: %@ ASR-%@ : %@ ASR-%@: %@ %@
Update
pair
pairState
sourceASRState
targetASRState
sourceTTSState
targetTTSState
mtState
needsUpdate
TQ,N,V_pairState
T@"_LTLocalePair",&,N,V_pair
T@"NSString",&,N,V_sourceASRState
T@"NSString",&,N,V_targetASRState
T@"NSString",&,N,V_mtState
T@"NSString",&,N,V_sourceTTSState
T@"NSString",&,N,V_targetTTSState
TB,N,V_needsUpdate
@"_LTTranslationToken"16@?0@"FTTranslationResponse_TranslationToken"8
com.apple.siri.translation.offline
@"_LTTranslationCandidate"16@?0@"EMTResult"8
sourceSentence
LTOfflineTranslationEngine.m
Missing result locale
bestConfidence
bestTranslation
@"NSString"16@?0@"_LTTranslationResult"8
v16@?0@"_LTTranslationResult"8
v24@?0@"NSString"8@?<v@?@@"NSError">16
v24@?0@"NSArray"8@"NSError"16
v24@?0@"_LTTranslationParagraph"8@?<v@?@@"NSError">16
mtStartTime
mtResultTime
mtLocale
mtBestConfidence
mtBestText
autodetect
v16@?0@"_LTSpeechRecognitionResult"8
asrResultTime
asrLocale
unknown
asrBestConfidence
asrBestText
v24@?0@"_LTSpeechRecognitionResult"8@"NSError"16
T@"_LTLocalePair",&,N,V_localePair
T@"NSArray",&,N,V_asrModelURLs
T@"NSURL",&,N,V_mtModelURL
male
female
com.apple.assistant.backedup
Output Voice
Gender
OfflineSpeechSynthesizer
@"_LTTranslationCandidate"16@?0@"FTSpeechTranslationMtResponse_TranslationPhrase"8
@"_LTTranslationCandidate"16@?0@"FTTranslationResponse_TranslationPhrase"8
q24@?0@"_LTAlignment"8@"_LTAlignment"16
MultilingualSpeechRecognizer
v32@?0@"NSLocale"8@"NSURL"16^B24
com.apple.multilingualrecognition.results
pbMatch
sense ID
definition
sourceMatch
source match
targetMatch
target match
@"_LTTranslationSense"16@?0@"NSObject"8
status
phrasebook_exact
phrasebookMatch
TB,N,GisPhrasebookMatch,V_phrasebookMatch
senseID
T@"NSString",C,N,V_senseID
T@"NSString",C,N,V_definition
T@"NSString",C,N,V_sourceMatch
T@"NSString",C,N,V_targetMatch
conversationID
selectedLocale
detectionResult
T@"NSString",C,N,V_conversationID
T@"NSString",C,N,V_requestID
T@"NSLocale",C,N,V_selectedLocale
T@"_LTLanguageDetectionResult",&,N,V_detectionResult
start
firstResponse
pageComplete
processName
timeToFirstResponse
timeToPageComplete
Td,R,N,V_start
Td,R,N,V_firstResponse
Td,R,N,V_pageComplete
T@"NSString",C,N,V_processName
dict
T@"NSDictionary",R,N
com.apple.translation.text
LTTranslationSession.m
v24@?0@"<_LTTranslationService>"8@?<v@?>16
requests
@"_LTTranslationParagraph"16@?0@"_LTParagraphTranslationRequest"8
feedback
translator
T@"_LTTranslator",&,N,V_translator
service
T@"<_LTTranslationService>",&,N,V_service
T@"NSURL",C,N,V_URL
FormatVersion
Language
Config
ASR-
LTTranslationRange.m
Invalid paramter: identifier is nil
T@"NSString",R,C,N,V_identifier
T@"NSString",R,C,N,V_text
shouldTranslate
TB,R,N,V_shouldTranslate
LTSpeechCompressor.m
Already started compressor
AudioConverterNew failed: %x
AudioConverterSetProperty/kAudioConverterEncodeBitRate failed: %x
Too many buffers
Cannot produce ASPD for PCM
i32@?0^I8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16^^{AudioStreamPacketDescription}24
range
T@"NSString",R,N,V_identifier
T{_NSRange=QQ},R,N,V_range
TB,N,V_shouldTranslate
translations
sourceString
sanitizedSourceString
alignments
NO_IDENTIFIER
T@"NSArray",C,N,V_translations
T@"NSLocale",C,N,V_locale
T@"NSString",C,N,V_sourceString
T@"NSString",C,N,V_sanitizedSourceString
T@"NSArray",C,N,V_alignments
@"NSString"16@?0@"_LTTranslationParagraph"8
com.apple.translation.combined
v32@?0@"NSString"8@"_LTTranslationResult"16@"NSError"24
offlineDelegateBuffer
T@"_LTSpeechTranslationResultsBuffer",&,N,V_offlineDelegateBuffer
offlineEngine
T@"<_LTTranslationEngine>",&,N,V_offlineEngine
onlineEngine
T@"<_LTTranslationEngine>",&,N,V_onlineEngine
com.apple.translation.async-map
v24@?0@8@"NSError"16
v32@?0@8Q16^B24
sourceContentAsJSONString
targetContentAsJSONString
T@"NSString",R,C,N,V_sourceContentAsJSONString
T@"NSString",R,C,N,V_targetContentAsJSONString
Translator
v16@?0@"<_LTTranslationService>"8
v16@?0@"NSDictionary"8
v16@?0@"_LTLanguageDetectionResult"8
v16@?0@"_LTTextLanguageDetectionResult"8
OfflineEngine
OnlineEngine
OfflineModelLoading
OfflineRecognizerLoading
ClientConnection
OfflineEtiquetteSanitizerLoading
OfflineTranslatorLoading
OfflineFormatterLoading
CombinedTranslation
XPC Server
Session
%@ %@ %@
node
T@"NSDictionary",&,N,V_node
T{_NSRange=QQ},N,V_range
T@"NSString",&,N,V_token
LTEtiquetteSanitizer
v32@?0@"NSString"8@16^B24
LTEtiquetteSanitizer.m
missing replacement tokens
etiquette.json
v56@?0@"NSString"8{_NSRange=QQ}16{_NSRange=QQ}32^B48
TOKEN
v32@?0@8@16^B24
com.apple.translation.speech
mini.json
ncs/dispatch.voc
ncs/lexicon.enh
ncs/itn_s.enh
MtApp
Empty recognition
No speech recognized
recognitionHandler
T@?,C,N,V_recognitionHandler
modelURL
T@"NSURL",R,N,V_modelURL
modelVersion
T@"NSString",R,N,V_modelVersion
T@"NSLocale",R,N,V_language
Error AudioQueueStart
state
Tq,R,N,V_state
com.apple.translationd.server
Offline models not available for language pair
engine
T@"<_LTTranslationEngine>",&,N,V_engine
T@"<_LTSpeechTranslationDelegate>",&,N,V_delegate
T@"NSUUID",&,N,V_sessionID
languageDetector
T@"_LTLanguageDetector",R,N,V_languageDetector
endpointer
T@"_LTHybridEndpointer",R,N,V_endpointer
formattedString
sanitizedFormattedString
lowConfidence
statistics
Td,N,V_confidence
TB,N,GisLowConfidence,V_lowConfidence
T@"NSArray",C,N,V_tokens
T@"NSString",C,N,V_formattedString
T@"NSString",C,N,V_sanitizedFormattedString
proToPostITN
T@"NSArray",C,N,V_proToPostITN
T@"NSArray",C,N,V_senses
T@"_LTTranslationStatistics",C,N,V_statistics
preToPostITN
T@"NSArray",R,N,V_preToPostITN
application-identifier
T@"<_LTClientConnectionDelegate>",W,N,V_delegate
QssRpc_immutable_generated.mm
Output Buffer is null
v20@?0r*8I16
v24@?0^v8Q16
T@"NSData",R,N
Ti,R,N
TB,R,N
T@"NSArray",R,N
T@"FTRecognitionSausage",R,N
Td,R,N
Tf,R,N
T@"FTAcousticFeature",R,N
T@"FTRecognitionResult",R,N
Tq,R,N
T@"FTAudioAnalytics",R,N
T@"FTLatnnMitigatorResult",R,N
TQ,R,N
TI,R,N
T@"FTStartSpeechRequest",R,N
T@"FTUserLanguageProfile",R,N
T@"FTUserAcousticProfile",R,N
T@"FTVocToken",R,N
T@"FTContextWithPronHints",R,N
T@"FTSiriTranslationInfo",R,N
T@"FTSpeechTranslationInfo",R,N
T@"FTSiriPayloadTranslationInfo",R,N
T@"FTWebTranslationInfo",R,N
T@"FTAlignment",R,N
T@"FTAStarFuzzyMatchingConfig",R,N
T@"FTTextToSpeechVoice",R,N
T@"FTTextToSpeechResource",R,N
T@"FTTextToSpeechRequestMeta",R,N
T@"FTTextToSpeechRequestContext",R,N
T@"FTTextToSpeechRequestExperiment",R,N
T@"FTTTSRequestFeatureFlags",R,N
T@"FTAudioDescription",R,N
T@"FTTextToSpeechMeta",R,N
T@"FTTextToSpeechFeature",R,N
T@"FTTextToSpeechCacheMetaInfo",R,N
T@"FTTranslationRequest",R,N
T@"FTTranslationLocalePair",R,N
T@"FTLanguageDetected",R,N
T@"FTTextToSpeechResponse",R,N
T@"FTServerEndpointFeatures",R,N
T@"FTDebugInfo",R,N
T@"FTMetricsInfo",R,N
T@"FTNeuRequest",R,N
T@"FTShortcutFuzzyMatchRequest_StringTokenPair",R,N
T@"FTStartPronGuessRequest",R,N
T@"FTAudioPacket",R,N
T@"FTFinishAudio",R,N
T@"FTCancelRequest",R,N
T@"FTPronGuessResponse",R,N
T@"FTStartBatchRecoverRequest",R,N
T@"FTBatchRecoverFinalResponse",R,N
T@"FTUpdateAudioInfo",R,N
T@"FTSetRequestOrigin",R,N
T@"FTSetSpeechContext",R,N
T@"FTSetSpeechProfile",R,N
T@"FTSetEndpointerState",R,N
T@"FTResetServerEndpointer",R,N
T@"FTCheckForSpeechRequest",R,N
T@"FTSetAlternateRecognitionSausage",R,N
T@"FTFinalSpeechRecognitionResponse",R,N
T@"FTPartialSpeechRecognitionResponse",R,N
T@"FTUpdatedAcousticProfile",R,N
T@"FTEndPointLikelihood",R,N
T@"FTEndPointCandidate",R,N
T@"FTRecognitionProgress",R,N
T@"FTCheckForSpeechResponse",R,N
T@"FTRecognitionCandidate",R,N
T@"FTRequestStatsResponse",R,N
T@"FTClientSetupInfo",R,N
T@"FTAudioLimitExceeded",R,N
T@"FTMultiUserStartSpeechRequest",R,N
T@"FTFinalBlazarResponse",R,N
T@"FTStartMultilingualSpeechRequest",R,N
T@"FTStartSpeechTranslationRequest",R,N
T@"FTSpeechTranslationAudioPacket",R,N
T@"FTStartSpeechTranslationLoggingRequest",R,N
T@"FTSpeechTranslationPartialRecognitionResponse",R,N
T@"FTSpeechTranslationFinalRecognitionResponse",R,N
T@"FTSpeechTranslationMtResponse",R,N
T@"FTSpeechTranslationTextToSpeechResponse",R,N
T@"FTSpeechTranslationServerEndpointFeatures",R,N
T@"FTBatchTranslationRequest",R,N
T@"FTBatchTranslationResponse",R,N
T@"FTStartTextToSpeechStreamingRequest",R,N
T@"FTBeginTextToSpeechStreamingResponse",R,N
T@"FTPartialTextToSpeechStreamingResponse",R,N
T@"FTFinalTextToSpeechStreamingResponse",R,N
T@"FTQssAckResponse",R,N
T@"FTStartLanguageDetectionRequest",R,N
T@"FTLanguageDetectionResponse",R,N
com.apple.translation.speech-timer
@"FTAudioFrame"16@?0@"NSData"8
@"NSString"16@?0@"_LTSpeechTranscription"8
%@: %f : %d
initialOnlineTimeout
Td,N,V_initialOnlineTimeout
onlineTimeout
Td,N,V_onlineTimeout
endpointTimeout
Td,N,V_endpointTimeout
completionBlock
T@?,C,N,V_completionBlock
final
transcriptions
sausage
Sausage
TB,N,GisFinal,V_final
T@"NSArray",&,N,V_transcriptions
bestRecognitionAlternatives
T@"_LTSpeechRecognitionSausage",&,N,V_bestRecognitionAlternatives
TranslateRequest
OfflineTextTranslation
OfflineBatchTextTranslation
OfflineSpeechTranslation
OfflineTextToSpeechTranslation
OnlineTextTranslation
Error
com.apple.translation
code
domain
domain_code
%@_%ld
underlying_domain
underlying_code
underlying_domain_code
@"NSDictionary"8@?0
com.apple.translation.analytics-event
errorDomain
errorCode
errorDescription
duration
T@"NSLocale",C,N,V_sourceLocale
T@"NSLocale",C,N,V_targetLocale
%@.%@
availableLocales
T@"NSArray",C,N,V_availableLocales
T@"NSArray",R,C,N,V_spans
bins
alternatives
bestIndex
spaceAfter
@"_LTSpeechRecognitionTokensAlternative"16@?0@"NSArray"8
@"NSString"16@?0@"_LTSpeechRecognitionBin"8
(%@)
T@"NSArray",&,N,V_bins
T@"NSArray",&,N,V_alternatives
bestAlternativeIndex
TQ,N,V_bestAlternativeIndex
Tq,N,V_confidence
hasSpaceAfter
TB,N,V_hasSpaceAfter
/siri.speech.qss_fb.Apg/PronGuess
Flatbuffers
v16@?0@"NSData"8
/siri.speech.qss_fb.Apg/BatchRecover
/siri.speech.qss_fb.Asr/Recognition
/siri.speech.qss_fb.Asr/ErrorBlamer
v24@?0@"NSData"8@"NSError"16
/siri.speech.qss_fb.Asr/Itn
/siri.speech.qss_fb.Asr/TextNormalization
/siri.speech.qss_fb.Asr/PostItnHammer
/siri.speech.qss_fb.Asr/KeywordFinder
/siri.speech.qss_fb.Asr/CorrectionsValidator
/siri.speech.qss_fb.Asr/GraphemeToPhoneme
/siri.speech.qss_fb.Blazar/MultiUser
/siri.speech.qss_fb.Blazar/Multilingual
/siri.speech.qss_fb.Blazar/SpeechTranslation
/siri.speech.qss_fb.Blazar/BatchTranslation
/siri.speech.qss_fb.Blazar/TextToSpeechRouter
/siri.speech.qss_fb.Blazar/TextToSpeechRouterStreaming
/siri.speech.qss_fb.Lmt/LmScorer
/siri.speech.qss_fb.Napg/CreateLanguageProfile
/siri.speech.qss_fb.Mt/Translation
/siri.speech.qss_fb.Tts/TextToSpeech
/siri.speech.qss_fb.Tts/TextToSpeechStreaming
/siri.speech.qss_fb.Nl/Neu
/siri.speech.qss_fb.Nl/IntentPredictionDemo
/siri.speech.qss_fb.Nl/ShortcutFuzzyMatch
/siri.speech.qss_fb.Afm/AStarFuzzyMatching
/siri.speech.qss_fb.Sls/LanguageDetection
PRIVACY_LINK
ON_DEVICE_FOOTER
OnDeviceOnly
showTranslatePrivacy
ON_DEVICE_PREF_NAME
CONFIRMATION_TITLE
CONFIRMATION_DESCRIPTION
NOT_NOW
OPEN_APP
@"_LTSpeechRecognitionTokensAlternative"16@?0@"FTRecognitionPhraseTokens"8
minConfidence
<no value>
%@-%@
<%@: source:%@ target:%@>
T@"NSLocale",R,N,V_sourceLocale
T@"NSLocale",R,N,V_targetLocale
v16@?0@"_LTLocalePair"8
com.apple.translation.ParagraphTranslationDone
mtAppService
T@"FTBlazarService",R,N,V_mtAppService
Text or ranges need to be specified
v32@?0@"_LTTranslationRange"8Q16^B24
ranges
T@"NSArray",C,N,V_ranges
Start loading
Failed to obtain LID asset
End load
LID Load
Start
Overriding confidence thresholds, setting to %ld
Confidence thresholds for source %f and target %f
Invalid source and target confidence threshold configuration
NumSamples: %ld
LID Audio Data
confidence: %@
CS-LID Result
Confident in source language (%lf) with threshold %lf
Confident in target language (%lf) with threshold %lf
LID detected %@ (confident: %@): %@
streamDidReceiveBatchTranslationStreamingResponse request_id %@
found BatchTranslationResponse request_id %@
FIXME: NULL FTBatchTranslationResponse!
GRPC error %d: %@
Translation error on %@: %@
Succeeded request %@ (%ld alignments)
Translation: %{private}@ for %{private}@
Missing paragraphBatchInfo for paragraph ID: %@
NULL FTFinalBlazarResponse!
found FTFinalBlazarResponse request_id %@ outstanding paragraphs %@ error %@
Publishing BatchTranslationEvent to FLLogger
Unrecognized message type from server recieved!
Failed to get siri data sharing opt in status: %@
Creating service with URL: %@, bundleID: %@
cancelServerTimeout: %@
batch timeout triggered
serverTimeoutFired %.2fs 
Found cached TTS data
Start TTS request: %@ / %@
TTS response (%d): %@
Should skip empty string to translate
Sending translation request: %@
Online: Translating string
TranslateString
Online: Finished translating
Error translating request: %@, error: %@
Finished translating request: %@
Sending batch request: bufferSizeExceeded %@ maxParagraphsExceeded %@ taskChanged %@ 
Translating: %{private}@ request_id %@
Spans: %@
Online: Translating paragraph: %@
TranslateParagraph
Sending batch for requestID: %@, task: %@, sessionID: %@, URL: %@
Translating: %lu batched paragraph(s)
Online: Finished translating paragraph: %@ error %@
Start translating sentence
Online: Translating sentence
TranslateSentence
Online: finished translating sentence
Start translating %ld paragraphs
Online speech or text to speech translation already ongoing
Online speech translation already ongoing
Invalidating current speech session with error: %@
Invalid chunk size: %d at offset %d, bytes count = %d
error %@ creating directory at path %@
error %@ writing to url %@
Client lag configuration is %f, %f, %@
Init of HEP
Auto endpointing is turned off
Start new HEP request
Could not get appropriate endpointer assets
Could not obtain SPG asset
Updating disconnected source endpointer threshold to %f
Request for sampling rate failed for source locale
Updating disconnected target endpointer threshold to %f
Have hybrid endpointer for source %@, for target %@
Received server endpointer features for source locale
Re-request sampling rate for source endpointer
Updating source endpointer threshold to %f
Received server endpointer features for target locale
Re-request sampling rate for target endpointer
Updating target endpointer threshold to %f
Unexpected locale %@ for server endpointer features
Adding audio samples %ld
Sending end of audio to SPG
ClientLag: serverProcessedAudioMs(%{public}ld) > effectiveClientProcessedAudioMs(%{public}f)
ClientLag: Not invoking HybridClassifier: sfLatency > clientLagThreshold: %{public}f > %{public}f
ClientLag: Using DefaultServerFeatures with disconnected-state sfLatency: %{public}f
ClientLag: Using ServerFeatures with ClampedSFLatency: %{public}f
ClientLag: Not Invoking HybridClassifier as serverProcessedAudioMs > effectiveClientProcessedAudioMs
HEP.feats: [%{public}ld,%{public}f,%{public}f,%{public}ld,%{public}f,%{public}f] & [(%{public}@),%{public}f,%{public}f] @ %{public}lu [%{public}f, %{public}d]
clientSilenceFeaturesAvailable
Endpointing decision from source endpointer %@
Endpointing decision from target endpointer %@
Failed to create playback service
Failed to start TTS playback: %@
Data length: %lu
Finished TTS playback
Asked to cancel speak session
No available endpointer assets
HEP not supported for given locale pair/configuration
Number of HEP assets %ld
Could not find suitable HEP asset for any language
Found asset for source %@, for target %@
Malformed config asset
Models - sourceASR: %d, targetASR: %d, mt: %d
Updating symlinks for %@
Failed to create directory %@ error %@
Failed to link mt-quasar-config.json %@
creating link from %@ to %@
Failed to link model file %@
Failed to remove language pair directory %@
Failed to rename temp language pair directory %@
Requested to download asset for: %@
Starting download for asset with attributes: %@
All asset downloads for language pair %@ completed successfuly
Reference counts before purge %@
Language pair directory doesn't exist %@
Starting purge for %@
Error deleting directory %@ error %@
Starting purge for asset : %@
error purging asset %@
All assets purged for language pair %@ finished (error: %@)
Reference counts after purge %@
Start speech translation with service
Drain queued buffers first
Append audio data
Start text to speech translation with service
TTS cache request: %@
Purging %ld items from TTS cache
Asset manager clearing caches
Update offline asset catalog
Asset catalog finished downloading with result %ld
Downloading config asset
Error downloading config asset %@
Finished downloading config asset
Failure updating all assets %@
Finished updating all assets
Run query: %@
Query result: %ld
Failed to fetch asset metadata. Result: %{public}ld
error querying installed assets
Config asset not installed!
Reading configuration plist %@
Failed to read plist %@
missing mt_app.offline.plist
Error creating speechTranslationAssetInfo: %@
Asset purge finished
Failed asset purge: %ld
Asset progress: %@
update: %@ %@
Asset download finished
Failed asset download: %@
getAutoDownloadedVoiceAssets %@
setAutoDownloadedVoiceAssets %@
Failed to deserialize JSON at path %@ error %@
No asset info found for language pair %@
Requested to delete all offline assets
Failed to delete asset link directory: %@
Failed asset query: %ld
Waiting for %ld assets to be deleted
All assets purged (error: %@)
%@ %@ Version %@ Capability %@ %@
----------------------------- sortedCatalogAssets ------------------------------------ 
----------------------------- Assets to download ------------------------------------ 
%@ %@ %@ %@
error downloading asset %@
----------------------------- Assets to purge --------------------------------------- 
error deleting asset %@
Config asset updated.
----------------------------- Fixing symlinks --------------------------------------- 
Error downloading offline assets %@
Reference counts after download %@
Error getting asset info %@
Missing asset entitlement
Fallback asset resource path : %{public}@
Error loading config data: %@ at url: %@
Error reading from plist: %@
Loaded config plist from : %@
Missing required resource! %@
Loading recognizers
Using model overrides as specified: %@
Creating multi recognizer: %@, %@
Offline modelVersions %@
Finished loading recognizers
LoadOfflineRecognizers
Loading etiquette sanitizers
loaded etiquette sanitizer for: %@
Finished loading etiquette sanitizers
LoadOfflineSanitizers
Loading translator
Creating translator with task %@ model URL: %@
Finished loading translator
LoadOfflineTranslator
Loading all models
Finished loading models
PreheatModels
Offline: Translating string
TranslateTokens
Done translating
Offline: Finished translating
Finished translating: %@
Translate sentence: %@
Translate pragraph: %@
Finished translating paragraph
Finished translation, sending analytics event
Translate text paragraphs (block completion handler)
Offline: Translating %ld paragraphs
TranslateParagraphs
Cancel speech translation
Add audio to engine
Notified of LID result: %@ is confident: %@
Starting translation
Offline: Translating text: %@
OfflineTranslation
Offline: Finished translating speech result, (id: %@)
Starting offline speech translation (auto detect language: %@, id: %@)
Offline: Translating speech result, (id: %@)
ModelVersion %@
LowConfidence (%f): %d with threshold %ld
Best recognition: %@
Siri Voice Defaults :%@ 
Speaking: %@ language code %@
Failed to start speaking request: %@
Failed to cancel offline TTS, error: %@
Finished offline TTS metrics:%@ 
Finished offline TTS, successfully: %@, error: %@
Starting recognition for %ld recognizers
Starting recognizer: %@
Starting ASR for %@
Recognition error: %@
Failed ASR (%@) with error: %@
ASR result (%@): %@
Recognizer finished
Completed ASR for %@
All recognizers finished
Propagate endAudio to recognizers
Session sending %ld requests
Error sending %ld paragraphs %{public}@
Finished sending %ld paragraphs
Session sending feedback
Received translation result for %@
Starting combined translation
Failed online TTS, will fallback to offline: %@
HEP triggered
Server translation finished (optional error: %@)
Online translation failed, continue with offline
Failed to clear caches: %@
Failed to complete _offlineLanguageStatus %@
Failed to complete _downloadAssetForLanguagePair %@
Failed to complete _purgeAssetForLanguagePair %@
Failed to complete availableLocalePairsForTask %@
Failed to complete additionalLikelyPreferredLocalesForLocale %@
Failed to complete configInfoForLocale %@
Failed to complete taskIsSupportedInCurrentRegion %@
Failed to complete text-LID request %@
Creating service proxy
Connection error: %@
Connection done
Creating SYNC service proxy
Failed sync preheat request
Failed to complete preheat request %@
Failed to initiate cleanup: %@
Failed to serialize logging request: %@
Failed to complete logging request: %@
Could not locate asset etiquette.json
Could not read %@: %@
Could not parse %@: %@
%@ is wrong type: %@
%@ contains bogus key/value pair: %@ => %@
Creating etiquette sanitizer with URL: %@
sanitizedString '%@' forString '%@' locale: %@
Error creating playback service, %d
Current audio output route: %@
AudioQueue initialized with session id: %d
Error disposing audio queue %d
mediaserverd reset
Error starting audio queue %d
Creating buffer of length: %ld
Failed to create audio buffer: %d
Failed to enqueue audio data: %d
Enqueued audio buffer at sample title: %.2f, size: %ld
Playback service running state changed
Error adding audio queue property listener %d
Wait for audio queue to stop
Audio queue playback stopped (%d)
Failed to remove property listener %d
Error flushing audio queue %d
Error stopping audio queue %d
Error AudioQueueStop %d
Error AudioQueueReset %d
Error checking is running property: %d
LTPlaybackServices %p played audio buffer at sample time: %f, size: %ld
Error AudioQueueFreeBuffer %d
Reusing cached offline engine for locales: %@
No asset info found for pair %@: %@
MT model URL: %@
Unsupported language pair requested for online engine
Creating offline engine
Creating online engine
Could not create online engine: %@
Could not create offline engine, using online only: %@
Creating combined engine
Requested preheat with context: %@
Cancel ongoing speech session: %@
Cancel ongoing speak session
Failed to create text translation engine: %@
Translating %ld paragraphs for route: %ld
Handling text translation request for route: %ld (autodetect: %@)
Failed to create translation engine: %@
Failed TTS request: %@
Handling speech translation request for route: %ld (autodetect: %@)
Failed to create speech translation engine: %@
Start speech translation session
Asked to cancel %@, current ongoing is: %@
Ignoring cancel request because of different session IDs
Resetting session
Add speech audio data for session
End speech audio data on session
Sending end of audio
Asked to cancel speech session
Skipping meta, failed to parse as JSON. %@
Translation candidate meta: %@
Skipping meta, disabled in user defaults
Client didn't set application-identifier entitlement
Client connection for: %@
Client disconnected, ask to cancel speech session
_LTTranslationService paragraphResult %@ error %@ paragraphError %@ 
Failed to deserialize logging request: %@ 
Starting speech translation with request ID: %@, session ID: %@, opt in status: %ld
Streaming connection finished with error: %@
Starting text to speech translation with request ID: %@, session ID: %@, opt in status: %ld
Streaming text translation session finished with error: %@
Setting server timeout for %.2fs
Server timeout triggered
Already endpointed, do not need to send additional data.
Start compressing audio
Sending end audio
Ending audio due to endpointer trigger
Ignoring LID result because not confident or not final
LID result received. Primary language recognized: %@
Using ASR fallback locale: %@
Sending MT responses if needed
Detected translation locale: %@
Result locale: %@
Sending %ld packets from compressor
Audio limit exceeded
Always sending ASR partial %@
Received final recognition response
Final recognition status: %d: %@
Recognition: %@
Insufficient information in server endpointer features response
Received translation response: %@
Received TTS response: %@ (%ld)
Unable to process TTS audio data
Final blazar response: %d %@
Remote service error %d: %@
Speech translation stream error: %@
Received server message
Sausage conf %ld for locale %@
Dominant language: %@
Language confidences: %@
Mapped language: %@
Could not find locale for %@ in available: %@
Sausage confidences: %@
Start Speech LID logging request
Speech LID logging request finished with error: %@
Speech LID logging request finished
Start Safari latency logging request
Received logging request response: [%d] %@
Logging request received unexpected response: %@
Logging request received error: %@
_LTSpeechTranslationResultsBuffer
_LTSpeechTranslationDelegate
NSObject
_LTPowerLogger
_LTTextLanguageDetectionResult
NSSecureCoding
NSCoding
Osprey
_LTDaemon
NSXPCListenerDelegate
_LTClientConnectionDelegate
_LTTranslationContext
_LTLanguageDetectionResult
_LTLanguageDetector
CSLanguageDetectorDelegate
LTTranslationError
_FTParagraphBatchInfo
_LTBatchTranslationResponseHandler
FTBatchTranslationResponseDelegate
_LTOnlineTranslationEngine
_LTTranslationEngine
_LTAudioData
_LTServerEndpointerFeatures
_LTHybridEndpointer
EARCaesuraSilencePosteriorGeneratorDelegate
_LTAlignment
_LTServerSpeakSession
_LTTaskContext
_LTHybridEndpointerAssetInfo
_LTSpeakRequest
_LTSpeechTranslationAssetInfo
_LTTranslationStatistics
NSCopying
_LTTranslationRequest
_LTTextTranslationRequest
_LTBatchTextTranslationRequest
_LTSpeechTranslationRequest
_LTTextToSpeechTranslationRequest
_LTTokenizer
_SentenceBoundaries
_LTTextToSpeechCache
_LTOfflineAssetManager
FTMutableUserLanguageProfile
FTMutableUserAcousticProfile
FTMutableRecognitionToken
FTMutableRecognitionPhraseTokens
FTMutableRecognitionPhraseTokensAlternatives
FTMutableRecognitionSausage
FTMutableSetAlternateRecognitionSausage
FTMutableRecognitionChoice
FTMutableRepeatedItnAlignment
FTMutableChoiceAlignment
FTMutableRecognitionResult
FTMutableRequestStatsResponse
FTMutableRequestStatsResponse_BoolStat
FTMutableRequestStatsResponse_Int32Stat
FTMutableRequestStatsResponse_DoubleStat
FTMutableItnAlignment
FTMutableAcousticFeature
FTMutableAudioAnalytics
FTMutableAudioAnalytics_SpeechRecognitionFeaturesEntry
FTMutableAudioAnalytics_AcousticFeaturesEntry
FTMutableFinalSpeechRecognitionResponse
FTMutablePartialSpeechRecognitionResponse
FTMutableStartSpeechRequest
FTMutableUserParameters
FTMutableMultiUserStartSpeechRequest
FTMutableUpdateAudioInfo
FTMutableContextWithPronHints
FTMutableSetSpeechContext
FTMutableSetSpeechProfile
FTMutableSetEndpointerState
FTMutableAudioPacket
FTMutableFinishAudio
FTMutableFinishAudio_ServerFeatureLatencyDistributionEntry
FTMutableUpdatedAcousticProfile
FTMutableWord
FTMutableUserDataEntity
FTMutableCategoryData
FTMutableCreateLanguageProfileRequest
FTMutableCreateLanguageProfileResponse
FTMutableStartPronGuessRequest
FTMutableCancelRequest
FTMutablePronunciation
FTMutableVocToken
FTMutablePronGuessResponse
FTMutableRecoverPronsRequest
FTMutableRecoverPronsResponse
FTMutableStartBatchRecoverRequest
FTMutableBatchRecoverFinalResponse
FTMutableItnRequest
FTMutableItnResponse
FTMutablePostItnHammerRequest
FTMutablePostItnHammerResponse
FTMutableTextNormalizationRequest
FTMutableNormalizedTokenVariant
FTMutableNormalizedToken
FTMutableTextNormalizationResponse
FTMutablePronChoice
FTMutableSanitizedPronToken
FTMutableTokenProns
FTMutableTokenProns_SanitizedSequence
FTMutableGraphemeToPhonemeRequest
FTMutableGraphemeToPhonemeResponse
FTMutableAlignment
FTMutableSpan
FTMutableRepeatedSpan
FTMutableSpeechTranslationInfo
FTMutableSiriTranslationInfo
FTMutableSiriPayloadTranslationInfo
FTMutableWebTranslationInfo
FTMutableTranslationRequest
FTMutableTranslationResponse
FTMutableTranslationResponse_TranslationToken
FTMutableTranslationResponse_TranslationPhrase
FTMutableEndPointLikelihood
FTMutableEndPointCandidate
FTMutableSetRequestOrigin
FTMutableRecognitionProgress
FTMutableResetServerEndpointer
FTMutableLatnnMitigatorResult
FTMutableRecognitionCandidate
FTMutableCheckForSpeechRequest
FTMutableCheckForSpeechResponse
FTMutableErrorBlamerRequest
FTMutableErrorBlamerResponse
FTMutableLmScorerToken
FTMutableLmScorerRequest
FTMutableLmScorerResponse
FTMutableAStarFuzzyMatchingConfig
FTMutableAStarFuzzyMatchingResult
FTMutableAStarFuzzyMatchingRequest
FTMutableAStarFuzzyMatchingResponse
FTMutableKeyword
FTMutableKeywordFinderRequest
FTMutableKeywordFinderResponse
FTMutableServerEndpointFeatures
FTMutableCorrectionsValidatorRequest
FTMutableCorrectionsAlignment
FTMutableCorrectionsValidatorResponse
FTMutableTTSRequestFeatureFlags
FTMutableTextToSpeechVoice
FTMutableTextToSpeechResource
FTMutableTextToSpeechMeta
FTMutableTextToSpeechRequestMeta
FTMutableTextToSpeechRequestContext
FTMutableTextToSpeechRequestContext_ContextInfoEntry
FTMutableTextToSpeechRequestExperiment
FTMutableRepeatedPhonemes
FTMutableTextToSpeechFeature
FTMutableTextToSpeechRequest
FTMutableTextToSpeechRequest_ContextInfoEntry
FTMutableAudioDescription
FTMutableWordTimingInfo
FTMutableTextToSpeechResponse
FTMutableStartTextToSpeechStreamingRequest
FTMutableStartTextToSpeechStreamingRequest_ContextInfoEntry
FTMutableBeginTextToSpeechStreamingResponse
FTMutablePartialTextToSpeechStreamingResponse
FTMutableFinalTextToSpeechStreamingResponse
FTMutableTextToSpeechCacheMetaInfo
FTMutableTextToSpeechCacheObject
FTMutableTextToSpeechCacheContainer
FTMutableQssAckResponse
FTMutableClientSetupInfo
FTMutableAudioLimitExceeded
FTMutableAudioFrame
FTMutableSpeechTranslationAudioPacket
FTMutableTranslationLocalePair
FTMutableStartSpeechTranslationRequest
FTMutableStartSpeechTranslationLoggingRequest
FTMutableSpeechTranslationPartialRecognitionResponse
FTMutableSpeechTranslationFinalRecognitionResponse
FTMutableSpeechTranslationMtResponse
FTMutableSpeechTranslationMtResponse_TranslationPhrase
FTMutableSpeechTranslationTextToSpeechResponse
FTMutableSpeechTranslationServerEndpointFeatures
FTMutableMatchingSpan
FTMutableNlUtterenceToken
FTMutableNeuRequest
FTMutableNeuOutput
FTMutableNeuOutput_MetaInfosEntry
FTMutableAlternativePrediction
FTMutableAlternativePrediction_MetaInfosEntry
FTMutableChunkPrediction
FTMutableChunkPrediction_MetaInfosEntry
FTMutableToken
FTMutableDebugInfo
FTMutablePositionalFeatures
FTMutableSpanFeatureIndices
FTMutableWordEmbeddings
FTMutableCharEmbeddings
FTMutableMetricsInfo
FTMutableShortcutFuzzyMatchRequest
FTMutableShortcutFuzzyMatchRequest_StringTokenPair
FTMutableShortcutFuzzyMatchResponse
FTMutableShortcutFuzzyMatchResponse_ShortcutScorePair
FTMutableIntentPredictionDemoRequest
FTMutableIntentPredictionDemoResponse
FTMutableLanguageParameters
FTMutableStartMultilingualSpeechRequest
FTMutableLanguageDetectionPrediction
FTMutableLanguageDetected
FTMutableFinalBlazarResponse
FTMutableBatchTranslationRequest
FTMutableBatchTranslationRequest_Paragraph
FTMutableBatchTranslationResponse
FTMutableBatchTranslationCacheContainer
FTMutableStartLanguageDetectionRequest
FTMutableLanguageDetectionResponse
FTMutablePronGuessStreamingRequest
FTMutablePronGuessStreamingResponse
FTMutableBatchRecoverStreamingRequest
FTMutableBatchRecoverStreamingResponse
FTMutableRecognitionStreamingRequest
FTMutableRecognitionStreamingResponse
FTMutableMultiUserStreamingRequest
FTMutableMultiUserStreamingResponse
FTMutableMultilingualStreamingRequest
FTMutableMultilingualStreamingResponse
FTMutableSpeechTranslationStreamingRequest
FTMutableSpeechTranslationStreamingResponse
FTMutableBatchTranslationStreamingRequest
FTMutableBatchTranslationStreamingResponse
FTMutableTextToSpeechRouterStreamingStreamingRequest
FTMutableTextToSpeechRouterStreamingStreamingResponse
FTMutableTextToSpeechStreamingStreamingRequest
FTMutableTextToSpeechStreamingStreamingResponse
FTMutableLanguageDetectionStreamingRequest
FTMutableLanguageDetectionStreamingResponse
_LTLanguagePairOfflineAvailability
_LTOfflineTranslationEngine
_LTOfflineSpeechSynthesizer
VSSpeechSynthesizerDelegate
LTLocaleIdentifier
_LTLanguageDetectorAssetInfo
_LTMultilingualSpeechRecognizer
_LTTranslationSense
_LTSpeechLIDLoggingRequest
_LTLoggingRequest
_LTSafariLatencyLoggingRequest
ABSD
_LTTranslationSession
TranslationAssetUtil
_LTTranslationRange
_LTSpeechCompressor
_LTTranslationSpan
_LTTranslationResult
_LTCombinedEngine
_LTAsyncMap
_LTTranslationFeedback
_LTTranslator
_LTMatch
_LTEtiquetteSanitizer
_LTSpeechRecognizer
_EARSpeechRecognitionResultStream
_LTPlaybackService
_LTTranslationServer
_LTServerSpeechSession
_LTTranslationService
_LTTranslationCandidate
_LTClientConnection
FTUserLanguageProfile
FLTBFBufferAccessor
FTUserAcousticProfile
FTRecognitionToken
FTRecognitionPhraseTokens
FTRecognitionPhraseTokensAlternatives
FTRecognitionSausage
FTSetAlternateRecognitionSausage
FTRecognitionChoice
FTRepeatedItnAlignment
FTChoiceAlignment
FTRecognitionResult
FTRequestStatsResponse
FTRequestStatsResponse_BoolStat
FTRequestStatsResponse_Int32Stat
FTRequestStatsResponse_DoubleStat
FTItnAlignment
FTAcousticFeature
FTAudioAnalytics
FTAudioAnalytics_SpeechRecognitionFeaturesEntry
FTAudioAnalytics_AcousticFeaturesEntry
FTFinalSpeechRecognitionResponse
FTPartialSpeechRecognitionResponse
FTStartSpeechRequest
FTUserParameters
FTMultiUserStartSpeechRequest
FTUpdateAudioInfo
FTContextWithPronHints
FTSetSpeechContext
FTSetSpeechProfile
FTSetEndpointerState
FTAudioPacket
FTFinishAudio
FTFinishAudio_ServerFeatureLatencyDistributionEntry
FTUpdatedAcousticProfile
FTWord
FTUserDataEntity
FTCategoryData
FTCreateLanguageProfileRequest
FTCreateLanguageProfileResponse
FTStartPronGuessRequest
FTCancelRequest
FTPronunciation
FTVocToken
FTPronGuessResponse
FTRecoverPronsRequest
FTRecoverPronsResponse
FTStartBatchRecoverRequest
FTBatchRecoverFinalResponse
FTItnRequest
FTItnResponse
FTPostItnHammerRequest
FTPostItnHammerResponse
FTTextNormalizationRequest
FTNormalizedTokenVariant
FTNormalizedToken
FTTextNormalizationResponse
FTPronChoice
FTSanitizedPronToken
FTTokenProns
FTTokenProns_SanitizedSequence
FTGraphemeToPhonemeRequest
FTGraphemeToPhonemeResponse
FTAlignment
FTSpan
FTRepeatedSpan
FTSpeechTranslationInfo
FTSiriTranslationInfo
FTSiriPayloadTranslationInfo
FTWebTranslationInfo
FTTranslationRequest
FTTranslationResponse
FTTranslationResponse_TranslationToken
FTTranslationResponse_TranslationPhrase
FTEndPointLikelihood
FTEndPointCandidate
FTSetRequestOrigin
FTRecognitionProgress
FTResetServerEndpointer
FTLatnnMitigatorResult
FTRecognitionCandidate
FTCheckForSpeechRequest
FTCheckForSpeechResponse
FTErrorBlamerRequest
FTErrorBlamerResponse
FTLmScorerToken
FTLmScorerRequest
FTLmScorerResponse
FTAStarFuzzyMatchingConfig
FTAStarFuzzyMatchingResult
FTAStarFuzzyMatchingRequest
FTAStarFuzzyMatchingResponse
FTKeyword
FTKeywordFinderRequest
FTKeywordFinderResponse
FTServerEndpointFeatures
FTCorrectionsValidatorRequest
FTCorrectionsAlignment
FTCorrectionsValidatorResponse
FTTTSRequestFeatureFlags
FTTextToSpeechVoice
FTTextToSpeechResource
FTTextToSpeechMeta
FTTextToSpeechRequestMeta
FTTextToSpeechRequestContext
FTTextToSpeechRequestContext_ContextInfoEntry
FTTextToSpeechRequestExperiment
FTRepeatedPhonemes
FTTextToSpeechFeature
FTTextToSpeechRequest
FTTextToSpeechRequest_ContextInfoEntry
FTAudioDescription
FTWordTimingInfo
FTTextToSpeechResponse
FTStartTextToSpeechStreamingRequest
FTStartTextToSpeechStreamingRequest_ContextInfoEntry
FTBeginTextToSpeechStreamingResponse
FTPartialTextToSpeechStreamingResponse
FTFinalTextToSpeechStreamingResponse
FTTextToSpeechCacheMetaInfo
FTTextToSpeechCacheObject
FTTextToSpeechCacheContainer
FTQssAckResponse
FTClientSetupInfo
FTAudioLimitExceeded
FTAudioFrame
FTSpeechTranslationAudioPacket
FTTranslationLocalePair
FTStartSpeechTranslationRequest
FTStartSpeechTranslationLoggingRequest
FTSpeechTranslationPartialRecognitionResponse
FTSpeechTranslationFinalRecognitionResponse
FTSpeechTranslationMtResponse
FTSpeechTranslationMtResponse_TranslationPhrase
FTSpeechTranslationTextToSpeechResponse
FTSpeechTranslationServerEndpointFeatures
FTMatchingSpan
FTNlUtterenceToken
FTNeuRequest
FTNeuOutput
FTNeuOutput_MetaInfosEntry
FTAlternativePrediction
FTAlternativePrediction_MetaInfosEntry
FTChunkPrediction
FTChunkPrediction_MetaInfosEntry
FTToken
FTDebugInfo
FTPositionalFeatures
FTSpanFeatureIndices
FTWordEmbeddings
FTCharEmbeddings
FTMetricsInfo
FTShortcutFuzzyMatchRequest
FTShortcutFuzzyMatchRequest_StringTokenPair
FTShortcutFuzzyMatchResponse
FTShortcutFuzzyMatchResponse_ShortcutScorePair
FTIntentPredictionDemoRequest
FTIntentPredictionDemoResponse
FTLanguageParameters
FTStartMultilingualSpeechRequest
FTLanguageDetectionPrediction
FTLanguageDetected
FTFinalBlazarResponse
FTBatchTranslationRequest
FTBatchTranslationRequest_Paragraph
FTBatchTranslationResponse
FTBatchTranslationCacheContainer
FTStartLanguageDetectionRequest
FTLanguageDetectionResponse
FTPronGuessStreamingRequest
FTPronGuessStreamingResponse
FTBatchRecoverStreamingRequest
FTBatchRecoverStreamingResponse
FTRecognitionStreamingRequest
FTRecognitionStreamingResponse
FTMultiUserStreamingRequest
FTMultiUserStreamingResponse
FTMultilingualStreamingRequest
FTMultilingualStreamingResponse
FTSpeechTranslationStreamingRequest
FTSpeechTranslationStreamingResponse
FTBatchTranslationStreamingRequest
FTBatchTranslationStreamingResponse
FTTextToSpeechRouterStreamingStreamingRequest
FTTextToSpeechRouterStreamingStreamingResponse
FTTextToSpeechStreamingStreamingRequest
FTTextToSpeechStreamingStreamingResponse
FTLanguageDetectionStreamingRequest
FTLanguageDetectionStreamingResponse
_LTOspreySpeechTranslationSession
FTSpeechTranslationResponseDelegate
_LTSpeechCompressorDelegate
LTArrayExtensions
_LTSpeechRecognitionResult
_LTAnalyticsEvent
_LTTextLanguageDetector
_LTTranslationParagraph
_LTSpeechRecognitionSausage
_LTSpeechRecognitionBin
_LTSpeechRecognitionTokensAlternative
FTApgService
FTAsrService
FTBlazarService
FTLmtService
FTNapgService
FTMtService
FTTtsService
FTNlService
FTAfmService
FTSlsService
FTPronGuessStreamingContext
FTBatchRecoverStreamingContext
FTRecognitionStreamingContext
FTMultiUserStreamingContext
FTMultilingualStreamingContext
FTSpeechTranslationStreamingContext
FTBatchTranslationStreamingContext
FTTextToSpeechRouterStreamingStreamingContext
FTTextToSpeechStreamingStreamingContext
FTLanguageDetectionStreamingContext
_LTTranslateSettingsController
_LTSpeechTranscription
JSONRepresentation
_LTLocalePair
_LTLoggingRequestHandler
_LTParagraphTranslationRequest
OspreyRequest
_LTTranslationToken
init
delegate
speechRecognitionResult:
translatorDidTranslate:
translationDidFinishWithError:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
languageDetectionResult:
languageDetectionCompleted
hybridEndpointerFoundEndpoint
serverEndpointerFeatures:locale:
cancel
paragraphTranslation:result:error:
stopBuffering
hasFailed
hasResults
setDelegate:
.cxx_destruct
_isBuffering
_lastASRResult
_translationResult
_didFinish
_error
_delegate
orderedSetWithObjects:
sharedInstance
logTranslateRequestEvent:requestType:routeType:
loggerQueue
setLoggerQueue:
requestTypeSet
setRequestTypeSet:
_loggerQueue
_requestTypeSet
currentHandler
handleFailureInMethod:object:file:lineNumber:description:
copy
countByEnumeratingWithState:objects:count:
objectForKeyedSubscript:
unsignedIntegerValue
allObjects
countForObject:
addObject:
decodeObjectOfClass:forKey:
arrayWithObjects:count:
setWithArray:
decodeObjectOfClasses:forKey:
encodeObject:forKey:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
initWithDetectedLocales:unknownLanguages:
initWithDetectionCounts:availableLocales:
dominantLocale
localeDetectionCount
unsupportedLanguageCounts
_dominantLocale
_localeDetectionCount
_unsupportedLanguageCounts
string
alternative_index
count
positional_tok_phrase_alt
objectAtIndexedSubscript:
tok_phrases
tokens
token_text
appendString:
add_space_after
confidence
setConfidence:
setFormattedString:
initWithRecognitionChoice:inSausage:
array
standardUserDefaults
registerDefaults:
_setupMemoryWarningListener
initWithMachServiceName:
_setQueue:
resume
notifyOfMemoryPressure
initWithConnection:server:
removeObject:
listener:shouldAcceptNewConnection:
clientConnectionClosed:
_translationListener
_listenerQueue
_connections
_server
decodeIntegerForKey:
decodeBoolForKey:
decodeInt32ForKey:
encodeInteger:forKey:
encodeBool:forKey:
encodeInt32:forKey:
uniqueID
setUniqueID:
sessionID
setSessionID:
taskHint
setTaskHint:
localePair
setLocalePair:
autodetectLanguage
setAutodetectLanguage:
censorSpeech
setCensorSpeech:
outputFileURL
setOutputFileURL:
asrModelURLs
setAsrModelURLs:
mtModelURL
setMtModelURL:
sourceURL
setSourceURL:
autoEndpoint
setAutoEndpoint:
lidThreshold
setLidThreshold:
route
setRoute:
audioSessionID
setAudioSessionID:
asrConfidenceThreshold
setAsrConfidenceThreshold:
clientIdentifier
setClientIdentifier:
dataSharingOptInStatus
setDataSharingOptInStatus:
_autodetectLanguage
_censorSpeech
_autoEndpoint
_audioSessionID
_uniqueID
_sessionID
_taskHint
_localePair
_outputFileURL
_asrModelURLs
_mtModelURL
_sourceURL
_lidThreshold
_route
_asrConfidenceThreshold
_clientIdentifier
_dataSharingOptInStatus
localeWithLocaleIdentifier:
dictionaryWithObjects:forKeys:count:
containsObject:
languageCode
isEqualToString:
allKeys
doubleValue
setDominantLanguage:
setConfidences:
dominantLanguage
confidences
isConfident
isFinal
initWithConfidences:isConfident:dominantLanguage:isFinal:
setIsFinal:
_isConfident
_isFinal
_dominantLanguage
_confidences
languageDetectorAssetInfoWithContext:error:
languageDetectorModelURL
initWithModelURL:
reversedPair
sourceLocale
_ltCsLocaleIdentifier
targetLocale
setSamplingRate:
setWithObjects:
setDictationLanguages:
resetForNewRequest:
length
addSamples:numSamples:
endAudio
cancelCurrentRequest
dictionary
setObject:forKeyedSubscript:
floatValue
localeIdentifier
languageDetectorDidDetectLanguageWithConfidence:confidence:isConfident:
startLanguageDetectionWithContext:delegate:
addSpeechAudioData:
cancelLanguageDetection
samplingRate
audioBitDepth
_context
_csLanguageDetector
_sourceLocaleConfidenceThreshold
_targetLocaleConfidenceThreshold
_endAudioCalled
_lastResult
_lidSignpostID
_resultQueue
_samplingRate
_audioBitDepth
errorWithDomain:code:userInfo:
mainBundle
localizedStringForKey:value:table:
mutableCopy
lt_errorWithCode:description:userInfo:
_ltLocaleIdentifier
currentLocale
localizedStringForLocaleIdentifier:
stringWithFormat:
lt_internalErrorWithCode:description:userInfo:
lt_onlineNotImplementedError
lt_incompatibleForcedRoutes
lt_lidModelLoadError
lt_speechTranslationOngoingError
lt_invalidRequestErrorWithDescription:
lt_speechTranslationOngoing
lt_speechLimitExceeded
lt_translationTimeout
lt_offlineTTSErrorWithError:
lt_unsupporedLocalePairError:
completion
setCompletion:
paragraph
setParagraph:
requestParagraph
setRequestParagraph:
_completion
_paragraph
_requestParagraph
request_id
content_type
contentAsFTBatchTranslationResponse
paragraph_id
return_code
return_string
span
translated_text
text
initWithOspreyBatchResponse:
setIdentifier:
setLocale:
setSourceString:
spans
updateAlignmentWithSourceSpan:targetSpan:
removeObjectForKey:
setHasFinalServerResponse:
contentAsFTFinalBlazarResponse
return_str
allValues
numberWithUnsignedInteger:
timeIntervalSinceNow
setResponseTimeMs:
setBatchTranslationEvent:
wrapAsAnyEvent
data
sharedLogger
report:application:
callCompletionHandlersWithError:
numberWithBool:
removeAllObjects
streamDidReceiveBatchTranslationStreamingResponse:
streamFailVerifyBatchTranslationStreamingResponse:
request
setRequest:
toLocale
setToLocale:
metricEvent
setMetricEvent:
batchedParagraphs
setBatchedParagraphs:
bufferSize
setBufferSize:
setSourceLocale:
setTargetLocale:
requestID
setRequestID:
startTime
setStartTime:
hasFinalServerResponse
completionHandlerCalled
setCompletionHandlerCalled:
_hasFinalServerResponse
_completionHandlerCalled
_request
_toLocale
_metricEvent
_batchedParagraphs
_bufferSize
_sourceLocale
_targetLocale
_requestID
_startTime
setMaxConcurrentOperationCount:
getSiriDataSharingOptInStatusWithCompletion:
defaultSessionConfiguration
initWithURL:configuration:
setUseCompression:
set_sourceApplicationBundleIdentifier:
blazarServiceWithBundleID:
_webTaskService
_blazarService
updateServerTimeout
serverTimeoutFired
sendBatchTranslationRequestWithDelegate:
tokenize:forLocale:
ttsCache
audioDataForText:
_ospreyTTSRequestWithText:
language
gender
_serviceForTask:
speech_id
setClientTraceIdentifier:
error_code
error_str
decoder_description
audioStreamBasicDescription
audio
initWithASBD:rawData:
cacheAudioData:forText:
performTextToSpeechRouter:requestBuilder:completion:
_tokenizeString:inLocale:
UUID
UUIDString
setTask:
setSpeech_id:
setRequest_id:
setSource_language:
setTarget_language:
setTranslation_phrase:
setApp_id:
_service
initWithOspreyResponse:
performTranslation:requestBuilder:completion:
whitespaceAndNewlineCharacterSet
stringByTrimmingCharactersInSet:
identifier
setTranslations:
startServerTimeoutTimer
setParagraph_id:
setText:
range
setStart_index:
setEnd_index:
shouldTranslate
setDo_not_translate:
_ltCompactMap:
setSpan:
cancelServerTimeout
setSession_id:
absoluteString
setUrl:
setParagraphs:
task
setContentAsFTBatchTranslationRequest:
setContent_type:
setTranslationTask:
setSourceLanguage:
setTargetLanguage:
setDeviceOS:
setDeviceType:
setOsVersion:
setBundleIdentifier:
session_id
setSystemLocale:
paragraphs
setNumberOfParagraphs:
performBatchTranslationWithDelegate:requestBuilder:completion:
sendBatchTranslationStreamingRequest:
timedEventWithName:
addFieldsFromDictionary:
sendLazy
_translate:context:completion:
_translateParagraph:index:context:completion:
enumerateObjectsUsingBlock:
_hasOngoingSpeechSession
initWithService:context:text:delegate:
_speechSessionCompletedWithError:
setCompletionBlock:
setLanguagesRecognized:
sendAudioData:
endpoint
sendEndAudio
initWithService:context:delegate:
setTtsCache:
initialize
translatesPair:
preheatAsynchronously:withContext:
translateSentence:withContext:completion:
translate:withContext:paragraphResult:completion:
startSpeechTranslationWithContext:delegate:
cancelSpeechTranslation
speak:withContext:completion:
startTextToSpeechTranslationWithContext:text:delegate:
_sendQueue
_translationQueue
_speechSession
batchTranslationResponseHandler
_timerQueue
_serverTimer
_assistantSettingsConnection
_ttsCache
objectForKey:
integerValue
boolForKey:
dictionaryForKey:
setObject:forKey:
configurationPropertyListWithName:
stringByAppendingString:
compare:
boolValue
numberWithInteger:
initWithLocaleIdentifier:
pairWithIdentifiers:
numberWithDouble:
null
URLWithString:
_populateWithOpusData:
bytes
appendBytes:length:
defaultManager
URLByDeletingLastPathComponent
path
fileExistsAtPath:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
writeToURL:options:error:
writeToURL:
asbd
rawData
packetCount
packetDescriptions
_asbd
_data
_packetCount
_packetDescriptions
_rawData
num_of_words
trailing_silence_duration
eos_likelihood
pause_counts
silence_posterior
processed_audio_duration_ms
decodeInt64ForKey:
decodeDoubleForKey:
encodeInt64:forKey:
encodeDouble:forKey:
defaultServerEndpointFeatures
wordCount
setWordCount:
trailingSilenceDuration
setTrailingSilenceDuration:
endOfSentenceLikelihood
setEosLikelihood:
setPauseCounts:
silencePosterior
setSilencePosterior:
setProcessedAudioDurationInMilliseconds:
GetDefaultEndpointerFeaturesForEndpointer:
initWithResponse:
eosLikelihood
pauseCounts
processedAudioDurationInMilliseconds
_wordCount
_trailingSilenceDuration
_eosLikelihood
_pauseCounts
_silencePosterior
_processedAudioDurationInMilliseconds
endpointAssetInfoWithContext:error:
caesuraModelURL
initWithConfigFile:samplingRate:
endpointerModelURL:
initWithConfiguration:
requestSupportedWithSamplingRate:
updateEndpointerThresholdWithValue:
addAudio:numSamples:
processedAudioMs
silenceFramesCountMs
silenceProbability
silenceDurationMs
initWithWordCount:trailingSilenceDuration:endOfSentenceLikelihood:pauseCounts:silencePosterior:clientSilenceFramesCountMs:clientSilenceProbability:silencePosteriorNF:serverFeaturesLatency:
didEndpointWithFeatures:audioTimestamp:featuresToLog:endpointPosterior:extraDelayMs:
clientSilenceFramesCountMs
serverFeaturesLatency
clientSilenceProbability
componentsJoinedByString:
didEndpointWithFeatures:silenceFeatures:endpointer:
clientSilenceFeaturesAvailable:
silenceDurationEstimateAvailable:numEstimates:clientProcessedAudioMs:
startEndpointingWithContext:delegate:
setServerEndpointerFeatures:withLocale:
endpointerThreshold
setEndpointerThreshold:
clientLagThresholdMs
setClientLagThresholdMs:
clampedSFLatencyMsForClientLag
setClampedSFLatencyMsForClientLag:
useDefaultServerFeaturesOnClientLag
setUseDefaultServerFeaturesOnClientLag:
_asset
_sourceEndpointer
_sourceEndpointerThreshold
_sourceDisconnectedEndpointerThreshold
_sourceEndpointerFeatures
_targetEndpointer
_targetEndpointerThreshold
_targetDisconnectedEndpointerThreshold
_targetEndpointerFeatures
_spg
_didEndpoint
_queue
_featureQueue
_endpointerSignpostID
_useDefaultServerFeaturesOnClientLag
_endpointerThreshold
_clientLagThresholdMs
_clampedSFLatencyMsForClientLag
valueWithRange:
rangeValue
sourceRange
setSourceRange:
targetRange
setTargetRange:
_identifier
_text
_sourceRange
_targetRange
initWithAudioSessionID:ASBD:
start
enqueue:packetCount:packetDescriptions:
flushAndStop
reset
_playback:context:completion:
stop
initWithEngine:
speak:context:completion:
_engine
_player
initWithSessionID:taskHint:localePair:deviceOS:deviceType:appIdentifier:
deviceOS
deviceType
appIdentifier
_deviceOS
_deviceType
_appIdentifier
endpointerIsAvailableWithContext:
selectAsset:withLocale:
getPreferredAsset:orAsset:withLocale:
attributes
valueForKey:
isPremium:
state
getLocalUrl
URLByAppendingPathComponent:
initWithAvailableAssets:context:
hybridepAssetFile
spgAssetFile
_spgAsset
_sourceLanguageAsset
_targetLanguageAsset
_hybridepAssetFile
_spgAssetFile
requestContext
forcedOfflineTranslation
_forcedOnlineTranslation
_startTranslationWithService:done:
completionHandler
setCompletionHandler:
_completionHandler
modelURLForLanguagePair:
_getTranslationConfig
referenceAssets:catalogAssets:
updateAvailableInAssets:
_validateSymlinksForAssets:
_createSymlinkDirectoryForAssets:
matchingASRAssetForLocale:inAssets:
isMTModel
isPhrasebook
matchesAsset:
isNewerCompatibleVersionThan:
getLocalFileUrl
isPassthrough
isCurrentlyAvailable
initWithLocales:
_mtModelOfflineState
setMtState:
setSourceASRState:
setTargetASRState:
setPairState:
setNeedsUpdate:
assetDirectory
cannonicalIdentifier
_languagePairDirectory
dataWithContentsOfURL:
JSONObjectWithData:options:error:
assetId
configAsset
URLByAppendingPathExtension:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
linkItemAtURL:toURL:error:
dataWithJSONObject:options:error:
writeToURL:atomically:
removeItemAtURL:error:
moveItemAtURL:toURL:error:
currentProgress
initWithParent:userInfo:
setTotalUnitCount:
becomeCurrentWithPendingUnitCount:
downloadAsset:userInitiated:completion:
resignCurrent
arrayByAddingObjectsFromArray:
assetIdentifierReferenceCountDictionary
deleteAsset:completion:
initWithInstalledAssets:catalogAssets:localePair:configInfo:assetManager:
createSymlinkDirectoryForMTAssets
speechModelURLForLocale:
speechModelVersionForLocale:
translationModelURL
isCompletePasshtroughModel
isCompleteBidirectionalModel
availabilityInfo
downloadAssetsUserInitiated:queue:completion:
purgeAssetUserInitiated:queue:completion:
_assetManager
_pairDictionary
_sourceASRModel
_targetASRModel
_allAssets
_mtAssets
_missingAssets
_missingMTAssets
_needsUpdate
_modelURL
whitespaceCharacterSet
componentsSeparatedByCharactersInSet:
_countWithTokenString:
setInputTokenCount:
setInputSubtokenCount:
allocWithZone:
inputTokenCount
inputSubtokenCount
statisticsWithEngineMeta:
copyWithZone:
_inputTokenCount
_inputSubtokenCount
initWithSourceLocale:targetLocale:
initWithLocalePair:
_offlineMTModelURL
opaqueSessionID
loggingType
_translationFailedWithError:
setForcedOfflineTranslation:
set_forcedOnlineTranslation:
set_offlineMTModelURL:
_mtConfidenceThreshold
set_mtConfidenceThreshold:
_forcedOfflineTranslation
__forcedOnlineTranslation
__offlineMTModelURL
__mtConfidenceThreshold
sentence
translations
firstObject
formattedString
setSentence:
textHandler
setTextHandler:
translationHandler
setTranslationHandler:
_sentence
_textHandler
_translationHandler
_paragraphs
_offlineASRModelURLs
initWithStreamDescription:
startSpeechTranslationWithContext:
_appendAudioPCMBuffer:
_appendAudioSampleBuffer:simulateRealtime:
nativeAudioFormat
format
int16ChannelData
frameLength
dataWithBytes:length:
_convertAndFeedPCMBuffer:
processInfo
systemUptime
sleepForTimeInterval:
subdataWithRange:
_drainAndClearAudioConverter
_simulateRealtimeBehavior:
initWithPCMFormat:frameCapacity:
setFrameLength:
mutableAudioBufferList
convertToBuffer:error:withInputFromBlock:
inputFormat
initFromFormat:toFormat:
setSampleRateConverterQuality:
appendAudioPCMBuffer:
append:simulateRealtime:
_lidModelURL
set_lidModelURL:
set_offlineASRModelURLs:
set_asrConfidenceThreshold:
set_lidThreshold:
_converter
_queuedBuffers
_done
__lidModelURL
__offlineASRModelURLs
__asrConfidenceThreshold
__lidThreshold
startTextToSpeechTranslationWithContext:text:
initWithLength:
mutableBytes
UTF8String
getCharacters:range:
predicateWithFormat:
filteredArrayUsingPredicate:
initWithUnit:
setLanguage:
setString:
substringWithRange:
enumerateTokensInRange:usingBlock:
stringWithCharacters:length:
_ltSentencesForLocale:
clear
_cacheQueue
_cache
initWithType:
queryMetaDataSync
date
timeIntervalSinceDate:
setDiscretionary:
setRequiresPowerPluggedIn:
setAllowsCellularAccess:
startCatalogDownload:options:then:
compareAssetVersionReversed:
sortedArrayUsingSelector:
isInstalled
isDownloading
catalogAssets
configAssetInAssets:
code
_clearCaches
updateAllAssets:
_refreshAllAssetsCatalogUpdated:completion:
_refreshCatalogIfNeededWithCompletion:
returnTypes:
results
assetsSortedByVersion:
isConfig
installedAssets
isASRModel
transcribesLocale:
isANEModel
bundleForClass:
URLForResource:withExtension:
dataWithContentsOfURL:options:error:
propertyListWithData:options:format:error:
_configPlistWithFileName:
sortUsingComparator:
_speechTranslationAssetInfoForLocalePair:installedAssets:catalogAssets:config:error:
purge:
longLongValue
progressWithTotalUnitCount:
totalExpected
totalWritten
numberWithLongLong:
setCompletedUnitCount:
attachProgressCallBack:
totalUnitCount
startDownload:then:
_queryLanguagePairStatus:
sharedManager
languages
genderStringFromGender:
downloadVoiceAsset:options:progressUpdateHandler:
preferredVoiceGender
arrayWithObject:
setLanguages:
setGender:
_vsLocaleIdentifier
_voiceAssetForLocaleIdentifier:
_downloadVoiceAsset:
setAutoDownloadedVoiceAssets:
getAutoDownloadedVoiceAssets:
URLForDirectory:inDomain:appropriateForURL:create:error:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
_assetIdentifiersForLanguagePairDirectory:
numberWithLong:
cannonicalLocalePair
_speechTranslationAssetInfoForLocalePair:error:
_runQuery:
debugDumpAssets:
needsUpdate
updateSpeechTranslationAssetSymLinks:
pairState
downloadVoiceAssetsForLanguagePair:
refreshAllIfNeededWithCompletion:
_downloadPassthroughAssetForLocale:userInitiated:completion:
getEndpointerAssetWithType:error:
resourceURL
fallBackAssetResourcePath
initWithAssetUrl:
localizedDescription
configurationPropertyListWithURL:
configAssetURL
addEntriesFromDictionary:
offlineLanguageStatus:
purgeAssetForLanguagePair:userInitiated:completion:
purgeAllAssetsExcludingConfig:completion:
downloadAssetsForLanguagePair:userInitiated:completion:
speechTranslationAssetInfoForLocalePair:error:
profile_blob
setProfile_blob:
profile_blob:
profile_blob_version
setProfile_blob_version:
profile_checksum
setProfile_checksum:
acoustic_profile_blob
acoustic_profile_version
setAcoustic_profile_version:
setAcoustic_profile_blob:
acoustic_profile_blob:
intValue
initWithInt:
initWithBool:
setToken_text:
start_milli_seconds
setStart_milli_seconds:
end_milli_seconds
setEnd_milli_seconds:
silence_start_milli_seconds
setSilence_start_milli_seconds:
setAdd_space_after:
phone_seq
setPhone_seq:
ipa_phone_seq
setIpa_phone_seq:
setTokens:
setTok_phrases:
has_unsuggested_alternatives
setHas_unsuggested_alternatives:
setPositional_tok_phrase_alt:
setAlternative_index:
itn_alignment
setItn_alignment:
post_itn_choice_indices
setPost_itn_choice_indices:
pre_itn_token_to_post_itn_char_alignments
setPre_itn_token_to_post_itn_char_alignments:
pre_itn
setPre_itn:
post_itn
setPost_itn:
pre_itn_nbest_choices
setPre_itn_nbest_choices:
post_itn_nbest_choices
setPost_itn_nbest_choices:
pre_itn_token_to_post_itn_char_alignment
setPre_itn_token_to_post_itn_char_alignment:
choice_alignments
setChoice_alignments:
bool_stats
setBool_stats:
int32_stats
setInt32_stats:
double_stats
setDouble_stats:
request_locale
setRequest_locale:
name
setName:
value
setValue:
initWithDouble:
first_pre_itn_token_index
setFirst_pre_itn_token_index:
last_pre_itn_token_index
setLast_pre_itn_token_index:
first_post_itn_char_pos
setFirst_post_itn_char_pos:
last_post_itn_char_pos
setLast_post_itn_char_pos:
initWithFloat:
acoustic_feature_per_frame
setAcoustic_feature_per_frame:
frame_duration
setFrame_duration:
speech_recognition_features
setSpeech_recognition_features:
acoustic_features
setAcoustic_features:
setKey:
initWithInteger:
setReturn_code:
setReturn_str:
recognition_result
setRecognition_result:
lang_profile_recreate_codes
setLang_profile_recreate_codes:
audio_analytics
setAudio_analytics:
watermark_detection
setWatermark_detection:
watermark_peak_average
setWatermark_peak_average:
latnn_mitigator_result
setLatnn_mitigator_result:
has_result
setHas_result:
recognition_text
setRecognition_text:
is_stable_result
setIs_stable_result:
audio_duration_ms
setAudio_duration_ms:
unsignedLongValue
initWithUnsignedLong:
initWithUnsignedInteger:
task_name
setTask_name:
codec
setCodec:
stream_results
setStream_results:
enable_server_side_endpoint
setEnable_server_side_endpoint:
device_type
setDevice_type:
device_os
setDevice_os:
mic_type
setMic_type:
udm_host
setUdm_host:
udm_port
setUdm_port:
tandem_mode
setTandem_mode:
store_audio
setStore_audio:
stream_unstable_results
setStream_unstable_results:
end_point_mode
setEnd_point_mode:
start_audio_bookmark
setStart_audio_bookmark:
is_far_field
setIs_far_field:
enable_utterance_detection
setEnable_utterance_detection:
enable_endpoint_candidate
setEnable_endpoint_candidate:
start_recognition_at
setStart_recognition_at:
start_endpointing_at
setStart_endpointing_at:
enable_hybrid_endpoint
setEnable_hybrid_endpoint:
client_endpointer_model_version
setClient_endpointer_model_version:
keyboard_identifier
setKeyboard_identifier:
input_origin
setInput_origin:
initial_recognition_candidate_id
setInitial_recognition_candidate_id:
disable_auto_punctuation
setDisable_auto_punctuation:
keyboard_dictation
setKeyboard_dictation:
experiment_id
setExperiment_id:
speech_request_source
setSpeech_request_source:
fork_id
setFork_id:
application_name
setApplication_name:
metadata
setMetadata:
start_speech_request
setStart_speech_request:
user_parameters
setUser_parameters:
primary_speech_id
setPrimary_speech_id:
product_id
setProduct_id:
vendor_id
setVendor_id:
contextual_text
setContextual_text:
pron_hints
setPron_hints:
left_context
setLeft_context:
right_context
setRight_context:
context_with_pron_hints
setContext_with_pron_hints:
user_language_profile
setUser_language_profile:
user_acoustic_profile
setUser_acoustic_profile:
audio_bytes
setAudio_bytes:
audio_bytes:
packet_count
setPacket_count:
total_audio_recorded_seconds
setTotal_audio_recorded_seconds:
features_at_endpoint
setFeatures_at_endpoint:
server_feature_latency_distribution
setServer_feature_latency_distribution:
updated_acoustic_profile
setUpdated_acoustic_profile:
pronunciations
orthography
setOrthography:
setPronunciations:
pronunciations:
frequency
setFrequency:
setTag:
setAttributes:
category_name
setCategory_name:
category_data
setCategory_data:
user_data
setUser_data:
setError_code:
setError_str:
incomplete_profile
setIncomplete_profile:
recreate_apg_prons
setRecreate_apg_prons:
reason
setReason:
phonemes
setPhonemes:
blob
setBlob:
blob:
apg_id
setApg_id:
voc_token
setVoc_token:
tts_pronunciations
setTts_pronunciations:
human_readable_prons
setHuman_readable_prons:
apg_ids
setApg_ids:
recovery_return_codes
setRecovery_return_codes:
voc_tokens
setVoc_tokens:
num_of_requested
setNum_of_requested:
num_of_processed
setNum_of_processed:
num_of_succeeded
setNum_of_succeeded:
words_list
setWords_list:
formatted_words_list
setFormatted_words_list:
post_itn_string
setPost_itn_string:
nbest_variants_max
setNbest_variants_max:
normalized_tokens
setNormalized_tokens:
original_token
setOriginal_token:
nbest_variants
setNbest_variants:
pron_sequence
setPron_sequence:
log_weight
setLog_weight:
token
setToken:
pron_source
setPron_source:
sanitized_sequences
setSanitized_sequences:
prons
setProns:
normalized_prons
setNormalized_prons:
sanitized_tokens
setSanitized_tokens:
is_pron_guessed
setIs_pron_guessed:
g2p_version
setG2p_version:
g2p_model_version
setG2p_model_version:
phoneset_version
setPhoneset_version:
aot_token_prons
setAot_token_prons:
jit_token_prons
setJit_token_prons:
index
setIndex:
start_index
end_index
do_not_translate
raw_sausage
setRaw_sausage:
raw_nbest_choices
setRaw_nbest_choices:
post_itn_tokens
setPost_itn_tokens:
post_itn_recognition
setPost_itn_recognition:
itn_alignments
setItn_alignments:
translation_phrase
pre_itn_payload
setPre_itn_payload:
post_itn_payload
setPost_itn_payload:
pre_sausage_payload
setPre_sausage_payload:
setSpans:
source_language
target_language
siri_translation_info
setSiri_translation_info:
speech_translation_info
setSpeech_translation_info:
siri_payload_translation_info
setSiri_payload_translation_info:
sequence_id
setSequence_id:
web_translation_info
setWeb_translation_info:
disable_log
setDisable_log:
opt_in_status
setOpt_in_status:
app_id
setReturn_string:
n_best_translated_phrases
setN_best_translated_phrases:
engine_input
setEngine_input:
engine_output
setEngine_output:
mt_alignment
setMt_alignment:
translated_tokens
setTranslated_tokens:
meta_info
setMeta_info:
low_confidence
setLow_confidence:
end_point_likelihood
setEnd_point_likelihood:
setProcessed_audio_duration_ms:
latitude
setLatitude:
longitude
setLongitude:
enable_geo_location_features
setEnable_geo_location_features:
longValue
initWithLong:
speech_packet_count
setSpeech_packet_count:
processed
setProcessed:
version
setVersion:
threshold
setThreshold:
score
setScore:
result_id
setResult_id:
setSnr:
fingerprint_detection
setFingerprint_detection:
start_speech_time
setStart_speech_time:
end_speech_time
setEnd_speech_time:
speech_detected
setSpeech_detected:
audio_packets
setAudio_packets:
ref_transcript
setRef_transcript:
blamer_report
setBlamer_report:
token_str
setToken_str:
log10_score
setLog10_score:
ngram_used
setNgram_used:
transcript
setTranscript:
setPpl:
enable_completion
setEnable_completion:
max_results
setMax_results:
max_expand_paths
setMax_expand_paths:
max_tm_score
setMax_tm_score:
abs_pruning_threshold
setAbs_pruning_threshold:
rel_pruning_threshold
setRel_pruning_threshold:
enable_word_boundary
setEnable_word_boundary:
max_path_num_at_boundary
setMax_path_num_at_boundary:
parabolic_error_wide
setParabolic_error_wide:
parabolic_error_center
setParabolic_error_center:
parabolic_error_bias
setParabolic_error_bias:
parabolic_error_min
setParabolic_error_min:
max_latency
setMax_latency:
word_penalty
setWord_penalty:
delimiter
setDelimiter:
matched_result
setMatched_result:
total_score
setTotal_score:
tm_score
setTm_score:
match_ids
setMatch_ids:
debug_information
setDebug_information:
matcher_id
setMatcher_id:
query
setQuery:
target
setTarget:
config
setConfig:
latency
setLatency:
expanded_path
setExpanded_path:
setResults:
keyword_orthography
setKeyword_orthography:
posterior
setPosterior:
keywords
setKeywords:
enable_sanitization
setEnable_sanitization:
corrected_sausage
setCorrected_sausage:
n_best_list
setN_best_list:
setNum_of_words:
setTrailing_silence_duration:
setEos_likelihood:
setPause_counts:
setSilence_posterior:
original_utterance
setOriginal_utterance:
corrected_utterance
setCorrected_utterance:
original_words
setOriginal_words:
corrected_words
setCorrected_words:
corrections
setCorrections:
fe_feature
setFe_feature:
fe_feature_only
setFe_feature_only:
quality
setQuality:
type
setType:
voice
setVoice:
resource
setResource:
channel_type
setChannel_type:
context_info
setContext_info:
dialog_identifier
setDialog_identifier:
experiment_identifier
setExperiment_identifier:
normalized_text
setNormalized_text:
phoneme_sequence
setPhoneme_sequence:
audio_type
setAudio_type:
enable_word_timing_info
setEnable_word_timing_info:
voice_name
setVoice_name:
preferred_voice_type
setPreferred_voice_type:
context
setContext:
experiment
setExperiment:
feature_flags
setFeature_flags:
sample_rate
setSample_rate:
format_id
setFormat_id:
format_flags
setFormat_flags:
bytes_per_packet
setBytes_per_packet:
frames_per_packet
setFrames_per_packet:
bytes_per_frame
setBytes_per_frame:
channels_per_frame
setChannels_per_frame:
bits_per_channel
setBits_per_channel:
reserved
setReserved:
word
setWord:
sample_idx
setSample_idx:
offset
setOffset:
setLength:
timestamp
setTimestamp:
setAudio:
audio:
setDecoder_description:
playback_description
setPlayback_description:
word_timing_info
setWord_timing_info:
feature
setFeature:
stream_id
setStream_id:
streaming_playback_buffer_size_in_seconds
setStreaming_playback_buffer_size_in_seconds:
current_pkt_number
setCurrent_pkt_number:
total_pkt_number
setTotal_pkt_number:
audio_length
setAudio_length:
original_session_id
setOriginal_session_id:
cache_meta_info
setCache_meta_info:
cache_object
setCache_object:
endpoint_threshold
setEndpoint_threshold:
endpoint_extra_delay
setEndpoint_extra_delay:
audio_frames
setAudio_frames:
source_locale
setSource_locale:
target_locale
setTarget_locale:
conversation_id
setConversation_id:
translation_locale_pairs
setTranslation_locale_pairs:
translation_request
setTranslation_request:
text_to_speech_requests
setText_to_speech_requests:
restricted_mode
setRestricted_mode:
translation_locale_pair
setTranslation_locale_pair:
detected_locale
setDetected_locale:
user_selected_locale
setUser_selected_locale:
senses
setSenses:
user_selected_sense
setUser_selected_sense:
user_interacted_senses
setUser_interacted_senses:
text_to_speech_response
setText_to_speech_response:
server_endpoint_features
setServer_endpoint_features:
saliency
setSaliency:
tags
setTags:
label
setLabel:
matchers
setMatchers:
is_variable_match
setIs_variable_match:
is_user_vocabulary
setIs_user_vocabulary:
is_app_vocabulary
setIs_app_vocabulary:
is_entity_name_node
setIs_entity_name_node:
is_entity_reference_node
setIs_entity_reference_node:
begin
setBegin:
setEnd:
match_type
setMatch_type:
speech_alternate
setSpeech_alternate:
semantic
setSemantic:
dbpedia_classes
setDbpedia_classes:
matching_tokens
setMatching_tokens:
is_salient
setIs_salient:
is_derived
setIs_derived:
matched_token_index
setMatched_token_index:
utterance
setUtterance:
interaction_id
setInteraction_id:
locale
input
setInput:
output
setOutput:
meta_infos
setMeta_infos:
example_id
setExample_id:
debug_info
setDebug_info:
predictions
setPredictions:
ner_score
setNer_score:
global_neu_score
setGlobal_neu_score:
nen_all_spans_aggregate_score
setNen_all_spans_aggregate_score:
ner_alternative_index
setNer_alternative_index:
setB:
setE:
entity_type
setEntity_type:
ner_entity_confidence_score
setNer_entity_confidence_score:
nen_title
setNen_title:
nen_id
setNen_id:
nen_entity_match_score
setNen_entity_match_score:
start_token_position
setStart_token_position:
end_token_position
setEnd_token_position:
position
setPosition:
metrics_info
setMetrics_info:
positional_features
setPositional_features:
global_features
setGlobal_features:
span_feature_indices
setSpan_feature_indices:
word_embeddings
setWord_embeddings:
char_embeddings
setChar_embeddings:
raw_instance_str
setRaw_instance_str:
neu_request
setNeu_request:
features
setFeatures:
indices
setIndices:
values
setValues:
shortcuts
setShortcuts:
raw_string
setRaw_string:
shortcut_score_pairs
setShortcut_score_pairs:
shortcut
setShortcut:
similarity_score
setSimilarity_score:
language_parameters_by_id
setLanguage_parameters_by_id:
is_low_confidence
setIs_low_confidence:
setTranslated_text:
locales
setLocales:
contentAsFTStartPronGuessRequest
setContentAsFTStartPronGuessRequest:
contentAsFTAudioPacket
setContentAsFTAudioPacket:
contentAsFTFinishAudio
setContentAsFTFinishAudio:
contentAsFTCancelRequest
setContentAsFTCancelRequest:
contentAsFTPronGuessResponse
setContentAsFTPronGuessResponse:
contentAsFTStartBatchRecoverRequest
setContentAsFTStartBatchRecoverRequest:
contentAsFTBatchRecoverFinalResponse
setContentAsFTBatchRecoverFinalResponse:
contentAsFTStartSpeechRequest
setContentAsFTStartSpeechRequest:
contentAsFTUpdateAudioInfo
setContentAsFTUpdateAudioInfo:
contentAsFTSetRequestOrigin
setContentAsFTSetRequestOrigin:
contentAsFTSetSpeechContext
setContentAsFTSetSpeechContext:
contentAsFTSetSpeechProfile
setContentAsFTSetSpeechProfile:
contentAsFTSetEndpointerState
setContentAsFTSetEndpointerState:
contentAsFTResetServerEndpointer
setContentAsFTResetServerEndpointer:
contentAsFTCheckForSpeechRequest
setContentAsFTCheckForSpeechRequest:
contentAsFTSetAlternateRecognitionSausage
setContentAsFTSetAlternateRecognitionSausage:
contentAsFTFinalSpeechRecognitionResponse
setContentAsFTFinalSpeechRecognitionResponse:
contentAsFTPartialSpeechRecognitionResponse
setContentAsFTPartialSpeechRecognitionResponse:
contentAsFTUpdatedAcousticProfile
setContentAsFTUpdatedAcousticProfile:
contentAsFTEndPointLikelihood
setContentAsFTEndPointLikelihood:
contentAsFTEndPointCandidate
setContentAsFTEndPointCandidate:
contentAsFTRecognitionProgress
setContentAsFTRecognitionProgress:
contentAsFTCheckForSpeechResponse
setContentAsFTCheckForSpeechResponse:
contentAsFTRecognitionCandidate
setContentAsFTRecognitionCandidate:
contentAsFTRequestStatsResponse
setContentAsFTRequestStatsResponse:
contentAsFTServerEndpointFeatures
setContentAsFTServerEndpointFeatures:
contentAsFTClientSetupInfo
setContentAsFTClientSetupInfo:
contentAsFTAudioLimitExceeded
setContentAsFTAudioLimitExceeded:
contentAsFTMultiUserStartSpeechRequest
setContentAsFTMultiUserStartSpeechRequest:
setContentAsFTFinalBlazarResponse:
contentAsFTStartMultilingualSpeechRequest
setContentAsFTStartMultilingualSpeechRequest:
contentAsFTLanguageDetected
setContentAsFTLanguageDetected:
contentAsFTStartSpeechTranslationRequest
setContentAsFTStartSpeechTranslationRequest:
contentAsFTSpeechTranslationAudioPacket
setContentAsFTSpeechTranslationAudioPacket:
contentAsFTStartSpeechTranslationLoggingRequest
setContentAsFTStartSpeechTranslationLoggingRequest:
contentAsFTSpeechTranslationPartialRecognitionResponse
setContentAsFTSpeechTranslationPartialRecognitionResponse:
contentAsFTSpeechTranslationFinalRecognitionResponse
setContentAsFTSpeechTranslationFinalRecognitionResponse:
contentAsFTSpeechTranslationMtResponse
setContentAsFTSpeechTranslationMtResponse:
contentAsFTSpeechTranslationTextToSpeechResponse
setContentAsFTSpeechTranslationTextToSpeechResponse:
contentAsFTSpeechTranslationServerEndpointFeatures
setContentAsFTSpeechTranslationServerEndpointFeatures:
contentAsFTBatchTranslationRequest
setContentAsFTBatchTranslationResponse:
contentAsFTStartTextToSpeechStreamingRequest
setContentAsFTStartTextToSpeechStreamingRequest:
contentAsFTBeginTextToSpeechStreamingResponse
setContentAsFTBeginTextToSpeechStreamingResponse:
contentAsFTPartialTextToSpeechStreamingResponse
setContentAsFTPartialTextToSpeechStreamingResponse:
contentAsFTFinalTextToSpeechStreamingResponse
setContentAsFTFinalTextToSpeechStreamingResponse:
contentAsFTQssAckResponse
setContentAsFTQssAckResponse:
contentAsFTStartLanguageDetectionRequest
setContentAsFTStartLanguageDetectionRequest:
contentAsFTLanguageDetectionResponse
setContentAsFTLanguageDetectionResponse:
pair
decodeObjectForKey:
setPair:
sourceASRState
targetASRState
mtState
sourceTTSState
setSourceTTSState:
targetTTSState
setTargetTTSState:
_pairState
_pair
_sourceASRState
_targetASRState
_mtState
_sourceTTSState
_targetTTSState
initWithOspreyToken:
stringWithString:
setLowConfidence:
updateWithEngineMeta:
initWithOspreyPhrase:
initWithOspreyMtResponsePhrase:
setFinal:
containsString:
setSanitizedFormattedString:
setTranscriptions:
initWithOspreySausage:choices:locale:
setBestRecognitionAlternatives:
initWithOspreyResponse:confidenceThreshold:isSanitized:
initWithOspreyPartialRecognitionResponse:isSanitized:
dictionaryWithDictionary:
initWithModelURLs:modelVersions:
initWithModelURL:language:
initWithModelURL:task:
loadTranslatorFrom:to:
_loadRecognizers
_loadTranslatorForTask:
_loadEtiquetteSanitizers
initWithText:confidence:
sanitizedStringForString:
lowConfidence
initWithFormattedString:sanitizedFormattedString:confidence:lowConfidence:tokens:preToPostITN:
metaInfo
resultWithLocale:translations:
oppositeToLocale:
addFieldsFromDictionary:internalOnly:
_handleTranslationResults:withContext:
setSanitizedSourceString:
translateTokens:from:to:completion:
sanitizedFormattedString
_translateString:withContext:toLocale:completion:
_paragraphResultFromSentences:
_ltSequentialMap:completion:
_translateParagraph:withContext:toLocale:completion:
_translate:withContext:toLocale:paragraphResult:completion:
cancelRecognition
bestTranscription
initWithCompletion:
speak:withContext:
passthroughResultWithString:sanitizedString:locale:
translateString:from:to:completion:
addFieldsWithError:
timestampWithName:
_translate:withContext:completion:
transcriptions
isLowConfidence
_getBestRecognitionResult:context:
startRecognitionForLocale:autoEndpoint:resultHandler:
initWithLocalePair:assetInfo:
_speak:context:completion:
_assetInfo
_recognizer
_synthesizer
_etiquetteSanitizers
_translator
_callbackQueue
_lidWaitGroup
_lidBestResult
_lidResult
_didEndpointSpeech
initWithSuiteName:
setLanguageCode:
setOutputPath:
setVoiceType:
setCanUseServerTTS:
startSpeakingRequest:
stopSpeakingAtNextBoundary:synchronously:error:
dictionaryMetrics
speechSynthesizer:didStartSpeakingRequest:
speechSynthesizer:withRequest:didReceiveTimingInfo:
speechSynthesizer:didFinishSpeakingRequest:successfully:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeakingRequest:withInstrumentMetrics:
speechSynthesizer:didPauseSpeakingRequest:
speechSynthesizer:didContinueSpeakingRequest:
speechSynthesizer:willSpeakRangeOfSpeechString:forRequest:
speechSynthesizer:didFinishSynthesisRequest:withInstrumentMetrics:error:
speechSynthesizer:didStartPresynthesizedAudioRequest:
speechSynthesizer:didStopPresynthesizedAudioRequest:atEnd:error:
speechSynthesizer:didFinishPresynthesizedAudioRequest:withInstrumentMetrics:error:
speechSynthesizer:didFinishPrewarmRequest:withError:
speechSynthesizer:didFinishSynthesisRequest:withError:
speechSynthesizer:didStopPresynthesizedAudioRequestAtEnd:error:
speechSynthesizerDidStartSpeaking:
speechSynthesizer:didFinishSpeaking:phonemesSpoken:withError:
speechSynthesizer:didFinishSpeaking:withError:
speechSynthesizer:didFinishSpeakingRequest:successfully:withError:
speechSynthesizerDidPauseSpeaking:
speechSynthesizerDidContinueSpeaking:
speechSynthesizer:willSpeakRangeOfSpeechString:
stringByReplacingOccurrencesOfString:withString:
_ltEqual:
_assetUrl
setAlignments:
initWithOspreySpeechTranslationMTResponse:
initWithModelURL:language:modelVersion:
enumerateKeysAndObjectsUsingBlock:
triggerServerSideEndPointer
startRecognitionWithAutoStop:resultHandler:
_recognizers
senseFromDictionary:
setSenseID:
setDefinition:
setPhrasebookMatch:
isPhrasebookMatch
setSourceMatch:
setTargetMatch:
sensesFromArray:
senseWithPhrasebookMatchMeta:
senseID
definition
sourceMatch
targetMatch
_phrasebookMatch
_senseID
_definition
_sourceMatch
_targetMatch
conversationID
setConversationID:
selectedLocale
setSelectedLocale:
detectionResult
setDetectionResult:
_conversationID
_selectedLocale
_detectionResult
combinedLocaleIdentifier
markResponse
markPageComplete
dict
firstResponse
pageComplete
processName
setProcessName:
_start
_firstResponse
_pageComplete
_processName
service
setService:
_getServiceProxyWithDelegate:errorHandler:block:
translationParagraph
translateParagraphs:withContext:completion:
_ensureServiceConnection:
log:
initWithTranslator:
translate:
provideFeedback:
setURL:
translator
setTranslator:
_outstandingRequests
_logging
_URL
requiredCapabilityIdentifier
minimumSupportedConfigurationVersion
maximumSupportedConfigurationVersion
assetVersion
isCompatibleWithThisDevice
isNewerVersionThan:
canBePurged
translatesLanguagePair:
formatVersion
initWithIdentifier:text:shouldTranslate:
_shouldTranslate
dealloc
appendData:
replaceBytesInRange:withBytes:length:
didCompressPackets:totalPacketCount:
initWithDelegate:
startCompressionNarrowband:
addAudioSampleData:
_audioConverter
_bufferedAudio
_packetIndex
_bytesConsumed
initWithIdentifier:range:
setShouldTranslate:
_range
sourceString
sanitizedSourceString
alignments
_locale
_translations
_sourceString
_sanitizedSourceString
_alignments
offlineEngine
onlineEngine
setOfflineEngine:
setOnlineEngine:
offlineDelegateBuffer
setOfflineDelegateBuffer:
_onlineTranslationStarted
_translationEnded
_serverCompleted
_offlineEngine
_onlineEngine
_offlineDelegateBuffer
_ltAsyncMap:queue:completion:
setObject:atIndexedSubscript:
objectEnumerator
nextObject
_ltAsyncMap:completion:
initWithSourceContent:targetContent:
sourceContentAsJSONString
targetContentAsJSONString
_sourceContentAsJSONString
_targetContentAsJSONString
clearCaches
_getSyncServiceProxyWithDelegate:errorHandler:block:
_offlineLanguageStatus:
_downloadAssetForLanguagePair:userInitiated:completion:
_purgeAssetForLanguagePair:userInitiated:completion:
_purgeAllAssets:
_updateAllAssets:
availableLocalePairsForTask:completion:
additionalLikelyPreferredLocalesForLocale:completion:
configInfoForLocale:otherLocale:completion:
task:isSupportedInCountry:completion:
languageForText:completion:
languagesForText:completion:
initWithMachServiceName:options:
setRemoteObjectInterface:
setExportedObject:
setExportedInterface:
invalidate
remoteObjectProxyWithErrorHandler:
initWithServiceName:options:
synchronousRemoteObjectProxyWithErrorHandler:
preheatWithContext:completion:
cleanup
archivedDataWithRootObject:requiringSecureCoding:error:
logWithRequestData:
taskIsSupportedInCurrentRegion:completion:
preheatForRequestSync:
preheatForRequest:completion:
startTranslationSession
_connection
initWithNode:range:
node
setNode:
setRange:
_node
_token
treeForReplacementTokens:
initWithReplacementTokenDictionary:language:
lowercaseString
enumerateSubstringsInRange:options:usingBlock:
removeObjectsInArray:
replaceCharactersInRange:withString:
replacementStringForString:forToken:
matchesForString:
stringByReplacingMatches:inString:
_replacementTree
supportedByQuasarConfig:
initWithLanguage:withSdapiConfig:quasarConfig:
initWithGeneralVoc:withLexiconEnh:withItnEnh:
initWithConfiguration:useQuasarFormatter:
setDetectUtterances:
setConcatenateUtterances:
runRecognitionWithResultStream:language:task:samplingRate:
recognitionHandler
resultWithPackage:formatter:locale:wordConfidenceThreshold:isFinal:
_recognizedResult:error:
detectUtterances
hasSpaceAfter
tokenName
hatToQsrString:
resultWithResult:formatter:locale:isFinal:
speechRecognizer:didRecognizePartialResult:
speechRecognizer:didFinishRecognitionWithError:
speechRecognizer:didRecognizeFinalResults:
speechRecognizer:didRecognizeFinalResults:tokenSausage:nBestChoices:
speechRecognizer:didRecognizeFinalResultPackage:
speechRecognizer:didProcessAudioDuration:
speechRecognizer:didRecognizeRawEagerRecognitionCandidate:
speechRecognizer:didProduceEndpointFeaturesWithWordCount:trailingSilenceDuration:eosLikelihood:pauseCounts:silencePosterior:processedAudioDurationInMilliseconds:
speechRecognizer:didRecognizePartialResultNbest:
modelURL
modelVersion
setRecognitionHandler:
_buffer
_formatter
_detectedSpeechEndpoint
_finalResult
_recognitionQueue
_modelVersion
_language
_recognitionHandler
retrieveSessionWithID:
currentRoute
outputs
portType
defaultCenter
handleMediaServerReset
addObserver:selector:name:object:
removeObserver:
isAudioQueueRunning
waitForAudioQueueStop
signalQueueRunningStateChanged
_audioQueue
_waitForStateChange
_stateChangeCondition
_state
_offlineEngineForContext:error:
_onlineEngineForContext:error:
_engineForContext:error:
cancelExistingSessions
initWithEngine:delegate:
_speechSessionCompleted
startLoggingRequest:
setAvailableLocales:
detectionForString:
detectionForStrings:
translateParagraphs:withContext:paragraphResult:completion:
cancelSpeechSession
cancelSpeechSessionWithID:
cleanupOfflineEngine
_offlineCachedEngine
_onlineCachedEngine
_speakSession
_logger
engine
setEngine:
languageDetector
endpointer
_languageDetector
_endpointer
interfaceWithProtocol:
translate:withContext:completion:
provideFeedback:withContext:
setClasses:forSelector:argumentIndex:ofReply:
dataUsingEncoding:
setStatistics:
preToPostITN
statistics
proToPostITN
setProToPostITN:
_lowConfidence
_formattedString
_sanitizedFormattedString
_confidence
_preToPostITN
_tokens
_senses
_statistics
_proToPostITN
cleanupOnDisconnect
setInterruptionHandler:
setInvalidationHandler:
valueForEntitlement:
processIdentifier
stringWithUTF8String:
remoteObjectProxy
logRequestOfType:context:
_clientDelegate
initWithName:
unarchivedObjectOfClasses:fromData:error:
_speechSessionID
initWithFlatbuffData:root:verify:
initWithBytes:length:encoding:
addObjectToBuffer:
initWithBytesNoCopy:length:deallocator:
flatbuffData
initWithFlatbuffData:
initAndVerifyWithFlatbuffData:
initWithFlatbuffData:root:
_storage
_root
numberWithInt:
numberWithFloat:
completionBlock
performSpeechTranslationWithDelegate:requestBuilder:completion:
_ospreySpeechTranslationRequestWithHybridEndpointer:
sendSpeechTranslationStreamingRequest:
initCommon
_ospreyTextToSpeechTranslationRequestWithText:
updateServerTimeout:
closeStream
_primaryLanguageRecognized
confirmDataIfNeeded
findASRFallbackLocale
_translationForLocale:
_handlePartialRecognitionResponse:
_handleFinalRecognitionResponse:
_handleAudioLimitExceededResponse:
_handleTranslationResponse:
_handleTTSResponse:
_handleFinalBlazarResponse:
_handleServerEndpointFeatures:
streamDidReceiveSpeechTranslationStreamingResponse:
streamFailVerifySpeechTranslationStreamingResponse:
initialOnlineTimeout
setInitialOnlineTimeout:
onlineTimeout
setOnlineTimeout:
endpointTimeout
setEndpointTimeout:
_streamContext
_asrBasedFallbackLocale
_finalASRResults
_mtResults
_confirmedTranslations
_speechCompressor
_audioPacketCount
_initialOnlineTimeout
_onlineTimeout
_endpointTimeout
_completionBlock
arrayWithCapacity:
arrayWithArray:
nBestResults
_transcriptionWithResult:locale:formatter:
recognition
initWithRecognition:wordConfidenceThreshold:
initWithFormattedString:locale:confidence:
initWithPackage:formatter:locale:wordConfidenceThreshold:isFinal:
initWithResult:formatter:locale:isFinal:
initWithString:locale:isFinal:
formattedStringWithStrings:
resultWithString:locale:isFinal:
bestRecognitionAlternatives
_final
_transcriptions
_bestRecognitionAlternatives
domain
userInfo
markStart
markEnd
_eventName
_endTime
_fields
processString:
languageHypothesesWithMaximum:
availableLocales
_availableLocales
initWithIdentifier:text:spans:
_spans
interpretationIndices
tokenSausage
hasSpaceBefore
lastObject
setHasSpaceAfter:
setBestAlternativeIndex:
setAlternatives:
alternatives
setBins:
bins
_bins
bestAlternativeIndex
_alternatives
_bestAlternativeIndex
_hasSpaceAfter
streamFailVerifyPronGuessStreamingResponse:
streamDidReceivePronGuessStreamingResponse:
bidirectionalStreamingRequestWithMethodName:requestBuilder:streamingResponseHandler:completion:
initWithGRPCStreamingCallContext:
streamFailVerifyBatchRecoverStreamingResponse:
streamDidReceiveBatchRecoverStreamingResponse:
performPronGuessWithDelegate:requestBuilder:completion:
performBatchRecoverWithDelegate:requestBuilder:completion:
streamFailVerifyRecognitionStreamingResponse:
streamDidReceiveRecognitionStreamingResponse:
unaryRequestWithMethodName:requestData:requestBuilder:responseHandler:
performRecognitionWithDelegate:requestBuilder:completion:
performErrorBlamer:requestBuilder:completion:
performItn:requestBuilder:completion:
performTextNormalization:requestBuilder:completion:
performPostItnHammer:requestBuilder:completion:
performKeywordFinder:requestBuilder:completion:
performCorrectionsValidator:requestBuilder:completion:
performGraphemeToPhoneme:requestBuilder:completion:
streamFailVerifyMultiUserStreamingResponse:
streamDidReceiveMultiUserStreamingResponse:
streamFailVerifyMultilingualStreamingResponse:
streamDidReceiveMultilingualStreamingResponse:
streamFailVerifyTextToSpeechRouterStreamingStreamingResponse:
streamDidReceiveTextToSpeechRouterStreamingStreamingResponse:
performMultiUserWithDelegate:requestBuilder:completion:
performMultilingualWithDelegate:requestBuilder:completion:
performTextToSpeechRouterStreamingWithDelegate:requestBuilder:completion:
performLmScorer:requestBuilder:completion:
performCreateLanguageProfile:requestBuilder:completion:
streamFailVerifyTextToSpeechStreamingStreamingResponse:
streamDidReceiveTextToSpeechStreamingStreamingResponse:
performTextToSpeech:requestBuilder:completion:
performTextToSpeechStreamingWithDelegate:requestBuilder:completion:
performNeu:requestBuilder:completion:
performIntentPredictionDemo:requestBuilder:completion:
performShortcutFuzzyMatch:requestBuilder:completion:
performAStarFuzzyMatching:requestBuilder:completion:
streamFailVerifyLanguageDetectionStreamingResponse:
streamDidReceiveLanguageDetectionStreamingResponse:
performLanguageDetectionWithDelegate:requestBuilder:completion:
writeFrame:
finishWriting
sendPronGuessStreamingRequest:
_grpcContext
sendBatchRecoverStreamingRequest:
sendRecognitionStreamingRequest:
sendMultiUserStreamingRequest:
sendMultilingualStreamingRequest:
sendTextToSpeechRouterStreamingStreamingRequest:
sendTextToSpeechStreamingStreamingRequest:
sendLanguageDetectionStreamingRequest:
initWithBundleIdentifier:
specifiersForPolicyOptions:force:
addObjectsFromArray:
groupSpecifierWithID:
rangeOfString:
valueWithNonretainedObject:
confirmOnDeviceIfNeeded:specifier:
readPreferenceValue:
preferenceSpecifierNamed:target:set:get:detail:cell:edit:
presenterForPrivacySplashWithIdentifier:
setPresentingViewController:
present
rootController
setPreferenceValue:specifier:
setTitle:
setPrompt:
setCancelButton:
setOkButton:
openAppToLanguages:
setConfirmationAction:
showConfirmationViewForSpecifier:useAlert:
defaultWorkspace
openApplicationWithBundleID:
specifiers
showTranslatePrivacy
minConfidence
jsonRepresentation
componentsSeparatedByString:
startSpeechLIDRequest:
startSafariLatencyLoggingRequest:
mtAppService
_mtAppService
ranges
setRanges:
_ranges
_ospreyDataSharingStatus
_ttsVoiceStringWithLocale:
B24@0:8@16
#16@0:8
@16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v24@0:8@16
v16@0:8
v32@0:8@16@24
v40@0:8@16@24@32
v24@0:8@"_LTLanguageDetectionResult"16
v32@0:8@"_LTServerEndpointerFeatures"16@"NSLocale"24
v24@0:8@"_LTSpeechRecognitionResult"16
v24@0:8@"_LTTranslationResult"16
v24@0:8@"NSError"16
v40@0:8@"NSString"16@"_LTTranslationResult"24@"NSError"32
@"_LTSpeechRecognitionResult"
@"_LTTranslationResult"
@"NSError"
@"<_LTSpeechTranslationDelegate>"
v40@0:8@16@24q32
@"NSObject<OS_dispatch_queue>"
@"NSOrderedSet"
@24@0:8@16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@32@0:8@16@24
@"NSLocale"
@"NSCountedSet"
B32@0:8@16@24
B32@0:8@"NSXPCListener"16@"NSXPCConnection"24
v24@0:8@"_LTClientConnection"16
@"NSXPCListener"
@"NSMutableArray"
@"_LTTranslationServer"
q16@0:8
v24@0:8q16
v20@0:8B16
I16@0:8
v20@0:8I16
@"NSString"
@"_LTLocalePair"
@"NSURL"
@"NSArray"
@40@0:8@16B24@28B36
@"NSDictionary"
v36@0:8@16@24B32
v36@0:8@"NSString"16@"NSDictionary"24B32
d16@0:8
@"_LTTranslationContext"
@"CSLanguageDetector"
@"_LTLanguageDetectionResult"
@40@0:8q16@24@32
@?16@0:8
v24@0:8@?16
@"_LTTranslationParagraph"
@"FTMutableBatchTranslationRequest_Paragraph"
v24@0:8@"FTBatchTranslationStreamingResponse"16
v24@0:8Q16
@"FTMutableBatchTranslationRequest"
@"LTSchemaBatchTranslationEvent"
@"NSMutableDictionary"
@"NSDate"
v28@0:8B16@20
v40@0:8@16@24@?32
v48@0:8@16@24@?32@?40
B24@0:8@"_LTLocalePair"16
v28@0:8B16@"_LTTranslationContext"20
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"_LTTranslationResult"@"NSError">32
v48@0:8@"NSArray"16@"_LTTranslationContext"24@?<v@?@"NSString"@"_LTTranslationResult"@"NSError">32@?<v@?@"NSError">40
v32@0:8@"_LTTranslationContext"16@"<_LTSpeechTranslationDelegate>"24
v24@0:8@"NSData"16
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"_LTAudioData"@"NSError">32
v40@0:8@"_LTTranslationContext"16@"NSString"24@"<_LTSpeechTranslationDelegate>"32
@24@0:8q16
v48@0:8@16q24@32@?40
@"NSOperationQueue"
@"FTMtService"
@"FTBlazarService"
@"_LTOspreySpeechTranslationSession"
@"_LTBatchTranslationResponseHandler"
@"NSObject<OS_dispatch_source>"
@"AFSettingsConnection"
@"_LTTextToSpeechCache"
@64@0:8{AudioStreamBasicDescription=dIIIIIIII}16@56
{AudioStreamBasicDescription=dIIIIIIII}16@0:8
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
@"NSData"
v24@0:8d16
v36@0:8^f16Q24f32
v24@0:8@"EARClientSilenceFeatures"16
B40@0:8@16@24@32
@"_LTHybridEndpointerAssetInfo"
@"_EAREndpointer"
@"NSNumber"
@"_LTServerEndpointerFeatures"
@"EARCaesuraSilencePosteriorGenerator"
{_NSRange=QQ}16@0:8
v32@0:8{_NSRange=QQ}16
{_NSRange="location"Q"length"Q}
@"<_LTTranslationEngine>"
@"_LTPlaybackService"
@64@0:8@16q24@32@40@48@56
@40@0:8@16@24@32
@"MAAsset"
v32@0:8@16@?24
@56@0:8@16@24@32@40@48
v36@0:8B16@20@?28
@"_LTOfflineAssetManager"
q24@0:8@16
@24@0:8^{_NSZone=}16
v28@0:8^{opaqueCMSampleBuffer=}16B24
@"AVAudioConverter"
@"<_LTTranslationService>"
v28@0:8B16@?20
v36@0:8@16B24@?28
@32@0:8@16^@24
@56@0:8@16@24@32@40^@48
@32@0:8q16^@24
i16@0:8
v20@0:8i16
f16@0:8
v20@0:8f16
@36@0:8@16q24B32
@28@0:8@16B24
v48@0:8@16@24@32@?40
v56@0:8@16@24@32@?40@?48
@"_LTSpeechTranslationAssetInfo"
@"_LTMultilingualSpeechRecognizer"
@"_LTOfflineSpeechSynthesizer"
@"EMTTranslator"
@"NSObject<OS_dispatch_group>"
v52@0:8@16@24B32@36@44
v48@0:8@16{_NSRange=QQ}24@40
v48@0:8@16@24@32@40
v44@0:8@16@24B32@36
v36@0:8@16B24@28
v44@0:8@16B24@28@36
v40@0:8@16{_NSRange=QQ}24
v32@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"NSArray"32
v52@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24B32@"NSString"36@"NSError"44
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32
v48@0:8@"VSSpeechSynthesizer"16{_NSRange=QQ}24@"VSSpeechRequest"40
v48@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"VSInstrumentMetrics"32@"NSError"40
v32@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24
v44@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24B32@"NSError"36
v48@0:8@"VSSpeechSynthesizer"16@"VSPresynthesizedAudioRequest"24@"VSInstrumentMetrics"32@"NSError"40
v40@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24@"NSError"32
v36@0:8@"VSSpeechSynthesizer"16B24@"NSError"28
v24@0:8@"VSSpeechSynthesizer"16
v44@0:8@"VSSpeechSynthesizer"16B24@"NSString"28@"NSError"36
v44@0:8@"VSSpeechSynthesizer"16@"VSSpeechRequest"24B32@"NSError"36
v40@0:8@"VSSpeechSynthesizer"16{_NSRange=QQ}24
@24@0:8@?16
@"_LTSafariLatencyLoggingRequest"
@"_LTTranslator"
@36@0:8@16@24B32
@"<_LTSpeechCompressorDelegate>"
^{OpaqueAudioConverter=}
@"NSMutableData"
@40@0:8@16{_NSRange=QQ}24
@"_LTSpeechTranslationResultsBuffer"
v32@0:8@?16@?24
v40@0:8@?16@24@?32
v32@0:8q16@?24
v40@0:8q16@24@?32
v40@0:8@16@?24@?32
@"NSXPCConnection"
v32@0:8@16d24
v72@0:8@16q24q32d40@48d56q64
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResult"24
v32@0:8@"_EARSpeechRecognizer"16@"NSError"24
v32@0:8@"_EARSpeechRecognizer"16@"NSArray"24
v48@0:8@"_EARSpeechRecognizer"16@"NSArray"24@"NSArray"32@"NSArray"40
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognitionResultPackage"24
v32@0:8@"_EARSpeechRecognizer"16d24
v32@0:8@"_EARSpeechRecognizer"16@"_EARSpeechRecognition"24
v72@0:8@"_EARSpeechRecognizer"16q24q32d40@"NSArray"48d56q64
@"_EARSpeechRecognizer"
@"_EARSpeechRecognitionAudioBuffer"
@"_EARFormatter"
@"_EARSpeechRecognitionResultPackage"
@60@0:8I16{AudioStreamBasicDescription=dIIIIIIII}20
@40@0:8@16q24@32
^{OpaqueAudioQueue=}
{_opaque_pthread_mutex_t="__sig"q"__opaque"[56c]}
{_opaque_pthread_cond_t="__sig"q"__opaque"[40c]}
@"_LTServerSpeechSession"
@"_LTServerSpeakSession"
@"_LTLoggingRequestHandler"
@"NSUUID"
@"_LTLanguageDetector"
@"_LTHybridEndpointer"
v32@0:8@"_LTTranslationContext"16@?<v@?@"NSError">24
v40@0:8@"_LTTranslationParagraph"16@"_LTTranslationContext"24@?<v@?@"_LTTranslationResult"@"NSError">32
v40@0:8@"NSArray"16@"_LTTranslationContext"24@?<v@?@"NSError">32
v32@0:8@"_LTTranslationFeedback"16@"_LTTaskContext"24
v32@0:8@"_LTTranslationContext"16@"NSString"24
v24@0:8@"_LTTranslationContext"16
v32@0:8@"NSString"16@?<v@?@"_LTLanguageDetectionResult">24
v32@0:8@"NSArray"16@?<v@?@"_LTTextLanguageDetectionResult">24
v40@0:8@"NSString"16@"_LTTranslationContext"24@?<v@?@"NSError">32
v24@0:8@?<v@?@"NSArray">16
v36@0:8@"_LTLocalePair"16B24@?<v@?@"NSError">28
v24@0:8@?<v@?@"NSError">16
v32@0:8q16@?<v@?@"NSArray">24
v40@0:8q16@"NSString"24@?<v@?B>32
v32@0:8@"NSLocale"16@?<v@?@"NSArray">24
v40@0:8@"NSLocale"16@"NSLocale"24@?<v@?@"NSDictionary">32
@60@0:8@16@24d32B40@44@52
@"_LTTranslationStatistics"
@"<_LTClientConnectionDelegate>"
@"NSData"16@0:8
@32@0:8@16r^{UserLanguageProfile=[1C]}24
@36@0:8@16r^{UserLanguageProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UserLanguageProfile>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{UserLanguageProfile=[1C]}
@32@0:8@16r^{UserAcousticProfile=[1C]}24
@36@0:8@16r^{UserAcousticProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UserAcousticProfile>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{UserAcousticProfile=[1C]}
@32@0:8@16r^{RecognitionToken=[1C]}24
@36@0:8@16r^{RecognitionToken=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionToken=[1C]}
@32@0:8@16r^{RecognitionPhraseTokens=[1C]}24
@36@0:8@16r^{RecognitionPhraseTokens=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionPhraseTokens>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionPhraseTokens=[1C]}
@32@0:8@16r^{RecognitionPhraseTokensAlternatives=[1C]}24
@36@0:8@16r^{RecognitionPhraseTokensAlternatives=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionPhraseTokensAlternatives>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionPhraseTokensAlternatives=[1C]}
@32@0:8@16r^{RecognitionSausage=[1C]}24
@36@0:8@16r^{RecognitionSausage=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionSausage>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionSausage=[1C]}
@32@0:8@16r^{SetAlternateRecognitionSausage=[1C]}24
@36@0:8@16r^{SetAlternateRecognitionSausage=[1C]}24B32
{Offset<siri::speech::schema_fb::SetAlternateRecognitionSausage>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SetAlternateRecognitionSausage=[1C]}
@32@0:8@16r^{RecognitionChoice=[1C]}24
@36@0:8@16r^{RecognitionChoice=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionChoice>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionChoice=[1C]}
@32@0:8@16r^{RepeatedItnAlignment=[1C]}24
@36@0:8@16r^{RepeatedItnAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedItnAlignment>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RepeatedItnAlignment=[1C]}
@32@0:8@16r^{ChoiceAlignment=[1C]}24
@36@0:8@16r^{ChoiceAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::ChoiceAlignment>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ChoiceAlignment=[1C]}
@32@0:8@16r^{RecognitionResult=[1C]}24
@36@0:8@16r^{RecognitionResult=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionResult>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionResult=[1C]}
@32@0:8@16r^{RequestStatsResponse=[1C]}24
@36@0:8@16r^{RequestStatsResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RequestStatsResponse=[1C]}
@32@0:8@16r^{BoolStat=[1C]}24
@36@0:8@16r^{BoolStat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::BoolStat>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BoolStat=[1C]}
@32@0:8@16r^{Int32Stat=[1C]}24
@36@0:8@16r^{Int32Stat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::Int32Stat>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Int32Stat=[1C]}
@32@0:8@16r^{DoubleStat=[1C]}24
@36@0:8@16r^{DoubleStat=[1C]}24B32
{Offset<siri::speech::schema_fb::RequestStatsResponse_::DoubleStat>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{DoubleStat=[1C]}
@32@0:8@16r^{ItnAlignment=[1C]}24
@36@0:8@16r^{ItnAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnAlignment>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ItnAlignment=[1C]}
@32@0:8@16r^{AcousticFeature=[1C]}24
@36@0:8@16r^{AcousticFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::AcousticFeature>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AcousticFeature=[1C]}
@32@0:8@16r^{AudioAnalytics=[1C]}24
@36@0:8@16r^{AudioAnalytics=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AudioAnalytics=[1C]}
@32@0:8@16r^{SpeechRecognitionFeaturesEntry=[1C]}24
@36@0:8@16r^{SpeechRecognitionFeaturesEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics_::SpeechRecognitionFeaturesEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechRecognitionFeaturesEntry=[1C]}
@32@0:8@16r^{AcousticFeaturesEntry=[1C]}24
@36@0:8@16r^{AcousticFeaturesEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioAnalytics_::AcousticFeaturesEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AcousticFeaturesEntry=[1C]}
@32@0:8@16r^{FinalSpeechRecognitionResponse=[1C]}24
@36@0:8@16r^{FinalSpeechRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalSpeechRecognitionResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{FinalSpeechRecognitionResponse=[1C]}
@32@0:8@16r^{PartialSpeechRecognitionResponse=[1C]}24
@36@0:8@16r^{PartialSpeechRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialSpeechRecognitionResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PartialSpeechRecognitionResponse=[1C]}
@32@0:8@16r^{StartSpeechRequest=[1C]}24
@36@0:8@16r^{StartSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartSpeechRequest=[1C]}
@32@0:8@16r^{UserParameters=[1C]}24
@36@0:8@16r^{UserParameters=[1C]}24B32
{Offset<siri::speech::schema_fb::UserParameters>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{UserParameters=[1C]}
@32@0:8@16r^{MultiUserStartSpeechRequest=[1C]}24
@36@0:8@16r^{MultiUserStartSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::MultiUserStartSpeechRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MultiUserStartSpeechRequest=[1C]}
@32@0:8@16r^{UpdateAudioInfo=[1C]}24
@36@0:8@16r^{UpdateAudioInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::UpdateAudioInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{UpdateAudioInfo=[1C]}
@32@0:8@16r^{ContextWithPronHints=[1C]}24
@36@0:8@16r^{ContextWithPronHints=[1C]}24B32
{Offset<siri::speech::schema_fb::ContextWithPronHints>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ContextWithPronHints=[1C]}
@32@0:8@16r^{SetSpeechContext=[1C]}24
@36@0:8@16r^{SetSpeechContext=[1C]}24B32
{Offset<siri::speech::schema_fb::SetSpeechContext>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SetSpeechContext=[1C]}
@32@0:8@16r^{SetSpeechProfile=[1C]}24
@36@0:8@16r^{SetSpeechProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::SetSpeechProfile>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SetSpeechProfile=[1C]}
@32@0:8@16r^{SetEndpointerState=[1C]}24
@36@0:8@16r^{SetEndpointerState=[1C]}24B32
{Offset<siri::speech::schema_fb::SetEndpointerState>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SetEndpointerState=[1C]}
@32@0:8@16r^{AudioPacket=[1C]}24
@36@0:8@16r^{AudioPacket=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioPacket>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AudioPacket=[1C]}
@32@0:8@16r^{FinishAudio=[1C]}24
@36@0:8@16r^{FinishAudio=[1C]}24B32
{Offset<siri::speech::schema_fb::FinishAudio>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{FinishAudio=[1C]}
@32@0:8@16r^{ServerFeatureLatencyDistributionEntry=[1C]}24
@36@0:8@16r^{ServerFeatureLatencyDistributionEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::FinishAudio_::ServerFeatureLatencyDistributionEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ServerFeatureLatencyDistributionEntry=[1C]}
@32@0:8@16r^{UpdatedAcousticProfile=[1C]}24
@36@0:8@16r^{UpdatedAcousticProfile=[1C]}24B32
{Offset<siri::speech::schema_fb::UpdatedAcousticProfile>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{UpdatedAcousticProfile=[1C]}
@32@0:8@16r^{Word=[1C]}24
@36@0:8@16r^{Word=[1C]}24B32
{Offset<siri::speech::schema_fb::Word>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Word=[1C]}
@32@0:8@16r^{UserDataEntity=[1C]}24
@36@0:8@16r^{UserDataEntity=[1C]}24B32
{Offset<siri::speech::schema_fb::UserDataEntity>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{UserDataEntity=[1C]}
@32@0:8@16r^{CategoryData=[1C]}24
@36@0:8@16r^{CategoryData=[1C]}24B32
{Offset<siri::speech::schema_fb::CategoryData>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CategoryData=[1C]}
@32@0:8@16r^{CreateLanguageProfileRequest=[1C]}24
@36@0:8@16r^{CreateLanguageProfileRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CreateLanguageProfileRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CreateLanguageProfileRequest=[1C]}
@32@0:8@16r^{CreateLanguageProfileResponse=[1C]}24
@36@0:8@16r^{CreateLanguageProfileResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CreateLanguageProfileResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CreateLanguageProfileResponse=[1C]}
@32@0:8@16r^{StartPronGuessRequest=[1C]}24
@36@0:8@16r^{StartPronGuessRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartPronGuessRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartPronGuessRequest=[1C]}
@32@0:8@16r^{CancelRequest=[1C]}24
@36@0:8@16r^{CancelRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CancelRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CancelRequest=[1C]}
@32@0:8@16r^{Pronunciation=[1C]}24
@36@0:8@16r^{Pronunciation=[1C]}24B32
{Offset<siri::speech::schema_fb::Pronunciation>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Pronunciation=[1C]}
@32@0:8@16r^{VocToken=[1C]}24
@36@0:8@16r^{VocToken=[1C]}24B32
{Offset<siri::speech::schema_fb::VocToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{VocToken=[1C]}
@32@0:8@16r^{PronGuessResponse=[1C]}24
@36@0:8@16r^{PronGuessResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PronGuessResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PronGuessResponse=[1C]}
@32@0:8@16r^{RecoverPronsRequest=[1C]}24
@36@0:8@16r^{RecoverPronsRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::RecoverPronsRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecoverPronsRequest=[1C]}
@32@0:8@16r^{RecoverPronsResponse=[1C]}24
@36@0:8@16r^{RecoverPronsResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::RecoverPronsResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecoverPronsResponse=[1C]}
@32@0:8@16r^{StartBatchRecoverRequest=[1C]}24
@36@0:8@16r^{StartBatchRecoverRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartBatchRecoverRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartBatchRecoverRequest=[1C]}
@32@0:8@16r^{BatchRecoverFinalResponse=[1C]}24
@36@0:8@16r^{BatchRecoverFinalResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchRecoverFinalResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchRecoverFinalResponse=[1C]}
@32@0:8@16r^{ItnRequest=[1C]}24
@36@0:8@16r^{ItnRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ItnRequest=[1C]}
@32@0:8@16r^{ItnResponse=[1C]}24
@36@0:8@16r^{ItnResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ItnResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ItnResponse=[1C]}
@32@0:8@16r^{PostItnHammerRequest=[1C]}24
@36@0:8@16r^{PostItnHammerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::PostItnHammerRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PostItnHammerRequest=[1C]}
@32@0:8@16r^{PostItnHammerResponse=[1C]}24
@36@0:8@16r^{PostItnHammerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PostItnHammerResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PostItnHammerResponse=[1C]}
@32@0:8@16r^{TextNormalizationRequest=[1C]}24
@36@0:8@16r^{TextNormalizationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextNormalizationRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextNormalizationRequest=[1C]}
@32@0:8@16r^{NormalizedTokenVariant=[1C]}24
@36@0:8@16r^{NormalizedTokenVariant=[1C]}24B32
{Offset<siri::speech::schema_fb::NormalizedTokenVariant>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{NormalizedTokenVariant=[1C]}
@32@0:8@16r^{NormalizedToken=[1C]}24
@36@0:8@16r^{NormalizedToken=[1C]}24B32
{Offset<siri::speech::schema_fb::NormalizedToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{NormalizedToken=[1C]}
@32@0:8@16r^{TextNormalizationResponse=[1C]}24
@36@0:8@16r^{TextNormalizationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextNormalizationResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextNormalizationResponse=[1C]}
@32@0:8@16r^{PronChoice=[1C]}24
@36@0:8@16r^{PronChoice=[1C]}24B32
{Offset<siri::speech::schema_fb::PronChoice>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PronChoice=[1C]}
@32@0:8@16r^{SanitizedPronToken=[1C]}24
@36@0:8@16r^{SanitizedPronToken=[1C]}24B32
{Offset<siri::speech::schema_fb::SanitizedPronToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SanitizedPronToken=[1C]}
@32@0:8@16r^{TokenProns=[1C]}24
@36@0:8@16r^{TokenProns=[1C]}24B32
{Offset<siri::speech::schema_fb::TokenProns>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TokenProns=[1C]}
@32@0:8@16r^{SanitizedSequence=[1C]}24
@36@0:8@16r^{SanitizedSequence=[1C]}24B32
{Offset<siri::speech::schema_fb::TokenProns_::SanitizedSequence>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SanitizedSequence=[1C]}
@32@0:8@16r^{GraphemeToPhonemeRequest=[1C]}24
@36@0:8@16r^{GraphemeToPhonemeRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::GraphemeToPhonemeRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{GraphemeToPhonemeRequest=[1C]}
@32@0:8@16r^{GraphemeToPhonemeResponse=[1C]}24
@36@0:8@16r^{GraphemeToPhonemeResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::GraphemeToPhonemeResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{GraphemeToPhonemeResponse=[1C]}
@32@0:8@16r^{Alignment=[1C]}24
@36@0:8@16r^{Alignment=[1C]}24B32
{Offset<siri::speech::schema_fb::Alignment>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Alignment=[1C]}
@32@0:8@16r^{Span=[1C]}24
@36@0:8@16r^{Span=[1C]}24B32
{Offset<siri::speech::schema_fb::Span>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Span=[1C]}
@32@0:8@16r^{RepeatedSpan=[1C]}24
@36@0:8@16r^{RepeatedSpan=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedSpan>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RepeatedSpan=[1C]}
@32@0:8@16r^{SpeechTranslationInfo=[1C]}24
@36@0:8@16r^{SpeechTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationInfo=[1C]}
@32@0:8@16r^{SiriTranslationInfo=[1C]}24
@36@0:8@16r^{SiriTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SiriTranslationInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SiriTranslationInfo=[1C]}
@32@0:8@16r^{SiriPayloadTranslationInfo=[1C]}24
@36@0:8@16r^{SiriPayloadTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::SiriPayloadTranslationInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SiriPayloadTranslationInfo=[1C]}
@32@0:8@16r^{WebTranslationInfo=[1C]}24
@36@0:8@16r^{WebTranslationInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WebTranslationInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{WebTranslationInfo=[1C]}
@32@0:8@16r^{TranslationRequest=[1C]}24
@36@0:8@16r^{TranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TranslationRequest=[1C]}
@32@0:8@16r^{TranslationResponse=[1C]}24
@36@0:8@16r^{TranslationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TranslationResponse=[1C]}
@32@0:8@16r^{TranslationToken=[1C]}24
@36@0:8@16r^{TranslationToken=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse_::TranslationToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TranslationToken=[1C]}
@32@0:8@16r^{TranslationPhrase=[1C]}24
@36@0:8@16r^{TranslationPhrase=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationResponse_::TranslationPhrase>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TranslationPhrase=[1C]}
@32@0:8@16r^{EndPointLikelihood=[1C]}24
@36@0:8@16r^{EndPointLikelihood=[1C]}24B32
{Offset<siri::speech::schema_fb::EndPointLikelihood>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{EndPointLikelihood=[1C]}
@32@0:8@16r^{EndPointCandidate=[1C]}24
@36@0:8@16r^{EndPointCandidate=[1C]}24B32
{Offset<siri::speech::schema_fb::EndPointCandidate>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{EndPointCandidate=[1C]}
@32@0:8@16r^{SetRequestOrigin=[1C]}24
@36@0:8@16r^{SetRequestOrigin=[1C]}24B32
{Offset<siri::speech::schema_fb::SetRequestOrigin>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SetRequestOrigin=[1C]}
@32@0:8@16r^{RecognitionProgress=[1C]}24
@36@0:8@16r^{RecognitionProgress=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionProgress>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionProgress=[1C]}
@32@0:8@16r^{ResetServerEndpointer=[1C]}24
@36@0:8@16r^{ResetServerEndpointer=[1C]}24B32
{Offset<siri::speech::schema_fb::ResetServerEndpointer>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ResetServerEndpointer=[1C]}
@32@0:8@16r^{LatnnMitigatorResult=[1C]}24
@36@0:8@16r^{LatnnMitigatorResult=[1C]}24B32
{Offset<siri::speech::schema_fb::LatnnMitigatorResult>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LatnnMitigatorResult=[1C]}
@32@0:8@16r^{RecognitionCandidate=[1C]}24
@36@0:8@16r^{RecognitionCandidate=[1C]}24B32
{Offset<siri::speech::schema_fb::RecognitionCandidate>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionCandidate=[1C]}
@32@0:8@16r^{CheckForSpeechRequest=[1C]}24
@36@0:8@16r^{CheckForSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CheckForSpeechRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CheckForSpeechRequest=[1C]}
@32@0:8@16r^{CheckForSpeechResponse=[1C]}24
@36@0:8@16r^{CheckForSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CheckForSpeechResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CheckForSpeechResponse=[1C]}
@32@0:8@16r^{ErrorBlamerRequest=[1C]}24
@36@0:8@16r^{ErrorBlamerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ErrorBlamerRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ErrorBlamerRequest=[1C]}
@32@0:8@16r^{ErrorBlamerResponse=[1C]}24
@36@0:8@16r^{ErrorBlamerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ErrorBlamerResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ErrorBlamerResponse=[1C]}
@32@0:8@16r^{LmScorerToken=[1C]}24
@36@0:8@16r^{LmScorerToken=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LmScorerToken=[1C]}
@32@0:8@16r^{LmScorerRequest=[1C]}24
@36@0:8@16r^{LmScorerRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LmScorerRequest=[1C]}
@32@0:8@16r^{LmScorerResponse=[1C]}24
@36@0:8@16r^{LmScorerResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::LmScorerResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LmScorerResponse=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingConfig=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingConfig=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingConfig>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AStarFuzzyMatchingConfig=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingResult=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingResult=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingResult>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AStarFuzzyMatchingResult=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingRequest=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AStarFuzzyMatchingRequest=[1C]}
@32@0:8@16r^{AStarFuzzyMatchingResponse=[1C]}24
@36@0:8@16r^{AStarFuzzyMatchingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::AStarFuzzyMatchingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AStarFuzzyMatchingResponse=[1C]}
@32@0:8@16r^{Keyword=[1C]}24
@36@0:8@16r^{Keyword=[1C]}24B32
{Offset<siri::speech::schema_fb::Keyword>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Keyword=[1C]}
@32@0:8@16r^{KeywordFinderRequest=[1C]}24
@36@0:8@16r^{KeywordFinderRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::KeywordFinderRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{KeywordFinderRequest=[1C]}
@32@0:8@16r^{KeywordFinderResponse=[1C]}24
@36@0:8@16r^{KeywordFinderResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::KeywordFinderResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{KeywordFinderResponse=[1C]}
@32@0:8@16r^{ServerEndpointFeatures=[1C]}24
@36@0:8@16r^{ServerEndpointFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::ServerEndpointFeatures>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ServerEndpointFeatures=[1C]}
@32@0:8@16r^{CorrectionsValidatorRequest=[1C]}24
@36@0:8@16r^{CorrectionsValidatorRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsValidatorRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CorrectionsValidatorRequest=[1C]}
@32@0:8@16r^{CorrectionsAlignment=[1C]}24
@36@0:8@16r^{CorrectionsAlignment=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsAlignment>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CorrectionsAlignment=[1C]}
@32@0:8@16r^{CorrectionsValidatorResponse=[1C]}24
@36@0:8@16r^{CorrectionsValidatorResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::CorrectionsValidatorResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CorrectionsValidatorResponse=[1C]}
@32@0:8@16r^{TTSRequestFeatureFlags=[1C]}24
@36@0:8@16r^{TTSRequestFeatureFlags=[1C]}24B32
{Offset<siri::speech::schema_fb::TTSRequestFeatureFlags>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TTSRequestFeatureFlags=[1C]}
@32@0:8@16r^{TextToSpeechVoice=[1C]}24
@36@0:8@16r^{TextToSpeechVoice=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechVoice>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechVoice=[1C]}
@32@0:8@16r^{TextToSpeechResource=[1C]}24
@36@0:8@16r^{TextToSpeechResource=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResource>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechResource=[1C]}
@32@0:8@16r^{TextToSpeechMeta=[1C]}24
@36@0:8@16r^{TextToSpeechMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechMeta>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestMeta=[1C]}24
@36@0:8@16r^{TextToSpeechRequestMeta=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestMeta>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRequestMeta=[1C]}
@32@0:8@16r^{TextToSpeechRequestContext=[1C]}24
@36@0:8@16r^{TextToSpeechRequestContext=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRequestContext=[1C]}
@32@0:8@16r^{ContextInfoEntry=[1C]}24
@36@0:8@16r^{ContextInfoEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestContext_::ContextInfoEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ContextInfoEntry=[1C]}
@32@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24
@36@0:8@16r^{TextToSpeechRequestExperiment=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequestExperiment>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRequestExperiment=[1C]}
@32@0:8@16r^{RepeatedPhonemes=[1C]}24
@36@0:8@16r^{RepeatedPhonemes=[1C]}24B32
{Offset<siri::speech::schema_fb::RepeatedPhonemes>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RepeatedPhonemes=[1C]}
@32@0:8@16r^{TextToSpeechFeature=[1C]}24
@36@0:8@16r^{TextToSpeechFeature=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechFeature>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechFeature=[1C]}
@32@0:8@16r^{TextToSpeechRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRequest=[1C]}
{Offset<siri::speech::schema_fb::TextToSpeechRequest_::ContextInfoEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
@32@0:8@16r^{AudioDescription=[1C]}24
@36@0:8@16r^{AudioDescription=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioDescription>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AudioDescription=[1C]}
@32@0:8@16r^{WordTimingInfo=[1C]}24
@36@0:8@16r^{WordTimingInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::WordTimingInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{WordTimingInfo=[1C]}
@32@0:8@16r^{TextToSpeechResponse=[1C]}24
@36@0:8@16r^{TextToSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechResponse=[1C]}
@32@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24
@36@0:8@16r^{StartTextToSpeechStreamingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartTextToSpeechStreamingRequest=[1C]}
{Offset<siri::speech::schema_fb::StartTextToSpeechStreamingRequest_::ContextInfoEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
@32@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{BeginTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BeginTextToSpeechStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BeginTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{PartialTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::PartialTextToSpeechStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PartialTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24
@36@0:8@16r^{FinalTextToSpeechStreamingResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalTextToSpeechStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{FinalTextToSpeechStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechCacheMetaInfo=[1C]}24
@36@0:8@16r^{TextToSpeechCacheMetaInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheMetaInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechCacheMetaInfo=[1C]}
@32@0:8@16r^{TextToSpeechCacheObject=[1C]}24
@36@0:8@16r^{TextToSpeechCacheObject=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheObject>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechCacheObject=[1C]}
@32@0:8@16r^{TextToSpeechCacheContainer=[1C]}24
@36@0:8@16r^{TextToSpeechCacheContainer=[1C]}24B32
{Offset<siri::speech::schema_fb::TextToSpeechCacheContainer>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechCacheContainer=[1C]}
@32@0:8@16r^{QssAckResponse=[1C]}24
@36@0:8@16r^{QssAckResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::QssAckResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{QssAckResponse=[1C]}
@32@0:8@16r^{ClientSetupInfo=[1C]}24
@36@0:8@16r^{ClientSetupInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::ClientSetupInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ClientSetupInfo=[1C]}
@32@0:8@16r^{AudioLimitExceeded=[1C]}24
@36@0:8@16r^{AudioLimitExceeded=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioLimitExceeded>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AudioLimitExceeded=[1C]}
@32@0:8@16r^{AudioFrame=[1C]}24
@36@0:8@16r^{AudioFrame=[1C]}24B32
{Offset<siri::speech::schema_fb::AudioFrame>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AudioFrame=[1C]}
@32@0:8@16r^{SpeechTranslationAudioPacket=[1C]}24
@36@0:8@16r^{SpeechTranslationAudioPacket=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationAudioPacket>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationAudioPacket=[1C]}
@32@0:8@16r^{TranslationLocalePair=[1C]}24
@36@0:8@16r^{TranslationLocalePair=[1C]}24B32
{Offset<siri::speech::schema_fb::TranslationLocalePair>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TranslationLocalePair=[1C]}
@32@0:8@16r^{StartSpeechTranslationRequest=[1C]}24
@36@0:8@16r^{StartSpeechTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechTranslationRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartSpeechTranslationRequest=[1C]}
@32@0:8@16r^{StartSpeechTranslationLoggingRequest=[1C]}24
@36@0:8@16r^{StartSpeechTranslationLoggingRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartSpeechTranslationLoggingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartSpeechTranslationLoggingRequest=[1C]}
@32@0:8@16r^{SpeechTranslationPartialRecognitionResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationPartialRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationPartialRecognitionResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationPartialRecognitionResponse=[1C]}
@32@0:8@16r^{SpeechTranslationFinalRecognitionResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationFinalRecognitionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationFinalRecognitionResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationFinalRecognitionResponse=[1C]}
@32@0:8@16r^{SpeechTranslationMtResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationMtResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationMtResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationMtResponse=[1C]}
{Offset<siri::speech::schema_fb::SpeechTranslationMtResponse_::TranslationPhrase>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
@32@0:8@16r^{SpeechTranslationTextToSpeechResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationTextToSpeechResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationTextToSpeechResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationTextToSpeechResponse=[1C]}
@32@0:8@16r^{SpeechTranslationServerEndpointFeatures=[1C]}24
@36@0:8@16r^{SpeechTranslationServerEndpointFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::SpeechTranslationServerEndpointFeatures>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationServerEndpointFeatures=[1C]}
@32@0:8@16r^{MatchingSpan=[1C]}24
@36@0:8@16r^{MatchingSpan=[1C]}24B32
{Offset<siri::speech::schema_fb::MatchingSpan>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MatchingSpan=[1C]}
@32@0:8@16r^{NlUtterenceToken=[1C]}24
@36@0:8@16r^{NlUtterenceToken=[1C]}24B32
{Offset<siri::speech::schema_fb::NlUtterenceToken>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{NlUtterenceToken=[1C]}
@32@0:8@16r^{NeuRequest=[1C]}24
@36@0:8@16r^{NeuRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::NeuRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{NeuRequest=[1C]}
@32@0:8@16r^{NeuOutput=[1C]}24
@36@0:8@16r^{NeuOutput=[1C]}24B32
{Offset<siri::speech::schema_fb::NeuOutput>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{NeuOutput=[1C]}
@32@0:8@16r^{MetaInfosEntry=[1C]}24
@36@0:8@16r^{MetaInfosEntry=[1C]}24B32
{Offset<siri::speech::schema_fb::NeuOutput_::MetaInfosEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MetaInfosEntry=[1C]}
@32@0:8@16r^{AlternativePrediction=[1C]}24
@36@0:8@16r^{AlternativePrediction=[1C]}24B32
{Offset<siri::speech::schema_fb::AlternativePrediction>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{AlternativePrediction=[1C]}
{Offset<siri::speech::schema_fb::AlternativePrediction_::MetaInfosEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
@32@0:8@16r^{ChunkPrediction=[1C]}24
@36@0:8@16r^{ChunkPrediction=[1C]}24B32
{Offset<siri::speech::schema_fb::ChunkPrediction>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ChunkPrediction=[1C]}
{Offset<siri::speech::schema_fb::ChunkPrediction_::MetaInfosEntry>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
@32@0:8@16r^{Token=[1C]}24
@36@0:8@16r^{Token=[1C]}24B32
{Offset<siri::speech::schema_fb::Token>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Token=[1C]}
@32@0:8@16r^{DebugInfo=[1C]}24
@36@0:8@16r^{DebugInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::DebugInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{DebugInfo=[1C]}
@32@0:8@16r^{PositionalFeatures=[1C]}24
@36@0:8@16r^{PositionalFeatures=[1C]}24B32
{Offset<siri::speech::schema_fb::PositionalFeatures>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PositionalFeatures=[1C]}
@32@0:8@16r^{SpanFeatureIndices=[1C]}24
@36@0:8@16r^{SpanFeatureIndices=[1C]}24B32
{Offset<siri::speech::schema_fb::SpanFeatureIndices>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpanFeatureIndices=[1C]}
@32@0:8@16r^{WordEmbeddings=[1C]}24
@36@0:8@16r^{WordEmbeddings=[1C]}24B32
{Offset<siri::speech::schema_fb::WordEmbeddings>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{WordEmbeddings=[1C]}
@32@0:8@16r^{CharEmbeddings=[1C]}24
@36@0:8@16r^{CharEmbeddings=[1C]}24B32
{Offset<siri::speech::schema_fb::CharEmbeddings>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{CharEmbeddings=[1C]}
@32@0:8@16r^{MetricsInfo=[1C]}24
@36@0:8@16r^{MetricsInfo=[1C]}24B32
{Offset<siri::speech::schema_fb::MetricsInfo>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MetricsInfo=[1C]}
@32@0:8@16r^{ShortcutFuzzyMatchRequest=[1C]}24
@36@0:8@16r^{ShortcutFuzzyMatchRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ShortcutFuzzyMatchRequest=[1C]}
@32@0:8@16r^{StringTokenPair=[1C]}24
@36@0:8@16r^{StringTokenPair=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchRequest_::StringTokenPair>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StringTokenPair=[1C]}
@32@0:8@16r^{ShortcutFuzzyMatchResponse=[1C]}24
@36@0:8@16r^{ShortcutFuzzyMatchResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ShortcutFuzzyMatchResponse=[1C]}
@32@0:8@16r^{ShortcutScorePair=[1C]}24
@36@0:8@16r^{ShortcutScorePair=[1C]}24B32
{Offset<siri::speech::schema_fb::ShortcutFuzzyMatchResponse_::ShortcutScorePair>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{ShortcutScorePair=[1C]}
@32@0:8@16r^{IntentPredictionDemoRequest=[1C]}24
@36@0:8@16r^{IntentPredictionDemoRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::IntentPredictionDemoRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{IntentPredictionDemoRequest=[1C]}
@32@0:8@16r^{IntentPredictionDemoResponse=[1C]}24
@36@0:8@16r^{IntentPredictionDemoResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::IntentPredictionDemoResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{IntentPredictionDemoResponse=[1C]}
@32@0:8@16r^{LanguageParameters=[1C]}24
@36@0:8@16r^{LanguageParameters=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageParameters>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LanguageParameters=[1C]}
@32@0:8@16r^{StartMultilingualSpeechRequest=[1C]}24
@36@0:8@16r^{StartMultilingualSpeechRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartMultilingualSpeechRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartMultilingualSpeechRequest=[1C]}
@32@0:8@16r^{LanguageDetectionPrediction=[1C]}24
@36@0:8@16r^{LanguageDetectionPrediction=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetectionPrediction>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LanguageDetectionPrediction=[1C]}
@32@0:8@16r^{LanguageDetected=[1C]}24
@36@0:8@16r^{LanguageDetected=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetected>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LanguageDetected=[1C]}
@32@0:8@16r^{FinalBlazarResponse=[1C]}24
@36@0:8@16r^{FinalBlazarResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::FinalBlazarResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{FinalBlazarResponse=[1C]}
@32@0:8@16r^{BatchTranslationRequest=[1C]}24
@36@0:8@16r^{BatchTranslationRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchTranslationRequest=[1C]}
@32@0:8@16r^{Paragraph=[1C]}24
@36@0:8@16r^{Paragraph=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationRequest_::Paragraph>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{Paragraph=[1C]}
@32@0:8@16r^{BatchTranslationResponse=[1C]}24
@36@0:8@16r^{BatchTranslationResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchTranslationResponse=[1C]}
@32@0:8@16r^{BatchTranslationCacheContainer=[1C]}24
@36@0:8@16r^{BatchTranslationCacheContainer=[1C]}24B32
{Offset<siri::speech::schema_fb::BatchTranslationCacheContainer>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchTranslationCacheContainer=[1C]}
@32@0:8@16r^{StartLanguageDetectionRequest=[1C]}24
@36@0:8@16r^{StartLanguageDetectionRequest=[1C]}24B32
{Offset<siri::speech::schema_fb::StartLanguageDetectionRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{StartLanguageDetectionRequest=[1C]}
@32@0:8@16r^{LanguageDetectionResponse=[1C]}24
@36@0:8@16r^{LanguageDetectionResponse=[1C]}24B32
{Offset<siri::speech::schema_fb::LanguageDetectionResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LanguageDetectionResponse=[1C]}
@32@0:8@16r^{PronGuessStreamingRequest=[1C]}24
@36@0:8@16r^{PronGuessStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::PronGuessStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PronGuessStreamingRequest=[1C]}
@32@0:8@16r^{PronGuessStreamingResponse=[1C]}24
@36@0:8@16r^{PronGuessStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::PronGuessStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{PronGuessStreamingResponse=[1C]}
@32@0:8@16r^{BatchRecoverStreamingRequest=[1C]}24
@36@0:8@16r^{BatchRecoverStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchRecoverStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchRecoverStreamingRequest=[1C]}
@32@0:8@16r^{BatchRecoverStreamingResponse=[1C]}24
@36@0:8@16r^{BatchRecoverStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchRecoverStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchRecoverStreamingResponse=[1C]}
@32@0:8@16r^{RecognitionStreamingRequest=[1C]}24
@36@0:8@16r^{RecognitionStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::RecognitionStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionStreamingRequest=[1C]}
@32@0:8@16r^{RecognitionStreamingResponse=[1C]}24
@36@0:8@16r^{RecognitionStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::RecognitionStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{RecognitionStreamingResponse=[1C]}
@32@0:8@16r^{MultiUserStreamingRequest=[1C]}24
@36@0:8@16r^{MultiUserStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::MultiUserStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MultiUserStreamingRequest=[1C]}
@32@0:8@16r^{MultiUserStreamingResponse=[1C]}24
@36@0:8@16r^{MultiUserStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::MultiUserStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MultiUserStreamingResponse=[1C]}
@32@0:8@16r^{MultilingualStreamingRequest=[1C]}24
@36@0:8@16r^{MultilingualStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::MultilingualStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MultilingualStreamingRequest=[1C]}
@32@0:8@16r^{MultilingualStreamingResponse=[1C]}24
@36@0:8@16r^{MultilingualStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::MultilingualStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{MultilingualStreamingResponse=[1C]}
@32@0:8@16r^{SpeechTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{SpeechTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::SpeechTranslationStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationStreamingRequest=[1C]}
@32@0:8@16r^{SpeechTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{SpeechTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::SpeechTranslationStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{SpeechTranslationStreamingResponse=[1C]}
@32@0:8@16r^{BatchTranslationStreamingRequest=[1C]}24
@36@0:8@16r^{BatchTranslationStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchTranslationStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchTranslationStreamingRequest=[1C]}
@32@0:8@16r^{BatchTranslationStreamingResponse=[1C]}24
@36@0:8@16r^{BatchTranslationStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::BatchTranslationStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{BatchTranslationStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRouterStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechRouterStreamingStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechRouterStreamingStreamingResponse=[1C]}
@32@0:8@16r^{TextToSpeechStreamingStreamingRequest=[1C]}24
@36@0:8@16r^{TextToSpeechStreamingStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechStreamingStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechStreamingStreamingRequest=[1C]}
@32@0:8@16r^{TextToSpeechStreamingStreamingResponse=[1C]}24
@36@0:8@16r^{TextToSpeechStreamingStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::TextToSpeechStreamingStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{TextToSpeechStreamingStreamingResponse=[1C]}
@32@0:8@16r^{LanguageDetectionStreamingRequest=[1C]}24
@36@0:8@16r^{LanguageDetectionStreamingRequest=[1C]}24B32
{Offset<siri::speech::qss_fb::LanguageDetectionStreamingRequest>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LanguageDetectionStreamingRequest=[1C]}
@32@0:8@16r^{LanguageDetectionStreamingResponse=[1C]}24
@36@0:8@16r^{LanguageDetectionStreamingResponse=[1C]}24B32
{Offset<siri::speech::qss_fb::LanguageDetectionStreamingResponse>=I}24@0:8^{FlatBufferBuilder={vector_downward=^{Allocator}BQQQ***}ISBBQBB^{set<flatbuffers::Offset<flatbuffers::String>, flatbuffers::FlatBufferBuilder::StringOffsetCompare, std::__1::allocator<flatbuffers::Offset<flatbuffers::String> > >}}16
r^{LanguageDetectionStreamingResponse=[1C]}
v24@0:8@"FTSpeechTranslationStreamingResponse"16
v32@0:8@16Q24
v32@0:8@"NSArray"16Q24
@48@0:8@16@24@32@40
@"FTSpeechTranslationStreamingContext"
@"_LTSpeechCompressor"
@52@0:8@16@24@32q40B48
@44@0:8@16@24@32B40
@"_LTSpeechRecognitionSausage"
v28@0:8@16B24
@"NLLanguageRecognizer"
@32@0:8@16q24
@40@0:8@16@?24@?32
@"<OspreyClientStreamingContext>"
@40@0:8@16@24d32
@20@0:8B16
@32@0:8@16d24
