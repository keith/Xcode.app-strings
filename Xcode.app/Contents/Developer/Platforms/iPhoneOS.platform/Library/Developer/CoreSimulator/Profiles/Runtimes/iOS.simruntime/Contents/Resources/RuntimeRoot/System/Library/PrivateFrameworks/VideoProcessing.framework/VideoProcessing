N2ma19CameraMotionSegmentE
>N2ma19SubtleMotionSegmentE
B`e>;
fff>
D@16MAComputeRequest
Bffffff
$CV&
C2wACA
?22MAImageAnalysisRequest
NSt3__120__shared_ptr_emplaceI25VCPImageHumanPoseAnalyzerNS_9allocatorIS1_EEEE
N2ma17DescriptorSegmentE
16VCPProtoKeypoint
B>fff?
G!?=
Ga>R
=q=J
ff&?R
Q8?H
?N4dlib7array2dIhNS_33memory_manager_stateless_kernel_1IcEEEE
N4dlib10enumerableIhEE
N4dlib33memory_manager_stateless_kernel_1IhEE
14VCPProtoBounds
N2ma11EncodeStatsE
N2ma15EncodeStatsAVE1E
N2ma15EncodeStatsAVE2E
N2ma13EncodeStatsHWE
N2ma13EncodeStatsSWE
<0L&=!
<yX(=4
<0L&=!
<yX(=
b=;p
Sc=;p
<5^:
e=X94
Y=X94</n#
=B`e<M
u`=e
w=B`e
333?fff?ff
N2ma24FineSubjectMotionSegmentE
NSt3__120__shared_ptr_emplaceI21VCPCNNEspressoContextNS_9allocatorIS1_EEEE
]@lwh
333?
G20MAImageComputeResult
333333
?333?
>N2ma22InterestingnessSegmentE
?333333
fff?
@oDA
43s?433?
333?43s?
@333?
N2ma19MovingObjectSegmentE
333333
N2ma18ObstructionSegmentE
?N2ma14QualitySegmentE
N2ma15RotationSegmentE
`@N2ma12SceneSegmentE
N2ma7SegmentE
MbP?
?ffffff
N4dlib17sequence_kernel_2INS_21lbfgs_search_strategy11data_helperENS_33memory_manager_stateless_kernel_1IcEEEE
N4dlib10enumerableINS_21lbfgs_search_strategy11data_helperEEE
N4dlib7removerINS_21lbfgs_search_strategy11data_helperEEE
N4dlib33memory_manager_stateless_kernel_1IdEE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_SB_SB_bEJRKNS_12placeholders4__phILi1EEERSB_SJ_RA12_fRA126_fbEEENS_9allocatorISO_EEFdS8_EEE
NSt3__110__function6__baseIFdN4dlib6matrixIdLl0ELl0ENS2_33memory_manager_stateless_kernel_1IcEENS2_16row_major_layoutEEEEEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_bEJRKNS_12placeholders4__phILi1EEERS9_SH_RA12_fRA126_fbEEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_bEEE
NSt3__110__function6__funcINS_6__bindIPFN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEERKS8_PfSB_SB_SB_bEJRKNS_12placeholders4__phILi1EEERSB_SJ_RA12_fRA126_fbEEENS_9allocatorISO_EEFS8_S8_EEE
NSt3__110__function6__baseIFN4dlib6matrixIdLl0ELl0ENS2_33memory_manager_stateless_kernel_1IcEENS2_16row_major_layoutEEES7_EEE
NSt3__16__bindIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_bEJRKNS_12placeholders4__phILi1EEERS9_SH_RA12_fRA126_fbEEE
NSt3__118__weak_result_typeIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_bEEE
NSt3__117bad_function_callE
N4dlib11fatal_errorE
N4dlib5errorE
NSt3__119basic_ostringstreamIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__115basic_stringbufIcNS_11char_traitsIcEENS_9allocatorIcEEEE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_SB_SB_SB_SB_SB_PiSB_SB_EJRKNS_12placeholders4__phILi1EEERSB_RA12_fSK_SK_SK_SK_SB_SC_SK_SK_EEENS_9allocatorISN_EEFdS8_EEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_S9_S9_S9_PiS9_S9_EJRKNS_12placeholders4__phILi1EEERS9_RA12_fSI_SI_SI_SI_S9_SA_SI_SI_EEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_S9_S9_S9_S9_S9_PiS9_S9_EEE
NSt3__110__function6__funcINS_6__bindIPFN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEERKS8_PfSB_SB_SB_SB_SB_SB_PiSB_SB_SB_EJRKNS_12placeholders4__phILi1EEERSB_RA12_fSK_SK_SK_SK_SB_SC_SK_SK_SK_EEENS_9allocatorISN_EEFS8_S8_EEE
NSt3__16__bindIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_S9_S9_S9_PiS9_S9_S9_EJRKNS_12placeholders4__phILi1EEERS9_RA12_fSI_SI_SI_SI_S9_SA_SI_SI_SI_EEE
NSt3__118__weak_result_typeIPFN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEERKS6_PfS9_S9_S9_S9_S9_S9_PiS9_S9_S9_EEE
NSt3__110__function6__funcINS_6__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS3_33memory_manager_stateless_kernel_1IcEENS3_16row_major_layoutEEEPfSB_EJRKNS_12placeholders4__phILi1EEERA126_fRA189_fEEENS_9allocatorISN_EEFdS8_EEE
NSt3__16__bindIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_EJRKNS_12placeholders4__phILi1EEERA126_fRA189_fEEE
NSt3__118__weak_result_typeIPFdRKN4dlib6matrixIdLl0ELl0ENS1_33memory_manager_stateless_kernel_1IcEENS1_16row_major_layoutEEEPfS9_EEE
N2ma17SlowMotionSegmentE
?N2ma20SubjectMotionSegmentE
>N2ma12TrackSegmentE
?33s?
22MAMovieAnalysisRequest
28VCPProtoImageHumanPoseResult
=AB/'
R[DmPJ>
@Z_g@
#=H!
@333?
u?ff&?
>fff
?333?
mcpl)
Q9RI
Q9RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
k;KY
Q:RI
Q9RI
k:RI
DX;$
d*<4
?F<4
DX;4
Q:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
j<<b
ew=I
{r<b
j<<>
ew<M
ew<>
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
{r<M
7x=J{
/>:#
O/<N
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
|P>-
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
=R' =
d=&S
:p>7
R&?t
@=R' =
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
f>HP|>L7
W?h"\?
h`?Ttd?
Dh?6
>w?,ey?
C{?,ey?
Dh?Ttd?
h`?h"\?
!>?Y
>HP|>B
 <X9
Yu=*
2?^K8?
R?p_W?
[?R'`?=,d?+
z?(~|?H
}?(~|?
g?=,d?R'`?
[?p_W?
=?^K8?\
d*>+
)>6<=>
e>Zd{>9
R&?-C,?
$H?6<M?
V??W[?$
eg?c
j??5n?
s?KYv?>yx?
Wz?>yx?KYv?
4q??5n?c
_??W[?
&R?6<M?
2?-C,?
A ?:#
>Zd{>
4Q>6<=>
ew<3
?F=F
+e>lxz>B>
eG?(~L?
aQ?4
j?mVm?
Np?S
s?]mu?
/|?q
w?]mu?S
Np?mVm?
aQ?(~L?
>lxz>
^)>=
?F=RI
=]mE=
;>`vO>x
~K?2UP?
U?GrY?
a?]me?5
(l?-!o?N
?t?KYv?'1x?^
{?(~|?
|?(~|?
y?'1x?KYv?
?t?N
q?-!o?
(l?5
h?]me?
]?GrY?
U?2UP?
=y>x
d>`vO>
{r=]mE=
u<RI
2D= Aq=
'>lx:>
!N>x
8E?q=J?
X?HP\?
m?2Up?<
v?'1x?
ky?'1x?
r?2Up?
H`?HP\?~
O?q=J?
+5?{
!N>lx:>
= Aq=
t<RI
{r<V}
>0L&>l
;.?}
&R?+
^?aTb?
t?KYv?
w?>yx?
y?,ey?,ey?
y?>yx?
w?KYv?
e?aTb?
J9?}
9>0L&>tF
4o=\
B=Qk
(m=M
G!?=
,?EG2?
K?2UP?O
\?Nb`?}
?t?]mu?KYv?
v?KYv?]mu?
?t?<
c?Nb`?$
T?2UP?
7?EG2?$
G!?Zd
4o<z6
9#>X
\>W[q>
f%?
;?R'@?
g?U0j?
n?2Up?N
q?2Up?
l?U0j?
E?R'@?C
>W[q>?
<=B>h=
q?aT
:P?tFT?~
m?-!o?
Np?-!o?
X?tFT?
a!>r
=B>h=[
=5^:=B`e=q=
k>n4
;?io@?
E?GrI?
Q?]mU?
&b?O
(l?mVm??5n?
n??5n?mVm?
X?]mU?n
M?GrI?
E?io@?
=B`e=5^:=
<B`e<
b='1
rh>[
*?I./?X94?
=?aTB?}
U?gDY?
I\?gDY?
F?aTB?d
9?X94?I./?u
rh>O
/>G
<B`e<
y'?D
1?0L6?
:?Di??
UO?X
.^?Nb`?aTb?
d?]me?
eg?+
Dh?+
f?]me?
d?aTb?Nb`?
UO?q
C?Di??
:?0L6?
V,>,
~;>_
|@?o
D?yXH?
UO?A
R?]mU?~
c?=,d?Ttd?Ttd?=,d?
X?]mU?A
K?yXH?o
Ga>_
~;>
Y<RI
sW=n
qJ>RI]>
+?R'0?4
D?yXH?q
Q?tFT?}
Z?HP\?
_?R'`?
h`?R'`?$
]?HP\?h
V?tFT?n
K?yXH?
4?R'0?
p>RI]>
qJ>~
sW=2
<RI
S#>4
#?B>(?
41?]m5?c
A?o
X?GrY?
Z??W[?
[?h"\?h"\?
[??W[?
Z?GrY?~
\=?c
9?]m5?
,?B>(?
S#><
ZS=V
=yX(=
N=Gry=*
0>%uB>
8g>5^z>
?n4 ?
$?gD)?h
F?GrI?
HN?2UP?
&R?F
V?p_W?
W?p_W?
&R?2UP?
K?GrI?}
-?gD)?
$?n4 ?
>5^z>
T>%uB>|
=Gry=
N=yX(=
Q<KY
WJ=F
s=Nb
->[B>>r
4!?"
1?]m5?
I<?Di??aTB?
O?2UP?
aQ?2UP?
E?aTB?Di??
8?]m5?
3b>r
O>[B>>V
41?4
=?io@?
H?q=J?
~K?(~L?6<M?H
M?6<M?(~L?
~K?q=J?U
B?io@?d
41?h
4o>v
@=B>h=
$>F%5>
sW>gDi>
V?E
%?gD)?
,?R'0?
S3?0L6?
>?R'@?
8E?a
B?R'@?_
9?0L6?
S3?R'0?
,?gD)?"
V?0
~{>gDi>
F>F%5>/
=B>h=
B<HP
u >io0>
t>J{
$?B>(?
1?X94?
6?X94?
+?B>(?
@>io0>
?n4 ?
,?I./?
1?I./?D
#?n4 ?
E6=tF
;X94<
fU=$
>ff&>
y'?u
c,?r
0?EG2?}
7?^K8?Y
8?^K8?
+5?}
3?EG2?
c,?u
y'?j
8V>9
5>ff&>
fU=|
<X94<B`
:0>[
_>iop>I
;.?{
;.?$
@"?$
>iop>
G!><
l=q=
~*>Gr9>p
H>>yX>
f%?=
+?-C,?
,?-C,?
h>>yX>p
H>Gr9>
{r<U
=R' =
d=&S
:p>7
R&?t
@=R' =
:B`e;
9=d]\=I
=d]\=Z
9=Qk
u`<RI
;B`e;
ew=r
\m>HP|>
c?r
>HP|>
%>>y
ew=a
2=tF
+=_)K=
(m=p
q,>#
q?_
q?h
q,>d;
(m=_)K=V
:_)K;|
?$=\
Sc=o
/>>y
2>I.?>_
6Z>_
L>I.?>
%>>y
/>n4
Sc=\
;_)K;4
|P>-
=W[1=
..>lx:>]
ZS>]
F>lx:>
AO=W[1=
5<HP
7;RI
d*;u
Sc=n
%>W[1>
U>w-a>
\m>~
\m>w-a>+
!=>W[1>
Jj<1
d*;RI
=R' =
sW=k+v=(
>B>(>
g3>m
>>:#J>=
U>w-a>
l>w-a>=
U>:#J>m
g3>B>(>
=k+v=
:=R' =
#<B`
h=J{
H?>:#J>+
U>:#J>
m4>z
)>-!
>R' >
m4>m
ZS>-
-r>HP|>
>HP|>
J*>R' >
?F<N
5=;pN=
>R' >z
!=>]
|P>]
g3>z
)>R' >b
xi=;pN=
{r;'
;B`e;X9
c<)\
>B>(>W[1>lx:>
C>lx:>W[1>B>(>-!
;B`e;o
T<KY
L=B`e=I.
..>}
6>I.?>
h>iop>~
x>iop>
DX>r
G>I.?>}
c>]
=B`e=
:_)K;RI
=yX(=
m=J{
P>>yX>
_>>yX>
kI>n
v>=yX(=
;_)K;
?F=d]\=F
8V>?
c>gDi>
t>5^z>$
>5^z>
4o>gDi>
s=d]\=
<;p
d*;KY
d*<b
ew=p_
2>Gr9>[
sW>v
8g>1
|>n4
3b>v
?>Gr9>
%>d;
Ga=:
d*<o
Q9RI
{r<N
=yX(=
x=p_
/>aT
X>RI]>
Ga>f
n>W[q>}
=y>lxz>Zd{>
|>HP|>HP|>
|>Zd{>lxz>
s>W[q>
rh>f
Ga>RI]>P
/>o
/;=yX(=
y;RI
<X94<
=z6+=6<==
ew=o
G!>ff&>
+>io0>F%5>
9>[B>>%uB>
qJ>_
QZ>?
+e>x
F>%uB>[B>>
9>F%5>io0>
+>ff&>
P=6<==z6+=u
/]<X94<r
;_)K;
{r<)\
q,=6<==
Ga=F
s=J{
u >/
!N>`vO>
|P>`vO>
2D>7
~;>~
N=6<==
;_)K;o
7;KY
=z6+=
/;=:
K=d]\=D
m=I.
V,>i
9>lx:>
<>6<=>
=>6<=>
;>lx:>l
u1>i
V,>
m=d]\=:
/;=z6+=
=yX(=Y
U=B`e=
9#>/
$>0L&>
d*>1
'>0L&>/
Yu=B`e=
?F=Y
7=yX(=u
{r<M
7x=J{
/>:#
O/<N
=yX(=
A=;pN=
h=k+v=n
=k+v=
[=;pN=
5=yX(=
ew<b
7:RI
j<<>
ew<M
ew<>
j<<b
ew=I
{r<b
DX;'
3"<4
=R' =U
(=W[1=Z
B=_)K=a
S=d]\=
d=d]\=a
S=_)K=\
9=W[1=U
(=R' =P
7;B`e;
?$=V
b=B>h=D
s=Gry=
\~=n
\~=Gry=F
m=B>h=e
?$=v
;B`e;4
{r<&
=R' =T
b=B`e=B>h=h
4o= Aq=
{r=F
{r= Aq=
(m=h
j=B>h=B`e=e
WJ=9
E6=|
%=R' =Qk
k:RI
>;B`e;'
#<X94<
z<KY
$=yX(=V
7=5^:=[
2D=]mE=
?F=]mE=
2D=\
<=5^:=
-2=2
+=yX(=
D<X94<
;B`e;
>;RI
DX;$
d*<4
?F<4
DX;4
Q:RI
Q9RI
k:RI
Q9RI
k;KY
Q:RI
Q9RI
7;_)K;
y;KY
3"<U
-<X94<
b<B`e<
4o<E
{r<!
ew<l
{r<E
h<B`e<e
#9<X94<
3"<RI
^;_)K;4
7:RI
Q9RI
d*;4
7;_)K;
DX;B`e;
{r;o
{r;B`e;
DX;_)K;4
d*;RI
7:RI
Q9RI
d*;4
>;_)K;
DX;B`e;
{r;l
k;B`e;
Q;_)K;
#;RI
7:RI
Q9RI
7:RI
Q9RI
q=J?\
~|zxvuusqpnmkjiggfecba`_^]]\[ZYXWVUTTSRQQPONNMMLKKJIIHGGGFFEDDCCBBBAA@@??>>===<<;;:::999888776666555444333322211110000////.....----,,,,+++++*****)))))((((('''''''&&&&&&%%%%%%$$$$$$$########""""""!!!!!!!!!        X|E
+>>%I
 "$&(*,.02468:<>@
################
 !!""##$$%%&'()*+,-./01234567
////////////////
?333333
?333333
ffffff
jnIA
?ffffff
@333333
hA)\
St12length_error
St11logic_error
St9exception
St12out_of_range
NSt3__112future_errorE
UUwwUU
UUwwUU
UUwwUU
UUwwUU
{toid_ZUQMIEB>;8530.+)'%#! 
ztnhc^YUPLHEA>;8520-+)'%#!
{uoid_ZVQMIEB?;8630.+)'%#! 
ztnhc^YUPLHEA>;8520-+)'%#!
* +!, -!.$/%0$1%2&3'4&5'6*7+8*9+:,;-<,=->.?/@0A1B0C1D2E3F4G5H4I5J6K7L6M7N8O9P:Q;R:S;T<U=V<W=X<Y=Z>[?\@]A^@_A`BaCbBcCdBeCfDgEhDiEjFkGlFmGnFoGpHqIrHsItHuIvJwKxJyKzJ{K|L}M|L}M~~
}n|n_^}ooO}~ooOl{]}n|n_^}ooO}~ooOl{]y
{{?|
zyzy
nz_O?
}n^n_O}onNnoo_^l{l}n^n_O}onNnoo_^l{ly
{{kyky
nn|}
oOl{?nn|}
oOl{?[
oo}nn^|l|k}
#,6A
)6FX
$/AXs
!)6G
!)6G[
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ZZXURNIC=6.&
ZWPF9+
+9FPWZZRC.
&=NXZUI6
2KYYK2
2KYXC
&IZU=
.NZR6
FZP+
+PZF
9WU.
&RX6
$SS$
$SS$
$SS$
@@@@@@@@@@@@@@@@ZWPF9+
2KYW9
FZP+
$SS$
<=:;8967452301./,-*+()&'$%"# !
>?<=:;67452301,-*+()&'"# !
>?:;894523./,-()&'"# !
>?:;6723./,-()$% !
>?:;4501*+&' !
>?6701()"#
>?23$%
89:;45670123,-./()*+$%&' !"#
DEFG@ABC<=>?89:;4567,-./()*+$%&' !"#
XYZ[PQRSLMNODEFG@ABC89:;4567,-./()*+ !"#
lmnodefg\]^_XYZ[PQRSHIJK@ABC89:;0123()*+ !"#
tuvwhijk`abcTUVWLMNO@ABC89:;,-./$%&'
lmno`abcPQRSDEFG4567()*+
defgHIJK0123
<=>?
 "$&(*,.02468:<>@
 !"#$%&''()*+,-./01223456789:;<<=>?@ABCDDEFGHIJKKLMNOPQQRSTUVWWXYZ[\]]^_`abbcdefghhijkllmnopqqrstuuvwxyzz{|}~~
?333333
?333333
333?
333?
333?
333?
333?
333?
333?
.0;0;0;0;0;0;0;
I%I%
]`v$
I%I%
]`v$
(Rt>
by>h_
>k!K
 !!""##$$%%&'()*+,-./01234567(-39@Hff
h8@ X0H(P
 x@`X
(pHhP
81*#
92+$
:3,%
;4-&
<5.'=6/>7?
aB#bCc
 !"#0123
 !"#@ABC`abc
 (/5
'.49
&-38<
%,27;>
$+16:=?
SaveStabilizationRecipe
v8@?0
HumanKeypoints
cnn_human_pose.espresso.net
res_256x256
res_192x192
VCPHumanPoseEspresso
@"VCPCNNModelEspresso"8@?0
res_320x192
res_192x320
%@ %@
timestamp
qualityScoreForLivePhoto
visualPleasingScore
overallFaceQualityScore
exposureScore
penaltyScore
textureScore
sharpness
faceResults
globalQualityScore
contentScore
GlobalXSum
GlobalYSum
Type
VCPCNNBlurAnalyzerEspresso.sharedModelPool-%lu
cnn_blurV2.espresso.net
cnn_blur.espresso.net
@"VCPObjectPool"8@?0
VCPBlurEspresso
res_299x299
res_400x400
res_400x300
res_300x400
cnn_blur.dat
cnn_landmark.espresso.net
VCPFaceLandmarkEspresso
Action
ActionScore
cnn_lm.dat
cnn_blink.espresso.net
VCPGazeEspresso
ImageAnalysis
MovieAnalysis
MAComputeRequestClass
B8@?0
Error: failed to processSampleBuffer
float32StorageType
forceCPU
sharedContext
allocator<T>::allocate(size_t n) 'n' exceeds maximum supported size
rawTime
stabCropRect
homography
Width
Height
sourceSize
inputBounds
timeRange
confidence
cnn_pets.espresso.net
VCPPetsEspresso
Failed to load asset
Asset contains no video tracks
Failed to create video track output
Failed to start decoding video track
Video processor cancelled
Failed to complete video decoding
com.apple.mediaanalysis.VCPVideoProcessorSession
Video processing requests must have completion handler
Specified request already active; cannot add
Failed to create request with specified configuration
Specified request not found; cannot remove
Sample buffer does not contain video frame
Sample buffer must contain uncompressed video
cnn_facepose.espresso.net
VCPPoseEspresso
cnn_pose.dat
cnn_smile.espresso.net
VCPSmileEspresso
cnn_smile.dat
QueryInternalFields
com.apple.mediaanalysis.sql
SELECT id, version, dateModified, dateAnalyzed, analysisTypes, flags, quality, masterFingerprint, adjustedFingerprint
, statsFlags
 FROM Assets WHERE localIdentifier=(?);
SELECT resultsType, results FROM Results WHERE assetId=(?);
SELECT resultsType, results FROM Results WHERE assetId=(?
) AND resultsType IN (?
SELECT id, localIdentifier, version, dateModified, dateAnalyzed, analysisTypes, flags, quality, masterFingerprint, adjustedFingerprint
 FROM Assets WHERE localIdentifier IN (?
SELECT assetId, resultsType, results FROM Results WHERE assetId IN (?
SELECT date FROM Blacklist WHERE localIdentifier=(?) AND count>=(?);
i8@?0
SELECT localIdentifier FROM Blacklist WHERE count>=(?) AND localIdentifier IN (?
SELECT localIdentifier FROM Blacklist WHERE count>=(?);
SELECT localIdentifier FROM Assets WHERE dateAnalyzed>=(?) UNION SELECT localIdentifier FROM Blacklist WHERE count>=(?) AND date>=(?);
SELECT localIdentifier, status, attempts, (date + (%lu << (3*min(attempts - 1, 5)))) FROM ProcessingStatus WHERE taskID=(?) AND status!=(?) AND localIdentifier IN (?
SELECT localIdentifier FROM ProcessingStatus WHERE taskID=(?) AND status=(?);
SELECT COUNT(*) FROM ProcessingStatus WHERE taskID=(?) AND status=(?);
DeviceClass
iPad
pLzf7OiX5nWAPUMj7BfI4Q
marketing-name
mediaanalysis://asset.mov
analysisConfidence
gyroStabilization
absoluteScore
relativeScore
humanScore
PHAssetScene
AveStats
Failed to parse AVE statistics frame attachment; re-generating statistics
iChatUsageString
EnableStatsCollect
EnableUserQPForFacetime
EnableUserRefForFacetime
EnableWeightedPrediction
UserFrameType
ReferenceFrameNumDriver
ReferenceL0
UserQpMap
MBStatistics
NotSync
com.apple.mediaanalysisd.timer
Orientation
Regions
StartDate
EndDate
TimeZone
AllDay
Title
Location
Notes
<VCPEvent: %p
%-9@  %@
Address
EmailAddress
Event
FlightInfo
Link
PhoneNumber
TrackingInfo
Transcript
Home face identification task cancelled
No face present in face crop
Photos identity model not present
mediaanalysisd
asset in (%@)
any person.personUUID in %@
total-allowed
face
PVPersonClusterManager
%@ | %@
Requested unavailable frame %d
DisableANEForFaceAnalysis
com.apple.mediaanalysis.FaceProcessingGroup
@"VNSession"8@?0
Error: no faceObservation
Error: unable to determine normalized face bounding box { { %f, %f } { %f, %f } }
@"VNRequest"16@?0#8
@"VNObservation"24@?0@"NSUUID"8@"VNRequest"16
Unable to serialize faceprint
personLocalIdentifier is empty
(verifiedType = %d) OR (verifiedType = %d)
personLocalIdentifier
B24@?0@"NSString"8@"NSDictionary"16
PVFace
Unable to find class %s
/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
/System/Library/PrivateFrameworks/PhotoVision.framework/Contents/MacOS/PhotoVision
PVGeometryUtils
PVFaceprint
textureness
hasFlash
stillTime
sceneprintBlob
useSceneprintInSceneAnalysis
mammal
bird
people
adult
animal
stuffed_animals
fire
fireplace
embers
flame
beach
liquid
ocean
lake
creek
river
snow
jacuzzi
pool
grass
plant
coral_reef
foliage
tree
grill
waterways
shore
waterfall
thunderstorm
manhole
aurora
light
spotlight
smoking_item
flag
flagpole
underwater
candle
kettle
teapot
storm
tornado
lightning
blossom
surfing
pyrotechnics
blizzard
fountain
billboards
curtain
lamp
drinking_glass
fondue
blender
storefront
garden
shrub
firecracker
bubble_soap
watersport
haze
volcano
aquarium
fishtank
flower
seaweed
jellyfish
fish
flashlight
bonfire
smoking
lakeshore
sparkler
sparkling_wine
shower
geyser
Point0
Point1
Radius
Theta
Length
q24@?0@"NSDictionary"8@"NSDictionary"16
cnn_human_pose_single.espresso.net
humanPoseResults
cnn_faceblur.dat
%@ canceled
%@ is not yet implemented
faceAdjustmentVersion != nil
additionalAttributes.sceneAnalysisVersion >= %d &&  additionalAttributes.sceneAnalysisVersion != %d
ScreenProgress
v24@?0@"NSDictionary"8@"NSError"16
Video stabilization task cancelled
Video stabilization processing failed
com.apple.mediaanalysisd.moviecurationresults
com.apple.mediaanalysisd.livephotokeyframeresults
com.apple.mediaanalysisd.das.dutycycle
com.apple.mediaanalysisd.das.dutycycle.task
com.apple.mediaanalysisd.analysis.pets
MediaType
AutoPlayableScore
SummaryDuration
IsTrimmed
KeyFrameIsSuggested
KeyFrameScoreDifference
KeyFrameTimestampOffset
KeyFrameIsFaceQualityDominant
KeyFrameIsSharpnessDominant
KeyFrameIsSemanticDominant
KeyFrameIsSuggestedEdit
KeyFrameScoreDifferenceEdit
KeyFrameTimestampOffsetEdit
KeyFrameIsFaceQualityDominantEdit
KeyFrameIsSharpnessDominantEdit
KeyFrameIsSemanticDominantEdit
previousQoS
previousQoSDuration
requestedQoS
taskName
DownloadAssetCount
DownloadBytes
Duration
Delay
AvgSpeed
NumberOfPetFacesDetected
NumberOfPetsDetected
SceneType
AggregatedBoundingBoxSizeRatio
LargestBoundingBoxSizeRatio
Quick Face ID task cancelled
ConcurrentFaceAnalysis
faceAdjustmentVersion = nil
Quick Face ID canceled with %lu job done
com.apple.mediaanalysis.VCPImageManager.decodequeue
VCPImageManager
@"VCPImageManager"8@?0
LogImageManager
v16@?0@"NSData"8
v16@?0@"NSError"8
v32@?0@8Q16^B24
%@ <%p>:
  person1LocalIdentifier  : %@
  person2LocalIdentifier  : %@
  reason                  : %@
asset.dateCreated
asset.addedDate
asset.filename
centerX
centerY
(clusterSequenceNumber > 0)
(manual == 0) AND (faceAlgorithmVersion = %d)
localIdentifier
Could not access the library
Canceled operation to get CSNs of faces missing from the library
v40@?0@"NSArray"8{_NSRange=QQ}16^B32
v32@?0@"NSString"8@"PHFetchResult"16^B24
(clusterSequenceNumber in %@)
Canceled operation to ungroup faces
v16@?0^B8
Canceled operation to uncluster faces
(clusterSequenceNumber = 0)
((clusterSequenceNumber > 0) AND (faceGroup = nil))
could not access the library
Canceled operation to cleanup grouped faces with CSN=0
No faceGroups found for person with localIdentifier '%@'
Failed to fetch faces from the faceGroup that contributed the most number of face to person with localIdentifier '%@'
photoLibrary is nil
clusterSequenceNumber IN %@
@"PHFace"16@?0@"NSNumber"8
v24@?0@"NSNumber"8^B16
v32@?0@"NSString"8@"NSNumber"16^B24
Saving clustering results cancelled
Canceled operation to reset library clusters
-[VCPPhotosPersistenceDelegate updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:]
person localIdentifiers
Failed to find persons with local identifiers: '%@'
B24@?0@"PHPerson"8@"NSDictionary"16
UpdateKeyFaces: Operation canceled
Unimplemented %s in VCPPhotosPersistenceDelecate
-[VCPPhotosPersistenceDelegate associateFace:withFaceCrop:error:]
-[VCPPhotosPersistenceDelegate clearDirtyStateOnFaceCrops:error:]
-[VCPPhotosPersistenceDelegate dirtyFaceCropsWithLimit:]
-[VCPPhotosPersistenceDelegate faceAssociatedWithFaceCrop:]
-[VCPPhotosPersistenceDelegate facesFromAsset:]
-[VCPPhotosPersistenceDelegate persistFaces:deleteFaces:forAsset:persistedFaces:error:]
-[VCPPhotosPersistenceDelegate persistGeneratedFaceCrops:error:]
-[VCPPhotosPersistenceDelegate recordNeedToPersonBuildOnFaceGroupContainingFace:error:]
-[VCPPhotosPersistenceDelegate suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:]
-[VCPPhotosPersistenceDelegate updateFaceprint:ofPersistedFace:error:]
(personBuilderState = %ld)
Canceled cleaning up merge candidates of verified persons
v24@?0@"PHFetchResult"8@"NSMutableSet"16
v24@?0@"VCPMergeCandidatePair"8^B16
Canceled cleaning up merge candidates
(trainingType = %d) || (trainingType = %d)
v32@?0@"PHPerson"8@"NSString"16^B24
B24@?0@"VCPMergeCandidatePair"8@"NSDictionary"16
(clusterSequenceNumber IN %@)
Person building cancelled
v32@?0@"NSNumber"8@"NSOrderedSet"16^B24
clusterSequenceNumber = %ld
clusterSequenceNumber != %ld
invalid merge candidate pair created from cluster rejections
potential invalid merge candidate pair created from cluster rejections
invalid merge candidate pair from cluster rejection for verified person
potential invalid merge candidate pair from cluster rejection for verified person
B16@?0^@8
no training faces in level1 cluster - create 'unverified person : verified/migrated person' candidate pair
all training faces on single verified person in level1 cluster - create 'unverified person : training person' candidate pair
all training faces on single verified person in level1 cluster - create 'unverified person : verified person' candidate pair
all training faces on single verified person in level1 cluster - create 'training person : verified person' candidate pair
invalid merge candidate pair because we may have a dirty level0 cluster
multiple training persons in level0 cluster - create 'training person : training person' pair
clusterSequenceNumber
single training person in level0 cluster - create 'training person : verified person with confirmed face' pair
single training person in level0 cluster - create 'verified persons with confirmed face : verified persons with confirmed face' pair
invalid merge candidate pair because one person has face rejected for the other
invalid merge candidate pair because we have > 3 verified persons in the face group
single training person in level1 cluster - create 'training person : verified person with confirmed face' pair
single training person in level1 cluster - create 'verified persons with confirmed face : verified persons with confirmed face' pair
level1 cluster - create 'training person : training person' pair
level1 cluster - create 'unverifed person : training person' pair
invalid merge candidate pair because we have a cluster rejection
v32@?0@"NSMutableSet"8@"NSMapTable"16@"NSSet"24
invalid merge candidate pair because we have a face on verified person but cluster-rejected on another verified person
-[VCPPhotosPersistenceDelegate buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:]
faceLocalIdentifier is nil
fetched %lu faces for %@
clusterSequenceNumber is nil
personLocalIdentifier is nil
fetched %lu persons for %@
Got a 'nil' photoLibrary. Cannot remove auto assigned faces
(manual = 0) AND ((nameSource = %d) OR (nameSource = %d) OR (nameSource = %d)) AND ((trainingType = %d) OR (trainingType = nil))
Operation to remove faces from verified persons has been canceled
Failed to removed faces from person with localIdentifiers '%@'
PVUtils
PVVisionHelper
not known
PVCanceler
PGGraphHelper
/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
/System/Library/PrivateFrameworks/PhotosGraph.framework/Contents/MacOS/PhotosGraph
cnn_person_detector.espresso.net
salientRegion
salientScore
cnn_saliency.dat
cnn_saliency.espresso.net
res_0
res_1
res_2
VCPSaliencyFullEspresso
DisableANEForSceneAnalysis
IncludeNSFW
IncludeLandmark
IncludeTaboo
IncludeSDG
DominantObjectDetection
SaliencyObjectnessDetection
JunkR14J9
SharpnessModel
TabooModel
NSFWModel
SDGModel
EnableSceneAssetConcurrency
PanoVNRequestMethod
com.apple.mediaanalysis.SceneProcessingGroup
IncludeDocumentGating
not to
document
v24@?0@"PVSceneTaxonomyNode"8^B16
v32@?0@"NSString"8@"NSDictionary"16^B24
AssetSource
AssetType
OCRModelBoundingBoxSizeRatio
OCRModelParsability
OCRModelRevision
rev1-PreAnalysis299x299
PreAnalysisDominantObjectDocumentConfidence
PreAnalysisReceiptOrDocumentConfidence
PreAnalysisScreenshotConfidence
PreAnalysisTextDocumentConfidence
ResourceType
com.apple.mediaanalysisd.ocr.parsability
@"NSDictionary"8@?0
v16@?0Q8
PVSceneTaxonomy
{{%.*g, %.*g}, {%.*g, %.*g}}
Email
Time
DateTime
DateDuration
TimeDuration
FlightInformation
TrackingNumber
http://trackingshipment.apple.com/?Company=%@&TrackingNumber=%@
v16@?0@"NSArray"8
Failed to create VNImageRequestHandler
v16@?0^{opaqueCMSampleBuffer=}8
LogLevel
yyyy-MM-dd HH:mm:ss
output1
output2
output3
cnn_hand_detector.espresso.net
com.apple.mediaanalysis
com.apple.mediaanalysisd.analysis
com.apple.mediaanalysisd.photos
com.apple.mediaanalysisd.homekit
com.apple.mediaanalysisd.homekitsession
dateModified
dateAnalyzed
masterFingerprint
adjustedFingerprint
performedAnalysisTypes
metadataRanges
SyncPoint
FaceResults
ShotTypeResults
SceneResults
QualityResults
JunkResults
BlurResults
ExposureResults
FeatureVectorResults
CameraMotionResults
SubjectMotionResults
FineSubjectMotionResults
SubtleMotionResults
OrientationResults
DistanceResults
IrisRecommendResults
IrisSharpnessResults
PreEncodeResults
MovingObjectsResults
ObstructionResults
SaliencyResults
CompositionResults
ClassificationResults
InterestingnessResults
MusicResults
UtteranceResults
ActivityLevelResults
FacePrintResults
PetsResults
PetsFaceResults
MovieSummaryResults
MovieHighlightResults
KeyFrameResults
KeyFrameBlurResults
KeyFrameStillResults
TrackingResults
LivePhotoEffectsResults
SceneChangeResults
ApplauseResults
BabbleResults
CheeringResults
LaughterResults
HumanPoseResults
HumanActionResults
HumanPoseInternalResults
HandsResults
LoudnessResults
KeyFrameResourceResults
SceneprintResults
VideoStabilizationResults
SongResults
HumanActionClassificationResults
FaceQualityFlag
attributes
energyValues
peakValues
facePosition
facePoseYaw
faceId
facePrint
sharpnessFaces
saliencyBounds
saliencyConfidence
featureVector
songSignature
sceneprint
vanishingPointConfidence
distance
sceneprintDistance
neighbor
neighborDateModified
slowMoFlicker
stabilizationRecipe
Data
objectBounds
junk
petsBounds
petsConfidence
keyFrameTime
keyFrameScore
bestPlaybackCrop
livePhotoEffectsRecipe
livePhotoEffectsGatingDescriptions
livePhotoEffectsMatchingScenes
aesthetic
sceneClassification
saliency
saliencyObjectness
overallScore
allScores
wellFramedSubjectScore
wellChosenBackgroundScore
tastefullyBlurredScore
sharplyFocusedSubjectScore
wellTimedShotScore
pleasantLightingScore
pleasantReflectionsScore
harmoniousColorScore
livelyColorScore
pleasantSymmetryScore
pleasantPatternScore
immersivenessScore
pleasantPerspectiveScore
pleasantPostProcessingScore
noiseScore
failureScore
pleasantCompositionScore
interestingSubjectScore
intrusiveObjectPresenceScore
pleasantCameraTiltScore
lowKeyLightingScore
acceptableCrop
preferredCrop
humanBounds
humanKeypoints
humanConfidence
humanID
handsBounds
handsKeypoints
handsKeypointsConfidents
handsID
frameQualityScore
faceQualityScore
texture
flashFired
QualityOfService
DutyCycling
VCPTaskIDs
GyroStabilization
PixelStabilization
MaxNumberOfAssetToProcess
ForceFullScan
Full Face, 
Face, 
Voice, 
Full Scene, 
Scene, 
Junk, 
Blur, 
Exposure, 
Distance, 
Feature, 
Saliency, 
Composition, 
Classification, 
ActivityLevel, 
CurationScore, 
Pets, 
MovieCuration, 
Effects, 
Audio Classification, 
Human pose, 
Loudness Measure, 
Hands, 
Video Stabilization Pixel, 
Video Stabilization Gyro, 
Gyro Analytics, 
Song detection, 
Video Interpolation, 
Human action, 
index
summaryTimerange
duplicate
SceneAnalysis
FaceAnalysis
EmbeddingAnalysis
hier_text_document
hier_tragic_failure
tragic_failure
screenshot
bad_framing
bad_lighting
blurry
food_or_drink
junk_other
medical_reference
negative
receipt_or_document
repair_reference
shopping_reference
utility_reference
junk_negative
hier_negative
junk_non_memorable
hier_non_memorable
junk_poor_quality
hier_poor_quality
No Resource
Soft Failure
Hard Failure
Duplicate Failure
Upload Failure
PhotoLibraries
ImageTooSmall
UsingBestResource
FacesToDelete
FacesToPersist
QuickFaceIdentification
processed
Confidence
BoundingBox
BaseRetryInterval
UserInteractive
UserInitiated
Default
Utility
Background
Unspecified
IrisObjectsResults
MetaFocusResults
MetaMotionResults
MetaMotionProcessedResults
MetaStabilizationResults
MetaStabilizationFrameResults
MetaHomographyDimensionResults
MetaHomographyResults
MetaPresentationTimeResults
MetaMotionBlurResults
MetaPTSResults
MetaOriginalPTSResults
MetaLensSwitchResults
summaryIsTrimmed
livePhoto
movie
@"NSMutableDictionary"8@?0
v32@?0@"VCPMovieHighlight"8Q16^B24
com.apple.mediaanalysisd.realtime
ContentType
faceMetadataArray
realtimeFaceRect
realtimeFaceRoll
realtimeFaceYaw
PriorityScore
InProcess
com.apple.mediaanalysis.service.management
com.apple.mediaanalysis.service.handler
MediaAnalysisService
Error issuing sandbox extension
v16@?0d8
[MediaAnalysis] Error connecting to background analysis service
Assets from multiple libraries not supported
v24@?0@"NSString"8@"NSError"16
PersonProcessingDeletePersons
faceCSN
faceIdentifier
personIdentifier
personFaceCount
status
requestAdvancedStatus
advancedStatus
PLPhotoAnalysisVisionServiceFaceReclusteringThreshold
PLPhotoAnalysisVisionServiceFaceReclusteringShouldRecluster
v24@?0@"NSArray"8@"NSError"16
v20@?0B8@"NSError"12
AllowOnDemand
AllowOnDemandPixel
AllowOnDemandGyro
AllowStreaming
KeepPrivateResults
MaxHighlightDuration
Standalone
StoreAnalysis
com.apple.mediaanalysis.ondemand
com.apple.mediaanalysis.storage
com.apple.mediaanalysis.VCPMediaAnalyzer.sandboxQueue
NoResultStrip
VCPMediaAnalyzer
v16@?0@"NSString"8
creationDate
UseSceneprintDistance
frame idx = %d
size = %d, track_target_exist = %d, target_lost = %d, tracking_score = %6.2f
before filter: frame(%d): time_stamp=%f, ave_motion=(%f,%f)
frame(%d): time_stamp=%f, ave_motion=(%f,%f), acc_var=(%f, %f), motion_chg=(%f, %f)
MaximumHighlightInSec
enabled
formatDescriptions
naturalSize
nominalFrameRate
preferredTransform
tracks
bounds
flags
B16@?0@"PHAssetResource"8
com.apple.VideoProcessing
com.apple.mediaanalysisd
Apple
kind == %d
mediaType == %d
kind == %d && kindsubtype != %d
mediaType == %d && !((mediaSubtype & %d) == %d)
kindsubtype == %d
(mediaSubtype & %d) == %d
UserOrig
UserAlgo
NoUserAlgo
NoAlgo
variation = %6.2f
sum = %6.2f, tracking_score = %6.2f
Target Captured @ [%5.0f, %5.0f, %5.0f, %5.0f]
initial @ [%d %d] s = %6.5f
stop    @ [%d %d] s = %6.5f
lost = %d
[%6.2f, %6.2f, %6.2f, %6.2f]
box0: (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
box1: (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
box : (x = %2.1f, y = %2.1f, w = %2.1f, h = %2.1f)
overlap_area = %6.2f, max_area = %6.2f, weight = %6.2f
derr = %6.2f, terr = %6.2f
add new expert with weight %6.2f
expert %d was replaced: voting weight(%6.2f --> %6.2f)!
after voting --> update target
detector and tracker did not match well --> experts vote
detector and tracker matched well --> update experts
PHAssetFace
PHAssetFaceExpression
v32@?0@"NSString"8@"NSString"16@"NSError"24
com.apple.mediaanalysis.quickfaceid.management
verifiedType = %@ OR verifiedType = %@
faceCount
uuid
roll == 0.0
isInVIPModel == YES
PVContext
PVFaceIDModel
PVImage
FaceIDModelLastGenerationKey
PhotoAnalysisServicePreferences.plist
faceWorkerState.plist
/var/mobile/Media/PhotoData
/var/mobile/Media/MediaAnalysis/mediaanalysis.db
MediaAnalysis
mediaanalysis.db
Angle
PHAssetSceneprint
seg %d: [%d, %d], sceneCut=%d
prev(%d) [%d, %d][%6.1f, %6.1f] qs = %6.2f, curr(%d) [%d, %d] [%6.1f, %6.1f]qs = %6.2f:
dist({%d %d}, {%d %d}) = %6.2f, th = %6.2f
prev: type = %d, fast = %d, gmv_sum {%6.1f, %6.1f}, merge = %d, split = 0
curr: type = %d, fast = %d, gmv_sum {%6.1f, %6.1f}, merge = %d, split = 0
segments
===========SceneChangeSegments=============
[%f, %f]
com.apple.mediaanalysisd.generic
Request terminated unexpectedly...
com.apple.mediaanalysis.VCPTaskProcessingService.connectionQueue
com.apple.mediaanalysis.VCPTaskProcessingService.batchRequestQueue
Failed to created sandbox extension for %@
CVPixelBuffer must be IOSurface-backed
v32@?0@"NSString"8Q16^B24
VCPVoiceover task cancelled
analyzeFace failed
analyzeScene failed
Start
face_model_tensor.dat
face_model_landmark_coordinates.dat
face_model_boundary.dat
com.apple.mediaanalysisd.VCPFaceShapeUpdate
Error detected at line 
Error detected in file 
Submodules/dlib/dlib/optimization/optimization.h
Error detected in function 
double dlib::find_min_box_constrained(search_strategy_type, stop_strategy_type, const funct &, const funct_der &, T &, const matrix_exp<EXP1> &, const matrix_exp<EXP2> &) [search_strategy_type = dlib::lbfgs_search_strategy, stop_strategy_type = dlib::objective_delta_stop_strategy, funct = std::__1::function<double (dlib::matrix<double, 0, 0, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>)>, funct_der = std::__1::function<dlib::matrix<double, 0, 0, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout> (dlib::matrix<double, 0, 0, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>)>, T = dlib::matrix<double, 51, 1, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>, EXP1 = dlib::matrix_op<dlib::op_uniform_matrix_3<double>>, EXP2 = dlib::matrix_op<dlib::op_uniform_matrix_3<double>>]
Failing expression was 
is_col_vector(x) && is_col_vector(x_lower) && is_col_vector(x_upper) && x.size() == x_lower.size() && x.size() == x_upper.size()
double find_min_box_constrained()
 The inputs to this function must be equal length column vectors.
 is_col_vector(x):       
 is_col_vector(x_upper): 
 x.size():               
 x_lower.size():         
 x_upper.size():         
The objective function generated non-finite outputs
 ************************** FATAL ERROR DETECTED ************************** 
 ************************** FATAL ERROR DETECTED ************************** 
 ************************** FATAL ERROR DETECTED ************************** 
Two fatal errors have been detected, the first was inappropriately ignored. 
To prevent further fatal errors from being ignored this application will be 
terminated immediately and you should go fix this buggy program.
The error message from this fatal error was:
**************************** FATAL ERROR DETECTED ****************************
******************************************************************************
EPORT_IN_USE
ETIMEOUT
ECONNECTION
ELISTENER
ERESOLVE
EMONITOR
ECREATE_THREAD
ECREATE_MUTEX
ECREATE_SIGNALER
EUNSPECIFIED
EGENERAL_TYPE1
EGENERAL_TYPE2
EGENERAL_TYPE3
EINVALID_OPTION
ETOO_FEW_ARGS
ETOO_MANY_ARGS
ESOCKET
ETHREAD
EGUI
EFATAL
EBROKEN_ASSERT
EIMAGE_LOAD
EDIR_CREATE
EINCOMPATIBLE_OPTIONS
EMISSING_REQUIRED_OPTION
EINVALID_OPTION_ARG
EMULTIPLE_OCCURANCES
ECONFIG_READER
EIMAGE_SAVE
ECAST_TO_STRING
ESTRING_CAST
EUTF8_TO_UTF32
EOPTION_PARSE
undefined error type
iteration: 
   objective: 
Submodules/dlib/dlib/matrix/matrix.h
const dlib::matrix::literal_assign_helper &dlib::matrix<double, 2, 2, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>::literal_assign_helper::operator,(const T &) const [T = double, num_rows = 2, num_cols = 2, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
r < m->nr() && c < m->nc()
You have used the matrix comma based assignment incorrectly by attempting to
supply more values than there are elements in the matrix object being assigned to.
Did you forget to call set_size()?
 r: 
 c: 
 m->nr(): 
 m->nc(): 
dlib::matrix<double, 2, 2, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>::literal_assign_helper::~literal_assign_helper() [T = double, num_rows = 2, num_cols = 2, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
!has_been_used || r == m->nr()
You have used the matrix comma based assignment incorrectly by failing to
supply a full set of values for every element of a matrix object.
const dlib::matrix::literal_assign_helper &dlib::matrix<double, 2, 1, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>::literal_assign_helper::operator,(const T &) const [T = double, num_rows = 2, num_cols = 1, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
dlib::matrix<double, 2, 1, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>::literal_assign_helper::~literal_assign_helper() [T = double, num_rows = 2, num_cols = 1, mem_manager = dlib::memory_manager_stateless_kernel_1<char>, layout = dlib::row_major_layout]
You have to supply column vectors to this function
double dlib::find_min_using_approximate_derivatives(search_strategy_type, stop_strategy_type, const funct &, T &, double, double) [search_strategy_type = dlib::lbfgs_search_strategy, stop_strategy_type = dlib::objective_delta_stop_strategy, funct = std::__1::function<double (dlib::matrix<double, 0, 0, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>)>, T = dlib::matrix<double, 6, 1, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>]
is_col_vector(x) && derivative_eps > 0
double find_min_using_approximate_derivatives()
x.nc():         
derivative_eps: 
Multiple cadence options specified
%@ value must be NSNumber
%@ value must be poisitive
%@ is not supported
v32@?0@"NSString"8@16^B24
Tracking
NumOfValidFrames
TrackingScore
Destructive Trim Range: [%.2f - %.2f]
after repare
after consecutive short merge
after sparse short merge
after post processing
=========Segment %s==========
v32@?0@"VCPSegment"8Q16^B24
 [%.2f - %.2f]: %.2f
--[%.2f - %.2f]
Embedding
NotImplementedException
[VCPAsset %@] should not be called
mediaType
mediaSubtypes
pixelWidth
pixelHeight
Live Photo
Pano Photo
Screenshot
HDR Photo
SDOF Photo
Photo
Slow-mo Movie
Timelapse Movie
Movie
Unknown
exif
imageWithPreferredDimension:
movie:
originalMovie:
quality
subjectMotionScore
objectsMotion
globalMotion
interestingnessScore
obstructionScore
trackingScore
sharpnessScore
sceneChangeScore
start
duration
VoiceResults
browDown_L
browDown_R
browInnerUp
browOuterUp_L
browOuterUp_R
cheekPuff
cheekSquint_L
cheekSquint_R
eyeBlink_L
eyeBlink_R
eyeLookDown_L
eyeLookDown_R
eyeLookIn_L
eyeLookIn_R
eyeLookOut_L
eyeLookOut_R
eyeLookUp_L
eyeLookUp_R
eyeSquint_L
eyeSquint_R
eyeWide_L
eyeWide_R
jawForward
jawLeft
jawOpen
jawRight
mouthClose
mouthDimple_L
mouthDimple_R
mouthFrown_L
mouthFrown_R
mouthFunnel
mouthLeft
mouthLowerDown_L
mouthLowerDown_R
mouthPress_L
mouthPress_R
mouthPucker
mouthRight
mouthRollLower
mouthRollUpper
mouthShrugLower
mouthShrugUpper
mouthSmile_L
mouthSmile_R
mouthStretch_L
mouthStretch_R
mouthUpperUp_L
mouthUpperUp_R
noseSneer_L
noseSneer_R
focalLengthInPixels
faceBounds
objects
faceRollAngles
faceAnchor
vertices
transform
blendshapes
geometry
dispatchQueue
regionsOfInterest
aggSubjectMotionScore
turboMode
frameWidth
frameHeight
VCPCaptureAnalysis
v24@?0f8Q12i20
com.apple.mediaanalysis.VCPClientDatabaseManager
cnn_content.dat
v24@?0^v8Q16
v32@?0@"NSString"8@"VCPVoteStats"16^B24
[MediaAnalysis][%@]Unable to open movie, skip
[MediaAnalysis][%@]Failed to create asset
[%@] Analysis cancelled
[%@] Analysis failed to complete
checksum
data
SceneprintHyperplaneLSH, 
NeuralHyperplaneLSH, 
<VCPFaceTimeFace: %p faceprint: %@>
gesture_recognition.espresso.net
facePrintBlob
facetime.sqlite
VCPFaceTimeDataModel
v24@?0@"NSPersistentStoreDescription"8@"NSError"16
Session
<VCPFaceTimeSession: %p sessionID: %@ callerID: %@ date: %@>
sessionID
callerID
faces
v20@?0f8^B12
com.apple.homekitanalysis.service.management
com.apple.homekitanalysis.service.handler
Failed to fetch person by local identifier (%@)
HMIAnalysisService
mediaanalysis://in-memory
com.apple.mediaanalysisd.VCPInMemoryAVAsset
com.apple.mediaanalysis.reachability
Not c
None
TransientConnection
Reachable
ConnectionRequired
ConnectionOnTraffic
InterventionRequired
ConnectionOnDemand
IsLocalAddress
IsDirect
IsWWAN
Frame: %u
%@ (face=%@ image=%@)
User canceled
v32@?0@"VCPFaceCropSourceDescriptor"8Q16^B24
{ { %f, %f }, { %f, %f} } is not a normalized rect
Image cannot provide an URL or a data representation
faceCropSourceDescriptor.face is nil
faceCropSourceDescriptor.image is nil
failed to create PVFaceCrop
cannot generate a facecrop without an originating face
cannot find originating face %@
cannot generate facecrop on manual originating face %@
Error: No faceCrop
Error: facecrop does not have any image data
Error: facecrop image data is not valid
Error: facecrop data does not have crop bounds information
Error: facecrop image size equals to 0
Error: failed to calculate normalized facecrop bounding box
Error: unable to obtain the facecrop image dimensions
Error: unable to create VNImageRequestHandler
Error: unable to create a VNRequest to detect face rectangle
Error: unable to create a VNRequest to create faceTorsoprint
Error: failed to analyze facecrop: %@
Error: failed to create faceprint for facecrop: %@
Error: failed to create PVFace from face observation
Error: invalide faceprint/faceTorsoprint
Error: face %@ has already been persisted with a facecrop
Error: face %@ does not have a faceprint
Error: could not fetch facecrop: %@
Error: could not publish facecrop analysis %@
could not locate face %@
v40@?0@"VCPFaceCropSourceDescriptor"8Q16Q24@"NSError"32
PVFaceCropUtils
PVFaceCrop
Measurement
Min (s)
Max (s)
Avg (s)
Total
Count
signpost
q24@?0@"PHSceneClassification"8@"PHSceneClassification"16
hand_keypoint_detector.espresso.net
version
types
date
statsFlags
typesWide
assetIdentifier
assetModificationDate
assetMasterFingerprint
assetAdjustedFingerprint
imageBlurResults
imageCompositionResults
imageFaceResults
imageFeatureResults
imageJunkResults
imageSaliencyResults
imageShotTypeResults
imagePetsResults
imagePetsFaceResults
imageSceneprintResults
livePhotoEffectsResults
livePhotoRecommendationResults
livePhotoSharpnessResults
livePhotoKeyFrameResults
livePhotoKeyFrameStillResults
movieActivityLevelResults
movieCameraMotionResults
movieClassificationResults
movieFaceResults
movieFaceprintResults
movieFeatureResults
movieFineSubjectMotionResults
movieInterestingnessResults
movieMovingObjectResults
movieMusicResults
movieObstructionResults
movieOrientationResults
moviePreEncodeResults
movieQualityResults
movieSaliencyResults
movieSceneResults
movieSceneprintResults
movieSubjectMotionResults
movieSubtleMotionResults
movieUtteranceResults
movieVoiceResults
movieSummaryResults
movieHighlightResults
imageExposureResults
imageHumanPoseResults
movieHumanPoseResults
movieApplauseResults
movieBabbleResults
movieCheeringResults
movieLaughterResults
movieHumanActionResults
movieLoudnessResults
moviePetsResults
moviePetsFaceResults
movieStabilizationResults
propertyKey %s 
result is nil %s
width
height
input_image_1
input_image_2
cnn_moflow.espresso.net
res_landscape
res_portrait
res_sqaure
VCPMoflowEspresso
SHMutableSignature
/System/Library/PrivateFrameworks/ShazamKit.framework/ShazamKit
/System/Library/PrivateFrameworks/ShazamKit.framework/Contents/MacOS/ShazamKit
identifier
faceSharpness
vanishingPoint
dominantLine
exposure
underExpose
eyeExpression
faceQuality
featureBlob
com.apple.mediaanalysisd.voiceover
Face
Scene
com.apple.voiceoveranalysis.service.management
com.apple.voiceoveranalysis.service.handler
VoiceOverAnalysisService
CVPixelbuffer not IOSurface backed
hand_keypoint_detector_acc.espresso.net
Failed to load imageURL: %@
NeuralHash+LSH invalid imageSignatureHash
Invalid NeuralHash+LSH (=)
shotType
stabilizeResult
outputFrameDurValue
cropRectX
cropRectY
cropRectHeight
cropRectWidth
timeScale
epoch
frameInstructions
autoloop
bounce
longexposure
stabilize
minVersion
AutoLoop
Bounce
LongExposure
Stabilize
NormStabilizeInstructions
Version
MinVersion
Params
loopFlavor
loopEnergy
outputFrameDur
loopSuggestionState
longExposureSuggestionState
recipeBlob
Error: failed to processImage
idx (%tu) is out of range (%tu)
timeValue
homographyParam
res_384x384
q24@?0@"NSNumber"8@"NSNumber"16
res_%dx%d
Home resident maintenance task cancelled
HMITaskService
errorCode
loopFadeLen
loopPeriod
loopStart
ErrorCode
activityScore
motionType
isFast
com.apple.homekitanalysis.session.management
com.apple.homekitanalysis.session.handler
No result handler registered
No VCPHomeKitAnalysisSession; cannot process message
HMIVideoAnalyzer
/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
/System/Library/PrivateFrameworks/HomeAI.framework/Contents/MacOS/HomeAI
classification
keypoints
faceID
faceprintBlob
revision
maxNumberHands
humanActionWindowSize
mouthExpression
position
isCloseup
actionScore
FramesPerSecond
interestScore
energy
peak
q24@?0@8@16
yyyy-MM-dd-HH-mm-ss
suggestionLog_
suggestions.html
function addPlaceHolders() {
addPlaceholdersForSet("visionInput", inputFaces);
addPlaceholdersForSet("visionOutput", outputFaces);
addPlaceholdersForSet("visionFiltered", filteredFaces);
function isElementHidden(element) {
var style = window.getComputedStyle(element);
return (style.display === 'none')
function updateVisibility() {
var allDivs = document.getElementsByTagName("div");
for (var i = 0; i < allDivs.length; i++) {
var d = allDivs[i];
if (!d.attributes["img"]) continue;
var rect = d.getBoundingClientRect();
if (
rect.top >= -100 &&
rect.left >= -100 &&
rect.bottom - 100 <= (window.innerHeight || document.documentElement.clientHeight) &&
rect.right - 100 <= (window.innerWidth || document.documentElement.clientWidth)
if (d.childNodes.length == 0) {
d.innerHTML = "<img src='" + d.attributes["img"].value + "' width='100' height='100'>";
else {
if (d.childNodes.length != 0) {
d.innerHTML = "";
function addPlaceholdersForSet(containerId, elements) {
var content = "";
for (var i = 0; i < elements.length; i++) {
content += "<div style='float: left; width: 100px; height: 100px; margin: 3px; background-color: darkgray' img='" + elements[i] + "'></div>"
document.getElementById(containerId).innerHTML = content;
document.onscroll = function (e) {
updateVisibility();
</script>
</head>
<body>
<p>Vision input:</p>
<div id="visionInput">
</div>
<p style="clear: both;">Vision output:</p>
<div id="visionOutput">
</div>
<p style="clear: both;">Vision filtered output:</p>
<div id="visionFiltered">
</div>
</div>
<script>
document.addEventListener("DOMContentLoaded", function (event) {
addPlaceHolders();
</script>
</body>
</html>
could not obtain access to the photo library
photo library could not provide suggestions
_suggestionsForPersonWithLocalIdentifier cancelled
v16@?0q8
<html>
<head>
<script>
 var inputFaces = [
v32@?0@"NSString"8@"NSArray"16@"NSError"24
var outputFaces = [
var filteredFaces = [
suggestPersonsForPersonWithLocalIdentifier cancelled
Input parameter is empty or nil: '%@'
PVCluster is nil
v32@?0@"NSSet"8Q16^B24
v32@?0@"NSString"8@"NSArray"16^B24
verifiedType != %d
VCPFaceProcessingDeleteAllVerifiedPersons
succeeded
failed
VCPFaceProcessingReclusterFacesWithThreshold
VCPFaceProcessingBuildPersons
VCPBuildPersons failed %d
VCPFaceProcessingPromotePersons
VCPPromotePersons failed %d
PVClusterer
PVSuggestionUpdateFinished
PVSuggestionUpdateCancelled
B32@?0@"NSDictionary"8Q16^B24
PVPersonPromoter
v32@?0@"PHFace"8Q16^B24
q24@?0@"PHAssetResource"8@"PHAssetResource"16
PersonBuilderMergeCandidatesEnabled
PersonBuilderLastMinimumFaceGroupSizeForCreatingMergeCandidates
personBuilderState != %lu
VCPFaceProcessingCleanupMergeCandidates
PVUserDefaults
Sceneprint task cancelled
[%@] Thumbnail is not locally available
[%@] Failed to load thumbnail image
[%@] Invalid sceneprint result
orientation
statisticsBlob
qualityScore
distanceToPreviousScene
flickerScore
sceneprintDistanceToPreviousScene
hasAction
v12@?0B8
Face clustering threshold should be in the range: [0.1, 1.0]
VCPFaceProcessingResetFaceClusteringState
VCPFaceProcessingPerformFaceClusteringAndWait
clusterer is not available
VCPFaceProcessingClusterFacesWithExtendTimeoutBlock
com.apple.mediaanalysis.clusteringQueue
curationScore
keyFrame
autoPlayable
playbackCrop
value
timescale
inputBoundsX
inputBoundsY
inputBoundsHeight
inputBoundsWidth
sourceSizeHeight
sourceSizeWidth
homographyParams
VCPMovieWriter.mediaDataRequest
com.apple.mediaanalysis.VCPSharedInstanceManager
Received action score %f - %f
=========%s==========
[%.2f - %.2f]: %.2f
capturePointSegmentIdx: %d
----[%.2f - %.2f]
startIdx = %d, endIdx = %d, count = %d, [%f, %f] with score %f captureTime=%f
interesting trim: [%f, %f], score = %.2f
 --[%.2f - %.2f]
com.apple.mediaanalysis.VCPVideoChatAnalysis
sport
cnn_activitylevel.dat
TrackSegments
Hand_waving
Hand_clapping
Dancing
Walking
Running
Jumping
cnn_human_action.espresso.net
regressiontree_landmark.dat
rtree_landmark_tracking.dat
com.apple.mediaanalysisd.VCPVideoFaceValidation
face_validation_warp_tri_list.dat
face_validation_warp
face_validation_warp_params.dat
%@_%d.dat
Cannot align faces: PVImage misses CGImage, URL, Data or pixelBuffer
Cannot align faces: failed to create VNImageRequestHandler.
Cannot align faces: failed to create VNAlignFaceRectangleRequest.
Cannot align faces: error: %@
v32@?0@"NSNumber"8@"VCPFace"16^B24
q24@?0@"VCPFace"8@"VCPFace"16
/tmp/
v32@?0@"NSNumber"8@"VNFaceprint"16^B24
v32@?0@"NSNumber"8@"NSNumber"16^B24
v32@?0@"NSNumber"8@"NSArray"16^B24
privECMVct
privEMBVct
privDFArray
privET
privImgG
privTZF
privAFS
privAFSt
privFM
relSampleTime
trajectoryHomography
presentingTimestamp
originalPresentingTimestamp
LivePhotoMetadataSetupDataVersion
FrameworkVersions
CMCaptureCore
mdta/com.apple.quicktime.live-photo-info
45.1
v32@?0@"NSString"8@"NSString"16^B24
SalientRegions
bound
plistRepresentation
v32@?0@"NSNumber"8@"VCPVideoObjectTracker"16^B24
q24@?0@"VCPSaliencyRegion"8@"VCPSaliencyRegion"16
q24@?0@"VNClassificationObservation"8@"VNClassificationObservation"16
q24@?0@"VCPClassification"8@"VCPClassification"16
[VideoTrackDecoder status] should not be called
[VideoTrackDecoder copyNextSampleBuffer] should not be called
[VideoTrackDecoder getNextCaptureSampleBuffer] should not be called
com.apple.mediaanalysis.VCPVideoTrackSyncDecoder
/Library/Audio/Tunings/Generic/AU/aufx-epv2-mediaanalysis-appl.plist
Times
ByteOffset
BytesPerRow
DirtyRegionArray
VCPRateControlSession
VCPRateControlSession %p (%dx%d)
com.apple.videotoolbox.videoencoder.h264.rtvc
NULL session
empty frame context
stored frame context is different from the input context,stored: %d
debug
map::at:  key not found
v210_crop_dither_2vuy
/Library/Caches/com.apple.xbs/Sources/VideoProcessing_Sim/VideoProcessing-960.24/VideoProcessing/Sources/Dither10to8bits.cpp
((x_offset+width_cropped+5)*2)<BytesPerRow_v210
convert_2vuy_from_native_to_fake_with_dither
randomDitherNoiseIndOffset<SIZE_10to8bitsNoiseU8
int32_t DitherCrop(CVPixelBufferRef, CVPixelBufferRef)
com.apple.VideoProcessing: [%s]: [VideoProcessing.framework] v210 -> crop -> dither -> 420: Odd height_cropped not supported for 420
com.apple.VideoProcessing: [%s]: [VideoProcessing.framework] v210 -> crop -> dither -> 420: Odd width_cropped not supported for 420
com.apple.VideoProcessing: [%s]: [VideoProcessing.framework] v210 -> crop -> dither -> 420: Currently not yet supporting odd x_offset for cropping
Failed to query number of CPUs
unordered_map::at: key not found
SideCar transition detection
com.apple.VideoProcessing.VCPSideCarMetal.submission
com.apple.VideoProcessing.VCPSideCarMetal.completion
TransitionDetectionQuad
[VCPEncStatsMonitor] %s: Input_fps=%.2f, Enc_fps=%.2f, Tx_fps=%.2f, Bit_rate (Total/Target/Video/FEC/Header)=%.0f/%.0f/%.0f/%.0f/%.0f, Enc_time=%.2f ms
com.apple.videoprocessing.statsq
VCPSession
SpillmapHeight
SpillmapWidth
OSStatus VCPSessionExecute(VCPSessionRef, CFDictionaryRef, CVPixelBufferRef *, size_t, CVPixelBufferRef *, size_t, VCPSessionCompletionCallback, void *)
com.apple.VideoProcessing: [%s]: [VideoProcessing.framework] Currently only supports destination buffer format 2vuy
com.apple.VideoProcessing: [%s]: [VideoProcessing.framework] Source buffer format must be v210
phase_y
phase_x
used_height
used_width
SCN_UUID
void WriteYuvFrame(CVPixelBufferRef, FILE *)
com.apple.VideoProcessing: [%s]: Unknown pixel format
FLS;RVRA1:1;AS:2;MS:-1;LTR;CABAC;CR:3;LF:-1;PR;CH1:4;FA:5;
FLS;RVRA1:0;PR;LF:-1;CR:1;CF:2;CH1:3;FA:4;
FLS;MS:-1;LF:-1;LTR;CABAC;POS:0;EOD:1;HTS:2;RR:3;
FLS;LF:-1;POS:5;EOD:1;HTS:2;RR:3;
FLS;
PSNRInControlByte
VCPCodec_LRP
VCPCodec_AVC1
SliceType
FirstMB
OSStatus VCPParseParameterSetsAndCreateConfigurationRecord(OSType, const uint8_t *const, size_t *, uint8_t *, size_t *)
com.apple.VideoProcessing: [%s]: VCPParseParameterSetsAndCreateConfigurationRecord failed, videoFormatDescription is NULL
avcC
com.apple.VideoProcessing: [%s]: CMVideoFormatDescriptionCreateFromH264ParameterSets failed (%d)
com.apple.VideoProcessing: [%s]: VCPParseParameterSetsAndCreateConfigurationRecord failed
OSStatus VCPParseConfigurationRecordAndCreateParameterSets(OSType, const uint8_t *const, size_t, uint8_t *, size_t *)
parameter sets buf overrun
LRPConfigurationRecordToParameterSets failed
com.apple.VideoProcessing: [%s]: VCPParseConfigurationRecordAndCreateParameterSets only supports HEVC for now
VCPCompressionSession
HEVC
H.264
VCPEnc %p (%dx%d, %s): Video compression session invalidated
/tmp/vcp
%s_%dx%d_%04lX
/tmp/vcp/VcpEnc_%s.hevc
/tmp/vcp/VcpEnc_%s.264
/tmp/vcp/SourceYuv_%s.yuv
[%s]: VCPEnc %p (%dx%d, %s): VCPRealTimeAnalysisServiceCreate Error
OSStatus VCPCompressionSessionCreate(CFAllocatorRef, int32_t, int32_t, CMVideoCodecType, CFDictionaryRef, CFDictionaryRef, CFAllocatorRef, VTCompressionOutputCallback, void *, VCPCompressionSessionRef *)
[com.apple.VideoProcessing] VCPEnc %p (%dx%d, %s): VCPRealTimeAnalysisServiceCreate Error
[%s]: VCPEnc %p (%dx%d, %s): Creating semaphore for VCPRealTimeAnalysisService failed 
[com.apple.VideoProcessing] VCPEnc %p (%dx%d, %s): Creating semaphore for VCPRealTimeAnalysisService failed 
macOS
VCPEnc %p (%dx%d, %s, %s)
Failed to create rate controller
Failed to create stats monitor
VideoProminence analysis enabled
VideoProminence analysis disabled
SignLanguageProminence
target_bitrate
ThermalLevel
VCPEnc %p (%dx%d, %s): Encoder got compression mode property: %d, but forced to %d
VCPEnc %p (%dx%d, %s): Unexpected compression mode: %d!
VideoProminence: kVCPCompressionPropertyKey_CompressionMode (set by AVC) = %d
CompressionMode
VCPEnc %p (%dx%d, %s): Encoder got ExpectedFrameRate property: %@, will be set to %@ to support %d-tile encoding
VCPEnc %p (%dx%d, %s): Encoder got %@ property = %@
VCPEnc %p (%dx%d, %s): Got 10b input and set HDRMetadataInsertionMode_Auto/HEVC_Main10_AutoLevel/bitdepth10
VCPEnc %p (%dx%d, %s): Failed to create %s video encoder with usage %d on %s, err = %d!
VCPEnc %p (%dx%d, %s): Created video encoder with usage %d on %s.
vcpFrameContext is NULL
[%s]: CMSampleBufferCreate failed
void VCPCompressionSessionCallback(void *, void *, OSStatus, VTEncodeInfoFlags, CMSampleBufferRef)
[com.apple.VideoProcessing] CMSampleBufferCreate failed
DoVi
HDR10
VCPEnc %p (%dx%d, %s %s): Compressed sample buffer size=%-6zu, repeat_app=%d, repeat_final=%d, dropped=%d, 
t_score=N/A     , 
t_score=%-8.3f, 
idr=%-3d, refresh=%-3d, 
frame_qp=%-2.2f, 
frame_qp=N/A, 
tile_id=%d/%d, tile_odr=%-6d, tile_loc=%-4d/%-4d/%-4d, time=%.2f ms, ts=%lld, duration=%lld, priority_score=%-5d, 
, hid_ts: %#llx
idr=N/A, refresh=N/A, frame_qp=N/A  , tile_id=%d/%d, tile_odr=N/A   , tile_loc=%-4d/%-4d/%-4d, time=%.2f ms 
real_wxh %dx%d
encoded_frames
header_bits
fec_bits
transmit_frames
encoded_bits
encoding_time
Callback's reference is NULL
Dump bistream error in VCPDecompressionSessionDecodeFrame.
;TILE:3;TIME:4;
TileOrder
TileID
failed to create CMSampleBuffer
PSNRArray
Invalid sample buffer
VCPEnc %p: Subframe width: %d height %d
VCPEnc %p (%dx%d, %s): Got video encoder specification: request_hw = %d, usage = %d, on %s
decodingOrderBase
VCPEnc %p: Encoder got number of tiles video specification: %d
NumberOfTiles
VisualizeDirtyTiles
EnablePerFrameLog
VCPEnc (%dx%d, %s): Failed to create video compression session, err = %d
input_frames
VCPEnc %p (%dx%d, %s): Encoder fails with err = %d, tile id %d order %d
SignpostID
SignpostTimeStamp
VCPEnc %p (%dx%d, %s): Encoder failed to create tile id %d, order %d
VCPEnc %p (%dx%d, %s): Encoder failed to create buffer for tile id %d, order %d
HIDTimeStamp
VCPEnc %p (%dx%d, %s): Get keyframe request. 
VCPEnc %p (%dx%d, %s): Get refresh request (ForceRefresh). 
VCPEnc %p (%dx%d, %s): Get refresh request (FMBS). 
VCPDecompressionSession
VCPDec %p (%dx%d, %s): Video decompression session invalidated
OSStatus VCPDecompressionSessionCreate(CFAllocatorRef, CMVideoFormatDescriptionRef, CFDictionaryRef, CFDictionaryRef, const VTDecompressionOutputCallbackRecord *, VCPDecompressionSessionRef *)
VCPDec %p (%dx%d, %s): Decoder failed to create video processor, err = %d
VCPDec %p (%dx%d, %s): Failed to create video decoder, err = %d
OSStatus DecompressionSessionCreateCommon(CFAllocatorRef, CMVideoFormatDescriptionRef, CFDictionaryRef, CFDictionaryRef, VCPDecompressionSessionRef)
%dx%d_%04lX
%s/VcpDec_%s_%s_FrameStats.txt
%-20s %s
Codec Type:
%-20s %dx%d
Resolution:
Cropped Resolution:
Negotiation String:
%17s %21s %21s %9s
Clean Rect
Checksum
%10s %7s %10s %10s %10s %10s %9s
Frame #
(w, h)
(h, v)
Matched
%s/VcpDec_%s_%s_Bitstream.26l
%s/VcpDec_%s_%s_Bitstream.hevc
FaceZoom
VCPDecompressionSessionSetProperty: vcpSession is NULL
VCPDec %p (%dx%d, %s): Failed to set max buffer age of decoder pixel buffer pool
VCPDec %p (%dx%d, %s): Failed to copy decoder pixel buffer pool
VCPDec %p (%dx%d, %s): Failed to create video decoder, usage = %d, on %s, err = %d; FLS = "%s"
VCPDec %p (%dx%d, %s): Created %s video decoder, usage = %d, on %s; FLS = "%s"
VCPDec %p (%dx%d, %s): Decoder could not parse config info!
hvcC
ChecksumMode
VCPDec %p (%dx%d, %s): Decoder FLS doesn't exist
VCPDec %p (%dx%d, %s): Decoder could not get FLS!
VCPDec %p (%dx%d, %s): Decoder failed to create an FLS, err = %d
NegotiationDetails
com.apple.VideoProcessing: [%s]: {VCPDecompressionSessionCreate} Forced SW decoder!
com.apple.VideoProcessing: [%s]: {VCPDecompressionSessionCreate} Forced HW decoder!
com.apple.VideoConference
FaceTimeDecoder
VCPDec %p (%dx%d, %s): Decoder failed to initialize stitching filter, err = %d
VCPDec %p (%dx%d, %s): Decoder failed to create stitching filter, err = %d
VCPDec %p: Decoder got buffer height video specification: %d
FrameBufferHeight
VCPDec %p: Decoder got buffer width video specification: %d
FrameBufferWidth
VCPDec %p: Decoder got number of tiles video specification: %d
VCPDec %p (%dx%d, %s): Failed to create decoder specification copy, err = %d
void VCPDecompressionSessionCallback(void *, void *, OSStatus, VTDecodeInfoFlags, CVImageBufferRef, CMTime, CMTime)
Codec: %s
Size: %dx%d
VRA: %dx%d
FR: %4.1f fps
Priority: %3d
%7d 
 %4zux%4zu 
 %4dx%4d 
 %9s
---- 
 %4d,%4d 
%9s 
 ------ status = %d, imageBuffer = %p ------
VCPDec %p (%dx%d, %s): Decoder callback status = %d, imageBuffer=%p, decodeFlags: 0x%x, infoFlags: 0x%x, timestamp: %d, time=%.2f ms
; VRA:%4dx%4d 
; VRA:%9s
; tile_id=%d, tile_odr=%d, tile_loc=%4d/%4d/%4d
; idle_copy=(%s)
; All subframes are ready.
; Subframes are not ready, received tile mask: 0x%x, expected: 0x%x
; This subframe is not processed.
hid_ts: %#llx
VCPDec %p (%dx%d, %s): Failed to filter the frame after tile (id %d, order %d)
VCPDec %p (%dx%d, %s): Failed to stitch non-dirty tile (id %d, order %d)
VCPDec %p (%dx%d, %s): Failed to stitch tile (id %d, order %d)
VCPDec %p (%dx%d, %s): Timestamp does not match, expected: %d, actual: %d
VCPDec %p (%dx%d, %s): Do not process this subframe because it should be dropped
VCPDec %p (%dx%d, %s): Tile order does not match, expected: %d, actual: %d
VCPDec %p (%dx%d, %s): Decoder failed to create stitched pixel buffer for subframe decoding!
VCPDec %p (%dx%d, %s): Decoder failed to create stitched pixel buffer pool for subframe decoding! (pixfmt %d)
RotationFlags
VraHeight
VraWidth
VCPDec %p (%dx%d, %s): Decoder checksum is N/A
VCPDec %p (%dx%d, %s) checksum mistach is found, but ignored
VCPDec %p (%dx%d, %s): Please file radar to VideoProcessing. You would see a green frame due to Checksum mismatch local %x <-> received %x
VCPDec %p (%dx%d, %s): Decoder checksum mismatch local %x <-> received %x
FrameYUVChecksum
v20@?0i8^{__CFDictionary=}12
void VCPDecompressionSessionCallback(void *, void *, OSStatus, VTDecodeInfoFlags, CVImageBufferRef, CMTime, CMTime)_block_invoke
com.apple.VideoProcessing: [%s]: {DecodePicture} Error: RealTimeAnalysis failed: %d
com.apple.VideoProcessing: [%s]: {DecodePicture} frameCount=%lld
com.apple.VideoProcessing: [%s]: failed to create timestamp_list
com.apple.VideoProcessing: [%s]: VCPRealTimeAnalysisServiceCreate Error
VCPDec: Failed to create video decompression session, err = %d
EnableVideoChatAnalysis
VCPDecompressionSessionDecodeFrame: sampleBuffer NULLL
VCPDecompressionSessionDecodeFrame: block_buffer is NULLL
VCPDecompressionControlByteProcessing: ParseControlByteFromBuffer failed 
OSStatus VCPDecompressionSessionDecodeFrame(VCPDecompressionSessionRef, CMSampleBufferRef, VTDecodeFrameFlags, void *, VTDecodeInfoFlags *)
Ignoring request for async decode (not supported with inloop chroma filter)
com.apple.VideoProcessing: [%s]: failed to create pixelBufferPool 
ExtraInloopFilter
VCPDecompressionSessionDecodeFrame: VCPDecompressionControlByteProcessing failed
Failed to recreate DecompressionSession, err = %d
RequestedRotationFlags
rtpTimestsamp
FramePriority
VCPDec %p (%s): Decoder failed to initialize vcpFrameContext, err = %d
VCPDec %p (%s): Decoder failed to create vcpFrameContext, err = %d
control_byte memory allocate failed!
VCPDec %p (%s) VCPDecompressionSessionCheckIfLastSubFrame incorrect parameter
VCPDec %p (%s) VCPDecompressionSessionCheckIfLastSubFrame ParseControlByteFromBuffer failed
VCPDec %p (%s) VCPDecompressionSessionCheckIfLastSubFrame time_stamp %llu posX %d posY %d posZ %d lastSub %d
[%s]: =============================================================================
void *VPDynamicConfig()
[com.apple.VideoProcessing] =============================================================================
test version
[%s]: VideoProcessing (%s): 
[com.apple.VideoProcessing] VideoProcessing (%s): 
[%s]: %s
[com.apple.VideoProcessing] %s
[%s]: To enabled Preference runtime update, defaults write com.apple.VideoProcessing EnablePreferencesRuntimeUpdate 1
[com.apple.VideoProcessing] To enabled Preference runtime update, defaults write com.apple.VideoProcessing EnablePreferencesRuntimeUpdate 1
[%s]: Preference runtime update enabled. Modify %s/Resources/Info.plist as needed.
[com.apple.VideoProcessing] Preference runtime update enabled. Modify %s/Resources/Info.plist as needed.
FaceTimeEncoder
CameraFacingType
FECPercentagePFrame
FECPercentageIFrame
FECPercentage
PadFrameToMinimumSize
frame %d: refresh frame requested
frame %d: key frame requested
Passed NALU that isn't a parameter set!
NALU too small
forbidden_zero_bit is 1
NALU (type %d) has no RBSP!
nuh_reserved_zero_6bits %u != 0
nuh_temporal_id_plus1 == 0
Temporal ID must be non-zero for NALU type %d
End of sequence/bitstream NALU (type %d) should NOT have RBSP data (%ld bytes)!
Temporal ID (%d) must be zero for NALU type %d
Invalid chroma_format_idc (%d)
separate_colour_plane_flag not supported
unique_lock::unlock: not locked
VCPRealTimeAnalysisService
VPImageBufferLSBAligned
Source buffer copy is needed. Check why we need to copy the source buffer.
Failed to copy source buffer
Invalid pixel format
Unexpected %d planes (too many)
SetBuffer: VRA buffers have different dimensions
Stride of %zd bytes is very aligned, this may cause slowdown
Luma/chroma bit depth mismatch not supported
Unsupported chroma_format_idc %d
Bit depth %d not currently supported
Too many (%d) active refs!
L1 found too few reference frames
L0 found too few reference frames
Temporal reference changed between slices
Temporal MVP enabled but pointing to invalid reference
=========== Slice ===========
  %-44s : %lld
first_slice_in_pic_flag
no_output_of_prior_pics_flag
slice_pic_parameter_set_id
dependent_slice_flag
slice_segment_address
slice_reserved_flag
slice_type
pic_output_flag
colour_plane_id
slice_pic_order_cnt_lsb
short_term_ref_pic_set_sps_flag
short_term_ref_pic_set_idx
slice_temporal_mvp_enable_flag
slice_sao_luma_flag
slice_sao_chroma_flag
num_ref_idx_active_override_flag
num_ref_idx_active
ref_pic_list_modification_flag_l0
list_entry_l0
ref_pic_list_modification_flag_l1
list_entry_l1
mvd_l1_zero_flag
cabac_init_flag
collocated_from_l0_flag
collocated_ref_idx
luma_log2_weight_denom
delta_chroma_log2_weight_denom
five_minus_max_num_merge_cand
slice_qp_delta
slice_cb_qp_offset
slice_cr_qp_offset
deblocking_filter_override_flag
slice_deblocking_filter_disabled_flag
slice_beta_offset_div2
slice_tc_offset_div2
slice_loop_filter_across_slices_enabled_flag
num_entry_point_offsets
offset_len_minus1
entry_point_offset_minus1
slice_segment_header_extension_length
Invalid VRA parameters %dx%d!
No slice found containing TB [%d][%d]!
num_tile_columns_minus1 (%d) out of range [0, %d]
num_tile_rows_minus1 (%d) out of range [0, %d]
Invalid ctb [%d][%d]
NULL buffer
Failed to find terminating bit
Unexpected NAL_unit_type (%d) in configuration record
AvcC contains %d sequence parameters sets. Only the first one will be extracted.
Failed to get simple stats from sample buffer
Sample attachment array does not exist
Sample attachment does not exist
Failed to process format description
Failed to process avcC
Failed to process hvcC
Invalid format extensions
Sample buffer does not exist
Invalid sample
Encoder returns error %d
Failed to create frame properties
scaling_list_pred_matrix_id_delta of %lld is out of range (%lld, %lld)
Unavailable long-term reference - POC %d!
Unused long-term reference with POC %d not found!
Unavailable short-term reference - POC %d!
Unused short-term reference with POC %d not found!
Long-term Foll:
Short-term Foll:
Long-term current:
Frame is NULL
Frame poc: %d
Short-term current after:
Short-term current before:
numPocLtFoll: %d
numPocStFoll: %d
numPocLtCurr: %d
numPocStCurrAfter: %d
numPocStCurrBefore: %d
numPocTotalCurr: %d
DPB overflow!
MarkRefs gets invalid combined RPS!
short_term
long_term
poc: %d
frame_num_driver: %d
reference_type: %s
<<<<<< [Poc %d]: SW DPB >>>>>>
Reserved aspect_ratio_idc %d
This PPS has already been parsed, a new one must be allocated instead
Invalid chroma_qp_offset_list_len_minus1 = %d
Ignoring PPS extension
8x8 collocated sad array creation failed
Initialize rdcost_ failed
Invalid slice type %d
Dependent slices not yet implemented!
Failed to initialize time!
hw.optional.bmi2
hw.optional.bmi1
hw.optional.avx2_0
hw.optional.avx1_0
hw.optional.sse4_2
hw.optional.sse4_1
hw.optional.supplementalsse3
hw.optional.sse3
hw.optional.sse2
hw.cachelinesize
hw.physicalcpu
hw.logicalcpu
false
Unknown option '%s'
Option '%s' starts with the wrong dash, please retype it
Invalid parameter '%s' to '%s'
%s:%d: Parse error (expected <option> : <argument>)
'%s' option too long!
Option '%s' is invalid!
%s:%d: Too many options (max %d)
Config file unreasonably large (%zu)
Unable to determine filesize
Unable to open config file '%s'
Config file within a config file not supported!
Hash of named enum '%s' and '%s' collide (%llx)! Change one of the names!
Hash of options '%s' and '%s' collide (%llx)! Change one of the names!
No preferences set
Got some other type than CFString for %s, ignoring
Read preference (%s, %s)
Ignoring preference (%s, %s)
Preference couldn't be easily converted to C string, ignoring
Unsupported bitDepth_y
Deblock not supported for chroma_format_idc %d
unsupported bitdepth
bit depth %d not supported
fps cannot be 0
requested bitrate is 0, ignoring level bitrate limits
luma(picture_size/picture_dim/sample_rate)/bit_rate is too big to fit in any level: (%d/%d/%d)/%d
maxNumSubLayersMinus1 (%d) out of range [0, %d]
profile_space_[layer_idx] == 0 failed!
major_level_[layer_idx] of %lld is out of range (%lld, %lld)
minor_level_[layer_idx] <= kMaxMinorLevel[major_level_[layer_idx]-1] failed!
general_max_10bit_constraint_flag not set!
Profile %d not supported
Need to implement inferrence of common HRD info
This VPS has already been parsed, a new one must be allocated instead
vps_num_layer_sets_minus1_ (%d) out of range [0, %d]
vps_num_layer_sets_minus1 > 0!!!
Ignoring VPS extension
vps_video_parameter_set_id_ of %lld is out of range (%lld, %lld)
vps_max_sub_layers_minus1_ of %lld is out of range (%lld, %lld)
vps_max_dec_pic_buffering_minus1_[idx] of %lld is out of range (%lld, %lld)
vps_max_num_reorder_pics_[idx] of %lld is out of range (%lld, %lld)
vps_max_latency_increase_plus1_[idx] of %lld is out of range (%lld, %lld)
vps_num_layer_sets_minus1_ of %lld is out of range (%lld, %lld)
vps_num_hrd_parameters_ of %lld is out of range (%lld, %lld)
ScaleReconFrameToInputDimension failed for PSNR
Request IDR because of encoding error
Failed to alloc resources!
 No Matching FrameStats Found
Negotiation String: %s
LRP 
%10s 
Time stamp
%10s%15s%5s%8s%14s%14s
Frame
Dimension
Bytes
Dlay(ms)
        FPS   
       Bitrate     
  FPS 
           PSNR         
%49s%s%49s
 %-9s%17s     
force
Bits
 %7s %7s
EncTime
HW-Time
 Ref POCs
(seconds)
LRP %6s (%6s) %4sx%-4s%4s%4s%7s%7s%7s%10s
Src #
Frm/  avg
act/ max
%5s/%4s/%3s
targ
 %9s/%-8s
%5s 
 %5s/%5s/%5s/%5s
comp
 %32s %32s %32s  
 %3s/%5s %3s %7s/%5s %2s
Rfrsh
(ms)
 %14s
time (ms)
%10.3f 
BEFORE
 AFTER
 -------- dropped: %s encoding --------
 %6s
 %6lu
 %4d/%4d
 %4.1f/%4.1f/%4.1f
 %8d/%-8d
 %4.1f 
 --.--/--.--/--.--/--.--
 ----------------------------------------------------------------------------------------------------
 %3d/%5d %3d %7d/%5d --
 (%6d) %4dx%4d %4s %5.1f/%5.1f %6lu
 %5.2f/%5.2f/%5.2f/%5.2f
%02x
-%32s
MD5 calculation error
 %3d/%5d %3d %7d/%5d %2d
 %7.2f %7.2f
 %7.2f ms
Unable to close file
No frame to encode.
Frame %d: Compress failed
Frame %d: GenerateFaceDeltaQp failed
Frame %d: Precompress failed
FinishPendingFrames failed
Frame %d: Preprocess failed
Frame %d: update control info failed
true
Sequence stats agent creation failed.
%m%d%g_%H%M%S
LOGNAME
/Users/%s/%s/tmp
/Library/Containers/com.apple.FaceTime/Data
%dx%d_%.0ffps
%s/LrpEnc_%s_%s_FrameStats.txt
%s/LrpEnc_%s_%s_Bitstream.hevc
%s/LrpEnc_%s_%s_Bitstream.264
%s/LrpEnc_%s_%s_SrcYuv.yuv
Unable to open file '%s'
yuv 
SetFile
setfile: failed with result=%d
%s/LrpEnc_%s_%s_ReconYuv.yuv
hevc
264 
PrepareModeDecision failed
Rate control creation failed.
PreProcessor creation failed.
VideoProcessorLRP creation failed.
Failed to get pixel format from sps
Setting up a PPS pointing to an inactive SPS
Failed to setup profile and level
MaxDpbSize constraint violated
VPS/SPS/PPS fail to get
Negotiation details unit creation failed.
Failed to get frame resource from frame pool.
NULL frame pushed!
Normal priority set
Background priority set
High Priority not supported for main thread
Frame %d: Gop-structure change fails
Frame %d: Hookup failed
Failed to initialize from sequence enc.
Unable to allocate frame_enc
Face: framenum= %d capture_timestamp= %lf x= %f y= %f w= %f h= %f, 
face_roll= %d, face_yaw= %d
ISP: framenum= %d capture_timestamp= %lf T= %lf AGC= %d sensorDGain= %d ispDGain= %d 
AEAverage= %d AWBRGain= %d AWBGGain= %d AWBBGain= %d normalSNR= %lf
[Poc %d]: number of LTR frames (%d) is smaller than number of LTR allowed (%d) in DPB
Error occurred in encoding frame %d
<<<<<< [Poc %d]: RPS >>>>>>
<<<<<< [Poc %d]: Long-term RPS >>>>>>
<<<<<< [Poc %d]: Short-term RPS >>>>>>
fps MUST be positive
Control byte creation failed.
Recon frame creation failed
Both IDR request and intra request appear, we choose to force IDR
Recon frame is NULL.
Precompress failed
Pre-comp init failed
before
after
Frame %d: dropped %s encoding
Frame %d: ManageDPB after dropping failed
Frame %d: ManageDPB failed
Frame %d: RateControlAfterEncoding failed
Failed to generate output data.
Failed to CalculateCheckSumOneFrame.
Failed to update DBP context
Setup References failed; Encode IDR
Failed to encode frame %d with error %d
Frame %d: FinishCompress() is failed
FrameEnc emit function receives an error: %d
EncodeSlice failed
Slice encode failed
Frame %d: PreEncode failed
Slice initialization failed
SliceEnc array creation failed
Compress() receives an error: %d
%hu:%hu:%hu:%hu:%hu:%hu:%hu:%hu:%u:%u
ref-struct: %d %c %d %d %d %d
 %d %d
Trailing parameters in reference structure, starting with '%s'
Invalid ref.predict_flag[%d] '%s'
Invalid num_ref_predict '%s'
Invalid delta_rps '%s'
Invalid rps scheme '%s'
Invalid ref.ref_used[%d] '%s'
Invalid ref.ref_frames[%d] '%s'
Invalid number_ref_active '%s'
Invalid number_ref_all '%s'
Invalid qp_offset '%s'
Invalid poc '%s'
Invalid frame_type '%s'
Invalid frame_idx_in_gop '%s'
Too many parameters to ref-struct
Bit depths %d/%d not supported; luma and chroma must match and be 8 or 10
default
capture
facetime
sidecar
airplay
safeview
Usage %s is un-supported, back to default
!GenerateExtraRPS() failed!
!(isp_driven_wp_ && en_analyze_wp_) failed!
qpm 5 mode does not work with mdmode smaller than 2.
(gop_list_[frm_num].poc > 0) && (gop_list_[frm_num].poc <= gop_size_[gop_id]) failed!
(gop_list_[frm_num].frame_type == 'P') || (gop_list_[frm_num].frame_type == 'R') || (gop_list_[frm_num].frame_type == 'L') failed!
gop_list_[frm_num].number_ref_active <= gop_list_[frm_num].number_ref_all failed!
%d + %d + 1 > %d
max_dpb_size: %d
number_long_term_ref: %d
number_short_term_ref: %d
bps_ > 0 failed!
width_ > 0 && height_ > 0 failed!
frame_rate_ > 0 failed!
iqp_ of %lld is out of range (%lld, %lld)
pqp_ of %lld is out of range (%lld, %lld)
number_frames_ > 0 failed!
frame_skip_interval_ >= 0 failed!
log2_min_cu_size_ of %lld is out of range (%lld, %lld)
log2_max_cu_size_ of %lld is out of range (%lld, %lld)
log2_max_cu_size_ >= log2_min_cu_size_ failed!
log2_min_tu_size_ of %lld is out of range (%lld, %lld)
log2_max_tu_size_ of %lld is out of range (%lld, %lld)
log2_max_tu_size_ >= log2_min_tu_size_ failed!
!(width_ & 7) failed!
!(height_ & 7) failed!
!(width_ & ((1 << log2_min_cu_size_) - 1)) failed!
!(height_ & ((1 << log2_min_cu_size_) - 1)) failed!
max_hierarchy_tu_intra_ of %lld is out of range (%lld, %lld)
max_hierarchy_tu_inter_ of %lld is out of range (%lld, %lld)
log2_max_cu_size_ >= log2_max_tu_size_ failed!
max_satd_luma_size_ == 4 || max_satd_luma_size_ == 8 || max_satd_luma_size_ == 16 || max_satd_luma_size_ == 32 failed!
fast_intra_ == 0 || fast_intra_ == 1 failed!
num_intra_rd_candidate_ <= 4 failed!
qpm_ of %lld is out of range (%lld, %lld)
dqp_depth_ of %lld is out of range (%lld, %lld)
qpm_param_ of %lld is out of range (%lld, %lld)
qpm_eq_ of %lld is out of range (%lld, %lld)
x86 does not support hardware scale
Invalid PreEncoder type
HW-aided encoding mode cannot use asynchronous preencoding
Frame reencoding cannot use asynchronous preencoding
preenc_async_ >= 0 failed!
preenc_throttle_ >= 1 failed!
Invalid codec type
dmm_ < kDmmType_MAX failed!
preenc_type_ > kPreEnc_None failed!
dmm_period_ != 0 failed!
adaptive_cudepth_ of %lld is out of range (%lld, %lld)
log2_max_cu_size_ - log2_min_cu_size_ <= 3 failed!
qpm_ > 0 failed!
PreEncoder must be "direct" in order to encode H264 bitstream
Desktop does not have hardware preencoder support
Bit depth %d not supported
RDCost init failed in LCUEnc
Failed to create reference selector.
Cannot do fast pre-comp since motion block size is equal to LCU size!
Unsupported log2_qpm_unit_size_ %d
Reference selector init failed
diff_masking_cu_ creation failed
Block size (%d) for transition detection is not supported
Spatial Sum of Square array creation failed
Spatial Sum array creation failed
DEV MEAN array creation failed
NxN SAD array creation failed
8x8 SAD array creation failed
8x8 SUM array creation failed
Motion block size is larger than LCU size!
long-term RPS creation failed
short-term RPS creation failed
RPS creation failed
Unsupported log2_unit_size_ %d (update SpatialSumSad)
Failed to find frame poc=%d in DPB
Number of LTRs in DPB is %d, more than specified (%d)!
substream %d: 
%d(%s) | 
Empty reference list for this frame
[Poc %d]: reference poc %d is set as both STR and LTR
[Poc %d]: failed to find LTR that is ready to be retired
SliceEnc initialization failed
SliceEnc creation in precomp failed.
Failed to initialize from PreComp.
NULL plane!
LanczosScaling only supports 4:2:0 biplanar
Pixel format mismatch between src and dst!
Invalid scaling dimensions %dx%d -> %dx%d
Invalid dimension %dx%d exceeds pixel buffer %ldx%ld
src and dst being the same buffer not supported so far!
Invalid dstHeight or dstWidth
10bit mono to 420 copy not implemented
Conversion between bitdepths not supported
Unsupported conversion from pixfmt 0x%x to 0x%x
UNALIGNED! %p %p
Bit depth %d is not supported
SAO assumes offsets will fit in int8_t
Resolution (%d x %d) and Frame rate (%.2f) is not supported in Quality 
Dropped before encoding.
Unknown negotiation string option: %s
RVRA1
PSNR
TILE
TIME
CABAC
RVRA
Ignoring feature "%s"
Unsupported codec type: %d
Negotiation detail string too long (%lu > %u)
Failed to alloc buffer for negotiation string!
ParseControlByteFromBuffer ExtractControlData failed
Number of extracted bytes is Wrong!
source and dst buffer cannot be the same so far!
Mocomp initialize failed
Trans initialize failed
Intra initialize failed
Interpolation cache initialize failed
Deblock initialize failed
ScaleActiveReference failed
InitReferenceLists failed
Ran out of allocated bufferspace
Slice header encoding failed
list_entry_l1_[%d] (%d) out of range [0, %d]
list_entry_l0_[%d] (%d) out of range [0, %d]
Bitstream initialization for SliceEnc failed
LCUEnc init failed
LCUEnc creation failed
Can't create semaphore
SubstreamContext creation failed
Substream bitstream initialization failed
RDCost init failed in SAOEnc
Attempt to allocate %zu bytes blocked
idx %d > kMaxID %d
delta_idx_minus1_ (%d) must be between 0-%d
Number of ref pics exceeds limit: %d + %d > %d
delta_poc_s0_minus1_[i] of %lld is out of range (%lld, %lld)
delta_poc_s1_minus1_[i] of %lld is out of range (%lld, %lld)
delta poc: %d, used: %d
Delta poc s1:
Delta poc s0:
num_positive_pics: %d
num_negative_pics: %d
No supported!
inter_ref_pic_set_prediction_flag: %d
  short_term_ref_pic_set(%d) {
    %-42s : %lld
inter_ref_pic_set_prediction_flag
delta_idx_minus1
delta_rps_sign
abs_delta_rps_minus1
      %-40s : %lld
used_by_curr_pic_flag
use_delta_flag
num_negative_pics
num_positive_pics
delta_poc_s0_minus1
used_by_curr_pic_s0_flag
delta_poc_s1_minus1
used_by_curr_pic_s1_flag
poc_lsb: %d, used: %d, poc: %d, delta_poc_msb_flag: %d
poc_lsb: %d, used: %d, poc: %d, delta_poc_msb_flag: %d, delta_poc_cycle: %d
idx: %d, delta_poc_msb_flag: %d
idx: %d, delta_poc_msb_flag: %d, delta_poc_cycle: %d
Long-term poc lsb:
Long-term sps:
num_long_term_pics: %d
num_long_term_sps: %d
  long_term_ref_pic_set {
num_long_term_sps
num_long_term_pics
lt_idx_sps
delta_poc_msb_present_flag
delta_poc_msb_cycle_lt
poc_lsb_lt
used_by_curr_pic_lt_flag
This SPS has already been parsed, a new one must be allocated instead
log2_max_pic_order_cnt_lsb_minus4 (%d) > %d
num_short_term_ref_pic_sets (%d) out of range [0, %d]
num_long_term_ref_pics_sps_ (%d) out of range [0, %d]
Ignoring SPS extension
PullVUIParamSet() is not implemented yet
Wrong forbidden_zero_bit in SPS: %d
Wrong nal_ref_idc in SPS: %d
Wrong nal_unit_type in SPS: %d
Wrong profile_idc in SPS: %d
Wrong seq_parameter_set_id in SPS: %d
Wrong chroma_format_idc in SPS: %d
Wrong bit_depth_luma_minus8 in SPS: %d
Wrong bit_depth_chroma_minus8 in SPS: %d
Wrong qpprime_y_zero_transform_bypass_flag in SPS: %d
Wrong seq_parameter_set_idin SPS: %d
Wrong num_ref_frames_in_pic_order_cnt_cycle in SPS: %d
Proposed level idc (%d) is not supported; Minimal level idc %d should be used based on profile %d, num_mb_f %d, num_mb_s %d, bps %d.
Cannot set max_dpb_size with level %d -> default to 2
configuration record initialization failed
extract parameter sets from configuration record failed
Configuration record creation from parameter sets failed
LRPConfigInfo: configuration record initialization failed
LRPConfigInfo: extract parameter sets from configuration record failed
Failed to parse SPS
LRPConfigInfo: extract sequence parameter sets from configuration record failed
ShowInfo
EnablePreferencesRuntimeUpdate
PreprocessingSmoothingFactor
PreprocessingTemporalFilterWeight
PostprocessingDitheringStrength
PostprocessingSharpeningStrength
PostprocessingNoResize
EnablePreprocessingTemporalNoiseReduction
EnablePreprocessingSpatialNoiseReduction
EnableAEControl
H264Decoder_DumpBitstream
H264VideoEncoder_EnableFrameStatsDumping
H264VideoEncoder_EnableSourceAndPropertyDumping
ShowFrameEncodingTime
DisableComplexityControl
EnableComplexityControlPrint
ComplexityControlThresholdHi
ComplexityControlThresholdLow
DisableTag3Dithering
ShowRoughConnectionInfo
TwoSlicesForEmbedded
SimplerModeDecisionForEmbedded
ForceFaceDrivenProcessing
UnifiedEncoderMode
EnableLowFrameRateMode
ForcePaddingToTargetBitrate
HWEncoderEnterBW
HWEncoderExitBW
EnableReferenceAffineWarping
DumpDetailedDPBInfo
SccMinNumRepeatedFramesSent
ForceAsync
H264VideoEncoder_EnablePSNR
[%s]: Configs for %s
void DynamicConfig_ListAllConfigs(const char *, int)
[com.apple.VideoProcessing] Configs for %s
[%s]: 
%s: 
[com.apple.VideoProcessing] 
%s: 
[%s]: %d
[com.apple.VideoProcessing] %d
[%s]: 
[com.apple.VideoProcessing] 
[%s]: DynamicConfg Error in SetConfig(): key index %d is out of range
int DynamicConfig_SetConfig(unsigned int, int)
[com.apple.VideoProcessing] DynamicConfg Error in SetConfig(): key index %d is out of range
[%s]: DynamicConfg Error in GetConfigKeyName(): key index %d is out of range
const char *DynamicConfig_GetConfigKeyName(unsigned int)
[com.apple.VideoProcessing] DynamicConfg Error in GetConfigKeyName(): key index %d is out of range
    Analyzing Audio Track - ID: %d Start: %lld/%d (%0.3fs) End: %lld/%d (%0.3fs)
[MediaAnalysis] save pixel-based recipe regardless of confidence
    Pixel Stabilization confidence doesn't pass the threshold
[MediaAnalysis] Human pose analysis - save keypoints
Failed to lock CVPixelBuffer (%p, %d)
Cannot lock NULL CVPixelBuffer
Lock attempt failed; cannot unlock buffer
Multiple unlock attempts; cannot unlock buffer
Failed to unlock CVPixelBuffer (%p, %d)
Video track rotation angle is not multiple of 90
Gyro analytics stored via dodML
copyImageToBGRHandKeypointCallFromSPI
preProcessingHandKeypointCallFromSPI
Not implemented, please use initWithOptions
Multiple sampling times (%0.1fs) intersect frame at %lld/%d
%@ skipping sample %lld at %lld/%d
%@ failed for sample at %lld/%d (%@)
[VCPDatabaseReader] Including internal fields in queries
[MediaAnalysis] Failed to open database
Closed analysis database
[MediaAnalysis] Unknown result key for result type %u
[MediaAnalysis] Error querying blacklist status for %@
[MediaAnalysis] Failed to query blacklisted assets
[MediaAnalysis] Failed to query asset %@
[MediaAnalysis] Failed to query analysis properties of asset %@
[MediaAnalysis] queryAnalysesForAssets Failed
[MediaAnalysis] Failed to query assets since %@
[MediaAnalysis] Failed to query failed assets for taskID: %lu
[MediaAnalysis] WARNING: ProcessingStatus entry with nil localIdentifier
Failed to extract NSArray from column %d (%@)
Live photo effects - skip using PHSceneClassification from PHAsset
Creating faceprint for face crop
Multiple faces present in face crop; using first
Loading quick identification model
Performing quick identification
Quick identification match found: %@
No quick identification match found
Home face identification task failed (%@)
Getting no object IDs when fetching assets on moment %@
VCPFaceAnalyzerReleaseCachedResources
Error: missing VNDetectFaceRectanglesRequest
Error: missing VNDetectFaceLandmarksRequest
Error: missing VNDetectFaceExpressionsRequest
Error: missing VNDetectFacePoseRequest
Error: missing VNCreateFaceTorsoprintRequest
Error: missing VNClassifyFaceAttributesRequest
Error: missing VNDetectFaceCaptureQualityRequest
Error: creating VNDetectFaceRectanglesRequest
Error: creating VNDetectFaceLandmarksRequest
Error: creating VNDetectFaceExpressionsRequest
Error: creating VNDetectFacePoseRequest
Error: creating VNCreateFaceTorsoprintRequest
Error: creating VNClassifyFaceAttributesRequest
Error: creating VNDetectFaceCaptureQualityRequest
Error: creating VNImageBlurScoreRequest
Error: creating VNImageExposureScoreRequest
Faceprint request failed to return a faceprint
Error creating Face VNRequest
VCPFaceAnalyzerImageRequestHandlerPerformRequest
Error: Face VNImageRequestHandler::performRequests: %@
Error: failed to create blur/exposure request
Error: blurScore %f out of bound [%f, %f]
Error: VNImageRequestHandler failed to perform blurRequests: %@
Error: exposureScore %f out of bound [%f, %f]
Error: VNImageRequestHandler failed to perform exposureRequests: %@
VCPFaceAnalyzerBlurExposureAnalysis
VCPFaceAnalyzerPVFaceCreation
VCPFaceAnalyzerVerifyAndMergeFaces
 [%@] Analysis completed; facesDetected %lu | facesToPersist: %lu | facesToDelete: %lu
VCPFaceAnalyzerLoadImageRequestHandler
Failed to create VNImageRequestHandler
Failed to analyze PVImage
Failed to refine analysis
VCPFaceAnalyzerPerformAnalysis
Unexpected media type (%lu)
[%@] Unexpected media type (%d)
%@ canceled (%@)
%@ failed (%@)
[MediaAnalysis] Image descriptor - found more than 1 VNImageprintObservations
VNImageprint init error: %@
Query progress: unsupport taskID (%lu)
Query progress: output parameter statistics must be non-nil
Query progress: unsupported taskID (%lu)
Query progress: %@ - %@
Query progress: unsupported taskID (%@)
Query progress: %@ - %lu out of %lu
VCPVideoStabilizationAssetProcessingTask
Video Stabilization processing failed
[%@] Quick Face ID task failed; skip processing
Quick Face ID batch %lu, jobs: %lu
Quick Face ID task canceled (%@)
Quick Face ID task failed (%@)
[Decode] Downscaling %zux%zu --> %zux%zu
[Decode] %.0fx%.0f --> %zu; subsampling %dx on decode
[Decode] Accelerated decode failed; falling back to CGImage
Found %lu faces with CSN > 0 but not in any face groups
VCP: %@
PersistFaceGroups: Photo library is missing a face with CSN = %@
PersistFaceGroups: Faces with these CSNs will be removed from the cluster cache: %@
PersistFaceGroups: Faces with these localIdentifiers will be re-clustered: %@
PersistFaceGroups: We should not get here! If we did, then we have a previously clustered face without a face group!
PersistFaceGroups: Failed to create a face group change request to add faces!
PersistFaceGroups: Failed to find a faceGroup for face '%@' with CSN: %d
PersistFaceGroups: No faces added to face groups!
PersistFaceGroups: Failed to find face with localIdentier: %@. Could not set its CSN to %@
PersistFaceGroups: Set personBuilderState of faceGroups: %@
PersistFaceGroups: Failed to delete empty face groups with error: %@
PersistFaceGroups: Canceled updating key faces unverified persons after persisting face groups.
PersistFaceGroups: Failed to update key faces unverified persons after persisting face groups. Error: %@
%s: Input parameter is empty or nil: '%@'
%s: %@
UpdateKeyFaces: Key Face exists. Ignoring %@
Updating key face %@ on person %@
Error: did not find single face group for unverified person, unable to set key face on face group, (number of face groups: %lu)
Error: could not set key face for person %@
Warning: Couldn't get faceprint data for face: %@. Ignoring
Error: Failed to get VNFaceTorsoprint from faceprint data, error: %@
Warning: Could not get representativeness for faces, error: %@
PersonBuilder: Deleted duplicate graph-verified persons '%@' from face group %@
PersonBuilder: Failed to delete duplicate graph-verified persons '%@' from face group %@
PersonBuilder: Deduped graph-verified persons '%@' from face group %@
PersonBuilder: Failed to dedupe graph-verified persons '%@' from face group %@
personLocalIdentifier for PHFace %@ is null; skip processing
Found no persons rejected for a rejection training face: %@
PersonBuilder: Did not find merge candidate persons with local identifiers: '%@'
PersonBuilder: Found invalid merge candidate pair ['%@' : '%@']
PersonBuilder: Already found merge candidate pair ['%@' : '%@']
PersonBuilder: Unexpected error - could not create merge candidate pair '%@' : '%@'
PersonBuilder: Unexpected error - could not create invalid merge candidate pair '%@' : '%@'
PersonBuilder: Cleared personBuilderState of faceGroup: '%@'
PersonBuilder: merge candidate pair '%@' : '%@' - reason: '%@'
Could not find a face with clusterSequenceNumber '%@' in the library
PersonBuilder: Got a 'nil' photoLibrary. Cannot build persons
PersonBuilder: Failed to find unverified person for faceGroups '%@'; These will be fixed up and retried later
PersonBuilder: Failed to fix up face groups without unverified person. Error: '%@'
PersonBuilder: Person Building faceGroup '%@'
PersonBuilder: Failed to find unverified person [unverifiedPerson: %@, unverifiedPersonLocalIdentifier: %@] for faceGroup '%@', skipping this face group
Person Builder: Quick classification faces found. Number of faces retained: %@. Number of faces reassigned %@
PersonBuilder: We may have a dirty level0 cluster, persons with training faces: %@
PersonBuilder: We may have a dirty level0 cluster, verified persons with confirmed face: %@
PersonBuilder: Unnamed unconfirmed faces in face group, '%@', without a training face: %@
PersonBuilder: Found training rejection, unassigned faces on trainingPersonLocalIdentifier in level0 cluster: %@
PersonBuilder: Skip processing level0 cluster since we have rejected face for training person '%@' in level1 cluster
PersonBuilder: Failed to build persons [Error: '%@']
PersonBuilder: ---> buildPersonsWithFaceClusterer, %s
PersonBuilder: Person Building is Disabled!
PersonBuilder: Cleared personBuilderState of faceGroups: %@
PersonBuilder: Failed to clear personBuilderState of faceGroups: %@, error: %@
PersonBuilder: <--- buildPersonsWithFaceClusterer
Got a 'nil' photoLibrary. Cannot remove auto assigned faces
Failed to remove auto-assigned faces from person '%@', error: %@
Apply Sharpness Model V1
Apply Sharpness Model V2
Unknown revision; apply Sharpness Model V%lu
Apply Taboo Model V3 (%lu)
Apply Taboo Model V1 (%lu)
Unknown Taboo Model revision; apply default (%lu)
Apply default Taboo Model revision (%lu)
Apply NSFW Model V3 (%lu)
Apply NSFW Model V1 (%lu)
Unknown NSFW Model revision; apply default (%lu)
Apply default NSFW Model revision (%lu)
Apply SDG Model V3 (%lu)
Apply SDG Model V1 (%lu)
Unknown SDG Model revision; apply default (%lu)
Apply default SDG Model revision (%lu)
Unsupported PanoVNRequestMethod (%lu); using default (URL)
Supported options: 0 - URL, 1 - FullBuffer, 2 - ScaledBuffer
Failed to load PVSceneTaxonomySoft
Including Pre Analysis VNRequests (%lu): %@
VCPSceneAnalyzerReleaseCachedResources
Failed to create VNClassifyImageAestheticsRequest
Failed to create VNSceneClassificationRequest
Failed to create VNCreateSceneprintRequest
Failed to create VNClassifyJunkImageRequest
Failed to create VNGenerateAttentionBasedSaliencyImageRequest
Failed to set VNCreateSceneprintRequest::setPrivateRevision %lu: %@
Failed to set VNClassifyJunkImageRequest::setPrivateRevision %lu: %@
Failed to set %@::setPrivateRevision %lu: %@
Failed to create %@
Unsupported observation label %@
Defaults write %@ add Document Gating
Error creating VNRequest
VCPSceneAnalyzerImageRequestHandlerPerformRequest
Failed to run VNImageRequestHandler::performRequests: %@
[PreAnalysis] Document label - %@ (%f) %@
[PreAnalysis] Document failed - %@
VCPSceneAnalyzerImageBlurAnalysis
VCPSceneAnalyzerExposureAnalysis
VCPSceneAnalyzerLoadImageRequestHandler
Failed to load imageURL: %@
VCPSceneAnalyzerPerformAnalysis
Analysis Cancelled
SceneProcessingLoadAsset
SceneProcessingAnalyzeAsset
  [%@] Failed to decode last frame of video, fall back to thumbnail 
[MediaAnalysis] Junk analayzer - unexpected %d VNObservations
CNNHandsDetectorEspresso: adopting model config: %@
CNNHandsDetectorEspresso: updating model config to %@
inferenceHandDetectorCallFromSPI
Unknown Media Analysis version specified (%d)
[MediaAnalysis][%@] No slow-mo timestamp mapping file URL found
[MediaAnalysis][%@] No slow-mo timestamp mapping file found
[MediaAnalysis][%@] Resource required for slow-mo timestamp adjustment is not present
[MediaAnalysis][%@] Failed to load resource for slow-mo timestamp adjustment
  [%@] Unknown analysis version %d; discarding
Base retry interval override (%lu seconds)
[MediaAnalysisResultsTypesForAnalysisTypes] Unknown result type
Not all needed analysis are available for video highlights.
[%.2f - %.2f] expressionScore=%.2f, actionScore=%.2f, voiceScore=%.2f, Score=%.2f
[%.2f - %.2f] keyFrameScore=%.2f, expressionScore=%.2f, actionScore=%.2f, voiceScore=%.2f, humanActionScore=%.2f, humanPoseScore=%0.2f, Score=%.2f
Media analysis client XPC connection interrupted
Media analysis client XPC connection invalidated
[MediaAnalysis] [MediaAnalyzer requestAnalysisTypes] call with invalid resourceURLs
Failed to issue sandbox extension on %@
[MediaAnalysis] Error connecting to background analysis service
[MediaAnalysis] Request %d has completed
[MediaAnalysis] Error connecting to Photos background analysis service
[MediaAnalysis] Unsupported task %lu
[MediaAnalysis] Asset processing request %d has completed
Failed to open Photo Library at %@
[MediaAnalysis] Error connecting to Photos Quick Face Identification service
[MediaAnalysis] Request %d is %.2f%% complete
[MediaAnalysis] Unknown analysis request %d; dropping cancellation request
[MediaAnalysis] No active analysis requests; dropping cancellation request
[MediaAnalysis] Failed to cancel background analysis: %@
[MediaAnalysis] Background analysis canceled
[MediaAnalysis] Error connecting to background analysis service: %@
[MediaAnalysis] Error connecting to request PersonPromoterStatus service
[MediaAnalysis] Request Person Preference %d has completed
[MediaAnalysis] Request VIP model filepath Preference %d has completed
[MediaAnalysis] Error connecting to request SuggestedPersons service
[MediaAnalysis] Request SuggestedPersons %d has completed
[MediaAnalysis] Error connecting to request UpdateKeyFacesOfPersons service
[MediaAnalysis] Request UpdateKeyFacesOfPersons %d has completed
[MediaAnalysis] Error connecting to request FaceCandidatesforKeyFace service
[MediaAnalysis] Request FaceCandidatesforKeyFace %d has completed
[MediaAnalysis] Error connecting to request ResetFaceClassificationModel service
[MediaAnalysis] Request ResetFaceClassificationModel %d has completed
[MediaAnalysis] Error connecting to request SuggestedMePersonIdentifier service
[MediaAnalysis] Request SuggestedMePersonIdentifier %d has completed
[MediaAnalysis] Request PersonPromoterStatus %d has completed
[MediaAnalysis] Error connecting to request ClusterCacheValidation service
[MediaAnalysis] Request ClusterCacheValidation %d has completed
[MediaAnalysis] Error connecting to request ResetFaceClusteringState service
[MediaAnalysis] Request ResetFaceClusteringState %d has completed
[MediaAnalysis] Error connecting to request ReclusterFaces service
[MediaAnalysis] Request ReclusterFaces %d has completed
[MediaAnalysis] Error connecting to request RebuildPersons service
[MediaAnalysis] Request RebuildPersons %d has completed
[MediaAnalysis] failed to get database sandbox extension
[MediaAnalysis] failed to consume sandbox extension
[MediaAnalysis] Consumed sandbox extension
[MediaAnalysis][%@] Storing on-demand analysis
[MediaAnalysis][%@] Failed to store on-demand analysis
[MediaAnalysis][%@]Unable to open movie
[MediaAnalysis][%@]Failed to create asset
[MediaAnalysis][%@] Received analysis request: %@
[MediaAnalysis][%@] Analysis requested for blacklisted asset
[MediaAnalysis][%@] Existing analysis based on old modification
[MediaAnalysis][%@] Existing analysis based on degraded asset
[MediaAnalysis][%@] Existing analysis satisfies request (%@)
[MediaAnalysis][%@] Existing analysis doesn't match asset state
[MediaAnalysis][%@] Existing analysis doesn't satisfy request (%@)
[MediaAnalysis][%@] Generating analysis on-demand: %@
[MediaAnalysis][%@] Analysis served: (%@)
[MediaAnalysis] [MediaAnalyzer requestAnalysisForAsset] call from invalid instance
[MediaAnalysis] Failed to obtain database for Photo Library %@
[MediaAnalysis] [MediaAnalyzer assetsAnalyzedSinceDate] call from invalid instance
[MediaAnalysis] Failed to obtain database for Photo Library (%@)
Cannot load %@ for %@, NSData length: %lu, content: %@
Cannot load %@ from PHAsset, NSData length: %lu, content: %@
[MediaAnalysis] [MediaAnalyzer distanceFromAsset] call from invalid instance
[MediaAnalysis] Failed to obtain database for assets
[MediaAnalysis] failed to request analyses
[MediaAnalysis] [requestAnalysesForAssets] call from invalid instance
[MediaAnalysis] [requestAnalysesForAssets] in standalone mode but on-demand not allowed
[MediaAnalysis] call from invalid instance
[MediaAnalysis] on-demand analysis requested in standalone mode
Warning: On demand analysis is not supported.
[MediaAnalysis] Failed to obtain database for collection %@
Warning: No face specified.
[MediaAnalysis] [requestLivePhotoEffectsForAssets] call from invalid instance
[MediaAnalysis] [requestLivePhotoEffectsForAssets] in standalone mode but on-demand not allowed
  [%@] Existing analysis outdated; dropping
VCPLightVideoAnalyzer
VCPVideoStabilizerPixel
VCPVideoFaceDetector
VCPFullVideoAnalyzer
VCPVideoSceneClassifier
VCPVideoActivityAnalyzer
VCPVideoSaliencyAnalyzer
VCPVideoHumanActionAnalyzer
VCPVideoHumanActionClassifier
VCPVideoPetsAnalyzer
VCPMovieCurationAnalyzer
VCPVideoStabilizer
VCPVideoInterpolator
    Analyzing Video Segment - Track ID: %d Start: %lld/%d (%0.3fs) End: %lld/%d (%0.3fs)
VCPAudioAnalyzer
    Video track has invalid full frame dimensions (%.f,%.f)
    Video track has invalid clean aperture rect
VCPVideoStabilizerGyro
  [%@] Asset doesn't have gyro metadata
    Video track has invalid dimensions (%.f,%.f)
VCPMovieAnalyzer
Face analysis - skip using PHFace from PHAsset
Face analysis - use PHFace expression from PHAsset
Face analysis - PHFace expression can only be used with PHFace
  [%@] Need Face Processing: no faceAdjustmentVersion
  [%@] Need Face Processing: faceAdjustmentVersion %@ != adjustmentTimestamp %@
  [%@] Fingerprint requested for asset with no objectID
  [%@] Fingerprinting failed
QuickFaceID Model: persistent storageDirectoryURL is nil; skip loading FaceID Model
QuickFaceID Model: cannot load FaceID Model: %@
QuickFaceID Model: model loaded in %.5f seconds
 [%@] QuickFaceID: no local resource
 [%@] QuickFaceID: failed to load image
 [%@] QuickFaceID: failed to analyze asset (%d)
 [%@] QuickFaceID: image too small to classify
 [%@] QuickFaceID: %lu faces detected in %.5f seconds; %.5f second per face
 [%@] QuickFaceID: classifying face: %@; skip processing face
 [%@] QuickFaceID: did not find a matching person for face located at (%.3f, %.3f)
 [%@] QuickFaceID: found person: %@
 [%@] QuickFaceID: %lu faces classified in %.5f seconds; %.5f second per face
 [%@] QuickFaceID: expected to find a person for person uuid = %@; skipping
 [%@] QuickFaceID: failed to persist classification results: %@
Quick Face ID failed to load persons model
 [%@] QuickFaceID: analyzing asset (deferType: %d)
 [%@] QuickFaceID: asset is not image
 [%@] QuickFaceID: processed %lu faces
QuickFaceID Model: Last job generation %.0fs ago, job is due = %d
QuickFaceID Model: Begin model generation
QuickFaceID Model: Model generation cancelled. Quitting
FaceID Model: fetch count for person %@: %lu
FaceID Model: fetch count without roll predicate for person %@: %lu
QuickFaceID Model: Could not create faceprint for face: %@. Error: %@
QuickFaceID Model: Could not add faceprint to model for face: %@.
QuickFaceID Model: Could not add faceprints to model. Error: %@
QuickFaceID Model: Finished model generation
QuickFaceID Model: Failed to persist model %@
QuickFaceID Model: Could not get face observations for person %@ - %@
QuickFaceID Model: Could not persist isInVIPModel on trained faces - %@
QuickFaceID Model: Finished model generation and persistence
QuickFaceID Model: No need to generate model
[%@] Asset has no small video derivative; skipping
[%@] File size exceeds streaming threshold; skipping
[%@] Duration exceeds streaming threshold; skipping
Unknown VCPTaskID (%lu); redirect to VCPTaskID_MediaAnalysis
  Analyzing degraded version of Movie
  [%@] missing Pre Analysis result
  Analyzing degraded version of Photo
VCPImageFaceDetector
VCPImageFaceExpressionAnalyzer
VCPImageJunkAnalyzer
VCPImageBlurAnalyzer
VCPLowResImageBlurAnalyzer
VCPImageExposureAnalyzer
VCPImageLivePhotoBlurAnalyzer
VCPImageCompositionAnalyzer
VCPImageDescriptor
VCPImageSaliencyAnalyzer
VCPImagePetsAnalyzer
VCPImageHumanPoseAnalyzer
VCPImageHandsAnalyzer
VCPLivePhotoAnalysis
VCPEffectsAnalyzer
[MediaAnalysis] PhotoAnalyzer - Original movie is not available, skip effects analysis
VCPLivePhotoKeyFrameAnalyzer
VCPPhotoAnalyzer
Face Processing storage directory: %@
No persistentStorageDirectoryURL for photoLibrary: %@
Unable to serialize library analysis preferences for %@: %@
Unable to write library analysis preferences for %@: %@
Key for setLibraryAnalysisPreferencesValue is nil
[MediaAnalysis] Sceneprint data - skip fetching from PHAsset
Error -[VNCreateSceneprintRequest setPrivateRevision:error:]
Error -[VNImageRequestHandler requestHandler:error:]
NSKeyedUnarchiver error: %@
Processing service no longer available; dropping results
[%@] Pre-warming XPC connection
[%@] Client XPC connection interrupted
[%@] Client XPC connection invalidated
NSXPCConnection_init
[%@] Error connecting to analysis service
[%@] Failed to find request with identifier %lu
Failed generate sandbox extension for %@ (%@)
[%@] Failed to find request with identifier %lu; dropping results
[%@] Request with identifier %lu does not contain asset with URL %@; dropping results
VCPVoiceOverAssetProcessingTask: missing processingTypes
VCPVoiceOverAssetProcessingTask: pixelBuffer is nil
VCPVoiceOverAssetProcessingTask: completionHandler is nil
VCPVoiceOverAssetProcessingTask: invalid processingTypes
VCPVoiceOverAssetProcessingTask: analyze face error: %@
VCPVoiceOverAssetProcessingTask: analyze scene error: %@
 VCPFaceShapeModel - caught exception in find_min_box_constrained()
VCPFaceShapeModel - caught exception in find_min()
 VCPFaceShapeModel - caught exception in find_min_using_approximate_derivatives()
Fail to initialize motionFlowAnalyzer
Fail in generating motion flow
Motion flow is null
Invalid VNRequest configuration (%@)
VNRequest must be non-nil
VCPFaceGeometry initWithCoder - vertices data missing
VCPFaceAnchor initWithCoder - unexpected size of transform data
VCPCaptureAnalysis - missing resolution properties for prewarming
Failed to open analysis database for Photo Library (%@)
Specified Photo Library has no URL (<%@>); cannot find analysis database
[DAS QoS] %@: %@ (%@) download %lu bytes
Requested resource exceeds maximum supported size
Resource already in the buffer. Skip downloading.
requestDownloadOfResource: %@
Download progress: %.2f
    Received %llu bytes (Overall: %llu/%llu)
Data received exceeds maximum supported size
Failed to download asset resource (%@)
Successfully downloaded asset resource
Failed to issue resource request
Download resource timed-out
Cancelling download
No faceprint is decoded from PHFace.
  [%@] Processing
[MediaAnalysis][%@]Unable to open movie, skip
  [%@] Analysis cancelled
  [%@] Analysis failed to complete
Failed to create media analysis directory
Successfully loaded FaceTime persistent store
Failed to load FaceTime persistent store
Failed to fetch all FaceTime sessions
Storing FaceTime Session
Cannot create VCPPersonBuilder
---> Canceling VCPBuildPersons
VCPBuildPersons canceled
VCPBuildPersons failed: %@
Cannot create PVPersonPromoter
---> Canceling VCPPromotePersons
Person Processing: Starting Person Promoting
Person Processing: Person Promoting %@
VCPPromotePersons canceled
VCPPromotePersons failed
HomeKit analysis client XPC connection interrupted
HomeKit analysis client XPC connection invalidated
[HomeKitAnalysis] Error connecting to background analysis service
[HomeKitAnalysis] Request %d is %.2f%% complete
[HomeKitAnalysis] Unknown analysis request %d; dropping cancellation request
[HomeKitAnalysis] No active analysis requests; dropping cancellation request
  Fullfilled content request: %@
  Fullfilled data request: %@
Reachability initialization failed; assuming no connection
Reachability flags invalid; assuming no connection
%sonnected to internet via WiFi/Ethernet
Network reachability flag changed to: %@
Generated faceCropData is nil
faceCropSourceDescriptors is 0
 [%@] facesToPersist: %lu | facesToDelete: %lu
 [%@] Publish facecrop %@ 
Failed to generate faceprint from facecrop %@ - %@
Failed to persist association of face %@ with facecrop %@ - %@
Failed to fetch just-persisted face with local identifier '%@', error: %@
failed to generate faceprint from facecrop %@ - %@
failed to update faceprint of face %@ associated with facecrop %@ - %@
PersonBuilder: Set personBuilderState of faceGroup: %@
Analyzing facecrop: %@
Facecrop %@ is not in a dirty state
Facecrop %@ does not have a payload (image data)
_updateFace failed for facecrop %@: %@
_recordNeedToPersonBuildOnFaceGroupContainingFace failed for facecrop %@: %@
  [%@] No faces detected; skip facecrop generation
 [%@] Facecrop will not be generated for the manual face %@
Library: %lu dirty face crops to analyze
Failed processing dirty facecrop %@ - %@
VCPFaceProcessingDirtyFaceCrops
[Perf] %s: %0.6fs
%-40s  %10s  %10s  %10s  %10s  %10s
  %-38s  %10.6f  %10.6f  %10.6f  %10.6f  %10zu
  [%@] No scene classification result fetched from pre analysis
Scene identifier %u has no name; ignoring
[%@] Asset has no small video derivative; cannot download
VCPPriorityAnalysis - Start initializing
VCPPriorityAnalysis - Finished initializing hand detector
VCPPriorityAnalysis - Finished initializing hand keypoint detector
VCPPriorityAnalysis - Finished initializing gesture recognizer
VCPPriorityAnalysis - Number of hand detected %lu
VCPPriorityAnalysis - Face/Hand IoU: %f, handToFaceRatio: %f
VCPPriorityAnalysis - gestureScore pre-thresholding: %f
VCPPriorityAnalysis - maxKeypointMotionScore: %f
VCPPriorityAnalysis - minMotionScore over time: %f
VCPPriorityAnalysis - pooledIOU over time: %f
VCPPriorityAnalysis - gesture score = %f, priority score after thresholding = %f
VCPPriorityAnalysis - Analysis subsampling ratio = %f
VCPPriorityAnalysis - output priority score = %f
song analysis failed %@
VoiceOver analysis client XPC connection interrupted
VoiceOver analysis client XPC connection invalidated
Pixel buffer not IOSurface-backed; dropping analysis request
[VoiceOverAnalysis] Error connecting to Photos background analysis service
[VoiceOverAnalysis] Asset processing request %d has completed
VCPEmbeddingAnalyzerLoadImageRequestHandler
VCPNeuralHashprintRequest
NeuralHashprint Vision request failed: %lu - %@
VCPImageHashSignatureRequest
NeuralHash+LSH Vision request failed: %lu - %@
NeuralHash+LSH invalid imageSignatureHash
NeuralHash+LSH failed to encode hash: %@
Invalid NeuralHash+LSH (=)
%@: %c%c%c%c-%c%c%c%c-%c%c%c%c-%c%c%c%c
VCPObjectPool failed to allocate object
ImageHandAnalyzer: input image aspectRatio = %f
ImageHandAnalyzer: aspectRatio = %@, queryAspectRatioVal = %@
ImageHandAnalyzer: feasibleShapeIndex = %d
ImageHandAnalyzer: detectorHeight = %d, detectorWidth = %d
Running Home Resident Maintenance task
Canceling Home Resident Maintenance task (%d)
HomeAI request submitted (%d)
[HomeKit] Failed to connect to analysis service (%@)
[HomeKit] VCPHomeKitAnalysisSession initialization fails (%@)
[HomeKit] Client XPC connection interrupted
[HomeKit] Client XPC connection invalidated
[HomeKit] Error connecting to background analysis service
copyImageToBGRHandDetectorCallFromSPI
scalerHandDetectorCallFromSPI
Restore clusterer error (ClusterState = %ld): %@
Restored clusterer, ClusterState = %ld
UpdateKeyFaces for: '%@'
could not update key faces for suggestions: %@
Loaded clustererState: %ld
Returning no suggestions because the clusterer is working
suggestions first phase query start
suggestions first phase query end
suggestions middle phase query start (includes face groups for person query)
suggestions middle phase query end
suggestions last phase query start
suggestions last phase query end
Getting suggestions for person: '%@', numberOfToBeConfirmedPersonSuggestions: %lu, numberOfToBeRejectedPersonSuggestions: %lu
Got %lu suggestions for person: '%@', numberOfToBeConfirmedPersonSuggestions: %lu, numberOfToBeConfirmedPersonSuggestions: %lu
Input parameter is empty or nil: '%@'
FaceID Model: Error could not remove person model at %@: %@
Person Processing: Starting Deleting Persons
VCPFaceProcessingDeleteAllVerifiedPersons
Person Processing: Deleting Persons %@
Person Processing: Starting Face Reclustering
VCPFaceProcessingReclusterFacesWithThreshold
Person Processing: Face Clustering %@
Person Processing: Starting Person Building
VCPFaceProcessingBuildPersons
Person Processing: Person Building %@
Person Processing: Starting Person Promotion
VCPFaceProcessingPromotePersons
Person Processing: Person Promotion %@
Attempt to download resource: %@
Choosing asset resource from preferred list: %@
Network is available, filtering list to remove the CPL Thumb, new list is: %@
No resources locally available, returning a downloadable hi-res resource: %@
Error resetting all FaceGroups Person Builder state: %@
Failed to clean up merge candidates. Error: %@
VCPFaceProcessingCleanupMergeCandidates
->->-> Enabling personBuilderMergeCandidates
Warning: Could not update the key faces of some merge candidates %@
Sceneprint task failed (%@)
Did cluster: %s
Reset restore clusterer error (ClusterState = %ld): %@
Reset restored clusterer, ClusterState = %ld
Person Processing: Starting Reset Face Clustering
VCPFaceProcessingResetFaceClusteringState
Person Processing: Reset Face Clustering Done
Person Processing: Starting Face Clustering
VCPFaceProcessingPerformFaceClusteringAndWait
Person Processing: Face Clustering Done
VCPFaceProcessingClusterFacesWithExtendTimeoutBlock
---> Start face cluster (%ld) with clustering status: %@
---> Finished face cluster (%ld) with clustering status: %@
---> Canceling face cluster
VCPFaceProcessingClusterFaces
VCPFaceProcessingClusterFacesIfNecessary
Real-time analysis client XPC connection interrupted
Real-time analysis client XPC connection invalidated
Real-time analysis client XPC connection error
VCPSceneTaxonomy - Failed to load PVSceneTaxonomy
VCPSceneTaxonomy - cannot find scene name for id %d
VCPSceneTaxonomy - cannot find scene id for scene name %@
Removing existing file at path %@
Failed to remove existing file at path %@ (%@)
Failed to create asset writer (%@)
Failed to create asset writer input
Failed to start asset writer
Pixel buffers are not IOSurface-backed; copying
VCPLandmarkValidator failed to validate image (%d)
Failed to align face bbox: aligner returned an empty rectange
Failed to align face bbox for faces in image, error: %@
Cannot Merge: %s faceprint, candidateFaceVersion: %u, contextVersion:%u
Cannot Merge: faceprintDistance (%f) < faceprintThreshold (%f)
Cannot Merge: could not get distance between queryFace: '%@' and candidateFace: '%@', error: '%@'
Existing Face: %@, %ldx%ld, %d, (%f, %f, %f), %@
Detected Face: %@, %ldx%ld, %d, (%f, %f, %f), %@
Cannot Merge in final stage: [mutableDetectedFaces containsObject:detectedFace] %d [facesToDelete containsObject:matchedExistingFace] %d
%lu Face(s) merged based on faceprints: %@
%lu Face(s) merged based on geometries (before): %@
%lu Face(s) merged based on geometries (filtered): %@
inferenceHandKeypointCallFromSPI
time=%.2f sharpness=%.2f, faceSharpness=%.2f, cameraM=%.2f, subjectM=%.2f, junk=%.2f, obstr=%.2f, exposure=%.2f, score=%.2f
VCPVideoKeyFrameBlurAnalyzer
VCPVideoKeyFrameFaceQualityAnalyzer
[MediaAnalysis] [VCPVideoMetaAnalyzer] Unknown analysis type %@
  Extreme aspect ratio %f; initialization failed
[MediaAnalysis] Sample at %lld/%d is being extended %0.1fx
Failed to serialize %@ (%@)
pixel format (%d) is not supported
Failed to get chroma subsampling shift
Header is larger than offset to plane %d
VCPRateControlSession: codec type '%c%c%c%c' is not supported
VCPRateControlSession: codec type '%c%c%c%c' is not supported on x86
Failed to create VCPRateControlSession
Failed to create private storage
Failed to initialize VCPRateControlSession
%s: Hardware encoder is not available
%s: Low latency RC mode requires hardware encoder
%s: encoder id is not supported
%s: VCPRateControlSession is created, use_hw: %d
CFDictionaryCreate failed
%s: %@ property = %@
%s: RC session is invalid
%s: empty image buffer
Failed to allocate sequence enc
%s: ParseCompressParams failed
%s: Encoder initialization failed
%s: Failed to initialize sequence
Baselayer framerate fraction should be either 0.5 or 1
%s: Failed to allocate source frame
%s: Failed to allocate frame info
%s: Failed to push frame
Invalid rate control session
%s: Invalid frame info
empty sequence
Profile argument not a string
Unsupported profile %s
Source image buffer attributes contain pixel format %d
CFArrayCreate (CreateProfileLevelDict) failed!
CFDictionaryCreate (CreateProfileLevelDict) failed!
CFDictionaryCreate failed
(key '%s'): bad
bad (key '%s') (out of range)
unsupported CFTypeID for SetCommonProperty()
unsupported CFTypeID for CopyCommonProperty()
unrecognised property key
%zu planes not supported
Offset is outside frame dimensions
Failed to get textures
Unable to get metal device
Initializing for GPU %llx
Unable to get command queue
Unable to get metal library for bundle %@ error: %@
No transition detection kernel
Unable to initialize metal session
pixfmt mismatch!
ReplaceBlockBufferInSampleBuffer failed
no sample attachment found
error in ComputeDirtyTiles
Frame dropped by encoder
POC %d:
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/ShazamKit.framework/ShazamKit
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/HomeAI.framework/HomeAI
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
softlink:r:path:/System/Library/PrivateFrameworks/PhotoVision.framework/PhotoVision
softlink:r:path:/System/Library/PrivateFrameworks/PhotosGraph.framework/PhotosGraph
VCPAudioAnalyzer
VCPSoundDetector
SNResultsObserving
NSObject
VCPAudioClassifier
VCPVideoStabilizer
VCPImageHumanPoseAnalyzer
CMTimerange
VCPSlowmo
VCPProtoLivePhotoKeyFrameResult
NSCopying
VCPBlurAnalyzer
VCPBoundingBox
LegacyConversion
VCPProtoResultLegacyConversionProtocol
VCPProtoMovieBabbleResult
VCPCNNBlock
VCPCNNBlurAnalyzer
VCPCNNBlurAnalyzerEspresso
VCPCNNBlurAnalyzerMPS
VCPCNNConvBlock
VCPCNNConvBlockGPU
VCPCNNConvBlockScalar
VCPCNNConvBlockVector
VCPCNNData
VCPCNNDataGPU
VCPCNNEspressoContext
VCPCNNFaceLandmarkDetector
VCPCNNFaceLandmarkDetectorEspresso
VCPCNNFaceLandmarkDetectorMPS
VCPCNNFlattenBlock
VCPCNNFullConnectionBlock
VCPCNNFullConnectionBlockGPU
VCPCNNFullConnectionBlockScalar
VCPCNNGazeAnalysis
VCPVideoGyroStabilizer
VCPCNNHandKeypointsDetector
VCPCNNMetalContext
VCPHumanPoseVideoRequest
VCPCNNModel
VCPCNNModelEspresso
VCPCNNPetsDetector
VCPProtoMovieApplauseResult
VCPCNNPetsDetectorEspresso
VCPCNNPoolingBlock
VCPCNNPoolingBlockGPU
VCPCNNPoolingBlockScalar
VCPVideoProcessor
PVPersonProtocol
VCPCNNPoolingBlockVector
VCPCNNPoseEstimator
VCPVideoProcessorSession
VCPCNNPoseEstimatorEspresso
VCPProtoLivePhotoKeyFrameFaceResult
VCPCNNPoseEstimatorMPS
VCPCNNSmileDetector
VCPCNNSmileDetectorEspresso
VCPCNNSmileDetectorMPS
VCPDatabaseBatchIterator
VCPDatabaseReader
VCPHuman
VCPDeviceInformation
VCPProtoMovieStabilizationResult
VCPProtoMovieHumanActionResult
VCPEdgeDetector
VCPEffectsAnalyzer
VCPImageExposurePreAnalyzer
VCPTimer
VCPExifAnalyzer
VCPFace
VCPFaceDetectionRange
VCPTimeMeasurement
VCPEvent
NSSecureCoding
NSCoding
VCPVisualIntelligenceAnalysisService
VCPHomeFaceIdentificationTask
PVPhotoLibraryProtocol
VCPFingerprint
VCPFaceAnalyzer
VCPFrameScoreFilter
FullAnalysis
VCPProtoLivePhotoKeyFrameStillResult
VCPProtoImageSceneprintResult
VCPFullVideoAnalyzer
VCPGaborFilter
VCPHoughTransform
VCPCNNPersonKeypointsDetector
VCPImageAnalyzer
VCPImageBlurAnalyzer
VCPMABaseTask
VCPMADTaskProtocol
VCPImageCompositionAnalyzer
VCPImageConverter
VCPImageDescriptor
VCPDistanceDescriptorProtocol
VCPImageExposureAnalyzer
VCPAnalysisProgressQuery
VCPImageFaceDetector
VCPImageFaceExpressionAnalyzer
VCPVideoStabilizationAssetProcessingTask
VCPImageFaceQualityAnalyzer
VCPImageLivePhotoBlurAnalyzer
VCPPhotosQuickFaceIdentificationLibraryProcessingTask
VCPKeypoint
VCPPersonObservation
VCPHandObservation
VCPImageManager
VCPProtoMovieHumanPoseResult
PFPhotosFaceRepresentation
VCPPhotosPersistenceDelegateAdditions
MediaAnalysis
VCPMergeCandidatePair
VCPPhotosPersistenceDelegate
PVPersistenceDelegate
PVPersonPromoterDelegate
VCPCNNPersonDetector
VCPImagePetsAnalyzer
VCPImageQualityAnalyzer
VCPImageSaliencyAnalyzer
VCPImageSaliencyAnalyzerFull
VCPImageSaliencyAnalyzerFullEspresso
VCPSceneProcessingImageManager
VCPPreAnalyzer
VCPInterAssetAnalyzer
VCPShareSheetAssetProcessingTask
VCPMAImageProcessingTaskProtocol
VCPJunkAnalyzer
VCPLandmarkValidator
VCPLightMotionAnalyzer
VCPLightVideoAnalyzer
VCPLogManager
VCPCNNHandsDetectorEspresso
VCPMovieCurationAnalyzer
VCPVideoKeyFrameResult
VCPMovieHighlightResult
VCPMovieCurationResults
VCPMovieHighlight
VCPExpressionSegment
VCPMovieHighlightAnalyzer
VCPMediaAnalysisServerProtocol
VCPMediaAnalysisClientProtocol
VCPMediaAnalysisService
FaceSuggestions
PersonBuilderAndPromoter
InternalTools
VCPStorageServiceProtocol
VCPMediaAnalyzer
VCPMetaSegment
VCPMAEmbeddingEntry
VCPMetaTrackDecoder
PVFaceProtocol
VCPMovieAnalyzer
VCPProtoImageHumanPoseResult
PVFetchResultProtocol
NSFastEnumeration
PHAssetResource
VCPMediaAnalysis
Exif
MediaAnalysisResults
MediaAnalysisPauseResume
VCPLivePhotoKeyFrameAnalyzer
VCPPHFaces
VCPPhotosQuickFaceIdentificationManager
MediaAnalysisPhoto
MediaAnalysisMovie
MediaAnalysisSceneProcessing
MovieResource
VCPPhotoAnalyzer
VCPPnPSolver
VCPSceneprintDescriptor
VCPSceneChangeAnalyzer
VCPSceneChangeSegment
VCPVideoPixelStabilizer
VCPTaskProcessingBatchRequestState
VCPTaskProcessingServiceProxy
VCPTaskProcessingClientProtocol
VCPTaskProcessingServerProtocol
VCPTaskProcessingService
VCPVoiceOverAssetProcessingTask
VCPFaceShapeModel
VCPMotionFlowSubtleMotionAnalyzer
VCPVideoProcessorNode
VCPFaceTensorModel
VCPVanishingPointDetector
VCPActionAnalyzer
CoreDataProperties
VCPAsset
Image
LivePhoto
Movie
VCPFaceGeometry
VCPFaceAnchor
VCPCaptureAnalysisSession
VCPClientDatabaseManager
VCPContentAnalysis
VCPDefaultPhotoLibraryManager
VCPDownloadManager
VCPVoteStats
VCPFaceRecognitionTask
VCPFullAnalysisURLProcessingTask
VCPFaceTimeFace
VCPProcessingStatusEntry
VCPCNNFastGestureRecognition
NSManagedObject
VCPProtoMovieSceneprintResult
VCPFaceTimePersistentStore
VCPFaceTimeSession
VCPProtoMoviePetsResult
VCPFrameAnalysisStats
VCPHomeKitAnalysisServerProtocol
VCPHomeKitAnalysisClientProtocol
VCPHomeKitAnalysisService
Client
Resident
VCPInMemoryAVAsset
AVAssetResourceLoaderDelegate
VCPInternetReachability
VCPGeneralCanceller
VCPFaceCropSourceDescriptor
VCPFaceCropGenerator
VCPFaceCropManager
VCPPhotosAsset
VCPPriorityAnalysis
VCPProtoAssetAnalysis
VCPProtoBounds
CGRect
VCPImageMotionFlowAnalyzer
VCPSongDetector
VCPProtoClassification
VCPProtoImageBlurResult
VCPProtoImageCompositionResult
VCPProtoImageExposureResult
VCPLoudnessAnalyzer
VCPProtoImageFaceResult
VCPProtoImageFeatureResult
VCPProtoImageJunkResult
VCPProtoImagePetsFaceResult
VCPVoiceOverServerProtocol
VCPVoiceOverClientProtocol
VCPVoiceOverService
VCPProtoMovieLaughterResult
VCPProtoImagePetsResult
VCPHandPoseVideoRequest
VCPMAEmbeddingAnalyzer
VCPLoaned
VCPObjectPool
VCPProtoImageSaliencyResult
VCPProtoImageShotTypeResult
VCPProtoLine
VCPProtoMovieCheeringResult
CGPoint
VCPProtoLivePhotoEffectsRecipe
VCPProtoLivePhotoEffectsResult
VCPHumanPoseImageRequest
VCPProtoLivePhotoFrameInstruction
VCPProtoLivePhotoRecommendationResult
VCPProtoLivePhotoSharpnessResult
VCPImageHandsAnalyzer
VCPHomeResidentMaintenanceTask
VCPProtoLivePhotoVariationParams
VCPProtoMovieActivityLevelResult
VCPProtoMovieCameraMotionResult
VCPHomeKitAnalysisSessionServerProtocol
VCPHomeKitAnalysisSessionClientProtocol
VCPHomeKitAnalysisSession
VCPHomeKitSessionExportedObject
VCPHomeKitMotionAnalyzer
VCPProtoMovieClassificationResult
VCPHandPoseImageRequest
VCPProtoMovieFaceprintResult
VCPRequest
VCPProtoMovieFaceResult
VCPProtoMovieFeatureResult
PVAssetProtocol
VCPProtoMovieFineSubjectMotionResult
VCPProtoMovieHighlightResult
VCPProtoMovieInterestingnessResult
PVMomentProtocol
VCPImageHumanPoseAnalyzerTopDown
VCPProtoMovieLoudnessResult
VCPProtoMovieMovingObjectResult
VCPProtoMovieMusicResult
VCPProtoMovieObstructionResult
VCPCNNHandsDetector
VCPFaceProcessingServiceWorker
VCPFaceUtils
VCPFaceVisionIntegrating
PVVisionIntegrating
VCPPersonBuilder
VCPVideoHumanActionAnalyzer
VCPPhotosSceneprintAssetProcessingTask
VCPProtoMovieOrientationResult
VCPVideoInterpolator
VCPProtoMoviePreEncodeResult
VCPProtoMovieQualityResult
VCPProtoMovieSaliencyResult
VCPProtoMovieSceneResult
VCPProtoMovieSubjectMotionResult
VCPFaceClusterer
PVFaceGroupProtocol
VCPProtoMovieSummaryResult
VCPProtoMovieUtteranceResult
VCPProtoMovieVoiceResult
VCPProtoPoint
VCPProtoMoviePetsFaceResult
VCPProtoTime
CMTime
VCPProtoTimeRange
CMTimeRange
VCPProtoVideoKeyFrame
VCPCallerIdentificationResult
VCPRealTimeAnalysisServerProtocol
VCPRealTimeAnalysisClientProtocol
VCPRealTimeAnalysisService
VCPRTLandmarkDetector
VCPProtoMovieStabilizationRecipe
VCPSceneTaxonomy
VCPSegment
VCPMovieAssetWriter
VCPSharedInstanceManager
VCPTrimAnalyzer
VCPURLAsset
VCPVideoChatAnalysis
VCPVideoActivityAnalyzer
VCPCompactResult
VCPVideoActivityDescriptor
VCPVideoHumanActionClassifier
VCPProtoMovieSubtleMotionResult
VCPVideoAnalyzer
VCPVideoFaceDetector
VCPVideoFaceMeshAnalyzer
bRVA
VCPFacePair
VCPFaceMerger
VCPPetsRegion
VCPVideoPetsAnalyzer
VCPVideoFacePoseAnalyzer
VCPVideoFacePoseFilter
BackwardCompatability
VCPVideoFullFaceDetector
VCPCNNHandKeypointsDetectorEspresso
VCPVideoGlobalAnalyzer
VCPVideoKeyFrame
VCPVideoKeyFrameAnalyzer
VCPVideoLightFaceDetector
VCPVideoMetaAnalyzer
VCPVideoMetaFaceAnalyzer
VCPVideoMetaFocusAnalyzer
VCPVideoMetaFocusSegment
VCPVideoMetaLensSwitchAnalyzer
VCPVideoMetaLivePhotoMetaAnalyzer
VCPVideoMetaMotionAnalyzer
VCPVideoMetaMotionSegment
VCPVideMetaOrientationAnalyzer
VCPVideoObjectTracker
VCPSaliencyRegion
VCPVideoSaliencyAnalyzer
VCPClassification
VCPVideoSceneClassifier
VCPVideoTrackDecoder
VCPVideoTrackStandardDecoder
VCPVideoTrackSubsamplingDecoder
VCPVideoTrackSyncDecoder
VCPVoiceDetector
VCPVoiceDetectorV2
Face
VCPCtrTracker
VCPBaseTracker
VCPSideCarMetal
init
detector
initWithTypes:
dealloc
dictionaryWithObjects:forKeys:count:
setupWithSample:andSampleBatchSize:
processAudioSamples:timestamp:
finalizeAnalysisAtTime:
dictionary
vcp_enabledTracksWithMediaType:
countByEnumeratingWithState:objects:count:
timeRange
trackID
initWithAsset:error:
audioFormatRequirements
assetReaderTrackOutputWithTrack:outputSettings:
addOutput:
startReading
copyNextSampleBuffer
setupWithSample:
processSampleBuffer:
status
results
addEntriesFromDictionary:
voiceDetections
initWithAnalysisTypes:forStreaming:
analyzeAsset:cancel:results:
analyzeSampleBuffer:
.cxx_destruct
_inputBuffer
_audioTimestamp
_audioBufferList
_sampleBatchSize
_voiceDetector
_audioClassifier
_loudnessAnalyzer
_songDetector
_bufferedSamples
_initialized
array
objectForKey:
numberWithFloat:
addObject:
confidence
addDetectionFromTime:toTime:confidence:
isEqual:
class
self
performSelector:
performSelector:withObject:
performSelector:withObject:withObject:
isProxy
isKindOfClass:
isMemberOfClass:
conformsToProtocol:
respondsToSelector:
retain
release
autorelease
retainCount
zone
hash
superclass
description
debugDescription
TQ,R
T#,R
T@"NSString",R,C
request:didProduceResult:
request:didFailWithError:
requestDidComplete:
initWithTrackStart:threshold:resultsKey:
_results
_activeStart
_activeEnd
_length
_sampleRate
_trackStart
_activeConfidence
_threshold
_minDetections
_resultsKey
initStandardFormatWithSampleRate:channels:
initWithFormat:
initWithPCMFormat:frameCapacity:
setFrameLength:
arrayWithObjects:count:
initWithSoundIdentifier:
objectForKeyedSubscript:
floatValue
addRequest:withObserver:error:
frameLength
mutableAudioBufferList
analyzeAudioBuffer:atAudioFramePosition:
_analysisTypes
_SNAnalyzer
_pcmBuffer
_framePosition
_detectors
saveStabilizationRecipe
resultFromLegacyDictionary:
correctionResultRef
setCorrectionResultRef:
setResults:
cropFraction
setCropFraction:
motionBlurVector
setMotionBlurVector:
gyroStabilization
validStabilization
_gyroStabilization
_validStabilization
_cropFraction
_analysisConfidence
_analysisResultRef
_correctionResultRef
_motionBlurVector
T^v,N,V_analysisResultRef
T^v,N,V_correctionResultRef
T@"NSDictionary",&,N,V_results
Tf,N,V_cropFraction
T@"NSMutableArray",&,N,V_motionBlurVector
TB,N,V_gyroStabilization
Tf,N,V_analysisConfidence
TB,N,V_validStabilization
vcp_isShortMovie
standardUserDefaults
persistentDomainForName:
boolValue
vcp_mediaAnalysisBundle
resourceURL
URLWithString:relativeToURL:
configForAspectRatio:
sharedModel:
numberWithBool:
initWithParameters:inputNames:outputNames:properties:
createModelWithHeight:srcWidth:
sharedManager
sharedInstanceWithIdentifier:andCreationBlock:
outputBlob
objectAtIndexedSubscript:
setObject:atIndexedSubscript:
numberWithInt:
count
intValue
flagsFromKeypoints:withMinConfidence:
setObject:forKeyedSubscript:
numberWithUnsignedInteger:
espressoForward:
parsePersons:width:height:
processPersons:width:height:
prepareModelWithConfig:
inputBlob
copyImage:toData:withChannels:
removeAllObjects
reInitModel
createInput:withBuffer:modelInputHeight:modelInputWidth:
generateHumanPose:
saveKeypoints
initWithKeypointsOption:aspectRatio:lightweight:forceCPU:sharedModel:flushModel:
updateModelForAspectRatio:
preferredInputFormat:height:format:
analyzePixelBuffer:flags:results:cancel:
trackingMode
setTrackingMode:
_modelEspresso
_netFileUrl
_inputData
_resConfig
_persons
_saveKeypoints
_inputWidth
_inputHeight
_heatmapNms
_forceCPU
_sharedModel
_flushModel
_trackingMode
TB,V_trackingMode
convertToOriginalTimeFromScaledTime:forExport:
vcp_convertToOriginalTimerangeFromScaledTimerange:
scaleTimeRange:toDuration:
vcp_scaleSlowmoTimeRange:withTimeMapping:inComposition:
hasSlowMotionAdjustments
initWithVideoAsset:videoAdjustments:
composition
insertTimeRange:ofAsset:atTime:error:
rampDown
rampUp
slowMotionRate
computeRampToTargetRate:forExport:outTimeSteps:outIntermediateRates:
slowMotionRampInRangeForExport:
slowMotionRampOutRangeForExport:
slowMotionTimeRange
vcp_scaleRampWithIntervals:andRates:inSlowmoTimerange:withTimeMapping:inComposition:
tracks
removeTrack:
objectAtIndex:
dictionaryRepresentation
stringWithFormat:
numberWithDouble:
setObject:forKey:
initWithCapacity:
addFaceResults:
faceResultsCount
clearFaceResults
faceResultsAtIndex:
allocWithZone:
copyWithZone:
faceResultsType
setGlobalQualityScore:
setHasGlobalQualityScore:
hasGlobalQualityScore
setContentScore:
setHasContentScore:
hasContentScore
readFrom:
writeTo:
copyTo:
mergeFrom:
timestamp
setTimestamp:
qualityScoreForLivePhoto
setQualityScoreForLivePhoto:
visualPleasingScore
setVisualPleasingScore:
overallFaceQualityScore
setOverallFaceQualityScore:
exposureScore
setExposureScore:
penaltyScore
setPenaltyScore:
textureScore
setTextureScore:
sharpness
setSharpness:
faceResults
setFaceResults:
globalQualityScore
contentScore
_timestamp
_contentScore
_exposureScore
_faceResults
_globalQualityScore
_overallFaceQualityScore
_penaltyScore
_qualityScoreForLivePhoto
_sharpness
_textureScore
_visualPleasingScore
_has
Td,N,V_timestamp
Tf,N,V_qualityScoreForLivePhoto
Tf,N,V_visualPleasingScore
Tf,N,V_overallFaceQualityScore
Tf,N,V_exposureScore
Tf,N,V_penaltyScore
Tf,N,V_textureScore
Tf,N,V_sharpness
T@"NSMutableArray",&,N,V_faceResults
TB,N
Tf,N,V_globalQualityScore
Tf,N,V_contentScore
setMinX:
setMinY:
setMaxX:
setMaxY:
initWithXYAndSize:y:width:height:confidence:
intersect:
union:
area
initWithCenterAndSize:y:width:height:confidence:
computeIntersectionOverUnion:
getCGRectWithClipWidth:height:
flag
setFlag:
_minX
_maxX
_minY
_maxY
_flag
Tf,V_minX
Tf,V_maxX
Tf,V_minY
Tf,V_maxY
Tf,V_flag
timeRangeWithCMTimeRange:
timeRangeValue
inputSize
setInputSize:
outputSize
setOutputSize:
input
setInput:
setOutput:
generateOutput
setGenerateOutput:
_inputSize
_outputSize
_output
_generateOutput
_executedOnGPU
T@"NSMutableArray",W,V_inputSize
T@"NSMutableArray",&,V_outputSize
T@"VCPCNNData",W,V_input
T@"VCPCNNData",&,V_output
T@"VCPCNNMetalContext",R,V_context
TB,V_generateOutput
analyzer
sdof
TB,V_sdof
objectPoolWithAllocator:
initWithRevision:
sharedModelPoolWithRevision:
getObject
object
getRevision
calculateScoreFromNetworkOutputV2:
calculateScoreFromNetworkOutput:outChannel:outHeight:outWidth:textureness:contrast:imgWidth:
copyBufferFrom:fromStride:toPtr:toStride:toWidth:toHeight:
prepareModelForSourceWidth:andSourceHeight:
getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:
computeSharpnessScore:textureness:contrast:imgWidth:cancel:
_srcWidth
_srcHeight
dynamicForward:paramFileUrl:cancel:
_modelURL
supportGPU
supportVectorForward
convBlockClass:
initWithParameters:filterNum:chunk:reLU:padding:groups:stride:batchNorm:
cnnDataWithGPUContext:
cnnData
setSize:
allocBuffers:
size
convBlockWithFilterSize:filterNum:chunk:reLU:padding:
convBlockWithFilterSize:filterNum:chunk:reLU:padding:groups:stride:batchNorm:
constructBlock:context:
useGPU
_filterSize
_filterNum
_filter
_bias
_chunk
_reLU
_padding
_padSize
_stride
_groups
_batchNorm
isFilterSizeSupported:
readFromDisk:quantFactor:
data
straightForwardForChunkFour
chunkFourForward
forward
CalculateDotProductOfChunk
cnnDataClass
initWithGPUContext:
initWithParameters:height:width:context:
bufferAllocCPU
cnnDataWithPlane:height:width:context:
randInit
convertCPUData2GPU
convertGPUData2CPU
reallocGPUTemporalBuffers
copyImage:withChunk:
normalization
softmax
setData:
isInputOutput
setIsInputOutput:
context
setContext:
_isInputOutput
_size
_data
_context
T@"NSMutableArray",&,V_size
T^f,V_data
TB,V_isInputOutput
T@"VCPCNNMetalContext",W,V_context
createContextWithForceCPU:
sharedEspressoContext:
initWithForceCPU:shared:
espressoContext
_espressoContext
T^v,R,N,V_espressoContext
_landmarks
normalization:
getInputBuffer
computeLandmarks:
_modelLandmarks
initWithParameters:
initWithParameters:NeuronType:
_weight
_numNeurons
_neuronType
readWeightsBias:weights:bias:inputDim:outputDim:quantFactor:
loadWeights:inputDim:outputDim:quantFactor:
copyImage:toData:
createInput:withBuffer:cnnInputHeight:cnnInputWidth:faceBounds:
detectEyeOpennessForFace:inBuffer:eyeOpenness:
_analysisDict
_metadata
_cropSize
init:sharedModel:modelName:
getInputBuffer:srcWidth:cnnInputHeight:cnnInputWidth:offset:
generateHandKeypoints:keypointConfidence:offset:
cvtHeatmaps2Keypoints:outHeight:outWidth:inHeight:inWidth:outChannel:keypoints:keypointConfidence:offset:
_std
_mean
initNewContext:
execute
device
setDevice:
commandQueue
setCommandQueue:
commandBuffer
setCommandBuffer:
_device
_commandQueue
_commandBuffer
T@"<MTLDevice>",&,V_device
T@"<MTLCommandQueue>",&,V_commandQueue
T@"<MTLCommandBuffer>",&,V_commandBuffer
initWithOptions:
location
parseResults:observations:
associatePersons:withExisingPersons:
arrayWithArray:
personID
removeLastObject
insertObject:atIndex:
computeActionScoreForPerson:
errorWithDomain:code:userInfo:
keypoints
normDistance:point2:
computeVarWithID:index1:index2:interVar:intraVar:
setRelativeActionScore:
setAbsoluteActionScore:
setPersonID:
bodyDistance:withBodyB:
removeObject:
processSampleBuffer:withOptions:error:
preferredInputSizeWithOptions:error:
preferredPixelFormat
cleanupWithOptions:error:
_personID
_preferredWidth
_preferredHeight
_preferredFormat
_analyzer
_existingPersons
_existingPersonsArray
_blocks
_quantFactor
T@"VCPCNNData",R,V_output
path
UTF8String
getPlanPhase
isEqualToString:
prepareModelInput:
prepareModelInputs:
numberWithUnsignedLong:
espressoForwardInputs:
getEspressoContext
inputBlobs
setInputBlobs:
outputBlobs
setOutputBlobs:
setInputBlob:
setOutputBlob:
resConfig
.cxx_construct
_net
_plan
_inputNames
_outputNames
_inputBlobs
_outputBlobs
_inputBlob
_outputBlob
T{vector<espresso_buffer_t, std::__1::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::__1::allocator<espresso_buffer_t>>=^{?}}},N,V_inputBlobs
T{vector<espresso_buffer_t, std::__1::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::__1::allocator<espresso_buffer_t>>=^{?}}},N,V_outputBlobs
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_inputBlob
T{?=^v^v[4Q][4Q]QQQQQQQQQQi},N,V_outputBlob
T@"NSString",R,N,V_resConfig
postProcBoxes:maxNumRegions:
detector:
petsDetection:petsRegions:petsFaceRegions:cancel:
setTimeRange:
setConfidence:
_confidence
_timeRange
T@"VCPProtoTimeRange",&,N,V_timeRange
Tf,N,V_confidence
boundsWithCGRect:
rectValue
generatePetsRegions:outHeight:outWidth:boxes:faceBoxes:maxNumRegions:
initWithMaxNumRegions:
createModel:srcWidth:
generatePetsBoxes:faceBoxes:cancel:
initWithParameters:poolY:chunk:
poolingBlockWithPoolX:poolY:chunk:
vcp_imageOrientation
progressHandler
_analyzeWithStart:andDuration:error:
initWithURL:
analyzeWithStart:andDuration:error:
_session
T@?,C,V_progressHandler
setVerifiedType:
setManualOrder:
keyFace
anonymizedName
favorite
setIsVerified:
pv_addMergeCandidatePersons:
personLocalIdentifiers
isVerified
manualOrder
Tq,N
T@"<PVFaceProtocol>",&,N
TB,D,N
dataUsingEncoding:allowLossyConversion:
base64EncodedStringWithOptions:
completionHandler
validateConfiguration:withError:
request
nodeWithRequest:andConfiguration:
orientation
initWithCMSampleBuffer:orientation:options:
containsObject:
frameInterval
timeInterval
shouldProcessSampleWithTimeRange:atSamplingInterval:
performRequests:error:
processSampleBuffer:withEndTime:error:
copy
addRequest:withConfiguration:error:
removeRequest:error:
processSampleBuffer:error:
flushWithEndTime:error:
setOrientation:
_queue
_nodes
_modified
_startTime
_nextSampleBuffer
_frameCount
_orientation
TI,N,V_orientation
computePoseScore:
setFaceBounds:
faceBounds
_faceBounds
T@"VCPProtoBounds",&,N,V_faceBounds
initWithParameters:useGPU:
getGPUContext
add:
fcBlockWithNumNeurons:NeuronType:
prepareNetworkFromURL:withInputSize:
forward:
output
_model
_input
computeSmileScore:
initWithDatabaseReader:forAssets:resultsTypes:batchSize:
nextBatch
localIdentifier
subarrayWithRange:
queryAnalysesForAssets:withTypes:
iteratorForAssets:withDatabaseReader:resultTypes:batchSize:
next
asset
analysis
_reader
_assets
_resultsTypes
_batchSize
_idxLast
_idxCurrent
_batchAnalyses
_asset
_analysis
T@"PHAsset",R,N,V_asset
T@"NSDictionary",R,N,V_analysis
vcp_mediaAnalysisDatabaseFilepath
shouldQueryInternalFields
stringWithString:
parseHeader:startColumn:analysis:
parseResults:typeColumn:dataColumn:results:
closeDatabase
openDatabase
executeDatabaseBlock:
queryHeaderForAsset:analysis:assetId:
queryResultsForAssetId:analysis:
queryResultsForAssetId:withTypes:analysis:
queryHeadersForAssets:analyses:idMap:
queryResultsForAssets:withTypes:batchResults:
entryWithLocalIdentifier:andTaskID:andStatus:andAttempts:andNextRetryDate:
queryBlacklistedLocalIdentifiers
queryAnalysisPropertiesForAsset:
queryLocalIdentifiersForTaskID:withStatus:
_sqlSerialQueue
_filepath
dateWithTimeIntervalSinceReferenceDate:
propertyListWithData:options:format:error:
flags
setFlags:
bounds
setBounds:
_flags
_bounds
TQ,V_flags
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bounds
Tf,V_confidence
supportsFeatureSet:
canRenderVariation
isHomePod
marketingName
absoluteScore
setAbsoluteScore:
relativeScore
setRelativeScore:
humanScore
setHumanScore:
_absoluteScore
_humanScore
_relativeScore
Tf,N,V_absoluteScore
Tf,N,V_relativeScore
Tf,N,V_humanScore
noiseReduction:sigma:imageFiltered:
gradientEstimation:width:height:gradient:gradientMag:
isInImage:width:height:
initWithImage:edgeMap:width:height:widthExtension:heightExtension:
detectWithSigma:lowThreshold:highThreshold:
_widthPadded
_heightPadded
_width
_height
_widthExt
_heightExt
_gradient
_image
_imageFiltered
_nonMaxSuppressed
_gradientX
_gradientY
_gradientMag
_edgeMap
usePHAssetScene
initWithAnalysisResults:
_hasFaceOrPet
initWithIntervalNanoseconds:isOneShot:andBlock:
timerWithInterval:unit:oneShot:andBlock:
destroy
timerWithIntervalSeconds:isOneShot:andBlock:
_source
_active
_isOneShot
transformUprightAboutTopLeft:
numberWithInteger:
addFaceResults:flags:
initWithProperties:forAnalysisTypes:
analyzeAsset:results:
_properties
_requestedAnalyses
faceBounds:height:
flagsForOrientation:width:height:
faceBoundsWithTransform:height:transform:
leftEyeClosed
setLeftEyeClosed:
rightEyeClosed
setRightEyeClosed:
smile
setSmile:
setYaw:
setTrackID:
faceQuality
setFaceQuality:
observation
setObservation:
_leftEyeClosed
_rightEyeClosed
_smile
_trackID
_faceQuality
_yaw
_observation
TB,V_leftEyeClosed
TB,V_rightEyeClosed
TB,V_smile
Tq,V_yaw
Ti,V_trackID
Tf,V_faceQuality
T@"VNFaceObservation",&,V_observation
start
setStart:
last
setLast:
position
setPosition:
faceID
setFaceID:
_position
_faceID
_start
_last
T{?=qiIq},V_start
T{?=qiIq},V_last
TQ,V_position
TQ,V_faceID
stop
elapsedTimeSeconds
started
_timebase
_elapsedTimeSeconds
Td,R,V_elapsedTimeSeconds
TB,R,V_started
encodeObject:forKey:
encodeBool:forKey:
decodeObjectOfClass:forKey:
decodeBoolForKey:
appendFormat:
appendString:
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
startDate
setStartDate:
endDate
setEndDate:
timeZone
setTimeZone:
allDay
setAllDay:
title
setTitle:
setLocation:
setUrl:
notes
setNotes:
_allDay
_startDate
_endDate
_timeZone
_title
_location
_url
_notes
T@"NSDate",&,N,V_startDate
T@"NSDate",&,N,V_endDate
T@"NSTimeZone",&,N,V_timeZone
TB,N,V_allDay
T@"NSString",&,N,V_title
T@"NSString",&,N,V_location
T@"NSURL",&,N,V_url
T@"NSString",&,N,V_notes
service
requestImageProcessingTask:forPixelBuffer:withOptions:andCompletionHandler:
requestImageProcessingTask:forAssetURL:withOptions:andCompletionHandler:
requestShareSheetProcessingForPixelBuffer:withOptions:andCompletionHandler:
requestShareSheetProcessingForAssetURL:withOptions:andCompletionHandler:
_service
initWithFaceCrop:andCompletionHandler:
configureRequest:withRevision:
initWithData:options:
taskWithFaceCrop:andCompletionHandler:
_faceCropData
setWantsIncrementalChangeDetails:
_defaultFetchOptions
_defaultAssetPropertySets
processInfo
processName
urlForApplicationDataFolderIdentifier:
URLForDirectory:inDomain:appropriateForURL:create:error:
fileExistsAtPath:isDirectory:
_phPeopleSortDescriptors
setPersonContext:
fetchAssetsForPersons:options:
fetchPersonsForAssetCollection:options:
fetchPersonsGroupedByAssetLocalIdentifierForAssets:options:
_defaultFacePropertySets
_phFaceSortDescriptors
pv_fetchFacesForPersonLocalIdentifiers:inMoment:
fetchedObjectIDs
andPredicateWithSubpredicates:
fetchFacesGroupedByAssetLocalIdentifierForAssets:options:
momentSortDescriptors
fetchMomentsWithOptions:
fetchAssetCollectionsWithLocalIdentifiers:options:
fetchMomentsForAssetsWithLocalIdentifiers:options:
_defaultAssetFetchOptions
fetchAssetsForFaceGroups:options:
_progressFromWorkerStatesDictionary:
requestTotalProgressCountsForWorkerType:states:completion:
fetchAssetCollectionsWithType:subtype:options:
setIncludeAssetSourceTypes:
pv_performChangesAndWait:error:
pv_persistentStorageDirectoryURL
pv_fetchPersonsWithLocalIdentifiers:
pv_fetchPersonsWithType:
pv_fetchPersonsInMoment:
pv_fetchCandidatePersonsForPerson:
pv_fetchInvalidCandidatePersonsForPerson:
pv_fetchPersonsGroupedByAssetLocalIdentifierForAssets:
pv_numberOfFacesWithFaceprints
pv_fetchFacesWithLocalIdentifiers:
pv_fetchFacesForPerson:
pv_fetchFacesForPerson:inMoment:
pv_fetchFacesForFaceGroup:
pv_fetchFacesGroupedByAssetLocalIdentifierForAssets:
pv_fetchMoments
pv_fetchMomentsWithLocalIdentifiers:
pv_fetchMomentsForPerson:
pv_fetchMomentsForAssetsWithLocalIdentifiers:
pv_fetchAssetsWithLocalIdentifiers:
pv_fetchAssetsInMoment:
pv_fetchAssetsForPerson:
pv_fetchAssetsForFaceGroup:
pv_fetchFaceGroups
pv_fetchFaceGroupsForPerson:
pv_fetchInvalidAssetIdentifiersForCommonComparison
pv_lastAssetDate
initWithMaster:adjusted:
master
adjusted
fingerprintWithMaster:adjusted:
isEqualToFingerprint:
_master
_adjusted
T@"NSString",R,V_master
T@"NSString",R,V_adjusted
initWithContext:
globalSession
releaseCachedResources
pointCount
normalizedPoints
setRevision:
setMetalContextPriority:
setPreferBackgroundProcessing:
_allowANE
defaultANEDevice
setProcessingDevice:
_configureRequest:withRevision:
boundingBox
landmarks
leftEye
_addRegion:toBoundingBox:
rightEye
leftEyebrow
rightEyebrow
nose
noseCrest
outerLips
innerLips
_rectFromMappingNormalizedRect:toBounds:
setBlurDeterminationMethod:
setMaximumIntermediateSideLength:
setRegionOfInterest:
warnings
addObjectsFromArray:
sourceWidth
sourceHeight
isLeftEyeClosed
isRightEyeClosed
hasSmile
blurScore
initWithLocalIdentifier:
setSourceWidth:
setSourceHeight:
setManual:
setFaceAlgorithmVersion:
setCenterAndSizeFromNormalizedFaceRect:
uuid
roll
setRoll:
faceCaptureQuality
doubleValue
setQuality:
pointFromNormalizedPoint:inBounds:
setLeftEyeX:
setLeftEyeY:
setRightEyeX:
setRightEyeY:
setMouthX:
setMouthY:
pose
computeYawPitchRollFromPoseMatrix:outputYaw:outputPitch:outputRoll:
setPoseYaw:
expressionsAndConfidence
setHasSmile:
faceTorsoprint
faceprint
serializeStateAndReturnError:
faceprintWithFaceprintData:faceprintVersion:
setFaceprint:
faceAttributes
ageCategory
label
identifier
setAgeType:
VN7exwFFmQF0AI9P7FjBljwEFu7QYUGCYE
setSexType:
eyesCategory
setEyesState:
smilingCategory
setSmileType:
faceHairCategory
setFacialHairType:
hairColorCategory
setHairColorType:
baldCategory
setBaldType:
glassesCategory
setGlassesType:
eyesState
setIsLeftEyeClosed:
setIsRightEyeClosed:
_createFaceRectanglesRequest:andFaceprintRequest:
_createFaceRectanglesRequest:andFaceLandmarksRequest:andFaceExpressionsRequest:andFacePoseRequest:andFaceprintRequest:andClassifyFaceAttributesRequest:andFaceCaptureQualityRequest:
_checkAnalysisRequests:forTooSmallFaceObservations:withAnalysisResults:
_createBlurRequests:andExposureRequests:forFaceObservations:
firstObject
getPVFaceFromVNFaceObservation:withSourceWidth:andSourceHeight:andVisionRequests:andAlgorithmVersion:andError:
setIsTooSmall:
setBlurScore:
_qualityMeasureForFace:countOfFacesOnAsset:
setQualityMeasure:
photoLibrary
setPhotoLibrary:
setIncludeNonvisibleFaces:
fetchFacesInAsset:options:
arrayWithCapacity:
pvFaceFromPHFace:copyPropertiesOption:
predicateWithFormat:
setPredicate:
setMinimumVerifiedFaceCount:
fetchPersonsWithLocalIdentifiers:options:
mutableCopy
removeObjectForKey:
_pvFaceArrayFromAsset:
valueForKey:
null
predicateWithBlock:
filteredArrayUsingPredicate:
_verifiedPersonsFetchResultWithLocalIdentifiers:andPhotoLibrary:andError:
personLocalIdentifier
setPersonLocalIdentifier:
mergeExistingFaces:withDetectedFaces:forImage:
imageURL
initWithURL:orientation:options:session:
imageData
initWithData:orientation:options:session:
assetWidth
assetHeight
_performAnalysis:withRequestHandler:options:sourceWidth:sourceHeight:
_refineAnalysis:forAsset:andImage:
analyzeWithImage:andAsset:andOptions:andResults:
_faceMerger
_processingGroup
_processingQueue
_sessionPool
_numFilterTabs
_scoreArray
_distanceVariance
_diffVariance
_numOfScores
vcp_isLivePhoto
vcp_fullAnalysisTypes
vcp_fullAnalysisTypesForAssetType:
textureness
setTextureness:
hasFlash
setHasFlash:
stillTime
setStillTime:
_stillTime
_textureness
_hasFlash
Tf,N,V_textureness
TB,N,V_hasFlash
Tf,N,V_stillTime
setSceneprintBlob:
sceneprintBlob
_sceneprintBlob
T@"NSData",&,N,V_sceneprintBlob
useSceneprintInSceneAnalysis
initWithFilterTabs:distanceVariance:diffVariance:
vcp_orientation
preferredTransform
initWithFrameWidthInMb:heightInMb:
setVideoActivityDescriptor:
videoActivityDescriptor
analyzeFrame:withTimestamp:andDuration:properties:flags:
seedAnalyzersWithPixelBuffer:startTime:
analyzePixelBuffer:withFrame:withTimestamp:andDuration:hasSubtleScene:
detectedFaces
estimateExpressionScore:encodeStats:frameWidth:frameHeight:
isStableMetaMotion:
frameExpressionScore
setFrameExpressionScore:
salientRegionsFromPixelBuffer:
reviseFrameTrackScore:saliencyRegions:
processAndEstimateQualityScore:
process:
ExtractActivityDescriptorFromStats:
setCameraMotionScore:
setSubjectActionScore:
setInterestingnessScore:
setColorfulnessScore:
setFrameProcessedByVideoAnalyzer:
setSubMbMotionAvailable:
computeExposureScoreOfFrame:
processFrameScore:validScore:
interestingnessScore
addSceneAnalysisResult:to:optional:
estimateQualityScore:
addResult:to:forKey:optional:
bound
initWithTransform:
initWithVideoTrack:withMetaOrientation:withPrivateResults:withFrameStats:isTimelapse:isIris:irisPhotoOffsetSec:irisPhotoExposureSec:slowMoRate:faceDominated:
prepareVideoAnalysisByScenes:
prepareLivePhotoAnalysisByScenes:
analyzeFrame:withTimestamp:andDuration:flags:
finishAnalysisPass:
privateResults
getSceneSwichFrequency
setNextCaptureFrame:
qualityScore
setQualityScore:
actionScore
setActionScore:
obstructionScore
setObstructionScore:
trackingScore
setTrackingScore:
objectsMotion
globalMotion
_encodeAnalysis
_preencodeAnalysis
_obstructionAnalysis
_sceneAnalysis
_motionFilter
_metadataAnalysis
_irisAnalysis
_frameBuffer
_idealHistogram
_isTimelapse
_isIris
_isSlowMo
_finalized
_hasInterestingScene
_isCaptureAnalysis
_privateResults
_videoFrameAnalysis
_trackScoreFilter
_metaMotionResults
_faceDominated
_subtleMotionAnalyzer
_sceneType
_qualityScore
_actionScore
_interestingnessScore
_obstructionScore
_trackingScore
_objectsMotion
_globalMotion
Tf,V_qualityScore
Tf,V_actionScore
Tf,V_interestingnessScore
Tf,V_obstructionScore
Tf,V_trackingScore
T@"NSDictionary",R,N,V_objectsMotion
T@"NSArray",R,N,V_globalMotion
createGaborFilterKernel:sigmaX:sigmaY:lambda:thetaInDegree:phaseInDegree:
initWithNumberOfScales:numOfOrientations:width:height:
processWithFilterScaleIdx:orientIdx:srcImage:outImage:width:height:
_filterBanks
_numScales
_numOrientations
_num
Transform
integerValue
sortUsingComparator:
initWithEdgeMap:mapWidth:mapHeight:angleStep:
DetectLinesWithThreshold:output:
_mapWidth
_mapHeight
_accumulator
_accWidth
_accHeight
_accHalfHeight
_angleStep
_verbose
minX
minY
maxX
maxY
createInput:withBuffer:cnnInputHeight:cnnInputWidth:box:
parseKeypoints:
initWithForceCPU:sharedModel:
analyzeFrame:withBox:keypoints:
processTile:results:cancel:
aggregateTileResults:tileRect:imageSize:landscape:results:
analyzePixelBufferInTiles:results:cancel:
calculateTextureness:height:width:sdof:result:
analyzerWithRevision:
setSdof:
initWithFaceResults:sdof:revision:
prepareFaceBlurModel:
scaleRegion:ofImage:toData:withWidth:andHeight:
getFaceScoreFromOutput:ratio:
computeSharpnessScore:forObjects:inImage:
computeRegionSharpness:width:height:stride:
estimateDistance:prevHomography:
analyzePixelBuffer:flags:withPreAnalysisScore:results:cancel:
computeLocalSharpness:
spatialPooling
computeCNNBasedSharpness:sharpnessScore:textureScore:contrast:cancel:
computeCNNFaceSharpness:result:cancel:
computeSharpnessScore:forFacesInImage:
computeGyroSharpness:
initWithFaceResults:sdof:
setGyroSharpnessParam:homographyResults:livePhotoStillDisplayTime:imageExposureTime:
_sharpnessBlocks
_faces
_framePTSResults
_homographyResults
_faceModel
_faceInput
_livePhotoStillDisplayTime
_imageExposureTime
_useGPU
_sdof
_contrast
_blurAnalyzer
Tf,R,V_sharpness
Tf,R,V_textureScore
run:
code
resourceRequirement
cancel
initWithCompletionHandler:
isCanceled
cancelBlock
setCancelBlock:
_started
_canceled
_cancelBlock
_completionHandler
T@?,R,N,V_completionHandler
T@?,C,N,V_cancelBlock
initWithImage:
detect:withConfidence:dominantLine:
arrayWithObjects:
resize:height:
_pixelFormat
_rgbColorSpace
_cgContext
_rgbFrame
_yuvFrames
_rgbToYuv
initWithData:
initWithCVPixelBuffer:options:
setTimeStamp:
imageprint
initWithState:error:
distanceToImageprint:error:
usePHAssetData
descriptorWithImage:
descriptorWithData:
serialize
computeDistance:toDescriptor:
_imagePrint
computeRegionNoise:blockTextureness:average:width:height:stride:
computeNoiseLevel:width:height:stride:textureness:
Tf,R,N,V_exposureScore
queryAnalysisPropertiesForAssets:
vcp_dateModified
vcp_modificationDate
isEqualToDate:
vcp_version
faceAdjustmentVersion
adjustmentVersion
vcp_needSceneProcessing
_countMediaAnalysisWithAssetBatch:andDatabase:
_countFaceAnalysisWithAssetBatch:
_countSceneAnalysisWithAssetBatch:
blacklistedLocalIdentifiersFromAssets:
queryFailedProcessingStatusFromAssets:forTaskID:
databaseForPhotoLibrary:
vcp_fetchOptionsForLibrary:forTaskID:
addFetchPropertySets:
fetchAssetsWithOptions:
_countAnalysisWithAssetBatch:andDatabase:andTaskID:
_countFailuresWithAssetBatch:andDatabase:andTaskID:
vcp_assetCountForTaskID:
_processedPredicateForTaskID:
vcp_assetCountWithInternalPredicate:forTaskID:
countForTaskID:withProcessingStatus:
_screenProgress
_queryProgressDetailExpress:forPhotoLibrary:andTaskID:
_scanPhotoLibrary:withTaskID:andStatistics:
queryProgressDetail:forPhotoLibrary:andTaskID:
unsignedIntegerValue
queryProgress:forPhotoLibrary:andTaskID:
setInputFaceObservations:
estimator
detectSmileForFace:inBuffer:smile:
detectPoseForFace:inBuffer:yaw:
faceDetection:faces:cancel:
isDuplicate:withRect:
removeObjectsInArray:
faceDetector
initWithFaceResults:
initWithAssets:andOptions:andCompletionHandler:
queryAnalysisForAsset:
vcp_results
initWithPHAsset:withExistingAnalysis:forAnalysisTypes:
analyzeAsset:streamed:
exportToLegacyDictionary
main
taskWithAssets:andOptions:andCompletionHandler:
_photoLibrary
_database
_cancel
_stabilizationType
_onDemandPixel
_onDemandGyro
analyzeDetectedFaces:faceResults:cancel:
faceQualityScores
setFaceQualityScores:
_faceQualityScores
T@"NSMutableArray",&,V_faceQualityScores
initWithMovingObjectsResults:
_movingObjects
initWithPhotoLibraries:andCompletionHandler:
deferredProcessingNeeded
processAsset:
fetchAssetsFromCameraSinceDate:options:
_concurrentFaceProcessing
_analyzeAsset:withManager:
fetchLimit
_photoLibraries
T{CGPoint=dd},N,V_location
setKeypoints:
relativeActionScore
absoluteActionScore
revision
_relativeActionScore
_absoluteActionScore
_revision
_keypoints
T@"NSArray",&,N,V_keypoints
Tf,N,V_relativeActionScore
Tf,N,V_absoluteActionScore
Ti,N,V_personID
Ti,N,V_revision
handID
setHandID:
_handID
Ti,N,V_handID
setNetworkAccessAllowed:
appendData:
defaultManager
requestDataForAssetResource:options:dataReceivedHandler:completionHandler:
privateFileURL
dataWithContentsOfURL:
createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:
setValue:forKey:
longValue
convertPixelBuffer:toPixelFormat:
loggingEnabled
drawImage:withOrientation:maxDimension:pixelBuffer:
canDecodeAcceleratedUniformTypeIdentifier:
acceleratedDecodeImageData:pixelFormat:maxDimension:pixelBuffer:flushCache:
decodeImageSource:pixelFormat:maxDimension:pixelBuffer:
dataForResource:
uniformTypeIdentifier
pixelBufferWithFormat:andMaxDimension:fromData:withUniformTypeIdentifier:flushCache:
getResourceValue:forKey:error:
sharedImageManager
imageForResource:pixelFormat:
imageForResource:pixelFormat:maxDimension:
pixelBufferWithFormat:fromImageURL:flushCache:
pixelBufferWithFormat:andMaxDimension:fromImageURL:
flushCache
_decodeSession
_transferSession
_decodeQueue
unsignedIntValue
centerX
centerY
qualityMeasure
clusterSequenceNumber
quality
photosFaceRepresentationSourceWidth
photosFaceRepresentationSourceHeight
photosFaceRepresentationCenterX
photosFaceRepresentationCenterY
photosFaceRepresentationSize
photosFaceRepresentationBlurScore
photosFaceRepresentationHasSmile
photosFaceRepresentationIsLeftEyeClosed
photosFaceRepresentationIsRightEyeClosed
photosFaceRepresentationQualityMeasure
photosFaceRepresentationClusterSequenceNumber
photosFaceRepresentationLocalIdentifier
photosFaceRepresentationRoll
photosFaceRepresentationQuality
indexSetWithIndexesInRange:
objectsAtIndexes:
persistenceDelegate_enumerateInChunksOfSize:withOverageAllowance:usingBlock:
enumerateObjectsUsingBlock:
setWithCapacity:
resultsAsArray
resultsAsSet
initWithPerson:andPerson:reason:
person1LocalIdentifier
person2LocalIdentifier
mergeCandidatePairWithPerson:andPerson:reason:
reason
_hash
_person1LocalIdentifier
_person2LocalIdentifier
_reason
T@"NSString",R,V_person1LocalIdentifier
T@"NSString",R,V_person2LocalIdentifier
T@"NSString",R,V_reason
librarySpecificFetchOptions
setMinimumUnverifiedFaceCount:
setFetchPropertySets:
sortDescriptorWithKey:ascending:
newAllFacesFetchOptionsWithPhotoLibrary:
setShouldPrefetchCount:
fetchFacesWithOptions:
countOfClusteringEligibleFaces
countOfUnclusteredFaces
newUnclusteredFacesFetchOptions
newFacesDeterministicSortDescriptors
setInternalSortDescriptors:
setInternalPredicate:
fetchFacesWithLocalIdentifiers:options:
fetchedObjects
fetchAssetsGroupedByFaceUUIDForFaces:
allValues
fetchMomentUUIDByAssetUUIDForAssets:options:
fetchPropertySetsIfNeeded
faceClusteringProperties
uuidFromLocalIdentifier:
nonGroupedGroupID
initWithUUIDString:
canceled
updateBlock
faceClusterSequenceNumbersOfFacesWithClusterSequenceNumbers:error:
minusSet:
allObjects
fetchFaceGroupsGroupedByFaceLocalIdentifierForFaces:options:
enumerateKeysAndObjectsUsingBlock:
enumerateFetchResult:withBatchSize:handler:
unionSet:
_ungroupFaceClusterSequenceNumbers:canceler:error:
strongToStrongObjectsMapTable
_categorizeGroupedFacesInFetchResult:intoFaceLocalIdentifiersByFaceGroup:ungroupedFaceLocalIdentifiers:canceler:photoLibrary:
_resetFaceClusterSequenceNumberOfFacesInFetchResult:inPhotoLibrary:canceler:error:
domain
keyEnumerator
changeRequestForFace:
setClusterSequenceNumber:
changeRequestForFaceGroup:
removeFaces:
performCancellableChangesAndWait:error:
setIncludeOnlyFacesInFaceGroups:
_fetchResultForUngroupedFacesWithNonZeroClusterSequenceNumberInPhotoLibrary:
_fetchResultForGroupedFacesWithClusterSequenceNumberSetToZeroInPhotoLibrary:
fetchFaceGroupsForPerson:options:
fetchFacesForPerson:options:
fetchFacesInFaceGroup:options:
newAllPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:
fetchAssociatedPersonsGroupedByFaceGroupLocalIdentifierForFaceGroups:options:
objectEnumerator
allKeys
dictionaryWithCapacity:
setWithArray:
creationRequestForFaceGroup
placeholderForCreatedFaceGroup
fetchKeyFaceForFaceGroup:options:
setPersonBuilderState:
addFaces:
setKeyFace:
removeObjectsForKeys:
deleteEmptyGroupsAndReturnError:
_localIdentifiersOfUnverifiedPersonsAssociatedWithFaceGroups:withCanceler:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:canceler:error:
fetchFaceGroupsWithOptions:
deleteFaceGroups:
cleanupUngroupedFacesWithNonZeroClusterSequenceNumbersWithCanceler:error:
fetchEmptyFaceGroupsWithOptions:
performChangesAndWait:error:
localizedDescription
newVisibleFacesFetchOptionsWithPhotoLibrary:
fetchKeyFaceForPerson:options:
bestRepresentativeFaceForPerson:qualityMeasureByFace:canceler:
verifiedType
changeRequestForPerson:
setKeyFace:forCluster:
bestRepresentativeFaceForPerson:qualityMeasureByFace:candidateFaces:canceler:
_facesFromFaceGroupWithMostNumberOfFacesOnPerson:options:error:
_faceToFaceCountMapForFaces:
qualityMeasureForFace:countOfFacesOnAsset:
_representativenessByFaceCSNFromFaces:canceler:
selectRepresentativeFromFaces:qualityMeasureByLocalIdentifier:representativenessByCSN:candidateFaces:
faceprintData
faceprintFromFaceprintArchive:error:
setFaceId:
setFaceTorsoprint:
representativenessFromFaceObservations:error:
newAssetFetchOptionsWithPhotoLibrary:
fetchAssetsForFaces:options:
setFetchLimit:
fetchMergeCandidatePersonsForPerson:options:
intersectSet:
removeMergeCandidatePersons:
fetchPersonsWithOptions:
_cleanupMergeCandidatesForVerifiedPersons:minimumFaceGroupSize:canceler:error:
minimumVerifiedFaceCount
minimumUnverifiedFaceCount
faceCount
predicate
evaluateWithObject:
newAllPersonsFetchOptionsWithPhotoLibrary:
_enumeratePersonsWithLocalIdentifiers:fetchOptions:personCache:usingBlock:
deletePersons:
changeRequestForDedupingGraphPersons:
fetchInvalidMergeCandidatePersonsForPerson:options:
nameSource
trainingType
isConfirmedFaceCropGenerationPending
newVerifiedPersonsFetchOptionsWithPhotoLibrary:
fetchRejectedPersonsForFace:options:
_getMergeCandidates:invalidMergeCandidates:forPersonsWithLocalIdentifiers:
fetchRejectedFacesForPerson:options:
progressWithTotalUnitCount:
filterUsingPredicate:
becomeCurrentWithPendingUnitCount:
setNameSource:
resignCurrent
personBuilderMergeCandidatesDisabled
addMergeCandidatePersons:
addInvalidMergeCandidatePersons:
fetchFacesOnAssetWithFace:options:
removeObjectAtIndex:
otherFacesOnAssetWithFace:options:
_duplicateFaceCSNsOnAssetForPerson:faceCSNsOnPerson:faceByCSNCache:
dedupeGraphVerifiedPersonsInFaceGroup:personCache:
minimumFaceGroupSizeForCreatingMergeCandidates
_getTrainingFacesByPerson:confirmedFaceCSNs:faceCSNsByPerson:faceCSNsByMigratedPerson:faceCSNsByQuickClassificationPerson:mergeCandidates:invalidMergeCandidates:rejectedPersonsByPerson:faceInFaceGroupByCSN:inFaces:personCache:canceler:
_getRejectedTrainingFaceCSNs:rejectedFaceCSNs:rejectedPersonLocalIdentifiers:forPerson:faceInFaceGroupByCSN:
_completePersonBuildingWithPersonsToUpdate:facesToRemoveByPerson:facesToAddByPerson:updateFaceGroup:newMergeCandidatePairs:newInvalidMergeCandidatePairs:faceInFaceGroupByCSN:personCache:keyFaceUpdateBlock:canceler:context:error:
nextObject
anyObject
level0ClusterAsFaceCSNsByLevel0KeyFaceCSNForClusterIdentifiedByFaceCSN:error:
_level0ClusterIdForFaceCSN:level0Clusters:
setWithSet:
intersectsSet:
quarantineTwinsOnAssetEnabled
_updateFaceCSNsToAddByPerson:faceCSNsToRemoveByPerson:faceInFaceGroupByCSN:faceCSNsByPersonLocalIdentifier:faceCSNsByMigratedPersonLocalIdentifier:personsToUpdate:
personBuildingDisabled
_updatedFaceGroupByFGLocalIdentifierFromClusterCSNsWithCanceler:fetchLimit:
_buildPersonsFromUpdatedFaceGroups:faceClusterer:keyFaceUpdateBlock:canceler:context:
cancelerWithUpdateBlock:
suggestedMeIdentifierWithPersonClusterManager:forPersons:updateBlock:
socialGroupsOverTheYearsWithPersonClusterManager:forPersons:updateBlock:
multiLevelSocialGroupsWithPersonClusterManager:forPersons:updateBlock:
densityClusteringForObjects:maximumDistance:minimumNumberOfObjects:withDistanceBlock:
newVerifiedPersonsWithAtLeastOneFaceFetchOptionsWithPhotoLibrary:
countOfFaces
countOfUnclusteredClusteringEligibleFaces
countOfClusteredFaces
unclusteredClusteringEligibleFaceLocalIdentifiers:
facesForClusteringWithLocalIdentifiers:faceprintVersion:groupingIdentifiers:
deterministicallyOrderedFaceIdentifiersWithLocalIdentifiers:faceprintVersion:
facesFromAsset:
invalidFaceClusterSequenceNumbersInClusterSequenceNumbers:canceler:error:
persistFaces:deleteFaces:forAsset:persistedFaces:error:
ungroupFaceClusterSequenceNumbers:batchSizeForUnclusteringFaces:canceler:error:
cleanupGroupedFacesWithClusterSequenceNumberSetToZeroWithCanceler:error:
updateFaceprint:ofPersistedFace:error:
persistGeneratedFaceCrops:error:
dirtyFaceCropsWithLimit:
clearDirtyStateOnFaceCrops:error:
associateFace:withFaceCrop:error:
faceAssociatedWithFaceCrop:
groupedClusterSequenceNumbersOfFacesInFaceGroupsOfMinimumSize:error:
persistChangesToAlgorithmicFaceGroups:faceCSNByLocalIdentifierForNewlyClusteredFaces:faceCSNsOfUnclusteredFaces:localIdentifiersOfUnclusteredFaces:persistenceCompletionBlock:canceler:error:
resetLibraryClustersWithCanceler:error:
recordNeedToPersonBuildOnFaceGroupContainingFace:error:
needsPersonBuilding
buildPersonsWithFaceClusterer:keyFaceUpdateBlock:canceler:context:extendTimeoutBlock:
suggestedPersonLocalIdentifierForPersonLocalIdentifier:faceClusterer:canceler:context:error:
logPVErrorMessage:
logPVWarningMessage:
logPVInfoMessage:
logPVDebugMessage:
faceAlgorithmUmbrellaVersion
setFaceAlgorithmUmbrellaVersion:
sceneAlgorithmUmbrellaVersion
setSceneAlgorithmUmbrellaVersion:
TI,N
keyFaceForPerson:qualityMeasureByFace:updateBlock:
performSocialGroupsIdentifiersWithPersonClusterManager:forPersons:overTheYearsComputation:updateBlock:
initWithPhotoLibrary:
cleanupMergeCandidatesWithMinimumFaceGroupSize:canceler:error:
fetchFaceWithLocalIdentifier:error:
fetchFaceWithClusterSequenceNumber:error:
fetchPersonWithLocalIdentifier:options:error:
removeAutoAssignedFacesFromVerifiedPersonsAndPrepareForPersonBuilding:canceler:error:
setPersonBuilderMergeCandidatesDisabled:
setUpdateBlock:
_faceAlgorithmUmbrellaVersion
_sceneAlgorithmUmbrellaVersion
_personBuilderMergeCandidatesDisabled
_updateBlock
TB,N,V_personBuilderMergeCandidatesDisabled
T@?,C,N,V_updateBlock
TI,N,V_faceAlgorithmUmbrellaVersion
TI,N,V_sceneAlgorithmUmbrellaVersion
generatePersonRegions:boxes:maxNumRegions:
createInput:withBuffer:inputHeight:inputWidth:
generatePersonBoxes:
personDetection:personRegions:cancel:
_outputsData
convertResultsToDict:results:
_petsDetector
vcp_quality
analyzeImageQuality:irisPhotoOffsetSec:cancel:
Tf,R,V_qualityScore
initWithMaxNumRegions:prune:
copyImage:toData:withChunk:
outputScaling
computeScore:width:height:posX:posY:
scaleImage:toData:withWidth:andHeight:
getSalientRegions:
saliencyDetection:salientRegions:cancel:
pruneRegions:
analyzerWith:prune:
generateSalientRegion:outHeight:outWidth:
_region
_score
_maxNumRegions
_prune
_createPixelBufferPoolWithTargetWidth:andTargetHeight:
initWithTargetWidth:andTargetHeight:
_createPixelBufferWithWidth:height:pixelFormat:pixelBuffer:
imageManager
imageManagerWithTargetWidth:andTargetHeight:
loadFullPixelBuffer:scaledPixelBuffer:fromImageURL:isPano:
_pixelBufferPoolBGRA
sharedTaxonomy
_includeDO
_includeSO
_includeLM
_includeNSFW
_includeSE
_includeSDG
numberWithUnsignedInt:
_createPixelBufferPool:withPixelFormat:
_convertFromBuffer:toLumaPixelBuffer:isPano:
_panoVNRequestMethod
initWithURL:options:session:
initWithCVPixelBuffer:options:session:
maximumLeafObservations
setMaximumLeafObservations:
maximumHierarchicalObservations
setMaximumHierarchicalObservations:
setPrivateRevision:error:
_useR14J9
_getNSFWModelRevision
_getSERevision
_getSDGModelRevision
stringValue
nodeForName:
highPrecisionThreshold
highRecallThreshold
threshold
sceneClassId
labels
_parseClassificationObservations:toClassificationResults:
_generateSceneClassifications:withClassificationResults:andDOResults:andJunkImageResults:andLMResults:andNSFWResults:andSEResults:andSDGResults:
aestheticScore
wellFramedSubjectScore
wellChosenBackgroundScore
tastefullyBlurredScore
sharplyFocusedSubjectScore
wellTimedShotScore
pleasantLightingScore
pleasantReflectionsScore
harmoniousColorScore
livelyColorScore
pleasantSymmetryScore
pleasantPatternScore
immersivenessScore
pleasantPerspectiveScore
pleasantPostProcessingScore
noiseScore
failureScore
pleasantCompositionScore
interestingSubjectScore
intrusiveObjectPresenceScore
pleasantCameraTiltScore
lowKeyLightingScore
narrowedBoundingBox
salientObjects
sceneprints
archivedDataWithRootObject:requiringSecureCoding:error:
children
_sceneNetDocumentTypeLabels
importProperties
importedBy
mediaSubtypes
_createAestheticsRequest:andClassificationRequest:andSceneprintRequest:andJunkImageRequest:andSaliencyImageRequest:andDORequest:andLMRequest:andNSFWRequest:andSERequest:andSDGRequest:andSORequest:andRawSceneprintRequest:
_includeOCRGating
defaultMetalDevice
textElements
setRecognize:
_collectSceneAnalysisResults:withClassificationResults:andJunkImageResults:andAestheticsResults:andSaliencyResults:andSceneprintResults:andDOResults:andLMResults:andNSFWResults:andSEResults:andSDGResults:andSaliencyObjectnessResults:
_reportOCRGatingConfidence:boundingBoxRatio:forAsset:andPreAnalysisResults:
_getSHRevision
_performBlurAnalysis:withPixelBuffer:usingAnalyzer:
_performSceneAnalysis:forAsset:withRequestHandler:
_performBlurAnalysis:withLumaPixelBuffer:isPano:isSDOF:
_performExposureAnalysis:withLumaPixelBuffer:
_loadImageURL:isPano:withRequestHandler:session:andLumaPixelBuffer:
_enableSceneAssetConcurrency
_performAnalysis:isPano:isSDOF:forAsset:withRequestHandler:andLumaPixelBuffer:
analyzeWithImageURL:isPano:isSDOF:forAsset:completionHandler:
analyzeWithPixelBuffer:isPano:isSDOF:results:cancel:
_imageManager
_sceneTaxonomy
_pool8Y
vcp_hasLocalMovie:
vcp_isVideoSlowmo
vcp_thumbnailResource
vcp_size
pixelWidth
pixelHeight
vcp_avAsset:
assetImageGeneratorWithAsset:
thumbnailSizeForAsset:withResources:
setMaximumSize:
setAppliesPreferredTrackTransform:
copyCGImageAtTime:actualTime:error:
initWithPixelFormat:
convertImage:yuvFrame:
vcp_isLocallyAvailable
vcp_localPhotoResourcesSorted:
_generateLastFrameDistanceDescriptor:withDescriptorClass:forAsset:
_getThumbnailForAsset:withResouces:andPixelFormat:
string
topCandidates:
stringByAppendingFormat:
length
initWithScannerType:passiveIntent:
category
type
getMailValue:label:
getPhoneValue:label:
value
localTimeZone
dateFromReferenceDate:referenceTimezone:timezoneRef:allDayRef:
extractStartDate:startTimezone:endDate:endTimezone:allDayRef:referenceDate:referenceTimezone:
subResults
URLWithString:
scanString:range:configuration:completionBlock:
setRecognitionLevel:
setMinimumTextHeight:
initWithURL:options:
processObservations:
taskWithPixelBuffer:options:andCompletionHandler:
taskWithAssetURL:options:andCompletionHandler:
_pixelBuffer
_assetURL
initWithModelFile:paramFile:numTri:triList:angle:
validateOneImage:landmarks:numofLandmarks:score:
_transArray
_meanLandmarkLoc
_triIndexMap
_numTri
_triList
T^f,V_orientation
cameraMotionDetection:
generateThresholds:withConfidences:
autoLiveMotionScore:
initWithQueue:turbo:
prewarmWithWidth:height:
analyzeFrame:withTimestamp:andDuration:completion:
_frame
_stats
_cameraMotionParams
_cameraMotionConfidences
_turbo
Tf,R,V_actionScore
vcp_firstEnabledTrackWithMediaType:
formatDescriptions
findMetaTrackforType:
initWithTrack:
analyzerForTrackType:withTransform:requestAnalyses:formatDescription:
copyNextMetadataGroup
processMetadataGroup:flags:
finalizeAnalysis
publicResults
lastObject
processMetaTrackForType:cancel:flags:
checkTimeRangeConsistency
postProcessOrientationResults
initWithAVAsset:forAnalysisTypes:
analyzeAsset:flags:
_avAsset
_transform
_metaTracks
_publicMutableResults
_privateMutableResults
T@"NSDictionary",R,N
timeWithCMTime:
currentLocale
setLocale:
sharedLogManager
dateFormatter
logLevel
_logLevel
Ti,R,V_logLevel
createModelWithResConfig:
substringToIndex:
assetResourcesForAsset:
initWithTransform:timeRange:isLivePhoto:frameStats:keyFrameResults:
initWithAnalysisType:isLivePhoto:hadFlash:hadZoom:
setMaxHighlightDuration:
analyzeFrame:withTimestamp:
preparePostProcessingStatsFromFaceRange:junkResults:
postProcess
postProcessKeyFrames
keyFrames
prepareRequiredQualityResult:junkDetectionResult:descriptorResult:faceResult:saliencyResult:actionResult:subtleMotionResult:voiceResult:keyFrameResult:sceneResults:humanActionResults:humanPoseResults:cameraMotionResults:orientationResults:frameSize:
generateHighlights
timerange
score
keyFrame
bestPlaybackCrop
isTrimmed
isAutoPlayable
reportMovieCurationAnalysisResults:withSummaryAnalytics:
addHighlight:to:
movieSummary
addSummary:to:
keyFrameScores
initWithAnalysisTypes:transform:timeRange:isLivePhoto:frameStats:hadFlash:hadZoom:keyFrameResults:
analyzeKeyFrame:withTimestamp:andDuration:flags:
loadVideoAnalysisResults:audioAnalysisResults:andFaceRanges:frameSize:
generateMovieCurations
_keyFrameAnalyzer
_highlightAnalyzer
_descriptorResults
_qualityResuls
_junkResults
_actionResults
_subtleMotionResults
_voiceResults
_sceneResults
_humanActionResults
_humanPoseResults
_cameraMotionResults
_saliencyResults
_orientationResults
_faceRanges
_frameSize
_frameStats
_isLivePhoto
_hadFlash
_hadZoom
initWithTime:andScore:
timeStamp
_timeStamp
T{?=qiIq},R,N,V_timeStamp
Tf,R,N,V_score
initWithTimeRange:score:andKeyFrame:
_keyFrame
_timerange
T{?={?=qiIq}{?=qiIq}},R,N,V_timerange
T@"VCPVideoKeyFrameResult",R,N,V_keyFrame
initWithPHAsset:
phAsset
highlights
_phAsset
_highlights
T@"PHAsset",R,N,V_phAsset
T@"NSMutableArray",R,&,N,V_highlights
descriptor
junkScore
expressionScore
voiceScore
humanActionScore
humanPoseScore
initWithTimeRange:
mergeSegment:
isShort
copyScoresFrom:
checkAutoPlayable
setTimerange:
setScore:
setJunkScore:
setExpressionScore:
setVoiceScore:
setHumanActionScore:
setHumanPoseScore:
setBestPlaybackCrop:
setIsAutoPlayable:
setIsTrimmed:
setDescriptor:
setKeyFrame:
_isAutoPlayable
_isTrimmed
_junkScore
_expressionScore
_voiceScore
_humanActionScore
_humanPoseScore
_descriptor
_bestPlaybackCrop
T{?={?=qiIq}{?=qiIq}},N,V_timerange
Tf,N,V_score
Tf,N,V_junkScore
Tf,N,V_qualityScore
Tf,N,V_expressionScore
Tf,N,V_actionScore
Tf,N,V_voiceScore
Tf,N,V_humanActionScore
Tf,N,V_humanPoseScore
T{CGRect={CGPoint=dd}{CGSize=dd}},N,V_bestPlaybackCrop
TB,N,V_isAutoPlayable
TB,N,V_isTrimmed
T@"VCPImageDescriptor",&,N,V_descriptor
T@"VCPVideoKeyFrame",&,N,V_keyFrame
T{?={?=qiIq}{?=qiIq}},N,V_timeRange
generateInitialSegments
computeHighlightScoreWithConstraint
computeQualityTrimFor:withKeyFrame:
computeActionFaceTrimFor:
computeSteadyTranslationTrimFor:
checkCameraZoom:
generateExpressionSegments:
analyzeOverallQuality:
pickKeyFramesInRange:
computeBestPlaybackCrop:
junkScoreForTimerange:
qualityScoreForTimerange:
SetKeyFramesForSegments:
computeExpressionScoreInTimerange:
computeActionScoreInTimerange:
computeVoiceScoreInTimeRange:
pickHighlightsFrom:
searchFeatureVectorOfSegment:
computeHighlightScoreOfSegment:
evaluateSegment:
addSegment:
computeHumanActionScoreInTimerange:
computeHumanPoseScoreInTimerange:
expressionChangeScore
actionScoreForTimerange:
subtleMotionScoreForTimerange:
expressionScoreForTimerange:
voiceScoreForTimerange:
cameraMotionScoreForTimerange:
visualPleasingScoreForTimerange:
computeHighlightScoreOfRange:
mergeShortSegments
mergeSimilarSegments
_qualityResults
_featureResults
_keyFrameResults
_expressionSegments
_internalResults
_internalConstraintResults
_maxDurationInSeconds
requestURLAssetAnalysis:forAssetWithResourcePaths:withOptions:analysisTypes:sandboxTokens:withReply:
requestAssetAnalysis:forPhotoLibraryURL:withLocalIdentifiers:realTime:withReply:
requestLibraryProcessing:withTaskID:forPhotoLibraryURL:withOptions:andReply:
requestAssetProcessing:withTaskID:forLocalIdentifiers:fromPhotoLibraryWithURL:withOptions:andReply:
cancelRequest:
cancelAllRequests
cancelBackgroundActivityWithReply:
notifyLibraryAvailableAtURL:
requestSuggestedPersons:withPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:andPhotoLibraryURL:andReply:
requestUpdateKeyFacesOfPersons:withLocalIdentifiers:andForceUpdate:andPhotoLibraryURL:andReply:
requestFaceCandidatesforKeyFace:withPersonsWithLocalIdentifiers:andPhotoLibraryURL:andReply:
requestResetFaceClassificationModel:withPhotoLibraryURL:andReply:
requestSuggestedMePersonIdentifier:withContext:andPhotoLibraryURL:andReply:
requestPersonPromoterStatus:withAdvancedFlag:andPhotoLibraryURL:andReply:
requestClusterCacheValidation:withPhotoLibraryURL:andReply:
requestResetFaceClusteringState:withPhotoLibraryURL:andReply:
requestReclusterFaces:withPhotoLibraryURL:andReply:
requestRebuildPersons:withLocalIdentifiers:andPhotoLibraryURL:andReply:
requestPersonPreferenceForPhotoLibraryURL:andReply:
requestVIPModelStorageFilepathForPhotoLibraryURL:andReply:
interfaceWithProtocol:
setClasses:forSelector:argumentIndex:ofReply:
initWithMachServiceName:options:
setExportedObject:
setRemoteObjectInterface:
reportProgress:forRequest:
setExportedInterface:
setInterruptionHandler:
setInvalidationHandler:
resume
taskForURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:
stringWithUTF8String:
connection
remoteObjectProxyWithErrorHandler:
vcp_defaultURL
vcp_url
requestProcessingWithTaskID:forPhotoLibrary:withOptions:progessHandler:andCompletionHandler:
errorWithDescription:
requestProcessingWithTaskID:forAssets:withOptions:progressHandler:andCompletionHandler:
vcp_defaultPhotoLibrary
taskWithPhotoLibraries:andCompletionHandler:
taskWithAssets:andCompletionHandler:
synchronousRemoteObjectProxyWithErrorHandler:
invalidate
sharedAnalysisService
analysisService
queryProgressDetail:forPhotoLibraryURL:andTaskID:
requestAnalysisTypes:forAssetWithResourceURLs:withOptions:progressHandler:andCompletionHandler:
requestBackgroundAnalysisForAssets:realTime:progessHandler:completionHandler:
requestBackgroundProcessingWithTaskID:forPhotoLibrary:progessHandler:completionHandler:
requestSceneProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestFaceProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestMultiWorkerProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestFullProcessingForPhotoLibrary:withOptions:progressHandler:andCompletionHandler:
requestLivePhotoEffectsForAssets:withOptions:progressHandler:andCompletionHandler:
requestSceneProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestFaceProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestQuickFaceIdentificationForPhotoLibraryURL:withOptions:andCompletionHandler:
requestSceneprintProcessingForAssets:withOptions:progressHandler:andCompletionHandler:
requestVideoStabilizationForAssets:withOptions:progressHandler:andCompletionHandler:
cancelBackgroundActivity
requestPersonPreferenceForPhotoLibraryURL:completionHandler:
requestVIPModelFilepathForPhotoLibraryURL:completionHandler:
_connection
_managementQueue
_handlerQueue
_progressBlocks
_nextRequestID
requestSuggestedPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:photoLibraryURL:progessHandler:completionHandler:
requestUpdateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:photoLibraryURL:progessHandler:completionHandler:
requestFaceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:photoLibraryURL:progessHandler:completionHandler:
requestResetFaceClassificationModelForPhotoLibraryURL:progressHandler:completionHandler:
requestSuggestedMePersonIdentifierWithContext:photoLibraryURL:progressHandler:completionHandler:
requestPersonPromoterStatusWithAdvancedFlag:photoLibraryURL:progressHandler:completionHandler:
requestClusterCacheValidationWithPhotoLibraryURL:progressHandler:completionHandler:
requestResetFaceClusteringStateWithPhotoLibraryURL:progressHandler:completionHandler:
requestReclusterFacesWithPhotoLibraryURL:progressHandler:completionHandler:
requestRebuildPersonsWithLocalIdentifiers:photoLibraryURL:progressHandler:completionHandler:
longLongValue
storeAnalysis:forAsset:fromPhotoLibraryURL:withReply:
registerClient:forPhotoLibraryURL:withReply:
sharedDatabaseForPhotoLibrary:
sceneClassifications
sceneIdentifier
vcp_setVersion:
vcp_setDateModified:
date
vcp_setDateAnalyzed:
vcp_setFlags:
vcp_fingerprint:
vcp_setFingerprint:
vcp_setResult:forKey:
vcp_addTypes:
mediaType
vcp_allResourcesForAsset:
vcp_fullAnalysisTypesForResources:
sharedInstance
hasWifiOrEthernetConnection
vcp_eligibleForStreaming:
vcp_eligibleForVideoDownload:
isVideo
canAnalyzeUndegraded:withResources:
setAllowStreaming:
hasAdjustments
vcp_hasLocalPhoto:
analyzeAsset:
isPhoto
vcp_types
absoluteString
pathExtension
movieAssetWithURL:
analyzerWithVCPAsset:withExistingAnalysis:forAnalysisTypes:
livePhotoAssetWithImageURL:andMovieURL:
imageAssetWithURL:
analyzerWithVCPAsset:forAnalysisTypes:
isAssetBlacklisted:blacklistDate:
_addClassificationResults:analysis:
vcp_degraded
_metaAnalysisTypesForAsset:
_analyzeOndemand:forAnalysisTypes:withExistingAnalysis:andOptions:storeAnalysis:
sharedMediaAnalyzer
_databaseForPhotoLibrary:
requestAnalysis:forAsset:withExistingAnalysis:andDatabase:andOptions:
queryAssetsAnalyzedSince:
setSortDescriptors:
fetchAssetsWithLocalIdentifiers:options:
assetsFromPhotoLibrary:analyzedSinceDate:completionHandler:
sceneprintProperties
sceneprint
distanceIdentity
setWithObject:
queryAnalysisForAsset:withTypes:
_getSceneDescriptors:asDescriptorClass:withSceneRange:andAnalysisResults:
_getDistanceDescriptorClass
_checkDuplicate:withAsset:duplicate:
_queryDistanceDescriptor:ofAsset:withExistingAnalysis:andDatabase:timeRange:lastFeature:isDegraded:
computeDistance:fromArray:toArray:
computeDistance:withDescriptorClass:fromAsset:toAsset:
vcp_flags
canUseLastFrameOfAsset:withResources:
generateDistanceDescriptor:withDescriptorClass:forAsset:withResources:lastFrame:
arrayWithObject:
dictionaryWithDictionary:
_typesToRemove:requested:
requestAnalysis:forAssets:withOptions:andProgressHandler:andCompletionHandler:
requestAnalysisTypes:forAssets:withOptions:andProgressHandler:analyses:
requestAnalysis:forAssets:withOptions:andProgressHandler:andError:
fetchAssetsInAssetCollection:options:
compare:
sortedArrayUsingSelector:
reverseObjectEnumerator
recognizeFaces:
vcp_queryPHFaces:results:
initWithFlagHasFaceOrPet:
assetWithPHAsset:
analyzeAsset:onDemand:cancel:statsFlags:results:
numberWithUnsignedLongLong:
_getDatabaseSandboxExtensionForPhotoLibraryURL:
requestAnalysisTypes:forAssetWithResourceURLs:withOptions:error:
analyzeOndemand:pairedURL:forAnalysisTypes:error:
requestAnalysisForAsset:analysisTypes:progressHandler:completionHandler:
cancelAnalysisWithRequestID:
assetsAnalyzedSinceDate:completionHandler:
distanceFromAsset:toAsset:duplicate:distance:
distanceFromAsset:timeRange:toAsset:timeRange:duplicate:distance:
requestAnalysesForAssets:analysisTypes:allowOndemand:progressHandler:completionHandler:
requestAnalysisTypes:forAssets:allowOndemand:progressHandler:error:
curateMovieAssetsForCollection:withAlreadyCuratedAssets:andDesiredCount:allowOnDemand:
requestCallerIdentificationForFaces:
requestMovieHighlightsForAssets:withOptions:
requestLivePhotoEffectsForAssets:allowOnDemand:flags:
completeStorage
_analysisQueue
_storageQueue
_storageGroup
_standalone
_noResultStrip
_sandboxQueue
_sandboxHandles
numOfFrames
updateSegment:
resetSegment:
finalizeAtTime:
_numOfFrames
T{?={?=qiIq}{?=qiIq}},R,N,V_timeRange
TQ,R,N,V_numOfFrames
assetReaderOutputMetadataAdaptorWithAssetReaderTrackOutput:
nextTimedMetadataGroup
_readerOutput
_readerOutputAdaptor
T@"NSData",R,N
TS,R,N
Tq,D,N
getMaximumHighlightInSec
vcp_setStatsFlags:
initWithVCPAsset:withExistingAnalysis:forAnalysisTypes:
vcp_setTypes:
vcp_statsFlags
vcp_addEntriesFromResults:
vcp_syncPoint
vcp_setSyncPoint:
tracksWithMediaType:
loadValuesAsynchronouslyForKeys:completionHandler:
vcp_addFlags:
processExistingAnalysisForTimeRange:analysisTypes:
createDecoderForTrack:timerange:forAnalysisTypes:
createVideoAnalyzer:withFrameStats:
videoStabilizerforAnalysisType:withMetadata:sourceSize:cropRect:
vcp_appendResults:
vcp_endTime
analyzeVideoSegment:timerange:forAnalysisTypes:cancel:
allowStreaming
loadPropertiesForAsset:
vcp_setQuality:
performMetadataAnalysisOnAsset:withCancelBlock:
vcp_fullFrameSize
vcp_cleanApertureRect
initWithMetadata:sourceSize:cropRect:
storeAnalytics:isLivePhoto:
vcp_startTime
analyzeVideoTrack:start:forAnalysisTypes:cancel:
generateKeyFrameResource:
vcp_removeSyncPoint
analyzeOverallQuality:withFpsRate:
generateLivePhotoRecommendationForResults:andPrivateResults:usingFaceAction:
setActivityLevel:
vcp_addStatsFlags:
setRequestedTimeToleranceAfter:
setRequestedTimeToleranceBefore:
vcp_appendResult:forKey:
initWithPHAsset:withPausedAnalysis:forAnalysisTypes:
maxHighlightDuration
faceDominated
setFaceDominated:
_supportConditionalAnalysis
_existingAnalysis
_prepareLivePhotoScenes
_allowStreaming
_maxHighlightDuration
TB,N,V_allowStreaming
Tf,N,V_maxHighlightDuration
TB,N,V_faceDominated
Tq,R,V_status
T@"VCPProtoBounds",&,N,V_bounds
Ti,N,V_flags
vcp_sortBySize
vcp_isPhotoResourceUsable:
vcp_isMovie
vcp_isVideoResourceUsable:
vcp_isOriginalLocal
vcp_hasLocalAdjustments
vcp_resourceWithType:
vcp_smallResourceMeetingCriteria:
vcp_isPhoto
vcp_localMovieResourcesSorted:
vcp_photoResourcesSorted:
bundleWithIdentifier:
vcp_captureDeviceMake
vcp_captureDeviceModel
vcp_isAppleCapture
unsignedLongValue
vcp_dateAnalyzed
vcp_fingerprint
vcp_streamedVideo
vcp_mutableResults
vcp_setResults:
vcp_time
vcp_timerange
vcp_setTimerange:
vcp_imagesPredicate:
vcp_stillImagesPredicate:
vcp_livePhotosPredicate:
vcp_moviesPredicate:
createFaceHeatMap:imageFaces:
computeOverallFaceQualityScore:
selectKeyFrameRangeWithMotion:stillTimestamp:isMetaMotion:
fetchAndComputeScoreForKeyFrame:withResult:
semanticScore
setSemanticScore:
copyFrom:
computeScoreForPhoto:withRefKeyFrame:
reportLivePhotoKeyFrameAnalysisResults:selectedKeyFrame:originalStillKeyFrame:stillScore:stillFQScore:stillTimestamp:useSemanticOnly:isKeyFrameSuggested:
getFaceHeat:
updateFaceHeatMap:
initWithWidth:height:
analyzeLivePhotoKeyFrame:irisPhotoOffsetSec:originalIrisPhotoOffsetSec:photoTextureScore:hadFlash:cancel:
_photoSharpnessReliable
_photoSharpness
_petsDominant
_ignoreFace
_faceHeatMap
vcp_faceRectFrom:
vcp_flagsForPHFace:withFaceRect:
objectID
_computeFingerPrintsOfAsset:completionHandler:
fetchAssetsMatchingAdjustedFingerPrint:photoLibrary:
fetchAssetsMatchingMasterFingerPrint:photoLibrary:
vcp_fetchAssetsMatchingFingerprint:forPhotoLibrary:
timeIntervalSinceReferenceDate
loadModelAtPath:error:
creationDate
imageWithURL:assetWidth:assetHeight:imageCreationOptions:adjustmentVersion:creationDate:
faceObservationFromFaceprintData:
classifyFaceObservation:withModel:error:
quickClassificationFaceAdjustmentVersion
_loadPersonsModel
_loadPVImage:forAsset:
_detectFacesWithPVImage:forAsset:withAnalysis:
_classifyFaces:forAsset:withResults:
_persistResults:withFaces:forAsset:
vcp_analysisPreferences
faceIDModelRebuildPeriod
faceIDModelAlwaysRebuild
_personsModelLastGenerationDidExceedTimeInterval
fetchPersonsForFaceIDModel
persistModel:toPath:error:
setIncludeOnlyFacesWithFaceprints:
newMutablePersonsModel
UUIDString
addFaceObservations:forPersonIdentifier:toModel:error:
_persistPersonsModel:error:
trainingFaceObservationsForPersonWithUniqueIdentifier:canceller:error:
arrayByAddingObjectsFromArray:
setIsInVIPModel:
_needToGeneratePersonsModel
_generatePersonsModelShouldForce:extendTimeoutBlock:cancel:
generatePersonsModelWithExtendTimeout:cancel:
_personsModel
_management
adjustmentTimestamp
setExcludeMontageAssets:
vcp_typeDescription
vcp_isSdofPhoto
vcp_isVideoTimelapse
sceneAnalysisProperties
sceneAnalysisVersion
sceneAnalysisTimestamp
instancesRespondToSelector:
attributesOfItemAtPath:error:
resourceForAsset:withResources:
vcp_originalSize
processExistingAnalyses:
mediaAnalysisProperties
blurrinessScore
vcp_usePHFace
vcp_needFaceProcessing
dictionaryWithObjectsAndKeys:
updateDegradedFlagForMajorDimension:
downscaleImage:scaledImage:majorDimension:
vcp_usePHFaceExpression
existingAnalysisForMovieAnalyzer
checkFaceDominant
initWithDictionary:
analyzeImage:performedAnalyses:cancel:
vcp_removeResultForKey:
_irisAnalyses
_phFaceResults
_phFaceFlags
_imageBlurTextureScore
_preAnalysisSharpnessScore
vcp_mediaAnalysisDirectory
fetchAssetsWithMediaType:options:
internalPredicate
isCloudPhotoLibraryEnabled
cplStatus
lastSuccessfulSyncDate
isExceedingQuota
lastCompletePrefetchDate
vcp_isCPLEnabled
vcp_isCPLDownloadComplete
_vcp_analysisPreferencesURL
dataWithPropertyList:format:options:error:
writeToURL:options:error:
_vcp_updateAnalysisPreferencesWithEntries:keysToRemove:
modelFileName
vcp_assetCountWithMediaType:forTaskID:
vcp_isCPLSyncComplete
vcp_canStreamingForFaceAnalysis
computeControlPointsCamera:Vt:
computePoints3DCamera
correctSigns
computeRT:T:
computeProjectionError:T:
configureGaussNewton:R6x1:betas:jacobian:residual:
getControlPoints
computeBarycentricCoordinates
computeSVDVt:Vt:
computeL6x10:L6x10:
computeR6x1:
estimateBetasN1:R6x1:betas:
estimateBetasN2:R6x1:betas:
estimateBetasN3:R6x1:betas:
optimizeBetas:R6x1:betas:
estimateRT:betas:R:T:projectionError:
estimatePose:
_numPoints
_controlPointsWorld
_controlPointsCamera
_pointsWorld
_pointsImage
_alphas
_points3DCamera
_cameraOrientation
unarchivedObjectOfClass:fromData:error:
computeDistance:withDistanceFunction:error:
_sceneprint
ComputeSceneDelta:
decideLensSwitchPoint:
PrintSegments
finalizeAnalysisPass:
isSegmentPoint
_sceneDeltaBuffer
_activeSegment
_sceneSegments
_firstFrame
_frameTimeRange
_currentStatus
_isSegmentPoint
setGyroStabilization:
valueWithCMTime:
setAnalysisResultRef:
analysisResultRef
setAnalysisConfidence:
analysisConfidence
setValidStabilization:
convertAnalysisResult
_analysisSessionRef
initWithAssetURLs:andPerAssetResultsHandler:
processResults:andError:forAssetURL:
flushWithError:
_assetURLs
_perAssetResultsHandler
initWithService:
processResults:andError:forAssetURL:withIdentifier:
proxyWithService:
initWithServiceName:
serviceWithName:
requestImageProcessingTask:forIOSurface:withOptions:andReply:
requestImageProcessingTask:forAssetURL:withSandboxToken:options:andReply:
requestImageProcessingTask:withIdentifier:forAssetURLs:withSandboxTokens:options:andReply:
allowedClasses
sandboxExtensionForURL:error:
taskWithAssetURLs:options:perAssetResultsHandler:andCompletionHandler:
requestImageProcessingTask:forAssetURLs:withOptions:perAssetResultsHandler:andCompletionHandler:
_serviceName
_connectionQueue
_batchRequestQueue
_batchRequestIdentifier
_batchRequestState
initWithProcessingTypes:forPixelBuffer:withOptions:andCompletionHandler:
_analyzeFace:error:
_analyzeScene:error:
taskWithProcessingTypes:forPixelBuffer:withOptions:andCompletionHandler:
_processingTypeScene
_processingTypeFace
_analysisFlags
_options
setupModel:
initWithFocalLengthInPixels:principalPoint:cameraTowardsPositiveZ:
updateIntrinsic:vc:
updateFocalLengthInPixels:
initWithModelFile:
numVertices
meanBlendshape
getInternal3dLandmarksCoordinates:lm3dPos:
componentsBlendshape
getOneInternalLandmarkCoordinates:lmCoord:lmWeight:lm3dPos:
updateBoundaryLandmarkCoordinates:pts2D:lm2D:lm3dPos:
project3Dto2D:intrinsinc:extrinsic:numVert:out2dpts:
calculateMesh:numVertices:blendshapes:outputMesh:
updateBoundaryLmForShapeOptimization
updateShapeCoeff:extrinsicMatrix:pts2D:exprWeights:outputblendshapes:
moveBoundaryLandmarks:output:isInput:
projectAndUpdateBoundary
optimizeProjectionMatrix:tracking:firstPass:
updateBoundary3dLandmarkBlendshapes:numBlendshapes:pts2D:lm2D:lmBlendshapes:
calculateBlendshapeWeights:prevWeights:lmBlendshapes:maxIter:
updateMeshAndLm3dAfterExpressionChange
calculateIdentityCoefficients:extrinsicMatrix:pts2D:exprWeights:lm3DMeanBlendshapes:lm3DComponents:maxIter:
calculateModelBlendshapes:outputBlendshapes:
tensorCoeff
blendshapeComponentIndex
calculatePosePnpSolver:
reestimateProjectionMatrixPnP
updateIdentityShape:
getPoseParam
estimateExtrinsicsWith:andPoints3D:andNumPoints:
initWithMode:
setCameraIntrinsics:uc:vc:
getEulerAngle:
resetIdentityAndExpressions
trackFaceMesh:
fitOneImage:
getPose
blendShapes
updateMeshVertices
processingMode
setProcessingMode:
identityInit
setIdentityInit:
meshVertices
vertexCount
detectionModeCounterShapeModel
setDetectionModeCounterShapeModel:
_tensorModel
_numVertices
_curMesh
_cur2D
_numInternalLms
_lmCoord
_lmWeight
_numBoundaryLms
_boundaryLmIndices
_numBoundaryVertices
_boundaryVertices
_boundaryLandmarkValidity
_chPts
_chPtSelected
_boundaryLmUpdated
_chCount
_curBlendshapes
_curCoeff
_curExprWeights
_prevExprWeights
_exprWeightDiagMatrix
_transformedCoeff
_blendShapeDelta
_trans
_intrinsicMatrix
_extrinsicMatrix
_eulerAngle
_rotMatrix
_LM2D
_LM3D
_lm3dBlendshapes
_lm3dMeanBlendshapes
_lm3dBlendshapeComponents
_numFrmsSinceLastShapeUpdate
_shapeUpdateInProgress
_poseSolver
_updateShapeQueue
_asyncBlendshapes
_asyncLmBlendshapes
_asyncExtMat
_asyncLm2d
_asyncWeights
_identityInit
_processingMode
_detectionModeCounterShapeModel
_meshVertices
_vertexCount
Ti,V_processingMode
TB,V_identityInit
T^,R,V_meshVertices
TQ,R,V_vertexCount
Ti,V_detectionModeCounterShapeModel
convertPixelBuffer:toPixelBuffer:withPixelFormat:
analyzeImages:secondImage:cancel:
getFlowWithHeight:andWidth:
prepareAnalyzerWithCVPixelBuffer:
preProcessing:
generateMotionFlow
generateSubleMotionScore:
subtleMotionScore
_flow
_block
_scale
_scaler
_motionFlowAnalyzer
_frameArray
_frameWidth
_frameHeight
_downScaleWidth
_downScaleHeight
_flowWidth
_flowHeight
_blockSize
_frameNum
_subtleMotionScore
Tf,R,V_subtleMotionScore
initWithRequest:andConfiguration:
_request
_frameInterval
_timeInterval
T@"VNRequest",R,N,V_request
T{?=qiIq},R,N,V_timeInterval
TQ,R,N,V_frameInterval
_numBlendshapePlusOne
_numComponents
_numIdentities
_meanBlendshape
_tensorCoeff
_componentsBlendshape
_blendshapeComponentIndex
Ti,R,V_numVertices
T^f,R,V_meanBlendshape
T^f,R,V_tensorCoeff
T^f,R,V_componentsBlendshape
T^i,R,V_blendshapeComponentIndex
prepareImage:
calculateOrientationResponses
generateOrientationMap
generateLineWeightMap:weightMap:
voteVanishingPoint:
searchVanishingPointandDominantLine:lineGroup:vanishingPoint:vanishingPointConfidence:dominantLine:
extractUsefulAreaFrom:to:withOffset:stridePadded:width:height:
averageOrientationResponses:withCurrentMap:
smoothFiltering:width:height:
calculateConfidence:lineDistance:vaninshingPoint:vanishingPointConfidence:
isVerticalOrHorizontal:
_orientationResponses
_orientionMap
_confidenceMap
_edgeWeightMap
_stridePadded
_offset
_validDimension
_pixelMean
_pixelVar
_gaborFilter
isScoreValid:
decideSegmentPointUsingHinkleyDetector:
isActive:
updateActiveThreshold
mergeSameTypeSegments
printSegments:
prepareTrimmingWithTrimStart:andTrimEnd:
mergeConsecutiveShortSegments
mergeSparseShortSegments
analyzeFrameWithTimeRange:andActionScore:
decideSegmentPointBasedOnActionScore:
finalizeWithDestructiveTrimStart:trimEnd:
postProcessSegmentsWithCaptureTime:trimStart:
segments
activeSegment
_activeHinkleyDetector
_activeThreshold
_postProcessStart
fetchRequest
checksum
T@"NSData",&,D,N
cloudIdentifier
T@"NSString",C,D,N
T@"NSDate",C,D,N
embeddingType
embeddingVersion
processed
random
exceptionWithName:reason:userInfo:
unimplementedExceptionForMethodName:
modificationDate
fingerprint
isImage
isMovie
mainFileURL
scenes
typeDescription
Tq,R,N
TQ,R,N
T@"NSDate",R,N
T@"VCPFingerprint",R,N
TB,R,N
T@"NSString",R,N
T@"NSURL",R,N
isPano
isLivePhoto
isScreenshot
isHDR
isSDOF
exif
imageWithPreferredDimension:
vcp_flashFired
vcp_scaledExposureTime
hadFlash
exposureTimeSeconds
photoOffsetSeconds
originalPhotoOffsetSeconds
Tf,R,N
isTimelapse
isSlowmo
duration
slowmoRate
timelapseRate
movie
streamedMovie
originalMovie
originalMovieSize
Td,R,N
dataWithBytes:length:
bytes
initWithVertices:vertexCount:
vertices
_vertices
TQ,R,N,V_vertexCount
Tr^,R,N
getBytes:length:
initWithTransform:blendShapes:geometry:
transform
geometry
_blendShapes
_geometry
T{?=[4]},R,N,V_transform
T@"NSDictionary",R,N,V_blendShapes
T@"VCPFaceGeometry",R,N,V_geometry
initWithFocalLengthInPixels:offline:
initWithFocalLengthInPixels:
initWithAnalysisTypes:withPreferredTransform:withFocalLengthInPixels:withAnalysisQueue:withTurbo:
frameFaceResults
transformForAngle:pixelBuffer:
flipTransform:
analyzeFrameForPose:withFaceRect:withTimestamp:
rotateTransform:byAngle:
analyzeFrame:withFaceRect:withRotation:withTimestamp:
isTracked
regionsOfInterest
analyzeFrameWithTimeRange:analysisData:
isReady
shouldCutAt:stillPTS:withCut:
analyzerForAnalysisTypes:withPreferredTransform:properties:
aggregateAnalysisForTypes:withFramesMeta:properties:
prewarmWithProperties:
updatePreferredTransform:properties:
analyzePixelBuffer:withTimestamp:andDuration:properties:error:
analyzePixelBuffer:withTimestamp:andDuration:properties:completion:
analyzeAudioBuffer:
aggregatedResults
_poseAnalyzer
_meshAnalyzer
_videoAnalysis
_audioAnalyzer
_faceDetector
_sceneChangeAnalyzer
_lightMotionAnalyzer
_trimAnalyzer
_homeKitMotionAnalyzer
_rotator
_rotatorForFacePose
_preferredTransform
_focalLengthInPixels
_aggregatedResults
_rotationAngleForFacePose
_preferredAngle
_preWarmed
T@"NSDictionary",R
sharedDatabaseManager
_databases
copyBlock:withStride:toBlock:
blockContentDetection:
contentAnalysis
detectPixelBuffer:contentType:
_previousContentType
_argbPixelBuffer
_argbTransferSession
sharedPhotoLibrary
defaultPhotoLibrary
fileSize
assetLocalIdentifier
mutableBytes
initWithBytesNoCopy:length:deallocator:
dataWithLength:
setDownloadIsTransient:
setProgressHandler:
_reportDownload:
cancelDataRequest:
maxSizeBytes
requestDownloadOfResource:
flush
setCancel:
_mutex
_buffer
_localIdentifier
_semaphore
_dataTask
T@?,C,N,V_cancel
initWithVotes:andCount:
rate
votes
setVotes:
setCount:
_votes
_count
Tq,N,V_votes
Tq,N,V_count
recognizeFace:
_sessions
initWithURLAsset:withOptions:analysisTypes:progressHandler:completionHandler:
_pairedAssetURL
_progressHandler
face
_faceprint
T@"VNFaceprint",&,N,V_faceprint
initWithLocalIdentifier:andTaskID:andStatus:andAttempts:andNextRetryDate:
taskID
attempts
nextRetryDate
_attempts
_nextRetryDate
TQ,R,N,V_taskID
T@"NSString",R,N,V_localIdentifier
TQ,R,N,V_status
TQ,R,N,V_attempts
T@"NSDate",R,N,V_nextRetryDate
createInput:keypoints:cnnInputHeight:cnnInputWidth:
getDetectionScore:
planDestroy
gestureDetection:score:
entityForName:inManagedObjectContext:
initWithEntity:insertIntoManagedObjectContext:
faceFromManagedObject:
T@"VCPProtoTime",&,N,V_timestamp
vcp_defaultMediaAnalysisDatabaseFilepath
stringByDeletingLastPathComponent
fileExistsAtPath:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
stringByAppendingPathComponent:
fileURLWithPath:
persistentStoreDescriptionWithURL:
bundleForClass:
mergedModelFromBundles:
persistentContainerWithName:managedObjectModel:
setPersistentStoreDescriptions:
viewContext
setMergePolicy:
newBackgroundContext
loadPersistentStoresWithCompletionHandler:
fetchRequestWithEntityName:
executeFetchRequest:error:
sessionFromManagedObject:
performBlockAndWait:
managedObjectForContext:
save:
fetchAllFaceTimeSessions
storeFaceTimeSession:
_persistentContainer
_backgroundContext
initWithSessionID:callerID:andDate:
sessionID
callerID
session
createWithSessionID:callerID:andDate:
faces
addFace:
setSessionID:
setCallerID:
setDate:
_sessionID
_callerID
_date
T@"NSString",&,N,V_sessionID
T@"NSString",&,N,V_callerID
T@"NSDate",&,N,V_date
T@"NSArray",R,N
mutableSetValueForKey:
promoteUnverifiedPersonsWithUpdateBlock:
reset
frameProcessedByVideoAnalyzer
cameraMotionScore
subjectActionScore
colorfulnessScore
subMbMotionAvailable
faceArea
setFaceArea:
frameProcessedByHumanAnalyzer
setFrameProcessedByHumanAnalyzer:
frameProcessedByFaceDetector
setFrameProcessedByFaceDetector:
setDetectedFaces:
_frameProcessedByVideoAnalyzer
_subMbMotionAvailable
_frameProcessedByHumanAnalyzer
_frameProcessedByFaceDetector
_cameraMotionScore
_subjectActionScore
_colorfulnessScore
_frameExpressionScore
_faceArea
_detectedFaces
_videoActivityDescriptor
TB,N,V_frameProcessedByVideoAnalyzer
Tf,N,V_cameraMotionScore
Tf,N,V_subjectActionScore
Tf,N,V_interestingnessScore
Tf,N,V_obstructionScore
Tf,N,V_colorfulnessScore
TB,N,V_subMbMotionAvailable
Tf,N,V_frameExpressionScore
Tf,N,V_faceArea
TB,N,V_frameProcessedByHumanAnalyzer
TB,N,V_frameProcessedByFaceDetector
T@"NSMutableArray",&,N,V_detectedFaces
T@"VCPVideoActivityDescriptor",&,N,V_videoActivityDescriptor
requestAnalysis:ofFragmentData:withRequestID:properties:andReply:
requestAnalysis:ofFragmentSurface:withRequestID:properties:andReply:
requestIdentification:forFaceCrop:withOptions:andReply:
requestResidentMaintenance:withOptions:andReply:
expectedClasses
requestAnalysis:ofAssetData:withProperties:progressHandler:andCompletionHandler:
requestAnalysis:ofAssetSurface:withProperties:progressHandler:andCompletionHandler:
requestIdentificationForFaceCrop:withOptions:andCompletionHandler:
requestResidentMaintenanceWithOptions:andCompletionHandler:
resourceLoader
setDelegate:queue:
contentInformationRequest
setContentType:
setContentLength:
setByteRangeAccessSupported:
dataRequest
requestedOffset
requestedLength
dataWithBytesNoCopy:length:freeWhenDone:
respondWithData:
finishLoading
resourceLoader:shouldWaitForLoadingOfRequestedResource:
resourceLoader:shouldWaitForRenewalOfRequestedResource:
resourceLoader:didCancelLoadingRequest:
resourceLoader:shouldWaitForResponseToAuthenticationChallenge:
resourceLoader:didCancelAuthenticationChallenge:
setReachabilityForFlags:update:
_callbackQueue
_reachability
_hasWifiOrEthernetConnection
TB,R,N,V_hasWifiOrEthernetConnection
setCanceled:
TB,N,V_canceled
initWithFace:image:
descriptorForFace:image:
image
_face
enumerateObjectsAtIndexes:options:usingBlock:
imageRectForNormalizedRect:
groupingIdentifier
newFaceCropFromImageURL:withFaceRect:groupingIdentifier:error:
newFaceCropFromImageData:withFaceRect:groupingIdentifier:error:
normalizedFaceRect
_faceCropDataForImage:andNormalizedFaceRect:error:
initWithFaceCropData:originatingFace:
_generateFaceCropWithDescriptor:andCancelBlock:error:
_reportCancellationOfRemainingFaceCropSourceDescriptors:withStartingIndex:andFailureBlock:
generateFaceCropsFromSourceDescriptors:withProgressBlock:andFailureBlock:andCancelBlock:
phFacesFromPVFaces:withFetchOptions:
deleteFaces:
changeRequestForAsset:
phFaceFromPVFace:withFetchOptions:
creationRequestForFace
assignPropertiesOfPVFace:toPHFaceChangeRequest:
placeholderForCreatedFace
setFaceAdjustmentVersion:
originatingFace
manual
faceCropData
creationRequestsForFaceCropsWithOriginatingFace:resourceData:
fetchFaceCropsWithLocalIdentifiers:options:
fetchFacesForFaceCrop:options:
isValidFaceCrop:
faceBoundsFromFaceCrop:error:
faceCropDimensionsFromFaceCrop:error:
normalizedRectForRect:inBoundsOfSize:
imageDimensions
initWithData:orientation:options:
_bestFaceForFaceDetectionRequest:withRect:
faceObservationWithRequestRevision:boundingBox:andAlignedBoundingBox:
setForceFaceprintCreation:
changeRequestForFaceCrop:
setState:
setFace:
_faceFromFaceCrop:error:
_clearDirtyStateOnFaceCrops:error:
_associateFace:withFaceCrop:error:
faceprintVersion
initWithFaceprintData:faceprintVersion:
_updateFaceprint:ofPersistedFace:error:
fetchFaceGroupsWithFace:options:
state
_faceAssociatedWithFaceCrop:
_generateAndAssociateFaceprintedFaceForFaceCrop:error:
faceAlgorithmVersion
_updateFace:withFaceCrop:error:
_recordNeedToPersonBuildOnFaceGroupContainingFace:error:
resourceData
initWithLocalIdentifier:faceCropData:
_persistGeneratedFaceCrops:forAsset:error:
fetchFaceCropsNeedingFaceDetectionWithOptions:
_pvFaceCropFromPHFaceCrop:
_processDirtyFaceCrop:error:
initWithPhotoLibrary:andContext:
_persistFaceAnalysis:forPHAsset:
generateAndPersistFaceCropsForFaces:withAsset:andImage:error:
processDirtyFaceCropsWithCancelBlock:andExtendTimeoutBlock:
_faceAnalyzer
assetResourcesForAsset:includeDerivatives:
resources
vcp_originalResource
fetchSceneClassificationsGroupedByAssetLocalIdentifierForAssets:
sceneNameFromSceneId:
_cachedResources
_onceExif
_cachedExif
_onceScenes
_cachedScenes
vcp_isDecodable
vcp_exifFromImageURL:
vcp_fileSize
photoIrisProperties
photoIrisStillDisplayTime
vcp_originalVideoResource
isLocallyAvailable
assetWithURL:
vcp_livePhotoStillDisplayTime
vcp_getFpsRate
vcp_hasAdjustments:
vcp_avAsset
vcp_hasLocalSlowmo:
vcp_adjustmentsResource
vcp_assetWithoutAdjustments:duration:
vcp_smallMovieDerivativeResource
assetWithData:
detector:forceCPU:sharedModel:inputConfig:
detector:sharedModel:modelName:
handsDetectionGFT:handsRegions:cancel:
timeIntervalSinceDate:
computeIOU:boxB:handToFaceRatio:
handKeypointsDetection:box:keypoints:keypointConfidence:forGFT:
normalizeKeypoints:handCenter:
computeMaxMinDistance:prevFrameKeypoints:
avgPooling:
minPooling:
maxPooling:
fastSignLanguageDetection:ofPixelBuffer:withMetadata:
priorityAnalysis
majorityVoting:numClass:
calculatePriorityScore:ofPixelBuffer:withMetadata:
_prevComputedScore
_rotationAngle
_frameCounter
_handDetectedInPreviousFrame
_handsDetector
_handsKeypointsDetector
_fastGestureDetector
_prevFrameHandKeypoint
_prevTimeStampHandDetected
_prevTimeSignLanguageDetected
_classIndexTracker
_gestureScoreTracker
_motionScoreTracker
_iouTracker
_handKeypointTracker
_prevHandCenter
addImageBlurResults:
addImageCompositionResults:
addImageFaceResults:
addImageFeatureResults:
addImageJunkResults:
addImageSaliencyResults:
addImageShotTypeResults:
addLivePhotoRecommendationResults:
addLivePhotoSharpnessResults:
addMovieActivityLevelResults:
addMovieCameraMotionResults:
addMovieClassificationResults:
addMovieFaceResults:
addMovieFaceprintResults:
addMovieFeatureResults:
addMovieFineSubjectMotionResults:
addMovieInterestingnessResults:
addMovieMovingObjectResults:
addMovieMusicResults:
addMovieObstructionResults:
addMovieOrientationResults:
addMoviePreEncodeResults:
addMovieQualityResults:
addMovieSaliencyResults:
addMovieSceneResults:
addMovieSubjectMotionResults:
addMovieUtteranceResults:
addMovieVoiceResults:
addImagePetsResults:
addMovieSummaryResults:
addMovieHighlightResults:
addImageExposureResults:
addLivePhotoEffectsResults:
addImagePetsFaceResults:
addImageSceneprintResults:
addMovieSceneprintResults:
addImageHumanPoseResults:
addMovieHumanPoseResults:
addMovieApplauseResults:
addMovieBabbleResults:
addMovieCheeringResults:
addMovieLaughterResults:
addLivePhotoKeyFrameResults:
addLivePhotoKeyFrameStillResults:
addMovieHumanActionResults:
addMovieSubtleMotionResults:
addMovieLoudnessResults:
addMoviePetsResults:
addMoviePetsFaceResults:
addMovieStabilizationResults:
setAssetIdentifier:
setAssetMasterFingerprint:
setAssetAdjustedFingerprint:
imageBlurResultsCount
clearImageBlurResults
imageBlurResultsAtIndex:
imageCompositionResultsCount
clearImageCompositionResults
imageCompositionResultsAtIndex:
imageFaceResultsCount
clearImageFaceResults
imageFaceResultsAtIndex:
imageFeatureResultsCount
clearImageFeatureResults
imageFeatureResultsAtIndex:
imageJunkResultsCount
clearImageJunkResults
imageJunkResultsAtIndex:
imageSaliencyResultsCount
clearImageSaliencyResults
imageSaliencyResultsAtIndex:
imageShotTypeResultsCount
clearImageShotTypeResults
imageShotTypeResultsAtIndex:
livePhotoRecommendationResultsCount
clearLivePhotoRecommendationResults
livePhotoRecommendationResultsAtIndex:
livePhotoSharpnessResultsCount
clearLivePhotoSharpnessResults
livePhotoSharpnessResultsAtIndex:
movieActivityLevelResultsCount
clearMovieActivityLevelResults
movieActivityLevelResultsAtIndex:
movieCameraMotionResultsCount
clearMovieCameraMotionResults
movieCameraMotionResultsAtIndex:
movieClassificationResultsCount
clearMovieClassificationResults
movieClassificationResultsAtIndex:
movieFaceResultsCount
clearMovieFaceResults
movieFaceResultsAtIndex:
movieFaceprintResultsCount
clearMovieFaceprintResults
movieFaceprintResultsAtIndex:
movieFeatureResultsCount
clearMovieFeatureResults
movieFeatureResultsAtIndex:
movieFineSubjectMotionResultsCount
clearMovieFineSubjectMotionResults
movieFineSubjectMotionResultsAtIndex:
movieInterestingnessResultsCount
clearMovieInterestingnessResults
movieInterestingnessResultsAtIndex:
movieMovingObjectResultsCount
clearMovieMovingObjectResults
movieMovingObjectResultsAtIndex:
movieMusicResultsCount
clearMovieMusicResults
movieMusicResultsAtIndex:
movieObstructionResultsCount
clearMovieObstructionResults
movieObstructionResultsAtIndex:
movieOrientationResultsCount
clearMovieOrientationResults
movieOrientationResultsAtIndex:
moviePreEncodeResultsCount
clearMoviePreEncodeResults
moviePreEncodeResultsAtIndex:
movieQualityResultsCount
clearMovieQualityResults
movieQualityResultsAtIndex:
movieSaliencyResultsCount
clearMovieSaliencyResults
movieSaliencyResultsAtIndex:
movieSceneResultsCount
clearMovieSceneResults
movieSceneResultsAtIndex:
movieSubjectMotionResultsCount
clearMovieSubjectMotionResults
movieSubjectMotionResultsAtIndex:
movieUtteranceResultsCount
clearMovieUtteranceResults
movieUtteranceResultsAtIndex:
movieVoiceResultsCount
clearMovieVoiceResults
movieVoiceResultsAtIndex:
imagePetsResultsCount
clearImagePetsResults
imagePetsResultsAtIndex:
movieSummaryResultsCount
clearMovieSummaryResults
movieSummaryResultsAtIndex:
movieHighlightResultsCount
clearMovieHighlightResults
movieHighlightResultsAtIndex:
imageExposureResultsCount
clearImageExposureResults
imageExposureResultsAtIndex:
livePhotoEffectsResultsCount
clearLivePhotoEffectsResults
livePhotoEffectsResultsAtIndex:
imagePetsFaceResultsCount
clearImagePetsFaceResults
imagePetsFaceResultsAtIndex:
imageSceneprintResultsCount
clearImageSceneprintResults
imageSceneprintResultsAtIndex:
movieSceneprintResultsCount
clearMovieSceneprintResults
movieSceneprintResultsAtIndex:
imageHumanPoseResultsCount
clearImageHumanPoseResults
imageHumanPoseResultsAtIndex:
movieHumanPoseResultsCount
clearMovieHumanPoseResults
movieHumanPoseResultsAtIndex:
movieApplauseResultsCount
clearMovieApplauseResults
movieApplauseResultsAtIndex:
movieBabbleResultsCount
clearMovieBabbleResults
movieBabbleResultsAtIndex:
movieCheeringResultsCount
clearMovieCheeringResults
movieCheeringResultsAtIndex:
movieLaughterResultsCount
clearMovieLaughterResults
movieLaughterResultsAtIndex:
livePhotoKeyFrameResultsCount
clearLivePhotoKeyFrameResults
livePhotoKeyFrameResultsAtIndex:
livePhotoKeyFrameStillResultsCount
clearLivePhotoKeyFrameStillResults
livePhotoKeyFrameStillResultsAtIndex:
movieHumanActionResultsCount
clearMovieHumanActionResults
movieHumanActionResultsAtIndex:
movieSubtleMotionResultsCount
clearMovieSubtleMotionResults
movieSubtleMotionResultsAtIndex:
movieLoudnessResultsCount
clearMovieLoudnessResults
movieLoudnessResultsAtIndex:
moviePetsResultsCount
clearMoviePetsResults
moviePetsResultsAtIndex:
moviePetsFaceResultsCount
clearMoviePetsFaceResults
moviePetsFaceResultsAtIndex:
movieStabilizationResultsCount
clearMovieStabilizationResults
movieStabilizationResultsAtIndex:
imageBlurResultsType
imageCompositionResultsType
imageFaceResultsType
imageFeatureResultsType
imageJunkResultsType
imageSaliencyResultsType
imageShotTypeResultsType
imagePetsResultsType
imagePetsFaceResultsType
imageSceneprintResultsType
livePhotoEffectsResultsType
livePhotoRecommendationResultsType
livePhotoSharpnessResultsType
livePhotoKeyFrameResultsType
livePhotoKeyFrameStillResultsType
movieActivityLevelResultsType
movieCameraMotionResultsType
movieClassificationResultsType
movieFaceResultsType
movieFaceprintResultsType
movieFeatureResultsType
movieFineSubjectMotionResultsType
movieInterestingnessResultsType
movieMovingObjectResultsType
movieMusicResultsType
movieObstructionResultsType
movieOrientationResultsType
moviePreEncodeResultsType
movieQualityResultsType
movieSaliencyResultsType
movieSceneResultsType
movieSceneprintResultsType
movieSubjectMotionResultsType
movieSubtleMotionResultsType
movieUtteranceResultsType
movieVoiceResultsType
movieSummaryResultsType
movieHighlightResultsType
imageExposureResultsType
imageHumanPoseResultsType
movieHumanPoseResultsType
movieApplauseResultsType
movieBabbleResultsType
movieCheeringResultsType
movieLaughterResultsType
movieHumanActionResultsType
movieLoudnessResultsType
moviePetsResultsType
moviePetsFaceResultsType
movieStabilizationResultsType
setHasQuality:
hasQuality
setStatsFlags:
setHasStatsFlags:
hasStatsFlags
setTypesWide:
setHasTypesWide:
hasTypesWide
hasAssetAdjustedFingerprint
version
setVersion:
types
setTypes:
statsFlags
typesWide
assetIdentifier
assetModificationDate
setAssetModificationDate:
assetMasterFingerprint
assetAdjustedFingerprint
imageBlurResults
setImageBlurResults:
imageCompositionResults
setImageCompositionResults:
imageFaceResults
setImageFaceResults:
imageFeatureResults
setImageFeatureResults:
imageJunkResults
setImageJunkResults:
imageSaliencyResults
setImageSaliencyResults:
imageShotTypeResults
setImageShotTypeResults:
imagePetsResults
setImagePetsResults:
imagePetsFaceResults
setImagePetsFaceResults:
imageSceneprintResults
setImageSceneprintResults:
livePhotoEffectsResults
setLivePhotoEffectsResults:
livePhotoRecommendationResults
setLivePhotoRecommendationResults:
livePhotoSharpnessResults
setLivePhotoSharpnessResults:
livePhotoKeyFrameResults
setLivePhotoKeyFrameResults:
livePhotoKeyFrameStillResults
setLivePhotoKeyFrameStillResults:
movieActivityLevelResults
setMovieActivityLevelResults:
movieCameraMotionResults
setMovieCameraMotionResults:
movieClassificationResults
setMovieClassificationResults:
movieFaceResults
setMovieFaceResults:
movieFaceprintResults
setMovieFaceprintResults:
movieFeatureResults
setMovieFeatureResults:
movieFineSubjectMotionResults
setMovieFineSubjectMotionResults:
movieInterestingnessResults
setMovieInterestingnessResults:
movieMovingObjectResults
setMovieMovingObjectResults:
movieMusicResults
setMovieMusicResults:
movieObstructionResults
setMovieObstructionResults:
movieOrientationResults
setMovieOrientationResults:
moviePreEncodeResults
setMoviePreEncodeResults:
movieQualityResults
setMovieQualityResults:
movieSaliencyResults
setMovieSaliencyResults:
movieSceneResults
setMovieSceneResults:
movieSceneprintResults
setMovieSceneprintResults:
movieSubjectMotionResults
setMovieSubjectMotionResults:
movieSubtleMotionResults
setMovieSubtleMotionResults:
movieUtteranceResults
setMovieUtteranceResults:
movieVoiceResults
setMovieVoiceResults:
movieSummaryResults
setMovieSummaryResults:
movieHighlightResults
setMovieHighlightResults:
imageExposureResults
setImageExposureResults:
imageHumanPoseResults
setImageHumanPoseResults:
movieHumanPoseResults
setMovieHumanPoseResults:
movieApplauseResults
setMovieApplauseResults:
movieBabbleResults
setMovieBabbleResults:
movieCheeringResults
setMovieCheeringResults:
movieLaughterResults
setMovieLaughterResults:
movieHumanActionResults
setMovieHumanActionResults:
movieLoudnessResults
setMovieLoudnessResults:
moviePetsResults
setMoviePetsResults:
moviePetsFaceResults
setMoviePetsFaceResults:
movieStabilizationResults
setMovieStabilizationResults:
_assetModificationDate
_quality
_statsFlags
_typesWide
_assetAdjustedFingerprint
_assetIdentifier
_assetMasterFingerprint
_imageBlurResults
_imageCompositionResults
_imageExposureResults
_imageFaceResults
_imageFeatureResults
_imageHumanPoseResults
_imageJunkResults
_imagePetsFaceResults
_imagePetsResults
_imageSaliencyResults
_imageSceneprintResults
_imageShotTypeResults
_livePhotoEffectsResults
_livePhotoKeyFrameResults
_livePhotoKeyFrameStillResults
_livePhotoRecommendationResults
_livePhotoSharpnessResults
_movieActivityLevelResults
_movieApplauseResults
_movieBabbleResults
_movieCameraMotionResults
_movieCheeringResults
_movieClassificationResults
_movieFaceResults
_movieFaceprintResults
_movieFeatureResults
_movieFineSubjectMotionResults
_movieHighlightResults
_movieHumanActionResults
_movieHumanPoseResults
_movieInterestingnessResults
_movieLaughterResults
_movieLoudnessResults
_movieMovingObjectResults
_movieMusicResults
_movieObstructionResults
_movieOrientationResults
_moviePetsFaceResults
_moviePetsResults
_moviePreEncodeResults
_movieQualityResults
_movieSaliencyResults
_movieSceneResults
_movieSceneprintResults
_movieStabilizationResults
_movieSubjectMotionResults
_movieSubtleMotionResults
_movieSummaryResults
_movieUtteranceResults
_movieVoiceResults
_types
_version
TI,N,V_version
TI,N,V_types
TI,N,V_flags
Td,N,V_date
Td,N,V_quality
TQ,N,V_statsFlags
TQ,N,V_typesWide
T@"NSString",&,N,V_assetIdentifier
Td,N,V_assetModificationDate
T@"NSString",&,N,V_assetMasterFingerprint
T@"NSString",&,N,V_assetAdjustedFingerprint
T@"NSMutableArray",&,N,V_imageBlurResults
T@"NSMutableArray",&,N,V_imageCompositionResults
T@"NSMutableArray",&,N,V_imageFaceResults
T@"NSMutableArray",&,N,V_imageFeatureResults
T@"NSMutableArray",&,N,V_imageJunkResults
T@"NSMutableArray",&,N,V_imageSaliencyResults
T@"NSMutableArray",&,N,V_imageShotTypeResults
T@"NSMutableArray",&,N,V_imagePetsResults
T@"NSMutableArray",&,N,V_imagePetsFaceResults
T@"NSMutableArray",&,N,V_imageSceneprintResults
T@"NSMutableArray",&,N,V_livePhotoEffectsResults
T@"NSMutableArray",&,N,V_livePhotoRecommendationResults
T@"NSMutableArray",&,N,V_livePhotoSharpnessResults
T@"NSMutableArray",&,N,V_livePhotoKeyFrameResults
T@"NSMutableArray",&,N,V_livePhotoKeyFrameStillResults
T@"NSMutableArray",&,N,V_movieActivityLevelResults
T@"NSMutableArray",&,N,V_movieCameraMotionResults
T@"NSMutableArray",&,N,V_movieClassificationResults
T@"NSMutableArray",&,N,V_movieFaceResults
T@"NSMutableArray",&,N,V_movieFaceprintResults
T@"NSMutableArray",&,N,V_movieFeatureResults
T@"NSMutableArray",&,N,V_movieFineSubjectMotionResults
T@"NSMutableArray",&,N,V_movieInterestingnessResults
T@"NSMutableArray",&,N,V_movieMovingObjectResults
T@"NSMutableArray",&,N,V_movieMusicResults
T@"NSMutableArray",&,N,V_movieObstructionResults
T@"NSMutableArray",&,N,V_movieOrientationResults
T@"NSMutableArray",&,N,V_moviePreEncodeResults
T@"NSMutableArray",&,N,V_movieQualityResults
T@"NSMutableArray",&,N,V_movieSaliencyResults
T@"NSMutableArray",&,N,V_movieSceneResults
T@"NSMutableArray",&,N,V_movieSceneprintResults
T@"NSMutableArray",&,N,V_movieSubjectMotionResults
T@"NSMutableArray",&,N,V_movieSubtleMotionResults
T@"NSMutableArray",&,N,V_movieUtteranceResults
T@"NSMutableArray",&,N,V_movieVoiceResults
T@"NSMutableArray",&,N,V_movieSummaryResults
T@"NSMutableArray",&,N,V_movieHighlightResults
T@"NSMutableArray",&,N,V_imageExposureResults
T@"NSMutableArray",&,N,V_imageHumanPoseResults
T@"NSMutableArray",&,N,V_movieHumanPoseResults
T@"NSMutableArray",&,N,V_movieApplauseResults
T@"NSMutableArray",&,N,V_movieBabbleResults
T@"NSMutableArray",&,N,V_movieCheeringResults
T@"NSMutableArray",&,N,V_movieLaughterResults
T@"NSMutableArray",&,N,V_movieHumanActionResults
T@"NSMutableArray",&,N,V_movieLoudnessResults
T@"NSMutableArray",&,N,V_moviePetsResults
T@"NSMutableArray",&,N,V_moviePetsFaceResults
T@"NSMutableArray",&,N,V_movieStabilizationResults
setAttributesFromLegacyDictionary:
setResults:withClass:forPropertyKey:
exportResultsWithPropertyKey:toLegacyDictionary:withKey:
imageAnalysisFromLegacyDictionary:
movieAnalysisFromLegacyDictionary:
setX0:
setY0:
setWidth:
setHeight:
Td,N,V_x0
Td,N,V_y0
Td,N,V_width
Td,N,V_height
sharedModel:inputNames:
prepareModelWithAspectRatio:
creatModel
createInput:withBuffer:cnnInputHeight:cnnInputWidth:
_inputsData
_cnnOutputWidth
_cnnOutputHeight
initWithCommonFormat:sampleRate:channels:interleaved:
append:atTime:error:
initRequiringSecureCoding:
encodedData
_signature
_endTime
setIdentifier:
_identifier
TI,N,V_identifier
setHasFaceSharpness:
hasFaceSharpness
setVanishingPoint:
setDominantLine:
vanishingPoint
dominantLine
_dominantLine
_vanishingPoint
T@"VCPProtoPoint",&,N,V_vanishingPoint
T@"VCPProtoLine",&,N,V_dominantLine
pointWithPoint:
lineFromPoint:toPoint:
pointValue
startPointValue
endPointValue
setUnderExpose:
setHasUnderExpose:
hasUnderExpose
exposure
setExposure:
underExpose
_exposure
_underExpose
Tf,N,V_exposure
Tf,N,V_underExpose
_processFormat
_peakValues
_momentaryEnergyValues
_loudnessSampleBuffer
_loudnessResults
_samplesFor100ms
_samplesForProcessingBufferList
setHasFaceQuality:
hasFaceQuality
eyeExpression
setEyeExpression:
_eyeExpression
Ti,N,V_eyeExpression
Ti,N,V_yaw
Tf,N,V_faceQuality
setFeatureBlob:
featureBlob
_featureBlob
T@"NSData",&,N,V_featureBlob
requestProcessing:ofIOSurface:withIdentifier:properties:options:andReply:
requestProcessingViaXPC:ofPixelBuffer:withOptions:andCompletionHandler:
requestProcessing:ofPixelBuffer:withOptions:andCompletionHandler:
initWithKeypointsOption:forceCPU:sharedModel:aspectRatio:modelName:
associateHands:withExisingHands:
handDistance:withhandB:
_existingHands
_loadImageURL:withSession:andRequestHandler:
_configureRequest:withRevision:preferANE:
initWithImageSignatureprintType:imageSignatureHashType:
imageNeuralHashprint
setInputSignatureprint:
imageSignatureHash
descriptorData
elementCount
elementType
encodeHashDescriptorWithBase64EncodingAndReturnError:
analyzeWithImageURL:requestTypes:completionHandler:
returnObject:
initWithObject:fromPool:
_object
_pool
T@,R,N,V_object
initWithAllocator:
_allocator
_objects
shotType
setShotType:
_shotType
Ti,N,V_shotType
setEnd:
_end
T@"VCPProtoPoint",&,N,V_start
T@"VCPProtoPoint",&,N,V_end
numberWithLongLong:
addFrameInstructions:
frameInstructionsCount
clearFrameInstructions
frameInstructionsAtIndex:
setAutoloop:
setBounce:
setLongexposure:
setStabilize:
frameInstructionsType
setEpoch:
setHasEpoch:
hasEpoch
setHasFlags:
hasFlags
stabilizeResult
setStabilizeResult:
outputFrameDurValue
setOutputFrameDurValue:
cropRectX
setCropRectX:
cropRectY
setCropRectY:
cropRectHeight
setCropRectHeight:
cropRectWidth
setCropRectWidth:
timeScale
setTimeScale:
epoch
frameInstructions
setFrameInstructions:
autoloop
bounce
longexposure
stabilize
minVersion
setMinVersion:
_epoch
_outputFrameDurValue
_autoloop
_bounce
_cropRectHeight
_cropRectWidth
_cropRectX
_cropRectY
_frameInstructions
_longexposure
_minVersion
_stabilize
_stabilizeResult
_timeScale
Ti,N,V_stabilizeResult
Tq,N,V_outputFrameDurValue
Ti,N,V_cropRectX
Ti,N,V_cropRectY
Ti,N,V_cropRectHeight
Ti,N,V_cropRectWidth
Ti,N,V_timeScale
Tq,N,V_epoch
T@"NSMutableArray",&,N,V_frameInstructions
T@"VCPProtoLivePhotoVariationParams",&,N,V_autoloop
T@"VCPProtoLivePhotoVariationParams",&,N,V_bounce
T@"VCPProtoLivePhotoVariationParams",&,N,V_longexposure
T@"VCPProtoLivePhotoVariationParams",&,N,V_stabilize
Ti,N,V_minVersion
Ti,N,V_version
exportToLegacyDictionaryFromFrameInstruction:
exportToLegacyDictionaryFromParam:withLoopFlavor:
setRecipeBlob:
hasRecipeBlob
loopSuggestionState
setLoopSuggestionState:
longExposureSuggestionState
setLongExposureSuggestionState:
recipeBlob
_longExposureSuggestionState
_loopSuggestionState
_recipeBlob
TQ,N,V_loopSuggestionState
TQ,N,V_longExposureSuggestionState
T@"NSData",&,N,V_recipeBlob
updateWithOptions:error:
processImage:withOptions:error:
raise
homographyParamsCount
clearHomographyParams
homographyParamAtIndex:
addHomographyParam:
homographyParams
setHomographyParams:count:
timeValue
setTimeValue:
_homographyParams
_timeValue
Tq,N,V_timeValue
T^f,R,N
indexOfObject:inSortedRange:options:usingComparator:
getClosestAspectRatio:
updateModelWithResConfig:
handsDetection:handsRegions:cancel:
convertSingleResultToDict:keypointConfidence:box:results:
initWithOptions:andCompletionHandler:
taskService
cancelTask:
submitTaskWithOptions:completionHandler:
taskWithOptions:andCompletionHandler:
_taskID
setLoopFadeLen:
setHasLoopFadeLen:
hasLoopFadeLen
setLoopPeriod:
setHasLoopPeriod:
hasLoopPeriod
setLoopStart:
setHasLoopStart:
hasLoopStart
errorCode
setErrorCode:
loopFadeLen
loopPeriod
loopStart
_errorCode
_loopFadeLen
_loopPeriod
_loopStart
Ti,N,V_errorCode
Ti,N,V_loopFadeLen
Ti,N,V_loopPeriod
Ti,N,V_loopStart
activityScore
setActivityScore:
_activityScore
Tf,N,V_activityScore
motionType
setMotionType:
isFast
setIsFast:
_motionType
_isFast
Ti,N,V_motionType
TB,N,V_isFast
startSessionWithProperties:andReply:
initWithProperties:andResultsHandler:
setWeakSession:
processMessageWithOptions:andReply:
processVideoFragmentAssetData:withOptions:andReply:
processResults:withReply:
sessionWithProperties:andResultsHandler:
processVideoFragmentAssetData:withOptions:andErrorHandler:
processVideoFragmentAssetData:withOptions:andCompletionHandler:
processMessageWithOptions:andCompletionHandler:
_formatDescription
_resultsHandler
weakSession
_weakSession
T@"VCPHomeKitAnalysisSession",W,N,V_weakSession
setPixelBuffer:
calculateFrameDifference:
computeRegionsofInterest
_regions
_diff
_ptrFirst
_ptrLast
_widthBlockNum
_heightBlockNum
addClassification:
classificationsCount
clearClassifications
classificationAtIndex:
classificationType
classifications
setClassifications:
_classifications
T@"NSMutableArray",&,N,V_classifications
setFaceprintBlob:
faceprintBlob
_faceprintBlob
TI,N,V_faceID
T@"NSData",&,N,V_faceprintBlob
useCPUOnly
_useCPUOnly
_maxNumHands
_humanActionWindowSize
TB,R,N,V_useCPUOnly
TI,R,N,V_revision
mouthExpression
setMouthExpression:
isCloseup
setIsCloseup:
_mouthExpression
_isCloseup
Ti,N,V_mouthExpression
Ti,N,V_position
TB,N,V_isCloseup
Ti,N,V_faceID
clsDistanceIdentity
filename
originalFilename
locationCoordinate
T{CLLocationCoordinate2D=dd},R,N
interestScore
setInterestScore:
_interestScore
Tf,N,V_interestScore
approximateLocation
coordinate
gpsHorizontalAccuracy
approximateCoordinate
isCoarse
estimatedAssetCount
_personDetector
_personKeypointsDetector
energy
setEnergy:
peak
setPeak:
_energy
_peak
Td,N,V_energy
Td,N,V_peak
addBounds:
boundsCount
clearBounds
boundsAtIndex:
boundsType
T@"NSMutableArray",&,N,V_bounds
initWithMaxNumRegions:forceCPU:sharedModel:inputConfig:
retrieveBoxes:outHeight:outWidth:boxes:anchorBox:
nonMaxSuppression:
drawLine:width:height:stride:point0:point1:drawPoint:
generateHandsBoxes:
generateHandsRegions:boxes:maxNumRegions:
drawRectangle:width:height:stride:keypoints:
cnnInputWidth
cnnInputHeight
vcp_persistentStorageDirectoryURL
initWithContext:persistenceDelegate:cacheDirectoryURL:visionIntegration:
setDateFormat:
absoluteURL
stringForObjectValue:
stringByAppendingString:
URLByAppendingPathComponent:
createDirectoryAtURL:withIntermediateDirectories:attributes:error:
fileSystemRepresentation
lastPathComponent
copyItemAtURL:toURL:error:
setIncludeHiddenAssets:
setIncludeAllBurstAssets:
_appendToSuggestionsLog:
restoreClusterCacheAndSyncWithLibrary:error:
minimumSuggestionSize
suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:minimumSuggestionFaceCount:
updateKeyFacesOfPersonsWithLocalIdentifiers:forceUpdate:context:reply:
_closeSuggestionsLoggingSession
_startAndSyncClusterCacheWithLibrary:reply:
isReadyToReturnSuggestions
_openSuggestionsLoggingSession
faceClusterSequenceNumbersOfKeyFacesInAlgorithmicFaceGroupsForPerson:verifiedClusterSequenceNumbers:
_logFaceToSuggestionsLog:
requestSuggestionsForFaceClusterSequenceNumbers:withClusteringFlags:updateHandler:error:
_suggestionsForPersonLocalIdentifier:clusterSequenceNumbers:excludePersonLocalIdentifiers:cancel:context:error:
_finalizeSuggestionsLog
_suggestionsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:cancel:error:
distantPast
vcp_setAnalysisPreferencesValue:forKey:
vcp_personsModelFilepath
removeItemAtPath:error:
requestSuggestedMePersonIdentifierAtURL:withError:
hasProcessedForLibrary:
initWithPhotoLibrary:andDelegate:
advancedStatus
differencesBetweenClustersInClusterCacheAndLibrary:
terminate
setEventManager:
removeClusteringStateCacheWithContext:cacheDirectoryUrl:error:
setProcessed:forLibrary:
_deleteAllVerifiedPersonsWithError:
reclusterFacesWithThreshold:shouldRecluster:withContext:extendTimeout:cancel:error:
workerWithPhotoLibrary:andContext:
_copyImageAtURLToSuggestionsLoggingSession:
suggestPersonsForPersonWithLocalIdentifier:toBeConfirmedPersonSuggestions:toBeRejectedPersonSuggestions:context:reply:cancel:
faceCandidatesforKeyFaceForPersonsWithLocalIdentifiers:context:reply:
resetPersonsModelWithContext:reply:
requestSuggestedMePersonIdentifierWithContext:reply:
personPromoterStatusWithContext:reply:
validateClusterCacheWithContext:reply:
resetFaceClusteringStateWithContext:reply:
reclusterFacesWithContext:reply:extendTimeout:cancel:
rebuildPersonsWithContext:reply:extendTimeout:cancel:
_clusterer
_persistenceDelegate
_suggestionLoggingDirectory
_suggestionLoggingSessionOpen
_suggestionsLoggingEnabled
indexesOfObjectsPassingTest:
removeObjectsAtIndexes:
vcp_reportDownload:
vcp_inMemoryDownload:toData:cancel:
setCenterX:
setCenterY:
leftEyeX
leftEyeY
rightEyeX
rightEyeY
mouthX
mouthY
poseYaw
isHidden
setHidden:
isInTrash
setIsInTrash:
setAdjustmentVersion:
setTrainingType:
setGroupingIdentifier:
_vnFaceAttributeAgeToPHFaceAgeTypeMap
ageType
_vnFaceAttributeSexToPHFaceSexTypeMap
sexType
_vnFaceAttributeEyesToPHEyesStateMap
_vnFaceAttributeSmileToPHFaceSmileTypeMap
smileType
_vnFaceAttributeFacialHairToPHFacialHairTypeMap
facialHairType
_vnFaceAttributeHairColorToPHFaceHairColorTypeMap
hairColorType
_vnFaceAttributeBaldToPHFaceBaldTypeMap
baldType
_vnFaceAttributeGlassesToPHFaceGlassesTypeMap
glassesType
_phFaceAgeTypeFromPVFace:
_phFaceSexFromPVFace:
_phFaceEyesStateFromPVFace:
_phFaceSmileTypeFromPVFace:
_phFaceFacialHairTypeFromPVFace:
_phFaceHairColorTypeFromPVFace:
_phFaceBaldTypeFromPVFace:
_phFaceGlassesTypeFromPVFace:
hidden
setInTrash:
analysisType
_firstLocallyAvailableResourceFromResources:
_assetResourceLargestToSmallestComparator
preferredResourcesForFaceProcessingWithAsset:
resourceForFaceProcessing:allowStreaming:
pvImageCreationOptions
resourceForFaceProcessingWithAsset:allowStreaming:
_pvFacesArrayFromPHFetchResult:copyPropertiesOption:
configureRequest:algorithmUmbrellaVersion:
performVisionForcedCleanupWithOptions:
performVisionForcedCleanup
_readFaceAnalysisState
vcp_faceAnalysisStateFilepath
initWithContentsOfFile:
writeToFile:atomically:
_setFaceAnalysisStateValue:forKey:
setChunkSizeForFetch:
setLastMinimumFaceGroupSizeForCreatingMergeCandidate:
pv_faceProcessingProgress
_setAllFaceGroupsNeedPersonBuilding
setPersonBuilderMergeCandidatesEnabled:
clusterer
initWithPhotoLibrary:andFaceClusterer:andContext:
performPersonBuildingWithCanceler:extendTimeoutBlock:error:
_faceClusterer
_state
_lastMinimumFaceGroupSizeForCreatingMergeCandidates
_personBuilderMergeCandidatesEnabled
computeVar:index2:interVar:intraVar:
scaleRect:scaleX:scaleY:
computeActionScore
intersectionOverUnion:rect:
addActiveResults:
processPersons:humanBounds:dominantPersonIdx:frame:timestamp:duration:
_timeLastProcessFullFrame
_bodyArray
_maxScore
_keyPersonResults
_poseResults
_activePoseResults
_crop
_humanRect
_actionScoreAbsolute
_actionScoreRelative
_scoreAbsoluteMax
_scoreRelativeMax
_lastHumanTimestamp
_tracker
_tracking
initWithAssets:andCompletionHandler:
vcp_isPano
Ti,N,V_orientation
isEnabled
initWithTimestamps:andIdentifier:andTrack:
setStatisticsBlob:
statisticsBlob
_statisticsBlob
T@"NSData",&,N,V_statisticsBlob
setDistanceToPreviousScene:
setHasDistanceToPreviousScene:
hasDistanceToPreviousScene
setFlickerScore:
setHasFlickerScore:
hasFlickerScore
setSceneprintDistanceToPreviousScene:
setHasSceneprintDistanceToPreviousScene:
hasSceneprintDistanceToPreviousScene
distanceToPreviousScene
flickerScore
sceneprintDistanceToPreviousScene
_distanceToPreviousScene
_flickerScore
_sceneprintDistanceToPreviousScene
Tf,N,V_distanceToPreviousScene
Tf,N,V_flickerScore
Tf,N,V_sceneprintDistanceToPreviousScene
hasAction
setHasAction:
_hasAction
TB,N,V_hasAction
startAndSyncClusterCacheWithLibrary:reply:
scheduleClusteringAfterRemovingFaceCSNs:addingFaceIdStrs:
numberOfAccumulatedClusterChanges
clusterIfNecessaryAndWait
clusterAndWait
performClusteringWithCompletion:
cancelClustering
setFaceClusteringThreshold:
resetFaceClusteringState:
performFaceClusteringAndWait
getClusters:threshold:utilizingGPU:error:
clustererState
_resetFaceClusteringStateWithContext:error:
clusterFacesWithExtendTimeoutBlock:andCancelBlock:
clusteringStatus
performFaceClusteringWithCompletion:
cancelFaceClustering
performFaceClusteringIfNecessaryAndWait
scheduleClusteringOfFacesWithLocalIdentifiers:
scheduleUnclusteringOfFacesWithClusterSequenceNumbers:
numberOfFacesPendingClustering
reclusterFacesWithThreshold:shouldRecluster:error:
getFaceClusters:clusteringThreshold:utilizingGPU:error:
clustererIsReadyToReturnSuggestions
resetClusterer
clusterFacesIfNecessaryWithExtendTimeoutBlock:andCancelBlock:
_visionIntegrating
fetchPersonAssociatedWithFaceGroup:options:
faceCountInFaceGroup
isDirty
setPlaybackCrop:
hasKeyFrame
hasPlaybackCrop
curationScore
setCurationScore:
autoPlayable
setAutoPlayable:
playbackCrop
_curationScore
_playbackCrop
_autoPlayable
Tf,N,V_curationScore
T@"VCPProtoVideoKeyFrame",&,N,V_keyFrame
TB,N,V_autoPlayable
T@"VCPProtoBounds",&,N,V_playbackCrop
setX:
setY:
Td,N,V_x
Td,N,V_y
setValue:
timescale
setTimescale:
_value
_timescale
Tq,N,V_value
Ti,N,V_timescale
T@"VCPProtoTime",&,N,V_start
T@"VCPProtoTime",&,N,V_duration
initWithCallerIdentifier:face:andConfidence:
callerIdentifier
_callerIdentifier
T@"PHFace",R,N,V_face
T@"NSString",R,N,V_callerIdentifier
Tf,R,N,V_confidence
lock
requestAnalysis:ofIOSurface:withProperties:withReply:
unlock
errorWithStatus:andDescription:
requestAnalysis:ofPixelBuffer:withProperties:withCompletionHandler:
_connectionLock
initFromConfigFile:numStage:numLandmarks:numTreePerStage:depthOfTree:numFeatures:
detectLandmark:width:height:stride:facerect:prevResult:result:
calculateFaceRectFromPrevLM:result:numOfLandmarks:
_internalLandmarkDetector
_numOfLandmarks
timeValuesCount
clearTimeValues
timeValueAtIndex:
addTimeValue:
homographyParamsAtIndex:
addHomographyParams:
timeValues
setTimeValues:count:
inputBoundsX
setInputBoundsX:
inputBoundsY
setInputBoundsY:
inputBoundsHeight
setInputBoundsHeight:
inputBoundsWidth
setInputBoundsWidth:
sourceSizeHeight
setSourceSizeHeight:
sourceSizeWidth
setSourceSizeWidth:
_timeValues
_inputBoundsHeight
_inputBoundsWidth
_inputBoundsX
_inputBoundsY
_sourceSizeHeight
_sourceSizeWidth
Tf,N,V_cropRectX
Tf,N,V_cropRectY
Tf,N,V_cropRectHeight
Tf,N,V_cropRectWidth
Tf,N,V_inputBoundsX
Tf,N,V_inputBoundsY
Tf,N,V_inputBoundsHeight
Tf,N,V_inputBoundsWidth
Tf,N,V_sourceSizeHeight
Tf,N,V_sourceSizeWidth
T^q,R,N
nodeForSceneClassId:
name
sceneIdFromSceneName:
numOfValidFrames
sumOfScore
initWithTimestamp:score:valid:
updateWithFirstFrame:score:valid:
updateSegment:score:valid:
updateDuration:
trimSegment:fromStart:
isContentTooShort
_sumOfScore
_numOfValidFrames
TQ,R,N,V_numOfValidFrames
assetWriterWithURL:fileType:error:
setupMetadataTrack
initWithURL:andTrack:
finish
isReadyForMoreMediaData
popSample
appendSampleBuffer:
cancelWriting
markAsFinished
finishWritingWithCompletionHandler:
assetWriterInputWithMediaType:outputSettings:sourceFormatHint:
setTransform:
addInput:
startWriting
startSessionAtSourceTime:
processMediaRequest
requestMediaDataWhenReadyOnQueue:usingBlock:
createAssetWriterInputWithFormatDescription:
copyPixelBuffer:toPixelBuffer:
pushSample:
metadata
metadataItemsFromArray:withKey:keySpace:
setMetadata:
initWithMediaType:outputSettings:sourceFormatHint:
initWithAssetWriterInput:
assetWriterInput
canAddInput:
initWithSampleBuffer:
metadataItemsFromArray:filteredByIdentifier:
initWithItems:timeRange:
appendTimedMetadataGroup:
appendMetadataTrack
assetWriterWithURL:andTrack:
addPixelBuffer:withTime:
_writer
_metadataAdaptor
_sampleQueue
_enqueueSemaphore
_dequeueSemaphore
_completionSemaphore
_pixelBufferPool
_pts
serialQueue_
sharedInstances_
generateCurationSegment
generateInterestingTrimBasedOnCaptureTime:
updateCurationThreshold
calculateCandidateScoreWithRangeAdjust:endIdx:candidateTimeRange:captureTime:
isCurated:
isTimestampSkipable:
checkTrimAt:captureTime:
finalizeWithDestructiveTrimStart:trimEnd:andCaptureTime:
bestTrimTimeRange
_actionAnalyzer
_bestTrimTimeRange
_curationThreshold
_inTrimStart
_inTrimEnd
_captureTime
_ready
_imageURL
_movie
_mediaType
_mediaSubtypes
_pixelWidth
_pixelHeight
initWithImageURL:isSDOF:
sdofImageAssetWithURL:
initWithImageURL:andMovieURL:
nominalFrameRate
initWithMovieURL:
currentVideoCall
callUUID
contactIdentifier
dateConnected
detectFaces:
checkAddFaces
videoChatAnalysis
analyzeFrame:
persistAnalysis
_detectionQueue
_faceTimeSession
_finished
descriptors
normalizeActivityDescriptor
initWithTimerange:andScore:
prepareActivityStats
generateActivityDescriptor
computeActivityScoreAtTime:
resetActivityStatsAtTime:
extractRequiredInfoFrom:toArray:
extractRequiredClassificationInfoFrom:toArray:
extractRequiredFaceInfoFrom:toArray:
validationScoreOfTimeRange:fromResult:startIdx:
actionScoreInTimeRange:
validateActivityScores
scaleBasedOnFaceForTimeRange:
addSceneSwitchFrequencyConstributionToActivityLevel:
addSceneClassificationContributionToActivityLevel:
initWithFrameStats:
preProcessQualityResults:interestingnessResults:obstructionResults:classificationResults:fineActionResults:faceResults:sceneSwitchFrequency:
finishAnalysisPass:fpsRate:
_activityDescriptor
_activityScores
_validActivityScores
_interestingnessResults
_obstructionResults
_classificationResults
_fineActionResults
_sceneSwitchFrequency
_lastProcessTime
_overallActivityLevel
_sportsSceneId
T{?={?=qiIq}{?=qiIq}},V_timerange
Tf,V_score
spatialDescriptorWithMvMagnitudeMean:
_widthInMb
_heightInMb
_motionMagnitudeHistogram
_motionMagnitude
T^f,R
createModel
prepareData:
detect
keypointsFromObservations:
analyzeBodyArray:
_inputChannels
_action
_poseRequest
_valid
dependencies
initWithTransform:withExistingFaceprints:frameStats:
initWithTransform:frameStats:faceDominated:
faceDetectorWithTransform:withExistingFaceprints:frameStats:tracking:faceDominated:cancel:
faceRanges
_angle
_timeLastDetection
_activeFaces
makeValidationDecision
updateIntrinsicWhenRotated
setFrame:
checkResolutionChange:withRotation:
validateFace:eulerAngles:
rotateLandmarks:width:height:landmarks:numLandmarks:
mapToCameraNegativeZ
bufferRotated
_faceCount
_inDetectionMode
_lmDetector
_lmTracker
_prevLM
_curLM
_detectionModeCounter
_trackingModeCounter
_lostTrackCounter
_angleStable
_validationScore
_validateFailedOnce
_validationQueue
_validationGroup
_valBuffer
_valBufferRotated
_valAngle
_valLM
_shapeModel
_faceValidator
_offline
_bufferRotated
T{?=[4]},R,N,V_pose
Tr^f,R,N
TB,R,N,V_bufferRotated
initWithFace:andFace:andScore:
face1
face2
_face1
_face2
T@"PVFace",R,N,V_face1
T@"PVFace",R,N,V_face2
Td,R,N,V_score
observationWithBoundingBox:
CGImage
initWithURL:orientation:options:
initWithCGImage:orientation:options:
initWithFaceObservations:
_faceObservationsWithBBoxFromPVFaces:mapping:
_bboxAlignedFaceObservationsFromFaceObservations:inImage:withError:
height
width
faceId
alignedBoundingBoxAsCGRect
faceMergeFaceprintDistanceThreshold
getDistance:toOtherFaceprint:error:
_alignBBoxForPVFaces:forImage:
setCoordinatesAndFeaturesFromFace:
_sortedViableFaceMergePairsFromQueryFaces:andCandidateFaces:
sortedViableMergeCandidateFacesFor:from:ignoreSourceAssetDimensions:matchScores:
initWith:confidence:
setBound:
_bound
T{CGRect={CGPoint=dd}{CGSize=dd}},V_bound
parseResults:toDetections:atTime:fromTime:addActiveRegions:
addDetectionToDict:withActiveRegions:forPetsDetections:fromTime:
_petsDetections
_petsFaceDetections
_timeLastProcess
_petsStart
_petsFaceStart
_petsAnalyer
_petsActiveRegions
_petsFaceActiveRegions
analyzeFrame:withFaceBounds:
setPose:
_landmarkDetector
_poseEstimator
_lastTimestamp
_points2D
_points3D
_pose
T{?=[4]},V_pose
rotationToEulerAngles:angles:
kalmanFiltering:T:
eulerAnglesToRotation:R:
filteringPose:
_previousState
_previousCovar
_previousStateIsValid
updateModelByAddingFaces:andRemovingFaces:canceller:error:
updateModelByAddingFaces:error:
vcp_updateModelByAddingFaces:
compareFace:withFace:
removeSmallestKeyFace
detectTrackFacesInFrame:withTimestamp:faces:
requestRevision
initWithType:cachePath:state:threshold:requestRevision:
clustererBuilderWithOptions:error:
objects
initForReadingFromData:error:
clusterFaces
updateWithExistingFaces
locationChange:relativeTo:landscape:
_latestTrackID
_smileDetector
_existingFaceprints
_latestFrameArea
_faceTrackers
_keyFaces
_reservedIDs
_facePrints
_allFaces
_frameFaceResults
hasMeaningfulSceneSegment:withFpsRate:
assetQualityScoreFromAnalysis:withFpsRate:
assetActionScoreFromAnalysis:
assetExpressionScoreFromAnalysis:
assetVoiceScoreFromAnalysis:
assetJunkScoreFromAnalysis:
assetCameraMotionScoreFromAnalysis:
scaleForTimeRange:basedOnFace:
isJunkTimeRange:basedOnResults:
subjectActivityInTimeRange:fromResults:
cameraActivityfromQuality:
assetActivityLevelFromAnalysisResults:
faceSharpness
isHeadingFrame
computeGlobalQuality
computeScoreFromColorfulness
computeScoreFromExposure
computeExpressionScore
computeScoreFromAction
computeGlobalQualityForLivePhoto
computeVisualPleasingScore
computePenaltyScore
computeContentScore
computeCurationScoreComponents
storeFrameResults
printStats
setFrameResults:
_subjectAction
_cameraMotion
_interestingness
_obstruction
_colorfulness
_subMb
_isHeadingFrame
_semanticScore
_faceSharpness
_expressionChangeScore
_frameResults
T{?=qiIq},N,V_timestamp
Tf,N,V_semanticScore
Tf,N,V_faceSharpness
TB,N,V_isHeadingFrame
Tf,N,V_expressionChangeScore
T@"NSMutableArray",&,N,V_faceQualityScores
T@"NSMutableDictionary",&,N,V_frameResults
initWithLivePhoto:
setKeyFrameTime:isHeadingFrame:
prepareFrameStats:
computeSharpnessOfFrame:
computeFaceQualityOfFrame:
finalizeKeyFrame
loadKeyFrameResult:timestamp:
adjustScoreByFace
modulateByJunk
modulateByTimeRange
setBlurAnalyzerFaceResults:
setFaceSharpness:
computeCurationScore
frameResults
hasGoodSubjectAction
setIsHeadingFrame:
resetStatsFlag
loadKeyFrameResults:
setFaceStatsFlag:detectedFaces:
setExpressionChangeScore:
setMotionStatsFlag:cameraMotion:subjectAction:interestingness:obstruction:colorfulness:exposureScore:humanActionStatsFlag:humanPoseScore:humanActionScore:subMb:
modulateByExposure
computeMinDistanceBetween:withSet:
_faceQualityAnalyzer
_keyFrames
_activeKeyFrame
_keyFrameScores
_inputKeyFrameResults
minProcessTimeIntervalInSecs
detectFaces:faces:
_lastestFaceID
_numFacesLastFrame
_lastVertices
_lastJawOpenness
initWithRequestAnalyses:formatDescription:
T@"NSDictionary",R,&,N
items
time
resetSegment:atTime:
focusStatus
addSegmentToResults
initWithFocusStatus:atTime:
updateSegment:atTime:
processFrameMetadata:
_mutableResults
T@"NSArray",R,&,N
setFocusStatus:
_focusStatus
Tq,V_focusStatus
hadZoom
setHadZoom:
minZoom
setMinZoom:
maxZoom
setMaxZoom:
_minZoom
_maxZoom
TB,N,V_hadZoom
Tf,N,V_minZoom
Tf,N,V_maxZoom
readGyroHomographyDimension:
gyroHomographyVersionIsValid:
readSoftwareStackVersion:
referenceSoftwareStackVersion
compareSoftwareStackVersion:withReferenceVersion:
getSetupDataFrom:
getFirstAtomWithFourCharCode:fromSetupData:
compareNumericVersion:withReferenceVersion:
componentsSeparatedByString:
numberFromString:
numberWithChar:
increaseLengthBy:
resetBytesInRange:
convertLivePhotoStruct:toDictionary:
dataType
dataValue
convertLivePhotoBinary:toDictionary:
defaultDesiredKeys
_prevEstimatedCenterMv
_deSerializedMetaBuffer
_metaFocusAnalyzer
_metaMotionAnalyzer
_requestAnalyses
_metadataStabilizationArray
_frameTimestampArray
_originalFrameTimestampArray
_metaLensSwitchAnalzer
_gyroHomographyIsValid
_gyroHomographyDimension
stabilityScore
decideSegmentPointBasedOn:
initWithAbsMotion:atTime:
absMotion
_hinkleyDetector
setAbsMotion:
setStabilityScore:
_absMotion
_stabilityScore
Tf,V_absMotion
Tf,V_stabilityScore
numberValue
setupTrackerWithReferenceFrame:withROI:
trackInFrame:
lostTrackInd
initWithObjectBounds:inFrame:timestamp:
trackObjectInFrame:
objectBoundsInitial
objectBounds
lostCount
_correlationTracker
_lostCount
_objectBoundsInitial
_objectBounds
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_objectBoundsInitial
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_objectBounds
T{?=qiIq},R,N,V_start
Ti,R,N,V_lostCount
initWithPlistRepresentation:
attachSalientRegions:toPixelBuffer:
plistRepresentation
isOutOfBoundary:
updateConfidence:prevBound:newBound:width:height:
pruneRegions:withOverlapRatio:
boundDistance:relativeTo:landscape:
_detections
_latestRegions
_timeLastTracking
_saliencyAnalyer
_trackers
_confidences
_activeRegions
initWithSceneId:withDuration:withConfidence:
sceneId
setSceneId:
setDuration:
sumConfidence
setSumConfidence:
_duration
_sumConfidence
_sceneId
T@"NSString",&,V_sceneId
Tf,V_duration
Tf,V_sumConfidence
addResult:start:duration:keyIsName:
compareObjectsOfInterest:withScenes:
addAggregatedScenes:timerange:
frameScenes
sceneResults
setSceneResults:
_existingScenes
_sceneTaxomy
_internalFrameScenes
T@"NSArray",&,V_sceneResults
naturalSize
decodeDimensionsForTrack:
settings
getNextCaptureSampleBuffer
_track
initWithTrack:timerange:withSettings:applyTransform:
assetReaderWithAsset:error:
cancelReading
track
initWithTrack:timerange:
_assetReader
_trackOutput
_nextSample
_status
initWithTrack:timerange:atInterval:
_decodeEnd
_sampleDuration
_nextSampleTime
_currentSample
assetReaderSampleReferenceOutputWithTrack:
canAddOutput:
findNextSample:timerange:
decodeSample:sample:
decodeTask
_trackReader
_launchOnce
_group
_inputSemaphore
_outputSemaphore
_cancelDecode
_decodeError
_decodeFinished
_decodedFrames
_outputFrameIdx
_sampleBuffer
setVoiceDetections:
_audioStream
_voiceActivity
_voiceStart
_voiceDetections
_utteranceDetections
_musicDetections
T@"NSMutableArray",&,V_voiceDetections
dictionaryWithContentsOfURL:
addDetectionFromTime:toTime:result:
setupWithAudioStream:
loadModel
_voiceActivityNew
_audioUnit
facePrintBlob
setBox:
stableInd
setStableInd:
setLostTrackInd:
T^{CGPoint=dd}
stable
lostTrack
T^{CGPoint=dd},VP
TB,Vstable
TB,VlostTrack
_transitionDetection
_textureCacheLuma
_textureCacheChroma
_textureCacheRGBALuma
_textureCacheRGBAChroma
_readAttributes
_writeAttributes
_packetPool
_blockDist
_submissionQueue
_completionQueue
_planeOffset
_planeBytesPerRow
setPacketLayout:
selectGPUForFrame:
cachedTexture:forPlane:withAttributes:
rgbaUnormTextureForLuma:withAttributes:
rgbaUintTextureForLuma:withAttributes:
rgbaUintTextureForChroma:withAttributes:
temporalTransitionScore:previousFrame:forRegion:
copyFromFrame:toTile:origin:size:withFence:
createEncodePacket:forRegion:instance:sequenceNumber:frameIndex:pts:duration:frameProperties:
waitUntilCompleted
commit
endEncoding
copyFromTexture:sourceSlice:sourceLevel:sourceOrigin:sourceSize:toBuffer:destinationOffset:destinationBytesPerRow:destinationBytesPerImage:
blitCommandEncoder
contents
newBufferWithLength:options:
waitUntilScheduled
commitAndWaitUntilSubmitted
copyFromTexture:sourceSlice:sourceLevel:sourceOrigin:sourceSize:toTexture:destinationSlice:destinationLevel:destinationOrigin:
dispatchThreadgroups:threadsPerThreadgroup:
setBytes:length:atIndex:
setBuffer:offset:atIndex:
setTexture:atIndex:
setComputePipelineState:
computeCommandEncoder
setLabel:
newComputePipelineStateWithFunction:error:
newFunctionWithName:
supportsFamily:
newDefaultLibraryWithBundle:error:
setCompletionQueue:
setSubmissionQueue:
setGPUPriority:
newCommandQueue
registryID
@28@0:8Q16B24
v16@0:8
@16@0:8
i24@0:8^{opaqueCMSampleBuffer=}16
i88@0:8^{AudioBufferList=I[1{AudioBuffer=II^v}]}16{AudioTimeStamp=dQdQ{SMPTETime=ssIIIssss}II}24
i24@0:8r^{?=qiIq}16
i40@0:8@16@?24^@32
{AudioTimeStamp="mSampleTime"d"mHostTime"Q"mRateScalar"d"mWordClockTime"Q"mSMPTETime"{SMPTETime="mSubframes"s"mSubframeDivisor"s"mCounter"I"mType"I"mFlags"I"mHours"s"mMinutes"s"mSeconds"s"mFrames"s}"mFlags"I"mReserved"I}
{AudioBufferList="mNumberBuffers"I"mBuffers"[1{AudioBuffer="mNumberChannels"I"mDataByteSize"I"mData"^v}]}
@"VCPVoiceDetector"
@"VCPAudioClassifier"
@"VCPLoudnessAnalyzer"
@"VCPSongDetector"
B24@0:8@16
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B16@0:8
B24@0:8#16
B24@0:8:16
Vv16@0:8
Q16@0:8
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
v32@0:8@16@24
v24@0:8@16
v32@0:8@"<SNRequest>"16@"<SNResult>"24
v32@0:8@"<SNRequest>"16@"NSError"24
v24@0:8@"<SNRequest>"16
@52@0:8{?=qiIq}16f40@44
v36@0:8r^{?=qiIq}16r^{?=qiIq}24f32
@"NSMutableArray"
{?="value"q"timescale"i"flags"I"epoch"q}
@"NSString"
@24@0:8Q16
i28@0:8^{opaqueCMSampleBuffer=}16i24
@"SNAudioStreamAnalyzer"
@"AVAudioPCMBuffer"
@80@0:8Q16@24{CGSize=dd}32{CGRect={CGPoint=dd}{CGSize=dd}}48
v24@0:8^v16
@24@0:8@16
@44@0:8B16@20B28B32B36B40
i16@0:8
i24@0:8@16
i40@0:8^i16^i24^I32
i28@0:8f16i20i24
i24@0:8^{__CVBuffer=}16
i36@0:8^{__CVBuffer=}16^f24i32
i24@0:8i16i20
i40@0:8^f16^{__CVBuffer=}24i32i36
i48@0:8^{__CVBuffer=}16^Q24^@32@?40
v20@0:8B16
@"VCPCNNModelEspresso"
@"NSURL"
v80@0:8{?={?=qiIq}{?=qiIq}}16@64@72
v96@0:8@16@24{?={?=qiIq}{?=qiIq}}32@80@88
@32@0:8@16d24
@24@0:8^{_NSZone=}16
v20@0:8f16
d16@0:8
v24@0:8d16
f16@0:8
{?="contentScore"b1"globalQualityScore"b1}
f40@0:8*16i24i28q32
i40@0:8^f16@24^{__CVBuffer=}32
@36@0:8f16f20f24f28f32
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8f16f20
@"NSDictionary"16@0:8
@24@0:8@"NSDictionary"16
i48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}24^f32i40i44
f52@0:8^f16i24i28i32*36f44i48
i52@0:8^{__CVBuffer=}16^f24^f32f40@?44
f24@0:8^f16
^f40@0:8i16i20^i24^i32
i48@0:8^f16*24f32i36@?40
v56@0:8*16q24^f32q40i48i52
@"VCPLoaned"
#20@0:8i16
@36@0:8i16i20i24B28B32
@48@0:8i16i20i24B28B32i36i40B44
i32@0:8@16@24
@"VCPCNNData"
B20@0:8i16
i28@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16s24
@36@0:8i16i20i24@28
i20@0:8B16
i28@0:8^{__CVBuffer=}16i24
^f16@0:8
v24@0:8^f16
@"VCPCNNMetalContext"
^v20@0:8B16
@24@0:8B16B20
^v16@0:8
i56@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24
i24@0:8^f16
@20@0:8i16
i52@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16^f24^f32i40i44i48
i36@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16i24i28i32
i32@0:8^{__CVBuffer=}16^f24
i72@0:8^f16^{__CVBuffer=}24i32i36{CGRect={CGPoint=dd}{CGSize=dd}}40
i64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48^B56
@72@0:8@16{CGSize=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40
v68@0:8{CGAffineTransform=dddddd}16B64
@32@0:8B16B20@24
i36@0:8^{CGPoint=dd}16^f24f32
^f48@0:8i16i20^i24^i32^f40
i64@0:8^f16i24i28i32i36i40^{CGPoint=dd}44^f52f60
i52@0:8^{__CVBuffer=}16@24[21{CGPoint=dd}]32[21f]40B48
@20@0:8B16
@"<MTLDevice>"
@"<MTLCommandQueue>"
@"<MTLCommandBuffer>"
f32@0:8@16@24
@40@0:8^{opaqueCMSampleBuffer=}16@24^@32
v48@0:8@16i24i28^f32^f40
f48@0:8{CGPoint=dd}16{CGPoint=dd}32
{CGSize=dd}32@0:8@16^@24
I16@0:8
B32@0:8@16^@24
@"VCPImageHumanPoseAnalyzer"
@"NSArray"
@24@0:8s16B20
[200@"VCPCNNBlock"]
@48@0:8@16@24@32@40
i40@0:8{vector<float *, std::__1::allocator<float *>>=^^f^^f{__compressed_pair<float **, std::__1::allocator<float *>>=^^f}}16
{vector<espresso_buffer_t, std::__1::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::__1::allocator<espresso_buffer_t>>=^{?}}}16@0:8
v40@0:8{vector<espresso_buffer_t, std::__1::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::__1::allocator<espresso_buffer_t>>=^{?}}}16
{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@0:8
v184@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16
{?="plan"^v"network_index"i}
@"VCPCNNEspressoContext"
{vector<espresso_buffer_t, std::__1::allocator<espresso_buffer_t>>="__begin_"^{?}"__end_"^{?}"__end_cap_"{__compressed_pair<espresso_buffer_t *, std::__1::allocator<espresso_buffer_t>>="__value_"^{?}}}
{?="data"^v"reserved"^v"dim"[4Q]"stride"[4Q]"width"Q"height"Q"channels"Q"batch_number"Q"sequence_length"Q"stride_width"Q"stride_height"Q"stride_channels"Q"stride_batch_number"Q"stride_sequence_length"Q"storage_type"i}
i52@0:8^f16i24i28@32@40i48
i48@0:8^{__CVBuffer=}16@24@32@?40
@"VCPProtoTimeRange"
i40@0:8@16@24@?32
@28@0:8i16i20i24
B72@0:8{?=qiIq}16{?=qiIq}40^@64
@"VCPVideoProcessorSession"
@"NSArray"16@0:8
v24@0:8@"<PVFetchResultProtocol>"16
@"<PVFaceProtocol>"16@0:8
v24@0:8@"<PVFaceProtocol>"16
i64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48^q56
B40@0:8@16@24^@32
B88@0:8{?={?=qiIq}{?=qiIq}}16{?=qiIq}64
B56@0:8^{opaqueCMSampleBuffer=}16{?=qiIq}24^@48
B32@0:8^{opaqueCMSampleBuffer=}16^@24
B48@0:8{?=qiIq}16^@40
v20@0:8I16
@"NSObject<OS_dispatch_queue>"
{CF<opaqueCMSampleBuffer *>="value_"^{opaqueCMSampleBuffer}}
@"VCPCNNModel"
@44@0:8@16@24@32i40
@"VCPDatabaseReader"
@"NSSet"
@"NSDictionary"
@"PHAsset"
i36@0:8^{sqlite3_stmt=}16i24@28
i40@0:8^{sqlite3_stmt=}16i24i28@32
i40@0:8@16^@24^q32
i32@0:8q16@24
i40@0:8q16@24@32
@32@0:8Q16Q24
^{sqlite3=}
Q28@0:8@16f24
v24@0:8Q16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@56@0:8^f16^f24Q32Q40i48i52
i28@0:8f16f20f24
i36@0:8^f16f24^f28
i64@0:8^f16Q24Q32{DSPSplitComplex=^f^f}40^f56
B28@0:8i16i20i24
{DSPSplitComplex="realp"^f"imagp"^f}
i52@0:8@16B24@?28^Q36^@44
@44@0:8Q16Q24B32@?36
@36@0:8Q16B24@?28
@"NSObject<OS_dispatch_source>"
@32@0:8@16Q24
{CGAffineTransform=dddddd}20@0:8I16
i32@0:8@16^Q24
i32@0:8^Q16^@24
@"NSMutableDictionary"
Q36@0:8B16Q20Q28
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8Q16Q24
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8Q16Q24{CGAffineTransform=dddddd}32
q16@0:8
v24@0:8q16
v20@0:8i16
@"VNFaceObservation"
{?=qiIq}16@0:8
v40@0:8{?=qiIq}16
{mach_timebase_info="numer"I"denom"I}
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@"NSDate"
@"NSTimeZone"
v40@0:8^{__CVBuffer=}16@24@?32
v40@0:8@16@24@?32
@"VCPTaskProcessingService"
B32@0:8@?16^@24
d24@0:8@16
@"NSURL"16@0:8
B32@0:8@?<v@?>16^@24
@"<PVFetchResultProtocol>"24@0:8@"NSArray"16
@"<PVFetchResultProtocol>"24@0:8Q16
@"<PVFetchResultProtocol>"24@0:8@"<PVMomentProtocol>"16
@"<PVFetchResultProtocol>"24@0:8@"<PVPersonProtocol>"16
@"NSDictionary"24@0:8@"<PVFetchResultProtocol>"16
@"<PVFetchResultProtocol>"32@0:8@"<PVPersonProtocol>"16@"<PVMomentProtocol>"24
@"<PVFetchResultProtocol>"32@0:8@"NSArray"16@"<PVMomentProtocol>"24
@"<PVFetchResultProtocol>"24@0:8@"<PVFaceGroupProtocol>"16
@"<PVFetchResultProtocol>"16@0:8
@"NSDate"16@0:8
@"NSSet"16@0:8
@32@0:8@16@24
v32@0:8@16Q24
i72@0:8^@16^@24^@32^@40^@48^@56^@64
i32@0:8^@16^@24
v32@0:8@16^{CGRect={CGPoint=dd}{CGSize=dd}}24
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
i40@0:8^@16^@24@32
v40@0:8@16@24@32
q32@0:8@16Q24
@60@0:8@16Q24Q32@40i48^@52
i56@0:8^@16@24@32Q40Q48
@40@0:8@16@24^@32
i40@0:8^@16@24@32
i48@0:8@16@24@32^@40
@"PVContext"
@"VCPFaceMerger"
@"NSObject<OS_dispatch_group>"
@"VCPObjectPool"
@28@0:8i16f20f24
f24@0:8f16B20
Q24@0:8Q16
@"NSData"
@64@0:8{CGAffineTransform=dddddd}16
@72@0:8@16@24@32@40B48B52f56f60f64B68
i48@0:8^{__CVBuffer=}16{?=qiIq}24
i80@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48^Q72
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72^Q80
i40@0:8{?=qiIq}16
f40@0:8@16^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}24i32i36
i64@0:8{?={?=qiIq}{?=qiIq}}16
i20@0:8i16
v24@0:8^{Frame=i{?=qiIq}{?=qiIq}{Translation=fff}{Translation=fff}fQf{Translation=fff}IB{Translation=fff}f{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}fff{Histogram=ff[3^i][2^i]}}16
f24@0:8^{Frame=i{?=qiIq}{?=qiIq}{Translation=fff}{Translation=fff}fQf{Translation=fff}IB{Translation=fff}f{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}fff{Histogram=ff[3^i][2^i]}}16
i36@0:8@16@24B32
i44@0:8^{__CFArray=}16@24@32B40
v24@0:8^{__CVBuffer=}16
v32@0:8^{Frame=i{?=qiIq}{?=qiIq}{Translation=fff}{Translation=fff}fQf{Translation=fff}IB{Translation=fff}f{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}fff{Histogram=ff[3^i][2^i]}}16@24
^{EncodeAnalysis=ii*^{__CVBuffer}{Translation=fff}^q^q^i^i^i^{Translation}^{FrameBuffer}^{EncodeStats}ff{MotionFieldAnalysis=^{EncodeStats}^f^f*iiiifffBB[2^i][2*][2^f][2^s][2^f][2i][2^i][2^f][2^f]{map<int, CGRect, std::__1::less<int>, std::__1::allocator<std::__1::pair<const int, CGRect>>>={__tree<std::__1::__value_type<int, CGRect>, std::__1::__map_value_compare<int, std::__1::__value_type<int, CGRect>, std::__1::less<int>, true>, std::__1::allocator<std::__1::__value_type<int, CGRect>>>=^{__tree_end_node<std::__1::__tree_node_base<void *> *>}{__compressed_pair<std::__1::__tree_end_node<std::__1::__tree_node_base<void *> *>, std::__1::allocator<std::__1::__tree_node<std::__1::__value_type<int, CGRect>, void *>>>={__tree_end_node<std::__1::__tree_node_base<void *> *>=^{__tree_node_base<void *>}}}{__compressed_pair<unsigned long, std::__1::__map_value_compare<int, std::__1::__value_type<int, CGRect>, std::__1::less<int>, true>>=Q}}}{ObjectDetection={Vector<ma::Object *>=^{__CFArray}}^{MotionVector}^f^i^i^iiiB}{ObjectTracking={Object=i{CGRect={CGPoint=dd}{CGSize=dd}}{CGPoint=dd}{CGPoint=dd}BffffB}{Object=i{CGRect={CGPoint=dd}{CGSize=dd}}{CGPoint=dd}{CGPoint=dd}BffffB}Bii^f^f^f^f^f^f^fqq^fiiqi{Vector<ma::ObjectTracking::Expert *>=^{__CFArray}}B}}[10f]{?=iii}{?=iiiiii}{?=iiiiii}{?=qiIq}fi^f^fBBqfff}
^{PreEncodeAnalysis=BB^{__CFData}^{__CFArray}B{Vector<unsigned int>=^{__CFArray}}{Vector<unsigned short>=^{__CFArray}}{Vector<float>=^{__CFArray}}{Vector<float>=^{__CFArray}}{?=qiIq}iQQ{EncodeParameters=iiIIISS}ffff{?=qiIq}dI}
^{ObstructionAnalysis={Vector<ma::ObstructionSegment *>=^{__CFArray}}^{ObstructionSegment}^{__CFArray}{?=qiIq}Bf}
^{SceneAnalysis={Vector<ma::SceneSegment *>=^{__CFArray}}^{SceneSegment}^{__CFArray}{?=qiIq}BffBBBBBiiB{CameraMotionAnalysis={Vector<ma::CameraMotionSegment *>=^{__CFArray}}^{CameraMotionSegment}^{__CFArray}{?=qiIq}Bf[6{HinkleyDetector=ffi{HinkleyStats=ffff}}]i{RotationAnalysis={Vector<ma::RotationSegment *>=^{__CFArray}}^{RotationSegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}i}BB}{SubjectMotionAnalysis={Vector<ma::SubjectMotionSegment *>=^{__CFArray}}^{SubjectMotionSegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}}{FineSubjectMotionAnalysis={Vector<ma::FineSubjectMotionSegment *>=^{__CFArray}}^{FineSubjectMotionSegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}B}{SubtleMotionAnalysis={Vector<ma::SubtleMotionSegment *>=^{__CFArray}}^{SubtleMotionSegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}B}{TrackingAnalysis={Vector<ma::TrackSegment *>=^{__CFArray}}^{TrackSegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}}{DescriptorAnalysis={Vector<ma::DescriptorSegment *>=^{__CFArray}}^{DescriptorSegment}^{__CFArray}{?=qiIq}Bf^{Rotator}^{__CFArray}}{MovingObjectAnalysis={Vector<ma::MovingObjectSegment *>=^{__CFArray}}^{MovingObjectSegment}^{__CFArray}{?=qiIq}Bfi}{InterestingnessAnalysis={Vector<ma::InterestingnessSegment *>=^{__CFArray}}^{InterestingnessSegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}}{QualityAnalysis={Vector<ma::QualitySegment *>=^{__CFArray}}^{QualitySegment}^{__CFArray}{?=qiIq}Bf{HinkleyDetector=ffi{HinkleyStats=ffff}}{?=qiIq}f^{FrameBuffer}ffffiiiBBB{?=qiIq}ff^{__CFArray}^{__CFArray}^{__CFArray}^{__CFArray}}{SlowMotionAnalysis={Vector<ma::SlowMotionSegment *>=^{__CFArray}}^{SlowMotionSegment}^{__CFArray}{?=qiIq}Bf^{FrameBuffer}^{__CVBuffer}{HinkleyDetector=ffi{HinkleyStats=ffff}}}}
^{MotionFilter=^{FrameBuffer}BB}
^{MetaDataAnalysis=B^{FrameBuffer}{Translation=fff}{Translation=fff}}
^{IrisAnalysis=ffiiB^{__CFArray}}
{FrameBuffer="frame_count_"i"buffer_"[35{Frame="frame_idx_"i"timestamp_"{?="value"q"timescale"i"flags"I"epoch"q}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"ave_motion_"{Translation="x_"f"y_"f"z_"f}"org_motion_"{Translation="x_"f"y_"f"z_"f}"quality_score_"f"distortion_"Q"distortion_norm_"f"motion_change_"{Translation="x_"f"y_"f"z_"f}"compressed_bytes_"I"blur_"B"acc_var_"{Translation="x_"f"y_"f"z_"f}"texture_"f"motion_result_"{MotionResult="significant_values_"[6f]"confidence_"[6f]"fine_action_score_"f"action_score_"f"track_score_"f"rotation_angle_"f"subtle_motion_score_"f"is_stable_"B"action_blocks_"i"action_motion_"f"valid_mb_"B"valid_submb_"B"support_size_"i"residual_var_"f"gmv_"[2f]"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"scene_delta_"f"scene_delta_ratio_"f"objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"detect_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"imported_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}}"interestingness_"f"obstruction_"f"colorfulness_score_"f"histogram_"{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}}]}
{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}
@"VCPFrameAnalysisStats"
@"VCPFrameScoreFilter"
@"VCPMotionFlowSubtleMotionAnalyzer"
@40@0:8i16i20Q24Q32
i56@0:8i16i20r^f24^f32Q40Q48
i60@0:8{Kernel=^fQQ}16f40f44f48f52f56
^^{Kernel}
@36@0:8^f16i24i28f32
i28@0:8i16@20
i48@0:8^f16^{__CVBuffer=}24i32i36@40
i40@0:8^{__CVBuffer=}16@24@32
i40@0:8^{__CVBuffer=}16@24@?32
i84@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56B72@76
i44@0:8^f16i24i28B32*36
@36@0:8@16B24Q28
@28@0:8@16B24
v40@0:8@16@24f32f36
f28@0:8@16f24
i40@0:8^{__CVBuffer=}16^f24@?32
i32@0:8^f16^{__CVBuffer=}24
i48@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}24@32i40i44
i52@0:8^{__CVBuffer=}16^Q24f32^@36@?44
[16f]
@"VCPCNNBlurAnalyzer"
@24@0:8@?16
B24@0:8^@16
@?16@0:8
v24@0:8@?16
{atomic<bool>="__a_"{__cxx_atomic_impl<bool, std::__1::__cxx_atomic_base_impl<bool>>="__a_value"AB}}
i32@0:8^{CGImage=}16^^{__CVBuffer}24
^{CGColorSpace=}
^{CGContext=}
^{__CVPixelBufferPool=}
@24@0:8^{__CVBuffer=}16
i32@0:8^f16@24
@"NSData"16@0:8
i32@0:8^f16@"<VCPDistanceDescriptorProtocol>"24
@24@0:8@"NSData"16
@"VNImageprint"
f56@0:8*16*24*32i40i44q48
f48@0:8*16i24i28q32*40
Q32@0:8@16@24
Q24@0:8@16
Q40@0:8@16@24Q32
i40@0:8@16Q24^@32
i40@0:8^@16@24Q32
i40@0:8^f16@24Q32
B80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
@40@0:8@16@24@?32
@"PHPhotoLibrary"
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
i44@0:8Q16Q24i32^^{__CVBuffer}36
i28@0:8^^{__CVBuffer}16i24
i48@0:8@16i24Q28^^{__CVBuffer}36B44
i44@0:8^{CGImage=}16I24Q28^^{__CVBuffer}36
i44@0:8^{CGImageSource=}16i24Q28^^{__CVBuffer}36
^{__CVBuffer=}48@0:8i16Q20@28@36B44
^{__CVBuffer=}28@0:8@16i24
^{__CVBuffer=}36@0:8@16i24Q28
^{__CVBuffer=}32@0:8i16@20B28
^{__CVBuffer=}36@0:8i16Q20@28
^{FigPhotoDecompressionSession=}
^{OpaqueVTPixelTransferSession=}
v40@0:8Q16Q24@?32
@40@0:8@16@24@32
v40@0:8@16Q24@?32
@24@0:8^@16
@36@0:8@16I24@28
@28@0:8@16I24
B56@0:8@16@24@32^@40^@48
B48@0:8@16Q24@32^@40
B44@0:8@16B24@28^@36
@32@0:8Q16^@24
B72@0:8@16@24@32@40@?48@56^@64
v56@0:8@16@?24@32@40@?48
@56@0:8@16@24@32@40^@48
@"NSSet"24@0:8^@16
@"NSArray"36@0:8@"NSArray"16I24@"NSMutableArray"28
@"NSArray"28@0:8@"NSArray"16I24
@"NSArray"24@0:8@"PHAsset"16
@"NSSet"40@0:8@"NSSet"16@"PVCanceler"24^@32
B56@0:8@"NSArray"16@"NSArray"24@"PHAsset"32^@40^@48
B48@0:8@"NSArray"16Q24@"PVCanceler"32^@40
B32@0:8@"PVCanceler"16^@24
B40@0:8@"PVFaceprint"16@"PVFace"24^@32
B32@0:8@"NSArray"16^@24
@"NSArray"24@0:8Q16
@"NSString"40@0:8@"PVFace"16@"PVFaceCrop"24^@32
@"PVFace"24@0:8@"PVFaceCrop"16
B44@0:8@"NSArray"16B24@"PVCanceler"28^@36
@"NSMutableArray"32@0:8Q16^@24
B72@0:8@"NSDictionary"16@"NSDictionary"24@"NSMutableSet"32@"NSMutableSet"40@?<v@?>48@"PVCanceler"56^@64
B32@0:8@"PVFace"16^@24
v56@0:8@"<PVFaceClusteringProtocol>"16@?<v@?@"NSArray">24@"PVCanceler"32@"PVContext"40@?<v@?>48
@"NSString"56@0:8@"NSString"16@"<PVFaceClusteringProtocol>"24@"PVCanceler"32@"PVContext"40^@48
v24@0:8@"NSString"16
@44@0:8@16@24B32@?36
@48@0:8@16d24Q32@?40
@"<PVFaceProtocol>"40@0:8@"<PVPersonProtocol>"16@"NSMapTable"24@?<v@?f^B>32
@"NSString"40@0:8@"PVPersonClusterManager"16@"NSSet"24@?<v@?f^B>32
@"NSArray"44@0:8@"PVPersonClusterManager"16@"NSSet"24B32@?<v@?f^B>36
@"NSArray"48@0:8@"NSArray"16d24Q32@?<d@?@@>40
v56@0:8@16@24^@32@40@48
B48@0:8@16@24@32^@40
B40@0:8Q16@24^@32
v48@0:8@16@24@32@?40
v112@0:8^@16^@24^@32^@40^@48^@56^@64^@72^@80@88@96@104
v56@0:8^@16^@24^@32@40@48
B112@0:8@16@24@32@40@48@56@64@72@?80@88@96^@104
Q32@0:8Q16@24
v64@0:8@16@24@32@40@48@56
v56@0:8@16@24@?32@40@48
@32@0:8@16^@24
@"VCPCNNPetsDetector"
i36@0:8@16f24@?28
@24@0:8i16B20
i40@0:8^{__CVBuffer=}16^f24i32i36
f40@0:8^f16i24i28i32i36
i32@0:8^f16i24i28
i24@0:8@?16
[5{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}]
[5f]
@24@0:8i16i20
i44@0:8^^{__CVBuffer}16^^{__CVBuffer}24@32B40
{CF<__CVPixelBufferPool *>="value_"^{__CVPixelBufferPool}}
i28@0:8^^{__CVPixelBufferPool}16I24
i36@0:8^{__CVBuffer=}16^^{__CVBuffer}24B32
i52@0:8@16B24^@28@36^^{__CVBuffer}44
i112@0:8^@16^@24^@32^@40^@48^@56^@64^@72^@80^@88^@96^@104
v80@0:8@16@24@32@40@48@56@64@72
i112@0:8^@16@24@32@40@48@56@64@72@80@88@96@104
v40@0:8f16f20@24@32
i40@0:8^@16^{__CVBuffer=}24@32
i40@0:8^@16^{__CVBuffer=}24B32B36
i32@0:8^@16^{__CVBuffer=}24
i56@0:8^@16B24B28@32@40^{__CVBuffer=}48
v48@0:8@16B24B28@32@?40
i48@0:8^{__CVBuffer=}16B24B28^@32@?40
@"VCPSceneProcessingImageManager"
@"PVSceneTaxonomy"
{CF<OpaqueVTPixelTransferSession *>="value_"^{OpaqueVTPixelTransferSession}}
B32@0:8@16@24
{CGSize=dd}32@0:8@16@24
i40@0:8^@16#24@32
^{__CVBuffer=}36@0:8@16@24i32
i52@0:8^@16#24@32@40B48
i48@0:8^f16@24@32@40
i40@0:8^f16@24@32
@40@0:8^{__CVBuffer=}16@24@?32
@40@0:8^{__CVBuffer=}16@"NSDictionary"24@?<v@?@"NSDictionary"@"NSError">32
@40@0:8@"NSURL"16@"NSDictionary"24@?<v@?@"NSDictionary"@"NSError">32
{CF<__CVBuffer *>="value_"^{__CVBuffer}}
@52@0:8@16^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}24C32*36^f44
i44@0:8^{__CVBuffer=}16^f24i32^f36
f24@0:8@16
i32@0:8[6f]16[6f]24
i24@0:8^{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}16
v80@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@?72
{Frame="frame_idx_"i"timestamp_"{?="value"q"timescale"i"flags"I"epoch"q}"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"ave_motion_"{Translation="x_"f"y_"f"z_"f}"org_motion_"{Translation="x_"f"y_"f"z_"f}"quality_score_"f"distortion_"Q"distortion_norm_"f"motion_change_"{Translation="x_"f"y_"f"z_"f}"compressed_bytes_"I"blur_"B"acc_var_"{Translation="x_"f"y_"f"z_"f}"texture_"f"motion_result_"{MotionResult="significant_values_"[6f]"confidence_"[6f]"fine_action_score_"f"action_score_"f"track_score_"f"rotation_angle_"f"subtle_motion_score_"f"is_stable_"B"action_blocks_"i"action_motion_"f"valid_mb_"B"valid_submb_"B"support_size_"i"residual_var_"f"gmv_"[2f]"duration_"{?="value"q"timescale"i"flags"I"epoch"q}"scene_delta_"f"scene_delta_ratio_"f"objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"detect_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}"imported_objects_"{Vector<ma::Object *>="vector_"^{__CFArray}}}"interestingness_"f"obstruction_"f"colorfulness_score_"f"histogram_"{Histogram="extremities_"f"overexposes_"f"histogram_"[3^i]"moments_hist_"[2^i]}}
^{EncodeStatsHW=^^?^B^B^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBiii^{OpaqueVTCompressionSession}^{__CFData}{?=qiIq}iiB}
[6[5f]]
i40@0:8@16@?24^Q32
i32@0:8@?16^Q24
@"AVAsset"
{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}
@148@0:8Q16{CGAffineTransform=dddddd}24{?={?=qiIq}{?=qiIq}}72B120@124B132B136@140
v56@0:8@16@24@32{CGSize=dd}40
@"VCPVideoKeyFrameAnalyzer"
@"VCPMovieHighlightAnalyzer"
{?="start"{?="value"q"timescale"i"flags"I"epoch"q}"duration"{?="value"q"timescale"i"flags"I"epoch"q}}
{CGSize="width"d"height"d}
@44@0:8{?=qiIq}16f40
@76@0:8{?={?=qiIq}{?=qiIq}}16f64@68
{?={?=qiIq}{?=qiIq}}16@0:8
@"VCPVideoKeyFrameResult"
@64@0:8{?={?=qiIq}{?=qiIq}}16
v64@0:8{?={?=qiIq}{?=qiIq}}16
@"VCPImageDescriptor"
@"VCPVideoKeyFrame"
@36@0:8Q16B24B28B32
i144@0:8@16@24@32@40@48@56@64@72@80@88@96@104@112@120{CGSize=dd}128
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{?={?=qiIq}{?=qiIq}}16
{?={?=qiIq}{?=qiIq}}68@0:8{?={?=qiIq}{?=qiIq}}16B64
{?={?=qiIq}{?=qiIq}}64@0:8{?={?=qiIq}{?=qiIq}}16
B64@0:8{?={?=qiIq}{?=qiIq}}16
f64@0:8{?={?=qiIq}{?=qiIq}}16
v60@0:8i16@20@28Q36@44@?52
v48@0:8i16@20@28B36@?40
v52@0:8i16Q20@28@36@?44
v60@0:8i16Q20@28@36@44@?52
v60@0:8i16@20@28@36@44@?52
v48@0:8i16@20B28@32@?40
v44@0:8i16@20@28@?36
v36@0:8i16@20@?28
v40@0:8i16B20@24@?32
v32@0:8@16@?24
v60@0:8i16@"NSArray"20@"NSDictionary"28Q36@"NSArray"44@?<v@?@"NSDictionary"@"NSError">52
v48@0:8i16@"NSURL"20@"NSArray"28B36@?<v@?@"NSDictionary"@"NSError">40
v52@0:8i16Q20@"NSURL"28@"NSDictionary"36@?<v@?@"NSError">44
v60@0:8i16Q20@"NSArray"28@"NSURL"36@"NSDictionary"44@?<v@?@"NSDictionary"@"NSError">52
v24@0:8@?<v@?@"NSError">16
v24@0:8@"NSURL"16
v60@0:8i16@"NSString"20@"NSArray"28@"NSArray"36@"NSURL"44@?<v@?@"NSArray"@"NSError">52
v48@0:8i16@"NSArray"20B28@"NSURL"32@?<v@?B@"NSError">40
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?@"NSArray"@"NSError">36
v36@0:8i16@"NSURL"20@?<v@?B@"NSError">28
v44@0:8i16@"NSDictionary"20@"NSURL"28@?<v@?@"NSString"@"NSError">36
v40@0:8i16B20@"NSURL"24@?<v@?@"NSDictionary"@"NSError">32
v36@0:8i16@"NSURL"20@?<v@?@"NSDictionary"@"NSError">28
v44@0:8i16@"NSArray"20@"NSURL"28@?<v@?B@"NSError">36
v32@0:8@"NSURL"16@?<v@?@"NSDictionary"@"NSError">24
v32@0:8@"NSURL"16@?<v@?@"NSString"@"NSError">24
v28@0:8d16i24
i56@0:8Q16@24@32@?40@?48
i44@0:8@16B24@?28@?36
i48@0:8Q16@24@?32@?40
i48@0:8@16@24@?32@?40
i32@0:8@16@?24
@"NSXPCConnection"
i64@0:8@16@24@32@40@?48@?56
i52@0:8@16B24@28@?36@?44
i40@0:8@16@?24@?32
i44@0:8B16@20@?28@?36
v48@0:8@"NSDictionary"16@"NSString"24@"NSURL"32@?<v@?>40
v40@0:8@"NSString"16@"NSURL"24@?<v@?@"NSString">32
q24@0:8@16
Q32@0:8Q16Q24
@52@0:8@16Q24@32@40B48
@48@0:8Q16@24@32^@40
@48@0:8@16@24Q32^@40
@56@0:8Q16@24@32@40@48
i48@0:8@16Q24@?32@?40
v40@0:8@16@24^q32
v88@0:8@16#24{?={?=qiIq}{?=qiIq}}32@80
@108@0:8#16@24@32@40{?={?=qiIq}{?=qiIq}}48B96^B100
v48@0:8@16@24^q32^f40
v144@0:8@16{?={?=qiIq}{?=qiIq}}24@72{?={?=qiIq}{?=qiIq}}80^q128^f136
i56@0:8Q16@24@32@?40@48
i52@0:8@16Q24B32@?36@?44
@52@0:8Q16@24B32@?36^@44
@56@0:8Q16@24@32@?40^@48
@44@0:8@16@24Q32B40
@"NSNumber"
@"AVAssetReaderOutputMetadataAdaptor"
S16@0:8
@40@0:8@16@24Q32
@72@0:8{?={?=qiIq}{?=qiIq}}16^Q64
@40@0:8@16r^{?={?=qiIq}{?=qiIq}}24Q32
i48@0:8@16r^{?={?=qiIq}{?=qiIq}}24Q32@?40
i64@0:8@16{?=qiIq}24Q48@?56
@32@0:8@?16^B24
@"VCPAsset"
@"VCPProtoBounds"
Q40@0:8^{?=Q^@^Q[5Q]}16^@24Q32
B20@0:8B16
{?={?=qiIq}{?=qiIq}}32@0:8@16f24B28
i48@0:8@16f24f28f32B36@?40
i56@0:8B16@20@28f36f40f44B48B52
f28@0:8f16@20
f48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
Q56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8@16
i32@0:8^@16@24
i40@0:8@16@24@32
i36@0:8B16@?20@?28
@"VNPersonsModel"
i40@0:8^Q16^Q24@?32
Q32@0:8q16Q24
Q32@0:8@16Q24
@40@0:8f16{CGPoint=dd}20B36
v32@0:8r^f16^{Matrix<float, 0, 0, false>=^fQII}24
i32@0:8^{Matrix<float, 0, 0, false>=^fQII}16^{Matrix<float, 0, 0, false>=^fQII}24
v24@0:8^{Matrix<float, 0, 0, false>=^fQII}16
i40@0:8^{Matrix<float, 0, 0, false>=^fQII}16^{Matrix<float, 0, 0, false>=^fQII}24^f32
f32@0:8[3[3f]]16[3f]24
i56@0:8^{Matrix<float, 0, 0, false>=^fQII}16r^f24[3[3f]]32[3f]40^f48
i56@0:8^{Matrix<float, 0, 0, false>=^fQII}16^{Matrix<float, 0, 0, false>=^fQII}24[4f]32^{Matrix<float, 0, 0, false>=^fQII}40^{Matrix<float, 0, 0, false>=^fQII}48
i40@0:8^{Matrix<float, 0, 0, false>=^fQII}16^{Matrix<float, 0, 0, false>=^fQII}24[4f]32
i36@0:8r^f16r^f24i32
[4[3f]]
@"VNSceneprint"
B24@0:8^{Frame=i{?=qiIq}{?=qiIq}{Translation=fff}{Translation=fff}fQf{Translation=fff}IB{Translation=fff}f{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}fff{Histogram=ff[3^i][2^i]}}16
[10f]
@"VCPSceneChangeSegment"
@32@0:8@16@?24
B40@0:8@16@24@32
v48@0:8@16@24@32Q40
v48@0:8@"NSDictionary"16@"NSError"24@"NSURL"32Q40
v56@0:8@16@24@32@40@?48
v64@0:8@16Q24@32@40@48@?56
v48@0:8@"NSString"16@"IOSurface"24@"NSDictionary"32@?<v@?@"NSDictionary"@"NSError">40
v56@0:8@"NSString"16@"NSURL"24@"NSString"32@"NSDictionary"40@?<v@?@"NSDictionary"@"NSError">48
v64@0:8@"NSString"16Q24@"NSArray"32@"NSArray"40@"NSDictionary"48@?<v@?@"NSError">56
v48@0:8#16^{__CVBuffer=}24@32@?40
v48@0:8#16@24@32@?40
v56@0:8#16@24@32@?40@?48
@48@0:8@16^{__CVBuffer=}24@32@?40
v24@0:8f16f20
v52@0:8^f16^f24^f32i40^f44
v48@0:8r^f16r^i24r^f32^f40
v48@0:8r^f16r^f24r^f32^f40
v32@0:8r^f16^f24
v52@0:8r^f16i24r^f28r^f36^f44
v36@0:8r^f16^f24B32
B24@0:8^f16
v56@0:8^f16^f24^f32^f40^f48
v44@0:8^f16^f24^f32i40
v68@0:8^f16^f24^f32^f40^f48^f56i64
{matrix<double, 6, 1, dlib::memory_manager_stateless_kernel_1<char>, dlib::row_major_layout>={layout<double, 6, 1, dlib::memory_manager_stateless_kernel_1<char>, 1>=[6d]}}16@0:8
B28@0:8i16B20B24
{?=[4]}16@0:8
^16@0:8
@"VCPFaceTensorModel"
[200{?="x"f"y"f"index"i}]
[200B]
[8f]
[9f]
[12f]
[3f]
[126f]
[189f]
@"VCPPnPSolver"
[51f]
i36@0:8^{__CVBuffer=}16^^{__CVBuffer}24i32
i24@0:8^{Frame=i{?=qiIq}{?=qiIq}{Translation=fff}{Translation=fff}fQf{Translation=fff}IB{Translation=fff}f{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}fff{Histogram=ff[3^i][2^i]}}16
i84@0:8^{__CVBuffer=}16^{Frame=i{?=qiIq}{?=qiIq}{Translation=fff}{Translation=fff}fQf{Translation=fff}IB{Translation=fff}f{MotionResult=[6f][6f]fffffBifBBif[2f]{?=qiIq}ff{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}{Vector<ma::Object *>=^{__CFArray}}}fff{Histogram=ff[3^i][2^i]}}24{?=qiIq}32{?=qiIq}56i80
{Scaler="pool_"^{__CVPixelBufferPool}"width_"i"height_"i"crop_rect_"{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}"sw_scaler_"^{OpaqueVTPixelTransferSession}}
@"VCPImageMotionFlowAnalyzer"
{vector<__CVBuffer *, std::__1::allocator<__CVBuffer *>>="__begin_"^^{__CVBuffer}"__end_"^^{__CVBuffer}"__end_cap_"{__compressed_pair<__CVBuffer **, std::__1::allocator<__CVBuffer *>>="__value_"^^{__CVBuffer}}}
@"VNRequest"
@24@0:8^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}16
v32@0:8^f16^f24
v44@0:8^f16i24^f28^f36
^i16@0:8
i40@0:8^{CGPoint=dd}16^f24^@32
v64@0:8^f16^f24Q32Q40Q48Q56
v28@0:8i16^f20
v40@0:8^f16Q24Q32
i56@0:8^f16@24^{CGPoint=dd}32^f40^@48
i52@0:8@16f24{CGPoint=dd}28^f44
i32@0:8@16^f24
[8^f]
@"VCPGaborFilter"
i68@0:8{?={?=qiIq}{?=qiIq}}16f64
i64@0:8{?=qiIq}16{?=qiIq}40
@"VCPSegment"
^{HinkleyDetector=ffi{HinkleyStats=ffff}}
^{__CVBuffer=}24@0:8Q16
{CGSize=dd}16@0:8
@32@0:8r^16Q24
r^16@0:8
@96@0:8{?=[4]}16@80@88
@"VCPFaceGeometry"
{?="columns"[4]}
@80@0:8Q16{CGAffineTransform=dddddd}24@72
@40@0:8Q16@24@32
@88@0:8Q16{CGAffineTransform=dddddd}24f72@76B84
B32@0:8r^{CGAffineTransform=dddddd}16@24
{CGAffineTransform=dddddd}64@0:8{CGAffineTransform=dddddd}16
{CGAffineTransform=dddddd}28@0:8i16^{__CVBuffer=}20
{?=[4]}84@0:8{?=[4]}16i80
@88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72^@80
i88@0:8^{__CVBuffer=}16{?=qiIq}24{?=qiIq}48@72@?80
i72@0:8{?={?=qiIq}{?=qiIq}}16@64
B68@0:8{?=qiIq}16{?=qiIq}40B64
@"VCPVideoFacePoseAnalyzer"
@"VCPVideoFaceMeshAnalyzer"
@"VCPFullVideoAnalyzer"
@"VCPImageBlurAnalyzer"
@"VCPAudioAnalyzer"
@"VCPVideoFullFaceDetector"
@"VCPSceneChangeAnalyzer"
@"VCPLightMotionAnalyzer"
@"VCPTrimAnalyzer"
@"VCPHomeKitMotionAnalyzer"
^{Rotator=^{__CVPixelBufferPool}iii^{OpaqueVTImageRotationSession}}
v40@0:8*16Q24^f32
i24@0:8^Q16
i32@0:8^{__CVBuffer=}16^Q24
^{__CVBuffer=}
@"NSObject<OS_dispatch_semaphore>"
@"NSMutableData"
@"NSURLSessionDataTask"
@32@0:8q16q24
@56@0:8@16@24Q32@?40@?48
@"VNFaceprint"
@56@0:8@16Q24Q32Q40@48
i40@0:8^f16^{CGPoint=dd}24i32i36
i32@0:8^{CGPoint=dd}16^f24
@"VCPProtoTime"
@"NSPersistentContainer"
@"NSManagedObjectContext"
@"VCPVideoActivityDescriptor"
v52@0:8Q16@24i32@36@?44
v52@0:8Q16@"NSData"24i32@"NSDictionary"36@?<v@?@"NSDictionary"@"NSError">44
v52@0:8Q16@"IOSurface"24i32@"NSDictionary"36@?<v@?@"NSDictionary"@"NSError">44
v44@0:8i16@"NSData"20@"NSDictionary"28@?<v@?@"NSString"@"NSError">36
v36@0:8i16@"NSDictionary"20@?<v@?@"NSDictionary"@"NSError">28
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceRenewalRequest"24
v32@0:8@"AVAssetResourceLoader"16@"AVAssetResourceLoadingRequest"24
B32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v32@0:8@"AVAssetResourceLoader"16@"NSURLAuthenticationChallenge"24
v24@0:8I16B20
^{__SCNetworkReachability=}
@"PVFace"
@"PVImage"
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
@48@0:8@16@?24@?32@40
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
i32@0:8@?16@?24
@"VCPFaceAnalyzer"
i28@0:8@16i24
i32@0:8^{CGPoint=dd}16^{CGPoint=dd}24
f40@0:8^{CGRect={CGPoint=dd}{CGSize=dd}}16^{CGRect={CGPoint=dd}{CGSize=dd}}24^f32
i40@0:8^f16^{__CVBuffer=}24@32
@"VCPCNNHandsDetector"
@"VCPCNNHandKeypointsDetector"
@"VCPCNNFastGestureRecognition"
{?="quality"b1"statsFlags"b1"typesWide"b1}
B40@0:8@16#24@32
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
i20@0:8f16
i40@0:8^{__CVBuffer=}16^{__CVBuffer=}24@?32
^f32@0:8^i16^i24
{vector<float *, std::__1::allocator<float *>>="__begin_"^^f"__end_"^^f"__end_cap_"{__compressed_pair<float **, std::__1::allocator<float *>>="__value_"^^f}}
@"SHMutableSignature"
{?="faceSharpness"b1}
@"VCPProtoLine"
@"VCPProtoPoint"
{?="underExpose"b1}
^{LkFsMeasure=IIqBIIddddqqIII[30[6f]]^f^f^f^{DspLibBiquad}^{DspLibBiquad}}
^{CAStreamBasicDescription=dIIIIIIII}
{vector<double, std::__1::allocator<double>>="__begin_"^d"__end_"^d"__end_cap_"{__compressed_pair<double *, std::__1::allocator<double>>="__value_"^d}}
{vector<float, std::__1::allocator<float>>="__begin_"^f"__end_"^f"__end_cap_"{__compressed_pair<float *, std::__1::allocator<float>>="__value_"^f}}
^{AUOutputBL={CAStreamBasicDescription=dIIIIIIII}*^{AudioBufferList}III}
{?="faceQuality"b1}
v60@0:8@16@24i32@36@44@?52
v60@0:8@"NSArray"16@"IOSurface"24i32@"NSDictionary"36@"NSDictionary"44@?<v@?@"NSDictionary"@"NSError">52
i48@0:8@16^{__CVBuffer=}24@32@?40
@"VCPImageHandsAnalyzer"
v36@0:8@16Q24B32
i40@0:8@16@24^@32
@48@0:8{CGPoint=dd}16{CGPoint=dd}32
@"VCPProtoLivePhotoVariationParams"
{?="epoch"b1"flags"b1}
@40@0:8^{__CVBuffer=}16@24^@32
f24@0:8Q16
v32@0:8^f16Q24
{?="list"^f"count"Q"size"Q}
@44@0:8i16B20B24@28@36
i48@0:8[21{CGPoint=dd}]16^f24@32@40
{?="loopFadeLen"b1"loopPeriod"b1"loopStart"b1}
v32@0:8@"NSDictionary"16@?<v@?@"NSError">24
v32@0:8@"NSDictionary"16@?<v@?@"NSDictionary"@"NSError">24
v40@0:8@"NSData"16@"NSDictionary"24@?<v@?@"NSDictionary"@"NSError">32
{CF<const opaqueCMFormatDescription *>="value_"^{opaqueCMFormatDescription}}
@"VCPHomeKitAnalysisSession"
{CLLocationCoordinate2D=dd}16@0:8
@"VCPCNNPersonDetector"
@"VCPCNNPersonKeypointsDetector"
@36@0:8i16B20B24@28
i48@0:8^f16i24i28@32[3[2f]]40
i36@0:8r^{vector<espresso_buffer_t, std::__1::allocator<espresso_buffer_t>>=^{?}^{?}{__compressed_pair<espresso_buffer_t *, std::__1::allocator<espresso_buffer_t>>=^{?}}}16@24i32
i72@0:8*16i24i28i32{CGPoint=dd}36{CGPoint=dd}52I68
i44@0:8*16i24i28i32^{CGPoint=dd}36
v28@0:8B16@?20
v44@0:8@16B24@28@?36
@64@0:8@16@24@32@?40@48^@56
@56@0:8@16@24@32@?40^@48
v64@0:8@16@24@32@40@?48@?56
v48@0:8@16@?24@?32@?40
@"PVClusterer"
@"VCPPhotosPersistenceDelegate"
i40@0:8@16^@24@?32
@32@0:8@16q24
S24@0:8@16
v28@0:8@16I24
v28@0:8@"VNRequest"16I24
v24@0:8@"NSDictionary"16
B40@0:8@16@?24^@32
@"VCPFaceClusterer"
v40@0:8i16i20^f24^f32
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48f52
f80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
i92@0:8@16@24i32^{__CVBuffer=}36{?=qiIq}44{?=qiIq}68
@"VCPVideoObjectTracker"
{?="distanceToPreviousScene"b1"flickerScore"b1"sceneprintDistanceToPreviousScene"b1}
B36@0:8@16B24^@28
B48@0:8^@16^d24^B32^@40
B60@0:8@16B24@28@?36@?44^@52
@"VCPFaceVisionIntegrating"
@"VCPProtoVideoKeyFrame"
@32@0:8{CGPoint=dd}16
@40@0:8{?=qiIq}16
@36@0:8@16@24f32
@"PHFace"
v48@0:8Q16@24@32@?40
v48@0:8Q16@"IOSurface"24@"NSDictionary"32@?<v@?@"NSDictionary"@"NSError">40
@28@0:8i16@20
v48@0:8Q16^{__CVBuffer=}24@32@?40
@"NSLock"
@44@0:8@16i24i28i32i36i40
v60@0:8*16i24i28i32^f36^f44^f52
v36@0:8^f16^f24i32
^{LandmarkDetector=iiiiiiiB^f^f^f^i^{ZPoint}^{RegressionTree}^?}
^q16@0:8
q24@0:8Q16
v32@0:8^q16Q24
{?="list"^q"count"Q"size"Q}
@20@0:8I16
@48@0:8{?=qiIq}16f40B44
v72@0:8{?={?=qiIq}{?=qiIq}}16f64B68
v44@0:8{?=qiIq}16B40
v24@0:8^{opaqueCMSampleBuffer=}16
i24@0:8^{opaqueCMFormatDescription=}16
i32@0:8^{__CVBuffer=}16^^{__CVBuffer}24
@"AVAssetWriter"
@"AVAssetWriterInput"
@"AVAssetWriterInputMetadataAdaptor"
{atomic<int>="__a_"{__cxx_atomic_impl<int, std::__1::__cxx_atomic_base_impl<int>>="__a_value"Ai}}
i88@0:8{?=qiIq}16{?=qiIq}40{?=qiIq}64
f56@0:8i16i20^{?={?=qiIq}{?=qiIq}}24{?=qiIq}32
B40@0:8{?=qiIq}16
B64@0:8{?=qiIq}16{?=qiIq}40
@"VCPActionAnalyzer"
@"AVURLAsset"
@"VCPFaceTimeSession"
i68@0:8@16@24@32@40@48@56f64
f80@0:8{?={?=qiIq}{?=qiIq}}16@64^i72
@68@0:8{?={?=qiIq}{?=qiIq}}16f64
v24@0:8^{EncodeStats=^^?^B^B^{MotionVector}^{MotionVector}^S^S^I^S^S^S^S^S^S^S^S^S^S^SIBBBii}16
@"VCPHumanPoseImageRequest"
@96@0:8{CGAffineTransform=dddddd}16@64@72B80B84@?88
@24@0:8f16B20
v40@0:8i16i20i24^f28i36
i84@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24i56{?=qiIq}60
r^f16@0:8
@"VCPRTLandmarkDetector"
@"VCPFaceShapeModel"
[5@"VCPLandmarkValidator"]
@40@0:8@16@24d32
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48
@72@0:8@16@24{?=qiIq}32^{?=qiIq}56@64
v104@0:8{?={?=qiIq}{?=qiIq}}16@64@72{?=qiIq}80
@"VCPImagePetsAnalyzer"
@20@0:8f16
B20@0:8f16
i80@0:8^{__CVBuffer=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{?=qiIq}56
v80@0:8{?=[4]}16
@"VCPCNNFaceLandmarkDetector"
@"VCPVideoFacePoseFilter"
[14f]
[21f]
i32@0:8[3[3f]]16[3f]24
i32@0:8[3f]16[3[3f]]24
i32@0:8[3f]16[3f]24
i24@0:8^{?=[4]}16
{Matrix<float, 12, 1, false>="m_data"[12f]}
{Matrix<float, 12, 12, false>="m_data"[144f]}
@80@0:8{CGAffineTransform=dddddd}16@64@72
B84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48B80
i56@0:8^{__CVBuffer=}16{?=qiIq}24@48
@"VCPCNNSmileDetector"
@"VCPCNNPoseEstimator"
B28@0:8@16f24
f72@0:8{?={?=qiIq}{?=qiIq}}16@64
f20@0:8f16
B72@0:8{?={?=qiIq}{?=qiIq}}16@64
i48@0:8@16{?=qiIq}24
v28@0:8B16@20
v60@0:8B16f20f24f28f32f36f40B44f48f52B56
@132@0:8{CGAffineTransform=dddddd}16{?={?=qiIq}{?=qiIq}}64B112@116@124
@"VCPImageFaceQualityAnalyzer"
@76@0:8{CGAffineTransform=dddddd}16@64B72
i32@0:8^{__CVBuffer=}16@24
@88@0:8@16{CGAffineTransform=dddddd}24Q72^{opaqueCMFormatDescription=}80
@"VCPVideoMetaFocusSegment"
@48@0:8q16{?=qiIq}24
v48@0:8q16{?=qiIq}24
@32@0:8Q16^{opaqueCMFormatDescription=}24
B24@0:8^{opaqueCMFormatDescription=}16
{CGSize=dd}24@0:8^{opaqueCMFormatDescription=}16
@24@0:8^{opaqueCMFormatDescription=}16
^{__CFData=}24@0:8^{opaqueCMFormatDescription=}16
^{__CFData=}28@0:8I16^{__CFData=}20
i32@0:8^{FigLivePhotoMetadata=I{FigLivePhotoMetadataV1Struct=fqffffffccSI[0{FigLivePhotoDetectedFaceV1Struct=qffffisS}]}}16@24
{CGVector="dx"d"dy"d}
@"VCPVideoMetaFocusAnalyzer"
@"VCPVideoMetaMotionAnalyzer"
@"VCPVideoMetaLensSwitchAnalyzer"
{HinkleyDetector="sensitivity_"f"threshold_"f"min_length_"i"stats_"{HinkleyStats="upper_"f"lower_"f"max_"f"min_"f}}
@"VCPVideoMetaMotionSegment"
@44@0:8f16{?=qiIq}20
v44@0:8f16{?=qiIq}20
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{__CVBuffer=}48{?=qiIq}56
@"VCPCtrTracker"
v32@0:8@16^{__CVBuffer=}24
f92@0:8f16{CGRect={CGPoint=dd}{CGSize=dd}}20{CGRect={CGPoint=dd}{CGSize=dd}}52i84i88
B48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@28@0:8@16f24
f84@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48B80
@"VCPImageSaliencyAnalyzer"
@32@0:8@16f24f28
v76@0:8@16{?=qiIq}24{?=qiIq}48B72
v72@0:8@16{?={?=qiIq}{?=qiIq}}24
@"VCPSceneTaxonomy"
{?=ii}24@0:8@16
^{opaqueCMSampleBuffer=}16@0:8
@"AVAssetTrack"
@32@0:8@16r^{?={?=qiIq}{?=qiIq}}24
@44@0:8@16r^{?={?=qiIq}{?=qiIq}}24@32B40
@"AVAssetReader"
@"AVAssetReaderTrackOutput"
^{opaqueCMSampleBuffer=}
@40@0:8@16r^{?={?=qiIq}{?=qiIq}}24r^{?=qiIq}32
i28@0:8B16^{?={?=qiIq}{?=qiIq}}20
i72@0:8{?={?=qiIq}{?=qiIq}}16^^{opaqueCMSampleBuffer}64
@"AVAssetReaderSampleReferenceOutput"
[2^{opaqueCMSampleBuffer}]
v40@0:8r^{?=qiIq}16r^{?=qiIq}24@32
{AudioStreamBasicDescription="mSampleRate"d"mFormatID"I"mFormatFlags"I"mBytesPerPacket"I"mFramesPerPacket"I"mBytesPerFrame"I"mChannelsPerFrame"I"mBitsPerChannel"I"mReserved"I}
i24@0:8r^{AudioStreamBasicDescription=dIIIIIIII}16
^{OpaqueAudioComponentInstance=}
v32@0:8^{__CVBuffer=}16^{CGPoint=dd}24
^{CGPoint=dd}16@0:8
v24@0:8^{CGPoint=dd}16
^{CGPoint=dd}
^{?=^{?}^{?}^{?}^{tplTracker_resampler_context}^{?}}
@"<MTLComputePipelineState>"
{CF<__CVMetalTextureCache *>="value_"^{__CVMetalTextureCache}}
{MetalBufferPool="pool_"@"NSMutableArray""device_"@"<MTLDevice>""allocSize_"Q"storageMode_"Q}
[4I]
@36@0:8^{__CVBuffer=}16i24@28
@32@0:8^{__CVBuffer=}16@24
{future<unsigned long long>=^{__assoc_state<unsigned long long>}}80@0:8^{__CVBuffer=}16^{__CVBuffer=}24{?={?=QQQ}{?=QQQ}}32
i88@0:8^{__CVBuffer=}16^{__CVBuffer=}24{?=QQQ}32{?=QQQ}56^{future<void>=^{__assoc_sub_state}}80
{future<CF<const __CFData *>>=^{__assoc_state<CF<const __CFData *>>}}140@0:8^{__CVBuffer=}16{?={?=QQQ}{?=QQQ}}24I72I76I80{?=qiIq}84{?=qiIq}108^{__CFDictionary=}132
mcpl
v024
ARGB
v024
mcpl
