?ffffff
=333333
(@ffffff
@ffffff
?333333
?ffffff
333333
@333333
f@es-8R
?333333
?333333
@333333
?333333
?333333
?ffffff
?333333
333>
0@ff&?
?ffffff
@333333
~?333333
ffffff
MbP?
MbP?
MbP?
x?333333
?333333
?333333
?ffffff
@33s?
emptyImage
extent
numberWithInt:
dictionaryWithObjects:forKeys:count:
imageByClampingToExtent
arrayWithObjects:count:
applyWithExtent:roiCallback:arguments:options:
imageByCroppingToRect:
outputImage
inputImage
setInputImage:
T@"CIImage",&,VinputImage
objectAtIndexedSubscript:
objectForKeyedSubscript:
CGRectValue
region
baseAddress
processWithInputs:arguments:output:error:
outputFormat
synchronizeInputs
roiForInput:arguments:outputRect:
formatForInputAtIndex:
PFKernelWithString:
floatValue
imageByApplyingTransform:
imageByApplyingFilter:
imageByApplyingFilter:withInputParameters:
transitionDepthsKernel
applyWithExtent:arguments:options:
thresholdKernel
vectorWithCGRect:
vectorWithX:Y:
customAttributes
inputFocusRect
setInputFocusRect:
inputScale
setInputScale:
T@"CIVector",C,N,VinputFocusRect
T@"NSNumber",C,N,VinputScale
convertToHalfFloat
applyWithExtent:arguments:
renormalize01
renormalizeThreshold
vectorWithX:Y:Z:
computeBand
protectInterior
filterWithName:withInputParameters:
denormalize
vectorWithX:Y:Z:W:
invertImage
normalizeToPhysicalDepth
foreground
filterCut
boxBlur3Mono
inputDisparityImage
setInputDisparityImage:
inputThresholdImage
setInputThresholdImage:
inputMaxNumVertices
setInputMaxNumVertices:
inputSigmaS
setInputSigmaS:
inputSigmaRLuma
setInputSigmaRLuma:
inputSigmaRChroma
setInputSigmaRChroma:
inputLambda
setInputLambda:
inputMaxNumIterations
setInputMaxNumIterations:
inputBandRange
setInputBandRange:
inputThresholdOffset
setInputThresholdOffset:
inputFilterCut
setInputFilterCut:
inputFeatherBandRange
setInputFeatherBandRange:
inputAdaptiveThresholdRange
setInputAdaptiveThresholdRange:
inputSigmaFallout
setInputSigmaFallout:
T@"CIImage",&,VinputDisparityImage
T@"CIImage",&,VinputThresholdImage
T@"NSNumber",C,N,VinputMaxNumVertices
T@"NSNumber",C,N,VinputSigmaS
T@"NSNumber",C,N,VinputSigmaRLuma
T@"NSNumber",C,N,VinputSigmaRChroma
T@"NSNumber",C,N,VinputLambda
T@"NSNumber",C,N,VinputMaxNumIterations
T@"CIVector",&,VinputBandRange
T@"NSNumber",C,N,VinputThresholdOffset
T@"NSNumber",C,N,VinputFilterCut
T@"NSNumber",C,N,VinputFeatherBandRange
T@"NSNumber",C,N,VinputAdaptiveThresholdRange
T@"NSNumber",C,N,VinputSigmaFallout
colorSpace
imageYCC444:matrix:fullRange:colorSpace:
_confidenceExtractRed
extractLuminance:
format
bytesPerRow
intValue
_kickLightKernel_pos
_kickLightKernel_neg
numberWithFloat:
inputWidth
setInputWidth:
inputStrength
setInputStrength:
inputRotate
setInputRotate:
inputPt1
setInputPt1:
inputPt2
setInputPt2:
inputPt3
setInputPt3:
inputPt4
setInputPt4:
inputPt5
setInputPt5:
inputPt6
setInputPt6:
inputOrientation
setInputOrientation:
inputCenterBottom
setInputCenterBottom:
T@"CIImage",&,N,VinputImage
T@"CIVector",&,N,VinputPt1
T@"CIVector",&,N,VinputPt2
T@"CIVector",&,N,VinputPt3
T@"CIVector",&,N,VinputPt4
T@"CIVector",&,N,VinputPt5
T@"CIVector",&,N,VinputPt6
T@"NSNumber",&,N,VinputWidth
T@"NSNumber",&,N,VinputStrength
T@"NSNumber",&,N,VinputRotate
T@"NSNumber",&,N,VinputOrientation
T@"NSNumber",&,N,VinputCenterBottom
_dualLightKernel
inputCenter1
setInputCenter1:
inputCenter2
setInputCenter2:
inputBottom1
setInputBottom1:
inputBottom2
setInputBottom2:
inputWidth1
setInputWidth1:
inputWidth2
setInputWidth2:
inputHeight1
setInputHeight1:
inputHeight2
setInputHeight2:
inputRotate1
setInputRotate1:
inputRotate2
setInputRotate2:
inputBrighten
setInputBrighten:
inputContrast
setInputContrast:
T@"CIVector",&,N,VinputCenter1
T@"CIVector",&,N,VinputCenter2
T@"CIVector",&,N,VinputBottom1
T@"CIVector",&,N,VinputBottom2
T@"NSNumber",&,N,VinputWidth1
T@"NSNumber",&,N,VinputWidth2
T@"NSNumber",&,N,VinputHeight1
T@"NSNumber",&,N,VinputHeight2
T@"NSNumber",&,N,VinputBrighten
T@"NSNumber",&,N,VinputRotate1
T@"NSNumber",&,N,VinputRotate2
T@"NSNumber",&,N,VinputContrast
_strobeKernel
_extractRed
doubleValue
imageByApplyingGaussianBlurWithSigma:
_contourLightKernel
inputCenter
setInputCenter:
inputEyes
setInputEyes:
inputHeight
setInputHeight:
T@"CIVector",&,N,VinputCenter
T@"CIVector",&,N,VinputEyes
T@"NSNumber",&,N,VinputHeight
T@"NSNumber",&,N,VinputScale
_portraitSpotKernel
inputDarken
setInputDarken:
T@"NSNumber",&,N,VinputDarken
_neckContourKernel
inputChin
setInputChin:
inputFaceOrientation
setInputFaceOrientation:
T@"CIVector",&,N,VinputChin
T@"NSNumber",&,N,VinputFaceOrientation
_extractRedStudio
_cheapEdgePreserve
_studioLightKernel
inputBlur
setInputBlur:
T@"NSNumber",&,N,VinputBlur
_faceContourMask
_darken
numberWithDouble:
kernelWithString:fromMetalLibraryData:
bundleWithIdentifier:
URLForResource:withExtension:
dataWithContentsOfURL:
rectValue
valueWithRect:
sanityCheckStatus
setSanityCheckStatus:
imageWidthScale
setImageWidthScale:
imageHeightScale
setImageHeightScale:
coreImageROIrect
setCoreImageROIrect:
T{CGRect={CGPoint=dd}{CGSize=dd}}
count
applyWithExtent:inputs:arguments:error:
inputFaceLandmarks
setInputFaceLandmarks:
_inputImage
_inputFaceLandmarks
T@"CIImage",&,N,V_inputImage
T@"NSDictionary",&,N,V_inputFaceLandmarks
initWithFaceLandmarks:forImageRect:
dataWithLength:
mutableBytes
bytes
allowPartialOutputRegion
initWithLength:
faceData
skinSampleRgon
boundsFloatRect
skinSeedPointCount
skinSeedPoints
headPerimeter
teethSeedPoints
leftIrisSeedPoints
rightIrisSeedPoints
eyebrowRightTopLine
boundsPath
eyebrowLeftTopLine
noseTipPerimeterPath
leftEyePair
rightEyePair
teethPair
faceBounds
rightEye
leftEye
mouthCenter
faceOrientationIndex
AdjustForPointX:Y:
CalculateVertices
CalculateEdges
setSkinSampleRgon:
setAdjustmentRect:
setHeadRect:
betweenTheEyes
setSkinSeedPointCount:
CalculateAndReturnVertices:
containsPointX:Y:
setBinSize:
setZDarkThr:
AdjustForPointX:Y:Z:
zDarkThr
containsPointPlanarConditionalX2:Y:Z:epsilonDark:epsilonLight:epsilonMid:shouldPrint:
setPerservesAlpha:
_srgbToIPT
boolValue
_rectToHueChroma
inputReturnHueChroma
_hueChromaToRect
_iptToSRGB
inputIsHueChroma
objectAtIndex:
_scaleHueZeroOne
contextWithOptions:
render:toBitmap:rowBytes:bounds:format:colorSpace:
colorWithRed:green:blue:alpha:colorSpace:
imageWithColor:
_scaleHuePi
imageWithBitmapData:bytesPerRow:size:format:colorSpace:
imageBySettingAlphaOneInExtent:
findPeakHue_Renderless:chromaMin:hueRange:
findPeakHue:chromaMin:hueRange:
inputHueRange
inputChromaMin
inputMaxDimension
inputReturnSmartColor
imageByInsertingIntermediate
_drawTriangle
leftCheekContour
leftCheekStrobe
imageByCompositingOverImage:
rightCheekContour
rightCheekStrobe
leftChinContour
leftNoseContour
rightChinContour
rightNoseContour
leftLipContour
rightLipContour
neckContour1
neckContourLeft
neckContourRight
_protectEyes
inputOrigImage
T@"LightingFacePoints",&,N,VinputFaceLandmarks
metalCommandBuffer
device
filterDescriptorWithWidth:height:arrayLength:kernelSpatialDiameter:kernelTemporalDiameter:epsilon:sourceChannels:guideChannels:preallocateIntermediates:
initWithDevice:filterDescriptor:
metalTexture
addObject:
encodeToCommandBuffer:sourceTextureArray:guidanceTexture:constraintsTextureArray:numberOfIterations:destinationTextureArray:
inputLightMap
inputLightMapWidth
inputLightMapHeight
inputGuideImage
inputGuidedFilterEpsilon
_polyKernel
_shadowKernel
inputLightMapImage
inputLocalLight
inputSmartShadows
length
initWithImageProvider:width:height:format:colorSpace:options:
countByEnumeratingWithState:objects:count:
setObject:forKey:
setValue:forKey:
imageWithCVPixelBuffer:options:
filterWithName:
inputKeys
containsObject:
imageWithCVPixelBuffer:
initWithPixelBuffer:
setColorSpace:
getFaceFeatures:
prepareRender:fromRect:toDestination:atPoint:error:
run:withContext:withFaceScales:withProxyRendering:
prewarmWithContext:andProxyRendering:
initWithBitmapData:width:height:bytesPerRow:format:
initWithRed:green:blue:alpha:
width
height
previewCubeName
bundleForClass:
pathForResource:ofType:
standbyCubeName
backgroundPreviewCubeName
prewarm:
prewarmFullSizeRender:
previewCubePath
standbyCubePath
backgroundPreviewCubePath
cubeColorSpaceName
_defaultVersion
_maxVersion
inputFaceMask
setInputFaceMask:
inputTeethMask
setInputTeethMask:
inputHairMask
setInputHairMask:
inputBlurMap
setInputBlurMap:
inputDisparity
setInputDisparity:
inputMatte
setInputMatte:
inputFaceLandmarkArray
setInputFaceLandmarkArray:
inputRenderProxy
setInputRenderProxy:
inputSpillCorrectedRatioImage
setInputSpillCorrectedRatioImage:
inputGenerateSpillMatte
setInputGenerateSpillMatte:
T@"CIImage",&,N,VinputFaceMask
T@"CIImage",&,N,VinputTeethMask
T@"CIImage",&,N,VinputHairMask
T@"CIImage",&,N,VinputBlurMap
T@"CIImage",&,N,VinputDisparity
T@"CIImage",&,N,VinputMatte
T@"NSArray",&,N,VinputFaceLandmarkArray
T@"NSNumber",&,N,VinputRenderProxy
T@"CIImage",&,N,VinputSpillCorrectedRatioImage
T@"NSNumber",&,N,VinputGenerateSpillMatte
setInputSmooth:
setInputEnrich:
setInputTeeth:
setInputLocalContrast:
colorWithRed:green:blue:alpha:
initWithFaceLandmarkDictionary:forImageRect:
vectorWithCGPoint:
leftEyeOutline
rightEyeOutline
_eyeBlurV2
noseTip
_protectEyesNose
_featherEdge
maskForLandmarks:withFilterNamed:
_textureDiff
_textureAdd
_whitenTeeth
imageByInsertingIntermediate:
_imageByRenderingToIntermediate
_eyeBrightenV2
_eyeBrightenSoftlight
eyeBlurForLandmarks:
faceMaskForLandmarks:
faceRect
protectEyesNose:withFaceMask:withOrientation:
processSkinIn:withFaceMask:
processTeethIn:withFaceMask:
processTeethIn:withTeethMask:
processEyesIn:withEyeBlur:landmarks:
_enrichV2
imageForLandmarks:
enrichImage:
getDraftMode:
getRefinedMatteMode:
getRenderSpillCache:
setDefaults
skinMaskForLandmarks:
teethMaskForLandmarks:
inputSmooth
inputEnrich
inputTeeth
inputLocalContrast
T@"NSNumber",&,N,VinputSmooth
T@"NSNumber",&,N,VinputEnrich
T@"NSNumber",&,N,VinputTeeth
T@"NSNumber",&,N,VinputEyes
T@"NSNumber",&,N,VinputLocalContrast
setInputKickLight:
setInputFaceLight:
setInputDepthThreshold:
centerNose
faceWidth
faceHeight
_faceVignetteStudio
leftKickLights
rightKickLights
bottomShadow
centerChin
leftNose
rightNose
noseStrobe
_applyFaceProtectStudio
_prepareDepth
inputKickLight
inputFaceLight
inputDepthThreshold
T@"NSNumber",&,N,VinputKickLight
T@"NSNumber",&,N,VinputFaceLight
T@"NSNumber",&,N,VinputDepthThreshold
setInputContour:
addObjectsFromArray:
_faceVignette
_transparentBorder
_applyTransparentBorder
_applyFaceProtect
_blendSingleChannelMask
_applyVignette
inputContour
T@"NSNumber",&,N,VinputContour
setInputUseAbsoluteDisparity:
setInputSharpenRadius:
setInputGrainAmount:
depthData
depthDataAccuracy
_getRefinedMatte
_applyRefinedMatte
thresholdMatte
thresholdAndApplyMatte
_applyVignetteStage
_CIPrepareBlackDepth
_CIPrepareBlackDisparity
_CIApplyBlackDepth
_CIApplyStageNoFeather
_CIApplyStageNoFeatherWithSpillRatio
_CIRefineBlackDepth
_faceProtect
invertRed
blendDepth
inputUseAbsoluteDisparity
inputSharpenRadius
inputGrainAmount
T@"NSNumber",&,N,VinputUseAbsoluteDisparity
T@"NSNumber",&,N,VinputSharpenRadius
T@"NSNumber",&,N,VinputGrainAmount
thresholdWhiteMatte
thresholdAndApplyWhiteBG
_CIPrepareWhiteDepth
_applyWhiteNoFeather
_getRefinedWhiteMatte
_applyRefinedWhiteMatte
numberWithUnsignedLong:
loadArchive:
init
setFaceData:
setLeftToRightVec:
leftToRightVec
setUpVec:
setNoseTipPerimeterPath:
setHeadPerimeter:
initWithMaxsize:segmentDelta:andAxis:
setMouthPerimeterLinePair:
mouthPerimeterLinePair
accomodatePoint:
bottom
bridgeGapsLinear
expandWithToleranceTop:bottom:
extrapolateAndJoinTopAndBottom
constructBezierWithToleranceTop:bottom:
setLeftEyePair:
setRightEyePair:
setTeethPair:
setS0:
setS1:
constructBezierWithToleranceOutside:andInside:
setEyebrowRightTopLine:
setEyebrowLeftTopLine:
setMouthTopLine:
setMouthBottomLine:
setNosePair:
dealloc
imageRect
setImageRect:
mouthTopLine
mouthBottomLine
nosePair
upVec
eyebrowLeft
eyebrowRight
mouthTop
mouthBottom
upperLipBottom
lowerLipTop
leftEyeUpper
rightEyeUpper
leftEyeLowerR2L
rightEyeLowerR2L
leftSideFace
rightSideFace
leftTopFace
rightTopFace
topFace
bottomFace
noseOutline
noseRightSide
noseLeftSide
noseCenterline
polylineDelta
_faceData
_eyebrowRightTopLine
_eyebrowLeftTopLine
_mouthTopLine
_mouthBottomLine
_leftEyePair
_rightEyePair
_mouthPerimeterLinePair
_teethPair
_nosePair
_noseTipPerimeterPath
_headPerimeter
_leftToRightVec
_upVec
_imageRect
T{CGRect={CGPoint=dd}{CGSize=dd}},V_imageRect
T@"ComputedFaceData",&,V_faceData
T@"Polyline",&,V_eyebrowRightTopLine
T@"Polyline",&,V_eyebrowLeftTopLine
T@"Polyline",&,V_mouthTopLine
T@"Polyline",&,V_mouthBottomLine
T@"PolylinePair",&,V_leftEyePair
T@"PolylinePair",&,V_rightEyePair
T@"PolylinePair",&,V_mouthPerimeterLinePair
T@"PolylinePair",&,V_teethPair
T@"PolylinePair",&,V_nosePair
T^{CGPath=},V_noseTipPerimeterPath
T^{CGPath=},V_headPerimeter
T{CGPoint=dd},V_leftToRightVec
T{CGPoint=dd},V_upVec
faceIndex
setFaceIndex:
setSkinSeedPoints:
setTeethSeedPoints:
setRightIrisSeedPoints:
setLeftIrisSeedPoints:
neckSeedPoints
setNeckSeedPoints:
setIOD:
adjustmentRect
headRect
setFaceBounds:
hasLeftEyePosition
setHasLeftEyePosition:
hasRightEyePosition
setHasRightEyePosition:
hasMouthPosition
setHasMouthPosition:
setLeftEye:
setRightEye:
setBetweenTheEyes:
setMouthCenter:
faceCenter
setFaceCenter:
leftRightVec
setLeftRightVec:
eyeTiltAngle
setEyeTiltAngle:
setFaceOrientationIndex:
skinSeedPointArray
teethSeedPointArray
leftIrisSeedPointArray
rightIrisSeedPointArray
neckSeedPointArray
_hasLeftEyePosition
_hasRightEyePosition
_hasMouthPosition
_faceIndex
_skinSeedPointCount
_eyeTiltAngle
_faceOrientationIndex
_skinSeedPoints
_teethSeedPoints
_rightIrisSeedPoints
_leftIrisSeedPoints
_neckSeedPoints
_iOD
_skinSampleRgon
_leftEye
_rightEye
_betweenTheEyes
_mouthCenter
_faceCenter
_leftRightVec
_adjustmentRect
_headRect
_faceBounds
Ti,V_faceIndex
T^{CGPoint=dd},V_skinSeedPoints
Ti,V_skinSeedPointCount
T^{CGPoint=dd},V_teethSeedPoints
T^{CGPoint=dd},V_rightIrisSeedPoints
T^{CGPoint=dd},V_leftIrisSeedPoints
T^{CGPoint=dd},V_neckSeedPoints
Td,V_iOD
T{CGRect={CGPoint=dd}{CGSize=dd}},V_adjustmentRect
T{CGRect={CGPoint=dd}{CGSize=dd}},V_headRect
T{CGRect={CGPoint=dd}{CGSize=dd}},V_faceBounds
TB,V_hasLeftEyePosition
TB,V_hasRightEyePosition
TB,V_hasMouthPosition
T{CGPoint=dd},V_leftEye
T{CGPoint=dd},V_rightEye
T{CGPoint=dd},V_betweenTheEyes
T{CGPoint=dd},V_mouthCenter
T{CGPoint=dd},V_faceCenter
T{CGPoint=dd},V_leftRightVec
Tf,V_eyeTiltAngle
T@"Rgon",&,N,V_skinSampleRgon
Tf,V_faceOrientationIndex
rightContour
leftContour
chinSpot
noseProtect
leftEyeHeight
leftEyeWidth
rightEyeHeight
rightEyeWidth
noseWidth
noseHeight
setFaceRect:
T{CGRect={CGPoint=dd}{CGSize=dd}},VfaceRect
imageTransformForOrientation:
dataWithBytes:length:
dictionaryWithDictionary:
setObject:forKeyedSubscript:
getBytes:length:
clearOutputMask:WithBytesPerRow:OutputRegion:
findToothMaskUsingInputImage:InputBytesPerRow:InputRegion:OutputMask:OutputBytesPerRow:OutputRegion:TeethBounds:SeedPoints:NumberOfSeedPoints:FillValue:
trainSkinMaskUsingInputImage:InputBytesPerRow:InputRegion:QuadRegion:
findSkinMaskUsingInputImage:InputBytesPerRow:InputRegion:OutputMask:OutputBytesPerRow:OutputRegion:FaceBounds:SeedPoints:NumberOfSeedPoints:FillValue:
drawEyeMaskUsingQuads:OutputMask:OutputBytesPerRow:OutputRegion:
lumaDilateRadius
setLumaDilateRadius:
lumaErodeRadius
setLumaErodeRadius:
chromaDilateRadius
setChromaDilateRadius:
chromaErodeRadius
setChromaErodeRadius:
_colorCube
_tempColorCube
_inputScalingForCube
_lumaDilateRadius
_lumaErodeRadius
_chromaDilateRadius
_chromaErodeRadius
Ti,N,V_lumaDilateRadius
Ti,N,V_lumaErodeRadius
Ti,N,V_chromaDilateRadius
Ti,N,V_chromaErodeRadius
_brightenSat
inputSat
inputPShift
inputTShift
_brightenFood
setRgonPtr:
setPointerToRgonArray:
decodeBytesForKey:returnedLength:
encodeBytes:length:forKey:
allocWithZone:
rgonPtr
Area
getValue:
recalculateMaxMins
CalculateFromVertices
CommonCenterForIndex:
XCenter
YCenter
MeanVertexDistFromX:Y:
setAspectRatio:
setMaxAxisIndex:
DistToPointX:Y:
Diameter
MinDiameter
createWithCollapsedOrphans2
IntersectionOfEdge:withEdge:resultPoint:
OutsideReturnFirstEdgeExcludingX:Y:
copy
UnionWith:
CollapseOrphans
newInterpolatedRgonFrom:withRgon:param:
copyWithZone:
encodeWithCoder:
initWithCoder:
Reset
vertexAtClockHour:
dASide:movesds:
dASide:movesds:retaining:pointsFromArray:
DirectionalDilateByAmount:xDirection:yDirection:
translateByAmount:xDirection:yDirection:
dentRgonInwardByAmount:xDirection:yDirection:
Dilate:
containsPointX:Y:inArray:ofCount:
pointX:Y:isOutsideBorderlinesInArray:ofCount:
containsPointX:Y:withTolerance:returnIndex:
Radius
AspectIndex
DiameterAtFacetCountMeasuredFromVertical:
RoundToPercent:
DistanceFromRgon:
DistanceBetweenCenters:
Density
Perimeter
AspectRatio
PrintVertices
PrintVerticesWithZCoord:
PrintConstraints
ShrinkByAmount:
intersectionEdge:withEdge:
unionRgonOf:withRgon:
IntersectionRgonOf:withRgon:
DistanceCenterToRGon:
maxAxisIndex
aspectRatio
ymax
setYmax:
ymin
setYmin:
xmax
setXmax:
xmin
setXmin:
currentArea
setCurrentArea:
setCount:
pointCount
setPointCount:
pointerToRgonArray
enclosedPoints
rgonArray
verticesUpToDate
maxDiameter
minDiameter
minAxisIndex
oblongness
lastFaceFlunked
_pointerToRgonArray
_enclosedPoints
T^[7f],VrgonPtr
T^f,V_pointerToRgonArray
Ti,VmaxAxisIndex
Tf,VaspectRatio
Tf,Vymax
Tf,Vymin
Tf,Vxmax
Tf,Vxmin
Tf,VcurrentArea
Tq,VpointCount
Td,Vcount
T@"NSArray",R,V_enclosedPoints
initWithCapacity:
decodeObjectForKey:
decodeIntegerForKey:
decodeDoubleForKey:
encodeObject:forKey:
encodeInteger:forKey:
encodeDouble:forKey:
array
containsPointX:Y:Z:
DistToPointX:Y:Z:
PrintFacets
test0
containsPointPlanarX:Y:Z:
containsPointPlanarConditionalX:Y:Z:epsilonDark:epsilonLight:
normalVectorForRgon1:withZ1:rgon2:withZ2:atIndex:placedInto:
zMin
setZMin:
zMax
setZMax:
zMinindex
setZMinindex:
zMaxindex
setZMaxindex:
binSize
binCount
binOffset
stack
Td,VzMin
Td,VzMax
Td,VbinSize
Ti,VzMinindex
Ti,VzMaxindex
Ti,VzDarkThr
xyFromS:
liesAbovePointX:Y:
liesBelowPointX:Y:
printPoints
printBounds
printRect
bridgeGapsMinimum
xyFromS2:
lengthenStart:end:
seglength
setSeglength:
nsegs
setNsegs:
axisV
setAxisV:
normV
setNormV:
xyBoundsRect
setXyBoundsRect:
arclength
isempty
sdelta
maxsize
yyData
T{CGPoint=dd},VaxisV
T{CGPoint=dd},VnormV
T{CGRect={CGPoint=dd}{CGSize=dd}},VxyBoundsRect
Td,Vs0
Td,Vs1
Td,Vseglength
TI,Vnsegs
T^{CGPath=},R,VboundsPath
initWithSegments:boundsRect:
adjustForX:Y:
npoints
createTopBottomRegion
normVtop
setNormVtop:
normVbottom
setNormVbottom:
_top
_bottom
T@"Polyline",R,&,V_top
T@"Polyline",R,&,V_bottom
T{CGPoint=dd},VnormVtop
T{CGPoint=dd},VnormVbottom
setIsempty:
smoothWithSize:
raiseTopBy:
lowerBottomBy:
boundsRect
printSummary
setLength:
xdatamin
xdatamax
topData
bottomData
Tf,Vlength
T^f,R
TB,Visempty
properties
objectForKey:
setNumberStyle:
setMaximumFractionDigits:
stringFromNumber:
stringWithFormat:
imageByApplyingTransform:highQualityDownsample:
sceneLuminance:
captureType:
calcColorStats:
smartToneStatistics
localLightStatisticsNoProxy
_softExposure
writeDebugData:
overlayText:strength:captureType:bv:
inputSkyMask
setInputSkyMask:
inputIsSunsetSunrise
setInputIsSunsetSunrise:
setInputLocalLight:
inputShadows
setInputShadows:
inputExposure
setInputExposure:
inputBrightness
setInputBrightness:
inputHighlights
setInputHighlights:
inputWhiteBalance
setInputWhiteBalance:
inputSaturation
setInputSaturation:
inputBrightSat
setInputBrightSat:
inputConfidence
setInputConfidence:
inputLowConfidence
setInputLowConfidence:
inputHighConfidence
setInputHighConfidence:
inputMaxFaceSize
setInputMaxFaceSize:
inputFaceBoxArray
setInputFaceBoxArray:
T@"CIImage",&,N,VinputSkyMask
T@"NSNumber",&,N,VinputIsSunsetSunrise
T@"NSNumber",&,N,VinputLocalLight
T@"NSNumber",&,N,VinputShadows
T@"NSNumber",&,N,VinputExposure
T@"NSNumber",&,N,VinputBrightness
T@"NSNumber",&,N,VinputHighlights
T@"NSNumber",&,N,VinputWhiteBalance
T@"NSNumber",&,N,VinputSaturation
T@"NSNumber",&,N,VinputBrightSat
T@"NSNumber",&,N,VinputConfidence
T@"NSNumber",&,N,VinputLowConfidence
T@"NSNumber",&,N,VinputHighConfidence
T@"NSNumber",&,N,VinputMaxFaceSize
T@"NSArray",&,N,VinputFaceBoxArray
_imageByApplyingGamma:
_foodVignette
inputBoundingBoxArray
setInputBoundingBoxArray:
inputUnionBox
setInputUnionBox:
inputVignetteStrength
setInputVignetteStrength:
T@"NSArray",&,N,VinputBoundingBoxArray
T@"NSNumber",&,N,VinputUnionBox
T@"NSNumber",&,N,VinputVignetteStrength
_highKey
valueWithBytes:objCType:
unarchivedObjectOfClass:fromData:error:
setWithObjects:
unarchivedObjectOfClasses:fromData:error:
archivedDataWithRootObject:requiringSecureCoding:error:
_convertToGrayscale
_kernelLocalContrast
writeToTIFF:
checkFeaturesDictionary:
_mixKernel
processSkinIn:withSkinMask:
_enrich
inputDepthMap
setInputDepthMap:
T@"CIImage",&,N,VinputDepthMap
imageByApplyingOrientation:
setInputFocalLengthNormalized:
setInputDepthDataScore:
setInputAdaptiveThresholdFaceGroupRange:
setInputAdaptiveThresholdFaceErrorMargin:
setInputAdaptiveThresholdZRangeConst:
setInputAdaptiveThresholdZRangeLinearDepth:
setInputAdaptiveThresholdConstOffset:
setInputAdaptiveThresholdLinearDepthOffset:
setInputAdaptiveThresholdDoDisparityError:
isEqualToString:
inputAdaptiveThresholdFaceGroupRange
inputAdaptiveThresholdFaceErrorMargin
inputAdaptiveThresholdDoDisparityError
setDefaultsAbsoluteDisparity
valueForKey:
portraitScore
_faceAndBodyFill_orient1
_faceAndBodyFill_orient6
_getFocusRect:
inputFocalLengthNormalized
_offsetImage:inputDisparity:thresholdImage:
_maxNumVerticesForImage:sigmaLuma:sigmaSpace:
integerValue
adaptiveNormalizationAbsolute
inputAdaptiveThresholdZRangeConst
inputAdaptiveThresholdZRangeLinearDepth
inputAdaptiveThresholdConstOffset
inputAdaptiveThresholdLinearDepthOffset
adaptiveNormalizationGPU
adaptiveNormalization2
inputFullSizeImage
setInputFullSizeImage:
inputMinimumEffectLevel
setInputMinimumEffectLevel:
inputBackgroundSeparationLikehood
setInputBackgroundSeparationLikehood:
inputDepthDataScore
T@"CIImage",&,N,VinputFullSizeImage
T@"NSNumber",C,N,VinputFocalLengthNormalized
T@"NSNumber",C,N,VinputAdaptiveThresholdFaceGroupRange
T@"NSNumber",C,N,VinputAdaptiveThresholdFaceErrorMargin
T@"NSNumber",C,N,VinputAdaptiveThresholdZRangeConst
T@"NSNumber",C,N,VinputAdaptiveThresholdZRangeLinearDepth
T@"NSNumber",C,N,VinputAdaptiveThresholdConstOffset
T@"NSNumber",C,N,VinputAdaptiveThresholdLinearDepthOffset
T@"NSNumber",C,N,VinputAdaptiveThresholdDoDisparityError
T@"NSNumber",C,N,VinputMinimumEffectLevel
T@"NSNumber",C,N,VinputBackgroundSeparationLikehood
T@"NSNumber",C,N,VinputDepthDataScore
workingColorSpace
cameraCalibrationData
intrinsicMatrix
intrinsicMatrixReferenceDimensions
allowSRGBTranferFuntionOnInputAtIndex:
{CGRect={CGPoint=dd}{CGSize=dd}}44@?0i8{CGRect={CGPoint=dd}{CGSize=dd}}12
inputFocusRect
fullROI
v8@?0
10.13
inputNeedsGammaCorrection
inputScale
kernel vec4 _pf_transitionDepths(__sample edges,__sample depthLo) { float v = float((edges.r) > 0.5)*depthLo.r; return vec4(v,v,v,1.0); }
PFSobelHV
CIMorphologyMaximum
inputMaxNumVertices
inputSigmaS
inputSigmaRLuma
inputSigmaRChroma
inputLambda
inputMaxNumIterations
inputBandRange
inputThresholdOffset
inputFilterCut
inputFeatherBandRange
inputAdaptiveThresholdRange
inputSigmaFallout
kernel vec4 _pf_renormalize01(__sample a,__sample b) { float zmin = b.r; float zmax = b.g; float v = (a.r - zmin)/(zmax-zmin); return vec4(v,v,v,1.0); }
kernel vec4 _pf_featherBand(__sample image,__sample threshold,__sample mm,vec3 params) { 
  float zMin = mm.r;
  float zMax = mm.g;
  float zRange = zMax - zMin;
  float lowerBandOffset  = -params.y * zRange;
  float upperBandOffset  = -params.x * zRange;
  float featherBandRange =  params.z * zRange;
  float bandRange = upperBandOffset - lowerBandOffset;
  float bandCenter = threshold.r + lowerBandOffset + bandRange / 2.0;
  float band = abs(image.r - bandCenter) - bandRange / 2.0;
  band = 1.0 - smoothstep(0.0, featherBandRange, band);
   return vec4(band,band,band,1.0);
kernel vec4 _pf_protectInterior(__sample C,__sample band) { 
   float v = max(min(C.r - band.r * 0.5,0.999),1e-4);
   return vec4(v,v,v,1.0);
kernel vec4 _pf_invertImage(__sample a) { float v = 1.0 - a.r; return vec4(v,v,v,1.0); }
kernel vec4 _pf_normalizeToPhysicalDepth(__sample threshold,__sample mm,float thresholdOffset) { float v = threshold.r + thresholdOffset *(1.0 -threshold.r)/(mm.g-mm.r);  return vec4(v,v,v,1.0); }
kernel vec4 _pf_foreground(__sample mask,__sample threshold) { float v = (mask.r < threshold.r) ? mask.r : 0.0; return vec4(v,v,v,1.0); }
kernel vec4 _pf_filterCut(__sample mask,__sample threshold,float filterCut) {
  float v = min(1.0, mask.r * filterCut / threshold.r);
  return vec4(v,v,v,1.0); }
kernel vec4 _pf_bb3Mono(sampler a) { 
   float r = 0.0;
   vec2 dc = destCoord();
   r += sample(a,samplerTransform(a, dc + vec2(-1.0, -1.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2(-1.0,  0.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2(-1.0,  1.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2( 0.0, -1.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2( 0.0,  0.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2( 0.0,  1.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2( 1.0, -1.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2( 1.0,  0.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2( 1.0,  1.0))).r;
   r *= 0.111111111;
   return vec4(r,r,r,1.0);
kernel vec4 _pf_denormalize(__sample image, __sample minMaxImage)
    float v = image.r;
    float maxV = minMaxImage.g;
    float minV = minMaxImage.r;
    v = v * (maxV - minV) + minV;
    return vec4(v,v,v,1.0);
kernel vec4 _pf_confidenceConvertToHalfFloat (__sample c) __attribute__((outputFormat(kCIFormatRGBAh))) {
  return c;
kernel vec4 _pf_renormalizeThreshold(__sample threshold,__sample disparityMinMax) { 
  float minV = disparityMinMax.x; 
  float maxV = disparityMinMax.y; 
  float range = maxV - minV; 
  float absoluteThreshold = threshold.r; 
  float v = (absoluteThreshold - minV) / max(0.0001,range); 
  return vec4(v,v,v,1.0); 
CIAreaMinMaxRed
CIConfidenceMap
CILinearToSRGBToneCurve
PortraitFastBilateralSolver
inputConfidenceMapImage
PFBoxBlur3_7
CIColorMatrix
inputRVector
inputGVector
inputBVector
kernel vec4 _pf_confidenceExtractRed (__sample c) __attribute__((outputFormat(kCIFormatRh))) {
  return vec4(c.r, 0.0, 0.0, 1.0);
CISRGBToneCurveToLinear
CIGaussianBlur
kernel vec4 _pf_boxBlur3_7_H(sampler image)
    vec2 dc = destCoord();
    float c =  sample(image, samplerTransform(image, dc + vec2(-7.0, 0.0))).r * 0.0005;
         c += sample(image, samplerTransform(image, dc + vec2(-6.0, 0.0))).r * 0.0032;
         c += sample(image, samplerTransform(image, dc + vec2(-5.0, 0.0))).r * 0.0128;
         c += sample(image, samplerTransform(image, dc + vec2(-4.0, 0.0))).r * 0.0352;
         c += sample(image, samplerTransform(image, dc + vec2(-3.0, 0.0))).r * 0.0736;
         c += sample(image, samplerTransform(image, dc + vec2(-2.0, 0.0))).r * 0.1216;
         c += sample(image, samplerTransform(image, dc + vec2(-1.0, 0.0))).r * 0.1632;
         c += sample(image, samplerTransform(image, dc + vec2( 0.0, 0.0))).r * 0.1797;
         c += sample(image, samplerTransform(image, dc + vec2( 1.0, 0.0))).r * 0.1632;
         c += sample(image, samplerTransform(image, dc + vec2( 2.0, 0.0))).r * 0.1216;
         c += sample(image, samplerTransform(image, dc + vec2( 3.0, 0.0))).r * 0.0736;
         c += sample(image, samplerTransform(image, dc + vec2( 4.0, 0.0))).r * 0.0352;
         c += sample(image, samplerTransform(image, dc + vec2( 5.0, 0.0))).r * 0.0128;
         c += sample(image, samplerTransform(image, dc + vec2( 6.0, 0.0))).r * 0.0032;
         c += sample(image, samplerTransform(image, dc + vec2( 7.0, 0.0))).r * 0.0005;
        
    return vec4(c,c,c,1.0);
kernel vec4 _pf_boxBlur3_7_V(sampler image)
    vec2 dc = destCoord();
    float c =  sample(image, samplerTransform(image, dc + vec2(0.0, -7.0))).r * 0.0005;
         c += sample(image, samplerTransform(image, dc + vec2(0.0,-6.0))).r * 0.0032;
         c += sample(image, samplerTransform(image, dc + vec2(0.0,-5.0))).r * 0.0128;
         c += sample(image, samplerTransform(image, dc + vec2(0.0,-4.0))).r * 0.0352;
         c += sample(image, samplerTransform(image, dc + vec2(0.0,-3.0))).r * 0.0736;
         c += sample(image, samplerTransform(image, dc + vec2(0.0,-2.0))).r * 0.1216;
         c += sample(image, samplerTransform(image, dc + vec2(0.0,-1.0))).r * 0.1632;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 0.0))).r * 0.1797;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 1.0))).r * 0.1632;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 2.0))).r * 0.1216;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 3.0))).r * 0.0736;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 4.0))).r * 0.0352;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 5.0))).r * 0.0128;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 6.0))).r * 0.0032;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 7.0))).r * 0.0005;
        
    return vec4(c,c,c,1.0);
kernel vec4 _pf_sobelHV(sampler image)        {
            vec2 dc = destCoord();
    float c0 = sample(image, samplerTransform(image, dc + vec2(-1.0,1.0))).r;
    float c1 = sample(image, samplerTransform(image, dc + vec2( 0.0,1.0))).r;
    float c2 = sample(image, samplerTransform(image, dc + vec2( 1.0,1.0))).r;
    float c3 = sample(image, samplerTransform(image, dc + vec2(-1.0,0.0))).r;
    float c5 = sample(image, samplerTransform(image, dc + vec2( 1.0,0.0))).r;
    float c6 = sample(image, samplerTransform(image, dc + vec2(-1.0,-1.0))).r;
    float c7 = sample(image, samplerTransform(image, dc + vec2( 0.0,-1.0))).r;
    float c8 = sample(image, samplerTransform(image, dc + vec2( 1.0,-1.0))).r;
    float h = abs((c0 + 2.0 * c1 + c2) - (c6 + 2.0 * c7 + c8));
    float v = abs((c0 + 2.0 * c3 + c6) - (c2 + 2.0 * c5 + c8));
    float total = (h + v);
    return vec4(total, total, total, 1.0);
kernel vec4 _pf_h9(sampler a)  { 
   float m = 0.0;
   vec2 dc = destCoord();
   for(int i = -4; i <= 4; i++) {
      m = max(m, sample(a,samplerTransform(a, dc + vec2(float(i), 0.0))).r);
   }
   return vec4(m,m,m,1.0);
kernel vec4 _pf_v7(sampler a)  { 
   float m = 0.0;
   vec2 dc = destCoord();
   for(int i = -3; i <= 3; i++) {
      m = max(m, sample(a,samplerTransform(a, dc + vec2(float(i), 0.0))).r);
   }
   return vec4(m,m,m,1.0);
kernel vec4 _pf_dilateRem(sampler a,sampler o) { 
   float m = sample(a, samplerCoord(a)).r;
   vec2 dc = destCoord();
   for(int i = -3; i<= 3; i++) {
      m = max(m, sample(o,samplerTransform(o, dc + vec2(float(i), 4.0))).r);
   }
   for(int i = -3; i<= 3; i++) {
      m = max(m, sample(o,samplerTransform(o, dc + vec2(float(i), -4.0))).r);
   }
   m = max(m, sample(o,samplerTransform(o, dc + vec2( 0.0, 5.0))).r);
   m = max(m, sample(o,samplerTransform(o, dc + vec2( 0.0,-5.0))).r);
   m = max(m, sample(o,samplerTransform(o, dc + vec2( 5.0, 0.0))).r);
   m = max(m, sample(o,samplerTransform(o, dc + vec2(-5.0, 0.0))).r);
   return vec4(m,m,m,1.0);
kernel vec4 _pf_sobelHVGeoMean(sampler image)        {
            vec2 dc = destCoord();
    float c0 = sample(image, samplerTransform(image, dc + vec2(-1.0,1.0))).r;
    float c1 = sample(image, samplerTransform(image, dc + vec2( 0.0,1.0))).r;
    float c2 = sample(image, samplerTransform(image, dc + vec2( 1.0,1.0))).r;
    float c3 = sample(image, samplerTransform(image, dc + vec2(-1.0,0.0))).r;
    float c5 = sample(image, samplerTransform(image, dc + vec2( 1.0,0.0))).r;
    float c6 = sample(image, samplerTransform(image, dc + vec2(-1.0,-1.0))).r;
    float c7 = sample(image, samplerTransform(image, dc + vec2( 0.0,-1.0))).r;
    float c8 = sample(image, samplerTransform(image, dc + vec2( 1.0,-1.0))).r;
    float h = (c0 + 2.0 * c1 + c2) - (c6 + 2.0 * c7 + c8);
    float v = (c0 + 2.0 * c3 + c6) - (c2 + 2.0 * c5 + c8);
    float total = sqrt(max(0.0000001,h*h + v*v));
    return vec4(total, total, total, 1.0);
kernel vec4 _pf_invertImages(__sample c) { float v = c.r; v = 1.0 - min(1.0,v); v = max(min(v,1.0),0.0001); return vec4(v,v,v,1.0); }
kernel vec4 _pf_dilateDisparityEdgeDetectLuminance(sampler image, vec2 ninj,sampler lumImage){
    float m = 0.0, n = 0.0;
    vec2 dc = destCoord();
    
    int i;
    for(i = -int(ninj.x); i <= int(ninj.x); i++) {
        float v = sample(image, samplerTransform(image, dc + vec2(float(i),0.0))).r;
        n = max(v,n);
    }
    for(i = -int(ninj.y); i <= int(ninj.y); i++) {
        float v = sample(image, samplerTransform(image, dc + vec2(0.0,float(i)))).r;
        m = max(v,m);
    }
    float r = m + n;
    float c0 = sample(lumImage, samplerTransform(lumImage, dc + vec2(-1.0,1.0))).r;
    float c1 = sample(lumImage, samplerTransform(lumImage, dc + vec2( 0.0,1.0))).r;
    float c2 = sample(lumImage, samplerTransform(lumImage, dc + vec2( 1.0,1.0))).r;
    float c3 = sample(lumImage, samplerTransform(lumImage, dc + vec2(-1.0,0.0))).r;
    float c5 = sample(lumImage, samplerTransform(lumImage, dc + vec2( 1.0,0.0))).r;
    float c6 = sample(lumImage, samplerTransform(lumImage, dc + vec2(-1.0,-1.0))).r;
    float c7 = sample(lumImage, samplerTransform(lumImage, dc + vec2( 0.0,-1.0))).r;
    float c8 = sample(lumImage, samplerTransform(lumImage, dc + vec2( 1.0,-1.0))).r;
    float h = abs((c0 + 2.0 * c1 + c2) - (c6 + 2.0 * c7 + c8));
    float v = abs((c0 + 2.0 * c3 + c6) - (c2 + 2.0 * c5 + c8));
    float total = h + v;
    float result = max(total, r);
    return vec4(result,result,result,1.0);
10.12
inputStrength
inputWidth
inputRotate
inputOrientation
inputCenterBottom
kernel vec4 _pf_kickLightKernel_pos(__sample im, vec2 xy1, vec4 abc1, vec2 xy2, vec4 abc2, vec2 xy3, vec4 abc3, vec2 xy4, vec4 abc4, float str) 
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
    dx = xy2.x-destCoord().x ; 
    dy = xy2.y-destCoord().y ; 
    float g = exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy)); 
    dx = xy3.x-destCoord().x ; 
    dy = xy3.y-destCoord().y ; 
    float ss = exp(-(abc3.r*dx*dx +2.0*abc3.g*dx*dy +abc3.b*dy*dy)); 
    dx = xy4.x-destCoord().x ; 
    dy = xy4.y-destCoord().y ; 
    float gg = exp(-(abc4.r*dx*dx +2.0*abc4.g*dx*dy +abc4.b*dy*dy)); 
    vec3 orig = im.rgb; 
    vec3 neg = min(im.rgb, 0.0); 
    vec3 pos = max(im.rgb, 1.0)-1.0; 
    im.rgb = clamp(im.rgb, 0.0, 1.0); 
    vec3 m = 1.0-im.rgb; 
    float a = 0.6; 
    vec4 result = im; 
    result.rgb = 1.0 - (pow(m, vec3(str))+a*( ((str-1.0)*m*(1.0-m*m))/(str*str))); 
    im.rgb = pow(im.rgb, vec3(1.0-((min(str, 2.95)-1.0)/2.6))); 
    result.rgb = mix(im.rgb, result.rgb, .85); 
    result.rgb = mix(orig, result.rgb+neg+pos, (s+g+ss+gg)); 
    return result; 
kernel vec4 _pf_kickLightKernel_neg(__sample im, vec2 xy1, vec4 abc1, vec2 xy2, vec4 abc2, vec2 xy3, vec4 abc3, vec2 xy4, vec4 abc4, float str) 
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
    dx = xy2.x-destCoord().x ; 
    dy = xy2.y-destCoord().y ; 
    float g = exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy)); 
    dx = xy3.x-destCoord().x ; 
    dy = xy3.y-destCoord().y ; 
    float ss = exp(-(abc3.r*dx*dx +2.0*abc3.g*dx*dy +abc3.b*dy*dy)); 
    dx = xy4.x-destCoord().x ; 
    dy = xy4.y-destCoord().y ; 
    float gg = exp(-(abc4.r*dx*dx +2.0*abc4.g*dx*dy +abc4.b*dy*dy)); 
    vec3 neg = min(im.rgb, 0.0); 
    vec3 pos = max(im.rgb, 1.0)-1.0; 
    im.rgb = clamp(im.rgb, 0.0, 1.0); 
    vec4 orig = im; 
    float lum = max(max(im.r, im.g), im.b); 
    vec3 gamma = compare(vec3(lum)-.001, vec3(0.0), pow(im.rgb, vec3(1.0-str*min(s+g+ss+gg, 1.0)))); 
    im.rgb = mix(gamma, mix(orig.rgb, orig.rgb*lum, -str*min(s+g+ss+gg, 1.0)), 0.3) ;
    im.rgb = mix(orig.rgb, im.rgb, 4.0*lum*(1.0-lum)) + pos + neg; 
    return im; 
inputBrighten
inputContrast
kernel vec4 _pf_dualLightKernel(__sample im, vec2 xy1, vec4 abc1, vec2 xy2, vec4 abc2, vec3 mcb) 
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
    dx = xy2.x-destCoord().x ; 
    dy = xy2.y-destCoord().y ; 
    float g = exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy)); 
    float contrast = .1*mcb.g*g; 
    vec3 neg = min(im.rgb, 0.0); 
    vec3 pos = max(im.rgb, 1.0)-1.0; 
    im.rgb = clamp(im.rgb, 0.0, 1.0); 
    vec3 orig = im.rgb; 
    float lum = (dot(im.rgb, vec3(.333333))); 
    float y = sqrt(lum); 
    vec3 light = vec3((1.0-y)*g-mcb.b*.4*(1.0-lum)*s); 
    float yy = compare(light.r, pow(lum, 1.0+abc1.a*light.r), pow(lum, 1.0+abc2.a*light.r)); 
    yy = mix(yy, 0.5, -(y*(1.0-y))*contrast); 
    im.rgb = lum > 0.0 ? im.rgb*yy/lum : vec3(0.0); 
    im.rgb = mix(orig.rgb, im.rgb, mcb.r) + pos + neg; 
    return im; 
kernel vec4 _pf_strobeKernel(__sample im, vec2 xy1, vec4 abc1, float str) 
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
    vec3 orig = im.rgb; 
    float lum = (dot(im.rgb, vec3(.333333))); 
    float y = sqrt(lum); 
    vec3 light = vec3(.4*(1.0-lum)*s); 
    float yy = pow(lum, 1.0-abc1.a*light.r); 
    im.rgb = lum > 0.0 ? im.rgb*yy/lum : vec3(0.0); 
    im.rgb = mix(orig.rgb, im.rgb, str); 
    return im; 
kernel vec4 _pf_contourExtractRed (__sample c) __attribute__((outputFormat(kCIFormatRh))) {
  return vec4(c.r, 0.0, 0.0, 1.0);
kernel vec4 _pf_contourLightKernel (__sample back, __sample fore, vec4 xy1, vec4 abc1, vec4 eyes, float str, float radius )
    fore = vec4(fore.r, fore.r, fore.r, 1.0);
    fore = max(fore, 0.0); 
    vec3 neg = min(back.rgb, 0.0); 
    vec3 pos = max(back.rgb, 1.0)-1.0; 
    back = clamp(back, 0.0, 1.0); 
    vec4 DCb = compare(0.25 - back, sqrt(back), ((16.0 * back - 12.0) * back + 4.0) * back);
    vec4 B  = back + (2.0 * fore - 1.0) * compare(0.5 - fore, DCb - back, back * (1.0 - back));
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = str*exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
    dx = eyes.x-destCoord().x ;
    dy = eyes.y-destCoord().y ;
    float le = .8*str*exp(-(dx*dx + dy*dy)/(2.0*radius)); 
    dx = eyes.z-destCoord().x ;
    dy = eyes.w-destCoord().y ;
    float re = .8*str*exp(-(dx*dx + dy*dy)/(2.0*radius)); 
    dx = xy1.z-destCoord().x ;
    dy = xy1.w-destCoord().y ;
    float chin = .5*str*exp(-(dx*dx + dy*dy)/(1.0*radius)); 
    B = mix(pow(B, vec4(1.6)), B, smoothstep(0.1, .7, fore.r+chin)) ;
    vec4 im = back; 
    im.rgb = mix(im.rgb, B.rgb, smoothstep(0.0,0.75,(s - re -le +chin))) + pos + neg; 
    return im; 
inputDarken
kernel vec4 _pf_portraitSpotKernel (__sample c, vec4 xy1, vec4 abc1, vec2 darken )
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
  vec3 orig = c.rgb; 
  vec3 neg = min(c.rgb, 0.0); 
  vec3 pos = max(c.rgb, 1.0)-1.0; 
  c.rgb = clamp(c.rgb, 0.0, 1.0); 
  vec3 m = 1.0-c.rgb; 
  float a = 0.6; 
  vec4 result = c; 
  float gamma = abc1.w; 
  result.rgb = 1.0 - (pow(m, vec3(gamma))+a*( ((gamma-1.0)*m*(1.0-m*m))/(gamma*gamma))); 
  c.rgb = pow(c.rgb, vec3(1.0-((min(gamma, 2.95)-1.0)/2.6))); 
  result.rgb = darken.g*mix(c.rgb, result.rgb, .85); 
  result.rgb = mix(darken.r*orig, result.rgb+neg+pos, s); 
  return result; 
inputFaceOrientation
kernel vec4 _pf_neckContour(__sample im, vec4 xy1, vec4 abc1, vec4 abc2, float str) 
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = -smoothstep(0.0, .1, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
    dx = xy1.z-destCoord().x ; 
    dy = xy1.w-destCoord().y ; 
    float ss = smoothstep(0.0, .1, exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy))) ; 
    s = clamp(ss+s, 0.0, 1.0); 
    im.rgb = mix(im.rgb, .85*im.rgb, str*s); 
    im.rgb = mix(im.rgb, im.rgb*im.rgb, .6*str*s); 
    return im; 
kernel vec4 _pf_contourExtractRedStudio (__sample c) __attribute__((outputFormat(kCIFormatRh))) {
  return vec4(c.r, 0.0, 0.0, 1.0);
kernel vec4 _pf_studioLightKernel (__sample back, __sample fore, vec4 xy1, vec4 abc1, vec4 eyes, float str, float radius )
 fore = vec4(fore.r, fore.r, fore.r, 1.0);
 fore = max(fore, 0.0); 
 fore = pow(fore, vec4(.65)); 
 vec3 neg = min(back.rgb, 0.0); 
 vec3 pos = max(back.rgb, 1.0)-1.0; 
 back = clamp(back, 0.0, 1.0); 
 vec4 DCb = compare(0.25 - back, sqrt(back), ((16.0 * back - 12.0) * back + 4.0) * back);
 vec4 B = back + (2.0 * fore - 1.0) * compare(0.5 - fore, DCb - back, back * (1.0 - back));
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = str*exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
 dx = eyes.x-destCoord().x ;
 dy = eyes.y-destCoord().y ;
 float le = .8*str*exp(-(dx*dx + dy*dy)/(2.0*radius)); 
 dx = eyes.z-destCoord().x ;
 dy = eyes.w-destCoord().y ;
 float re = .8*str*exp(-(dx*dx + dy*dy)/(2.0*radius)); 
 dx = xy1.z-destCoord().x ;
 dy = xy1.w-destCoord().y ;
 float chin = .5*str*exp(-(dx*dx + dy*dy)/(1.0*radius)); 
 B = mix(pow(B, vec4(1.6)), B, smoothstep(0.1, .7, fore.r+chin)) ;
 vec4 im = back; 
 im.rgb = mix(im.rgb, B.rgb, smoothstep(0.0,0.75,(s - re -le +chin))) + pos + neg; 
 return im; 
kernel vec4 _pf_cheapEdgePreserveStudio (__sample i, __sample b) 
 float d = 1.0*distance(i.rgb, b.rgb); b = mix(b, i, d); 
 return b; 
kernel vec4 _pf_strobeKernelV2(__sample im, vec2 xy1, vec4 abc1, float str) 
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
    vec3 orig = im.rgb; 
    float lum = (dot(im.rgb, vec3(.333333))); 
    float y = sqrt(lum); 
    vec3 light = vec3(.4*(1.0-lum)*s); 
    float yy = pow(lum, 1.0-abc1.a*light.r); 
    im.rgb = lum > 0.0 ? im.rgb*yy/lum : vec3(0.0); 
    im.rgb = mix(orig.rgb, im.rgb, str*lum); 
    return im; 
inputBlur
kernel vec4 _pf_contourExtractRedV2 (__sample c) __attribute__((outputFormat(kCIFormatRh))) {
 return vec4(c.r, 0.0, 0.0, 1.0);
kernel vec4 _pf_contourLightKernelV2 (__sample back, __sample fore, vec4 xy1, vec4 abc1, vec4 eyes, float str, float radius )
 fore.r = pow(fore.r, .85); 
 fore = vec4(fore.r, fore.r, fore.r, 1.0);
 fore = max(fore, 0.0); 
 vec3 neg = min(back.rgb, 0.0); 
 vec3 pos = max(back.rgb, 1.0)-1.0; 
 back = clamp(back, 0.0, 1.0); 
 vec4 DCb = compare(0.25 - back, sqrt(back), ((16.0 * back - 12.0) * back + 4.0) * back);
 vec4 B = back + (2.0 * fore - 1.0) * compare(0.5 - fore, DCb - back, back * (1.0 - back));
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = str*exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
 dx = eyes.x-destCoord().x ;
 dy = eyes.y-destCoord().y ;
 float le = .8*str*exp(-(dx*dx + dy*dy)/(2.0*radius)); 
 dx = eyes.z-destCoord().x ;
 dy = eyes.w-destCoord().y ;
 float re = .8*str*exp(-(dx*dx + dy*dy)/(2.0*radius)); 
 dx = xy1.z-destCoord().x ;
 dy = xy1.w-destCoord().y ;
 float chin = .5*str*exp(-(dx*dx + dy*dy)/(1.0*radius)); 
 B = mix(pow(B, vec4(1.6)), B, smoothstep(0.1, .7, fore.r+chin)) ;
 vec4 im = back; 
 im.rgb = mix(im.rgb, B.rgb, pow(fore.r, 0.35)*smoothstep(0.0,0.75,(s - re -le +chin))); 
 im.rgb = mix(back.rgb, im.rgb, pow(fore.r, .15)) + pos + neg; 
 return im; 
kernel vec4 _pf_cheapEdgePreserveContourV2 (__sample i, __sample b) 
 float d = 1.25*distance(i.rgb, b.rgb); b = mix(b, i, d); 
 return b; 
kernel vec4 _pf_faceContourMask(__sample im, vec4 xy1, vec4 abc1, vec4 abc2) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = 1.75*exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
 float g = exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy)); 
 g = clamp(g-s, 0.0, 1.0); 
 g = smoothstep(0.0, 0.18, g); 
 return vec4(g,g,g,1.0); 
kernel vec4 _pf_darkenContour(__sample im, float str) 
 im = clamp(im, 0.0, 1.0); 
 vec4 im2 = 1.0 - sqrt(1.0-im*im); 
 float y = dot(im.rgb, vec3(.333333)); 
 float y2 = 1.0 - sqrt(1.0-y*y); 
 vec4 im3 = (y>0) ? im*y2/y : vec4(0.0, 0.0, 0.0, 1.0) ; 
 float s = im.r + im.g + im.b - y; 
 im3 = mix(im2, im3, s); 
 im3 = mix(im, im3, str); 
 return vec4(im3.rgb, 1.0); 
CIHighKey
CIBlendWithMask
inputBackgroundImage
inputMaskImage
com.apple.PortraitFilters
loadMetalLib_block_invoke
PortraitFilters.m
bundle
portrait_filters
metallib
metalLibData
orientation
+[CIPortraitFaceMaskProcessorKernel processWithInputs:arguments:output:error:]
CIPortraitFaceMask.mm
CGRectIsIntegral(faceROI)
+[CIPortraitFaceMaskProcessorKernel roiForInput:arguments:outputRect:]
false
sanityCheckStatus
processedImageWidth
processedImageHeight
CoreImageROIrect
faceROI
faceLandmarks
inputImageExtent
skinRgonStack
skinColorToleranceDark
skinColorToleranceLight
skinColorToleranceMid
eps2
inputReturnHueChroma
kernel vec4 _pf_srgbToIPT(__sample im) 
 vec3 lms = im.r * vec3(0.3139902162, 0.15537240628, 0.01775238698) + 
 im.g * vec3(0.63951293834, 0.75789446163, 0.1094420944) + 
 im.b * vec3(0.04649754622, 0.08670141862, 0.87256922462); 
 lms = sign(lms)*pow(abs(lms), vec3(0.43)); 
 vec3 ipt = lms.r * vec3(0.4, 4.455, 0.8056) + 
 lms.g * vec3(0.4, -4.851, 0.3572) + 
 lms.b * vec3(0.2, 0.396,-1.1628); 
 return vec4(ipt, im.a); 
kernel vec4 _pf_rectToHueChroma(__sample im) 
 vec4 ihc = im; 
 ihc.g = atan(im.b, im.g); 
 ihc.b = sqrt(im.g*im.g+im.b*im.b); 
 return ihc; 
inputIsHueChroma
kernel vec4 _pf_iptToSRGB(__sample ipt) 
 vec3 lms = ipt.r * vec3(1.0000, 1.0000, 1.0000) + 
 ipt.g * vec3(0.0976,-0.1139, 0.0326) + 
 ipt.b * vec3(0.2052, 0.1332,-0.6769); 
 lms = sign(lms)*pow(abs(lms), vec3(1.0/.43)); 
 vec3 im = lms.r * vec3(5.472212058380287, -1.125241895533569, 0.029801651173470) + 
 lms.g * vec3(-4.641960098354471, 2.293170938060623, -0.193180728257140) + 
 lms.b * vec3(0.169637076827974, -0.167895202223709, 1.163647892783812); 
 return vec4(im, ipt.a); 
kernel vec4 _pf_hueChromaToRect(__sample ihc) 
 vec4 ipt = ihc; 
 ipt.g = ihc.b * cos(ihc.g); 
 ipt.b = ihc.b * sin(ihc.g); 
 return ipt; 
chromaMin
hueRange
+[CIHueChromaHistProcessor formatForInputAtIndex:]
CISmartGradient.m
imageExtents
+[CIHueChromaHistProcessor roiForInput:arguments:outputRect:]
arguments[@"imageExtents"]
[arguments[@"imageExtents"] count] > input
+[CIAveColorProcessor formatForInputAtIndex:]
imageExtent
+[CIAveColorProcessor roiForInput:arguments:outputRect:]
arguments[@"imageExtent"]
+[CIColorGradientProcessor formatForInputAtIndex:]
+[CIColorGradientProcessor roiForInput:arguments:outputRect:]
10.15
inputReturnSmartColor
inputHueRange
inputChromaMin
inputMaxDimension
inputHeight
kernel vec4 _pf_scaleHue(__sample im, float s) 
 im.g = (im.g+s)/(2.0*s); 
 return im; 
kernel vec4 _pf_scaleHuePi(__sample im, float s) 
 im.g = im.g*2.0*s - s; 
 return im; 
CIIPTtoSRGB
CISoftCubicUpsample
CIDither
inputIntensity
CISRGBtoIPT
CIAreaAverage
float _inTriangle(vec2 p1, vec2 p2, vec2 p3){ 
 float b1 = (p1.x - p3.x) * (p2.y - p3.y) - (p2.x - p3.x) * (p1.y - p3.y); 
 return b1; 
 bool _isInTriangle(vec4 p12, vec2 p34, vec2 pt){ 
 bool b1, b2, b3 ;
 vec2 v1 = p12.xy; 
 vec2 v2 = p12.zw; 
 vec2 v3 = p34.xy; 
 b1 = _inTriangle(pt, v1, v2) < 0.0; 
 b2 = _inTriangle(pt, v2, v3) < 0.0; 
 b3 = _inTriangle(pt, v3, v1) < 0.0; 
 return ((b1 == b2) && (b2 == b3)); 
 kernel vec4 _pf_drawTriangle(__sample im, vec4 p12, vec2 p34, float str, float alpha) 
 vec2 pt = destCoord(); 
 bool ins = _isInTriangle(p12, p34, pt); 
 vec4 scaled = clamp(str*im, 0.0, 1.0); 
 float y = dot(im.rgb, vec3(.333333)); 
 float s = im.r+im.g+im.b-3.0*y; 
 s = -.333*smoothstep(0.0, .333, s) + .333; 
 scaled.rgb = s*(scaled.rgb-str*y)+str*y; 
 scaled.a = alpha * (.3*y+.7); 
 im = ins ? scaled : vec4(0.0); 
 return im; 
kernel vec4 _pf_protectEyes(__sample im, vec4 eyes, float radius) 
 vec2 pt = destCoord(); 
 float dx = eyes.x-pt.x; 
 float dy = eyes.y-pt.y; 
 float a = 1.0 - exp(-(dx*dx + dy*dy)/(2.0*radius)); 
 im *= a; dx = eyes.z-pt.x; 
 dy = eyes.w-pt.y; 
 a = 1.0 - exp(-(dx*dx + dy*dy)/(2.0*radius)); 
 im *= a; 
 return im; 
CIHardLightBlendMode
guidedFilterEpsilon
+[CIDynamicGuidedFilter formatForInputAtIndex:]
CIDynamicLocalLight.mm
+[CIDynamicGuidedFilter roiForInput:arguments:outputRect:]
inputLightMapWidth
NSNumber
inputLightMapHeight
inputGuidedFilterEpsilon
inputLocalLight
inputSmartShadows
kernel vec4 _pf_shadowKernelDynamic(__sample im, __sample adj, float str) 
 adj.r = 3.4*adj.r-1.2; 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 vec4 orig = im; 
 float y = sqrt(dot(im.rgb, vec3(.33333))); 
 float s = mix(0.0, adj.r, str); 
 vec3 gain = s > 0.0 ? vec3(0.0*s) : vec3(-2.75*s*s, -2.75*s*s, -2.5*s*s); 
 gain *= 1.0 - .9*smoothstep(.5, .7, im.b); 
 im.rgb = im.rgb*im.rgb*gain + im.rgb*(1.0-gain); 
 float m = 1.0 + 1.85*s*(max(0.1-y, 0.0))*(1.0 - .9*smoothstep(.5, 0.7, im.b)) ;
 im.rgb = (clamp(m*im.rgb, 0.0, 1.0)); 
 float midAmt = s < 0.0 ? min(s*s,1.0) : 0.0; 
 y = y*(1.0-y); 
 im.rgb = sqrt(im.rgb); 
 float pivot = .4; 
 float a = midAmt*y; 
 float b = -pivot*a; 
 vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt); 
 im.rgb = mix(im.rgb, pix, 0.8); 
 im.rgb = max(im.rgb, 0.0); 
 im.rgb *= im.rgb; 
 im.rgb = clamp(im.rgb, 0.0,1.0)+pos+neg; 
 return im; 
kernel vec4 _pf_polyKernelDynamic(__sample im, __sample adj, float str) 
 adj.r = 3.4*adj.r-1.2; 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 vec4 orig = im; 
 float y = sqrt(dot(im.rgb, vec3(.33333))); 
 float s = mix(0.0, adj.r, str); 
 vec3 gain = s > 0.0 ? vec3(1.5*s) : vec3(1.75*s, 1.75*s, 1.55*s)*(1.0-.9*smoothstep(.5, .7, im.b)); 
 im.rgb = im.rgb*im.rgb*gain + im.rgb*(1.0-gain); 
 im.rgb = (clamp(im.rgb, 0.0, 1.0)); 
 float midAmt = min(str, .5); 
 y = y*(1.0-y); 
 im.rgb = sqrt(im.rgb); 
 float pivot = max(adj.g, 0.5); 
 float a = midAmt*y; 
 float b = -pivot*a; 
 vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt); 
 im.rgb = mix(im.rgb, pix, 0.8); 
 im.rgb = max(im.rgb, 0.0); 
 im.rgb *= im.rgb; 
 im.rgb = clamp(im.rgb, 0.0,1.0)+pos+neg; 
 return im; 
-[CILLFilter outputImage]
CGRectEqualToRect([guideImage extent], [inputImage extent])
inputImage != nil
guideImage != nil
inputLocalLight != nil
CGRectEqualToRect([lightMapImage extent], [inputImage extent])
CILocalLight
_lightMapImageFromData_block_invoke
x == 0
y == 0
width == lmWidth
height == lmHeight
v56@?0^v8Q16Q24Q32Q40Q48
allPoints
faceContour
innerLips
leftEye
leftEyebrow
leftPupil
medianLine
nose
noseCrest
outerLips
rightEye
rightEyebrow
rightPupil
faceJunkinessIndex
faceOrientationIndex
faceBoundingBox
inputRenderProxy
inputDisparity
inputDepthMap
inputBlurMap
inputMatte
inputFaceMask
inputTeethMask
inputHairMask
inputFaceLandmarkArray
pf_binary_archive
pf_binary_archive_fullsize
CIPortraitEffectStudioV2
CIPortraitEffectStageMonoV2
CIPortraitEffectStageWhite
CIPortraitEffectContourV2
CIPortraitEffectStageV2
10.11
inputGenerateSpillMatte
scube
inputSmooth
inputEnrich
inputTeeth
inputEyes
inputLocalContrast
render_lighting_proxy
com.apple.coremedia
refineStageMatte
renderSpillCache
kernel vec4 _pf_whitenteethV2(__sample pix, __sample mask, float amt) 
 float m = mask.g; 
 vec4 modifiedPix = pow(clamp(pix,0.0, 1.0), vec4(.35)); 
 modifiedPix.b += .1; 
 modifiedPix = modifiedPix * modifiedPix; 
 vec4 displayPix = clamp(modifiedPix,0.0, 1.0); 
 displayPix.a = 1.0; 
 float r = clamp(1.0 - pix.r/(pix.r+pix.g+pix.b), 0.0, 1.0); 
 displayPix.rgb = mix(pix.rgb, displayPix.rgb, r*max(m, 0.0)); 
 displayPix.a = pix.a; 
 return mix(pix, displayPix, amt); 
kernel vec4 _pf_enrichV2 (__sample s, float amt,vec4 params ) { 
 vec4 orig = s; 
 s = clamp(s, 0.0, 1.0); 
 float x0 = params.r; 
 float x1 = params.g; 
 float delta = params.b; 
 float pwr = params.a; 
 s = pow( s, vec4(pwr)); 
 float x2 = 1.0 - delta; 
 float m1 = 0.5/(x1-x0); 
 float b1 = - m1 * x0; 
 float m2 = (.5 - delta)/(x2 - x1); 
 float b2 = (m1-m2) * x1 + b1; 
 vec4 w = (1.0 - step(x1, s)) * (vec4(m1)*s + vec4(b1)) + step(x1, s) * (vec4(m2)*s + vec4(b2)) + step(x2,s) * ( s - (vec4(m2)*s + vec4(b2))) ; 
 w.rgb = clamp(w.rgb, 0.0, 1.0); 
 x0+= .02; 
 x1+= .0005; 
 m1 = 0.5/(x1-x0); 
 b1 = - m1 * x0; 
 m2 = (.5 - delta)/(x2 - x1); 
 b2 = (m1-m2) * x1 + b1; 
 w.r = (1.0 - step(x1, s.r)) * ((m1)*s.r + (b1)) + step(x1, s.r) * ((m2)*s.r + (b2)) + step(x2,s.r) * ( s.r - ((m2)*s.r + (b2))) ; 
 w.r = clamp(w.r, 0.0, 1.0); 
 x0-= .01; 
 x1+= .000; 
 m1 = 0.5/(x1-x0); 
 b1 = - m1 * x0; 
 m2 = (.5 - delta)/(x2 - x1); 
 b2 = (m1-m2) * x1 + b1; 
 w.b = (1.0 - step(x1, s.b)) * ((m1)*s.b + (b1)) + step(x1, s.b) * ((m2)*s.b + (b2)) + step(x2,s.b) * ( s.b - ((m2)*s.b + (b2))) ; 
 w.b = clamp(w.b, 0.0, 1.0); 
 w.rgb = w.rgb * w.rgb; 
 w.r = pow(w.r, .75); 
 w = mix(orig, w, vec4(amt) ); w.a = 1.0; 
 return w; 
kernel vec4 _pf_eyeBrightenV2 (__sample im, __sample m, float str) 
 float y = dot(im.rgb, vec3(0.333333)); 
 vec3 bright = mix(im.rgb, 3.0*im.rgb, m.r); 
 im.rgb = mix(im.rgb, bright, y*str); 
 return im; 
kernel vec4 _pf_eyeBrightenSoftlightV2 (__sample uCb, __sample m, float str) 
 float g = .75*(1.0-dot(uCb.rgb, vec3(.333333))); 
 vec4 uCf = vec4(g, g, g, 1.0); 
 vec4 D = compare(uCb-0.25, ((16.0*uCb-12.0)*uCb+4.0)*uCb, sqrt(uCb)); 
 vec4 Ct = clamp(uCb + (2.0*uCf-1.0) * compare(uCf - 0.5, uCb*(1.0-uCb), D-uCb), 0.0, 1.0); 
 vec4 bright = Ct; 
 uCf.rgb = mix(uCb.rgb, bright.rgb, m.r); 
 uCf.rgb = mix(uCb.rgb, uCf.rgb, str); 
 return uCf; 
kernel vec4 _pf_textureDiffV2 (__sample c, __sample b, float scale) 
 vec3 fullDiff = c.rgb - b.rgb; 
 c.rgb = compare(fullDiff, scale*fullDiff, fullDiff); 
 return c; 
kernel vec4 _pf_textureAddV2 (__sample c, __sample b, float scale) 
 scale = c.r > b.r ? .5*scale : scale; 
 c.rgb = c.rgb + scale*b.rgb; 
 return c; 
kernel vec4 _pf_cheapEdgePreserveV2 (__sample i, __sample b) 
 float d = .75*distance(i.rgb, b.rgb); 
 b = mix(b, i, d); 
 return b; 
kernel vec4 _pf_protectEyesNose (__sample faceMask, vec4 eyes, vec4 abc1, vec4 abc2, vec2 centerNose, vec4 abc3) 
 vec2 d = destCoord(); 
 float dx = eyes.x-d.x; 
 float dy = eyes.y-d.y; 
 float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
 faceMask.rgb -= s; 
 dx = eyes.z-d.x; 
 dy = eyes.w-d.y; 
 s = exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy)); 
 faceMask.rgb -= s; 
 dx = centerNose.x-d.x; 
 dy = centerNose.y-d.y; 
 s = exp(-(abc3.r*dx*dx +2.0*abc3.g*dx*dy +abc3.b*dy*dy)); 
 faceMask.rgb -= s; 
 faceMask = clamp(faceMask, 0.0, 1.0); 
 return faceMask; 
kernel vec4 _pf_eyeBlurV2 (__sample faceMask, vec4 eyes, vec4 abc1, vec4 abc2, vec4 abc3, vec4 abc4) 
 vec2 d = destCoord(); 
 float dx = eyes.x-d.x; 
 float dy = eyes.y-d.y; 
 float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
 faceMask.b += s; 
 faceMask.a += s; 
 dx = eyes.z-d.x; 
 dy = eyes.w-d.y; 
 s = exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy)); 
 faceMask.b += s; 
 faceMask.a += s; 
 s = exp(-(abc4.r*dx*dx +2.0*abc4.g*dx*dy +abc4.b*dy*dy)); 
 faceMask.r += s; 
 faceMask.a += s; 
 dx = eyes.x-d.x; 
 dy = eyes.y-d.y; 
 s = exp(-(abc4.r*dx*dx +2.0*abc4.g*dx*dy +abc4.b*dy*dy)); 
 faceMask.r += s; 
 faceMask.a += s; 
 faceMask = clamp(faceMask, 0.0, 1.0); 
 return faceMask; 
kernel vec4 _pf_featherEdgeLight(__sample im, vec4 b, float t) 
 vec2 dc = destCoord(); 
 float dxl = smoothstep(0.0, t, abs(dc.x-b.x)); 
 float dxr = smoothstep(0.0, t, abs(dc.x-b.z)); 
 float dyt = smoothstep(0.0, t, abs(dc.y-b.y)); 
 float dyb = smoothstep(0.0, t, abs(dc.y-b.w)); 
 im.rgb = vec3(dxl*dxr*dyt*dyb); 
 im = clamp(im, 0.0, 1.0); 
 return im; 
inputFaceLandmarks
CIGaussianGradient
roll
inputCenter
inputRadius
inputColor0
inputColor1
CIAdditionCompositing
CIMultiplyBlendMode
CIPortraitFaceMask
CIPhotoGrain
inputAmount
inputISO
CIBlendWithBlueMask
CIMix
CIPortraitSkinMask
CIPortraitToothMask
-[CIPortraitEffectLightV2 processEyesIn:withEyeBlur:landmarks:]
CIPortraitEffectV2.mm
eyeBlur
CIBlendWithRedMask
CISharpenLuminance
inputSharpness
inputKickLight
inputFaceLight
CIStudioPreview
kernel vec4 _pf_prepareDepthV2 (__sample c, float m) 
 c.r = smoothstep(m, 0.7, 2.0*c.r); 
 return c.rrra; 
kernel vec4 _pf_faceVignetteStudioV2(__sample vig, vec2 xy1, vec4 abc1) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, .4, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))); 
 vig.rgb = min(vig.rgb + vec3(s), 1.0); 
 return vig; 
kernel vec4 _pf_applyFaceProtectStudio(__sample im, __sample fg, __sample fp, __sample vig) 
 im.rgb = mix(im.rgb, fg.rgb, (1.0-fp.r)*vig.r); 
 return im; 
CISmartToneFilter
inputShadows
CIVibrance
CIPortraitLightingSide
inputImage
inputPt1
inputPt2
inputPt3
inputPt4
inputPt5
inputPt6
CIPortraitLightingFront
inputCenter1
inputBottom1
inputCenter2
inputHeight1
inputWidth1
inputHeight2
inputWidth2
inputRotate2
CIPortraitLightingSpot
CIPortraitLightingStrobeV2
CIPortraitLightingStudio
CIExposureAdjust
inputEV
CIContourPreview
kernel vec4 _pf_prepareDepthContourV2 (__sample c, float m) 
 c.r = smoothstep(m, 0.7, 2.0*c.r); 
 return vec4(vec3(c.r), 1.0); 
kernel vec4 _pf_blendSingleChannelMaskV2 (__sample c, __sample b, __sample m) 
 c.rgb = mix(c.rgb, b.rgb, m.r); 
 return c; 
kernel vec4 _pf_faceVignetteContourV2(__sample im, __sample vig, vec2 xy1, vec4 abc1) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, .4, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))); 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_applyVignetteContourV2(__sample im, __sample fg, __sample vig, float amt) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = mix(im.rgb, pow(im.rgb, vec3(2.0)), (1.0-.6*vig.rgb)*.1); 
 im.rgb = mix(im.rgb, im.rgb*(vig.rgb), amt) + pos + neg; 
 return im; 
kernel vec4 _pf_applyFaceProtect(__sample im, __sample fg, __sample fp, __sample vig) 
 im.rgb = mix(im.rgb, fg.rgb, (1.0-fp.r)*vig.r); 
 return im; 
kernel vec4 _pf_transparentBorder(__sample im, vec3 params) 
 vec2 dc = destCoord(); 
 float d = exp(-params.b*((dc.x - params.r)*(dc.x-params.r)+(dc.y - params.g)*(dc.y - params.g))); 
 d = smoothstep(0.02, .2, d); 
 im += vec4(d); 
 im = clamp(im, 0.0, 1.0); 
 return im; 
kernel vec4 _pf_applyTransparentBorder(__sample im, __sample alphaMatte) 
 im.a = alphaMatte.a; 
 im = premultiply(im); 
 return im; 
unionRect
faceLandmarksArray
CIPortraitLightingEdge
CIPortraitContour
inputOrigImage
CIPortraitLightingContourV2
CIPortraitLocalContrast
CIStageStandby
inputUseAbsoluteDisparity
inputSharpenRadius
inputGrainAmount
kernel vec4 _pf_prepareBlackDisparityV2 (__sample dm, const float thresh) 
 float g = 1.0-smoothstep(0.0, thresh, 4.0*dm.r); 
 return vec4(g,g,g, 1.0); 
kernel vec4 _pf_prepareBlackDepthV2 (__sample dm, const float thresh) 
 float g = 1.0-smoothstep(0.0, thresh, 2.0*dm.r*dm.r); 
 return vec4(g,g,g, 1.0); 
kernel vec4 _pf_applyBlackDepthV2 (__sample im, __sample dm, float g) 
 im.rgb *= pow(dm.r, g); 
 return im; 
kernel vec4 _pf_applyStageNoFeather (__sample im, __sample dm) 
 im.rgb = mix(im.rgb*im.rgb*im.rgb, im.rgb, dm.r); 
 im.rgb = mix(vec3(0.0), im.rgb, dm.r); 
 return im; 
kernel vec4 _pf_applyStageNoFeatherSpill (__sample im, __sample spill) 
 vec3 div2 = sqrt(vec3(1.0)-(spill.rgb*spill.rgb)); 
 spill.r = div2.r>0.01? (spill.r / div2.r):0.0; 
 spill.g = div2.g>0.01? (spill.g / div2.g):0.0; 
 spill.b = div2.b>0.01? (spill.b / div2.b):0.0; 
 spill.rgb = spill.rgb*vec3(4.0); 
 spill.rgb = smoothstep(0.0, 1.0, spill.rgb); 
 im.rgb = mix(vec3(0.0), max(vec3(0.005),im.rgb), spill.rgb); 
 return im; 
kernel vec4 _pf_getRefinedMatte (__sample spill) 
 vec3 div2 = sqrt(vec3(1.0)-(spill.rgb*spill.rgb)); 
 spill.r = div2.r>0.01? (spill.r / div2.r):0.0; 
 spill.g = div2.g>0.01? (spill.g / div2.g):0.0; 
 spill.b = div2.b>0.01? (spill.b / div2.b):0.0; 
 spill.rgb = spill.rgb*vec3(4.0); 
 spill.rgb = mix(min(spill.rgb, 1.0), smoothstep(0.0, 1.0, spill.rgb), .5); 
 return vec4(spill.rgb, 1.0); 
kernel vec4 _pf_applyRefinedMatte (__sample im, __sample spill, __sample edge) 
 im.rgb = im.rgb * spill.rgb; 
 im.rgb = mix(im.rgb, im.rgb*im.rgb*im.rgb, edge.rgb); 
 return im; }
kernel vec4 _pf_refineBlackDepthV2 (__sample im, __sample dm, __sample bm, __sample protect, vec3 g, __sample aft) 
 float b = smoothstep(0.0, 1.0, pow(dm.r*bm.r,g.r)+protect.r); 
 im.rgb = max(im.rgb, 0.0); 
 vec3 gamma = (g.b) > 0.0 ? vec3(1.0+g.g-g.g*b*b*dm.r) : vec3(1.0+g.g-g.g*b*b); 
 im.rgb = pow(im.rgb, gamma); 
 im.rgb = mix(vec3(0.0), im.rgb, b); 
 gamma = vec3(1.35-.35*b*aft.r); 
 im.rgb = pow(im.rgb, gamma); 
 float r = im.r/(im.r+im.g+im.b+0.00001); 
 float sat = max(min(1.0, (1.3-.9*r)), 0.0); 
 float y = dot(im.rgb, vec3(.3333333)); 
 im.rgb = mix(sat*(im.rgb-y)+y, im.rgb, b*dm.r); 
 return im; 
kernel vec4 _pf_faceVignetteStageV2(__sample im, __sample vig, vec2 xy1, vec4 abc1) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, .4, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_faceProtectV2(__sample im, __sample vig, vec2 xy1, vec4 abc1, float feather) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, feather, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_applyVignetteStageV2(__sample im, __sample vig, float amt) 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = mix(im.rgb, im.rgb*(vig.rgb), amt); 
 im.rgb = mix(im.rgb, im.rgb*im.rgb, (1.0-vig.rgb)*.3); 
 return im; 
kernel vec4 _pf_invertRedV2(__sample rNormalized) __attribute__((outputFormat(kCIFormatRh))) 
 return vec4(1.0 - rNormalized.r, 0.0, 0.0, 1.0); 
kernel vec4 _pf_blendDepthV2(__sample depth, __sample tightDepth, __sample im, __sample blur, __sample weight) 
  float d = distance(im.rgb, blur.rgb); 
  float g = mix(tightDepth.r, depth.r, weight.r); 
  g += (d*weight.r*(1.0-dot(im.rgb, vec3(.333333)))); 
  g = clamp(g, 0.0, 1.0); 
  return vec4(g, g, g, 1.0); 
kernel vec4 _pf_thresholdMatteV2(__sample matte, __sample blurMatte, float low, float high) 
 float m = smoothstep(low, high, matte.r)*blurMatte.r; 
 matte.rgb *= m; 
 return matte; 
kernel vec4 _pf_thresholdAndApplyMatteV2(__sample im, __sample matte, __sample m2, vec4 params, float edgeGamma) 
 float low = params.x; float high = params.y; float gamma = params.z; float gain = params.w; float m = smoothstep(low, high, pow(matte.r, gamma+edgeGamma*m2.r)); 
 im.rgb *= m; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = pow(im.rgb, vec3(1.0+gain-gain*matte.r)); 
 im.rgb = mix(.5*im.rgb*im.rgb, im.rgb, 1.0-m2.r); 
 float r = im.r/(im.r+im.g+im.b+0.00001); 
 float sat = max(min(1.0, (1.0-r)), 0.0); 
 float y = dot(im.rgb, vec3(.3333333)); 
 im.rgb = mix(sat*(im.rgb-y)+y, im.rgb, m); 
 return im; 
CIDifferenceBlendMode
kernel vec4 _pf_red(__sample s) { return s.xxxw; }
CIMotionBlur
inputAngle
CICheapMorphology
CIPhotoEffectStageMono
CISmartBlackAndWhite
inputTone
kernel vec4 _pf_thresholdAndApplyWhiteBG(__sample im, __sample matte, __sample m2, float low, float high, float gamma, float gain) 
 float m = smoothstep(low, high, pow(matte.r, gamma+.5*m2.r)); 
 im.rgb = mix(vec3(1.0), im.rgb, m); 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = pow(im.rgb, vec3(1.0+gain-gain*m)); 
 im.rgb = mix(.5*im.rgb*im.rgb, im.rgb, 1.0-m2.r); 
 float r = im.r/(im.r+im.g+im.b+0.00001); 
 float sat = max(min(1.0, (1.3-.9*r)), 0.0); 
 float y = dot(im.rgb, vec3(.3333333)); 
 im.rgb = mix(sat*(im.rgb-y)+y, im.rgb, m); 
 return im; 
kernel vec4 _pf_thresholdWhiteMatte(__sample matte, __sample blurMatte, float low, float high) 
 float m = smoothstep(low, high, matte.r)*blurMatte.r; 
 matte.rgb *= m; 
 return matte; 
kernel vec4 _pf_prepareWhiteDepth (__sample dm, const float thresh) 
 float g = 1.0-smoothstep(0.0, thresh, 2.0*dm.r*dm.r); 
 return vec4(g,g,g, 1.0); 
kernel vec4 _applyWhiteNoFeather (__sample im, __sample dm) 
 im.rgb = mix(im.rgb*im.rgb*im.rgb, im.rgb, dm.r); 
 im.rgb = mix(vec3(1.0), im.rgb, dm.r); 
 return im; 
kernel vec4 _getRefinedWhiteMatte (__sample spill) 
 vec3 div2 = sqrt(vec3(1.0)-(spill.rgb*spill.rgb)); 
 spill.r = div2.r>0.01? (spill.r / div2.r):0.0; 
 spill.g = div2.g>0.01? (spill.g / div2.g):0.0; 
 spill.b = div2.b>0.01? (spill.b / div2.b):0.0; 
 spill.rgb = spill.rgb*vec3(4.0); 
 spill.rgb = mix(min(spill.rgb, 1.0), smoothstep(0.4, 1.0, spill.rgb), 1.0); 
 return vec4( spill.rgb, 1.0 ); 
kernel vec4 _applyRefinedWhiteMatte (__sample im, __sample spill, __sample edge, __sample alpha) 
 im.rgb *= spill.rgb; 
 im.rgb = mix(im.rgb, im.rgb*im.rgb*im.rgb, min(2.0*edge.r, 1.0)); 
 im.rgb = mix(vec3(1.0), im.rgb, alpha.r); 
 return im; }
loadArchive:
true
allocSpanStack:s
allocSpanStack:s->firstChunk
pushSpan:s->stackHeadChunk->next
allocSpanStack: span stack could not be allocated
spanSearch: empty span
freeSpanStack: span stack is null
seedFill: can not push span onto stack
seedFill: can not allocate span stack
-[CIPortraitToothMask outputImage]
CIPortraitToothMask.m
( imageExtentN.origin.x == 0 ) && ( imageExtentN.origin.y == 0 )
+[CIPortraitToothMaskProcessor processWithInputs:arguments:output:error:]
CGRectIsIntegral(teethROI)
CGRectMakeWithVisionDictionaryRepresentation( faceLandmarkDictionary[@"faceBoundingBox"], &faceRectInBuffer )
CGPointMakeWithVisionDictionaryRepresentationAndTransform( pointDictionary, faceRectInBuffer, &pnt1 )
+[CIPortraitToothMaskProcessor roiForInput:arguments:outputRect:]
teethROI
inputImageTransformN1
inputImageTransform1N
useMetal
-[CPUFaceMask clearOutputMask:WithBytesPerRow:OutputRegion:]
CPUFaceMask.m
outputMaskBaseAddr
-[CPUFaceMask trainSkinMaskUsingInputImage:InputBytesPerRow:InputRegion:QuadRegion:]
inputBGRAImageBaseAddr
ChromaDilation %d: minDilateLuma=%f
-[CPUFaceMask findSkinMaskUsingInputImage:InputBytesPerRow:InputRegion:OutputMask:OutputBytesPerRow:OutputRegion:FaceBounds:SeedPoints:NumberOfSeedPoints:FillValue:]
seedPoints
-[CPUFaceMask findToothMaskUsingInputImage:InputBytesPerRow:InputRegion:OutputMask:OutputBytesPerRow:OutputRegion:TeethBounds:SeedPoints:NumberOfSeedPoints:FillValue:]
-[CPUFaceMask drawEyeMaskUsingQuads:OutputMask:OutputBytesPerRow:OutputRegion:]
eyeQuads
eyeQuads->nQuads <= FACEMASK_MAX_NEYEQUADS
initBitmask:b
initBitmask:b->body
initBitmask: bitmap record can not be allocated
initBitmask: bitmap body can not be allocated
termBitmask: bitmap was null
setBitInBitmask: coordinate out of range
bitmaskBoundingBitmapRectWithSeedPoint: seed point outside bitmask
CPUFaceMask_Clear
CPUFaceMask_algorithms.c
outputMaskBaseAddr != NULL
( bounds.x >= region.x ) && ( bounds.y >= region.y ) && ( bounds.z <= region.z ) && ( bounds.w <= region.w )
simd_all( length > 0 ) && simd_all( offset >= 0 )
CPUFaceMask_MinMax
minMaxObj != NULL
inputBGRAImageBaseAddr != NULL
CPUFaceMask_PopulateCube
outputCube != NULL
CPUFaceMask_GenerateMask
spanTable != NULL
firstSpanInRows != NULL
inputCube != NULL
CPUFaceMask_GenerateToothMask
CPUFaceMask_DrawSpans
simd_all( length > 0 )
CPUFaceMask_DrawEye
eyeQuads != NULL
inputSat
inputPShift
inputTShift
kernel vec4 _pf_brightenSat(__sample im, __sample noise, float str, float sat, float pShift, float tShift) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 vec3 lms = im.r * vec3(0.3139902162, 0.15537240628, 0.01775238698) + 
 im.g * vec3(0.63951293834, 0.75789446163, 0.1094420944) + 
 im.b * vec3(0.04649754622, 0.08670141862, 0.87256922462); 
 lms = sign(lms)*pow(abs(lms), vec3(0.43)); 
 vec3 ipt = lms.r * vec3(0.4, 4.455, 0.8056) + 
 lms.g * vec3(0.4, -4.851, 0.3572) + 
 lms.b * vec3(0.2, 0.396,-1.1628); 
 float c = sqrt(ipt.g*ipt.g+ipt.b*ipt.b); 
 float h = atan(ipt.b, ipt.g); 
 float brightGreen = exp(-(h-1.735)*(h-1.735)/(0.35*0.35))*ipt.r ;
 float blueDamp = exp(-(h+1.9)*(h+1.9)/(0.75*0.75))*ipt.r ;
 blueDamp *= (1.0 - smoothstep(0.65, 0.75, c)); 
 float s = 1.0 + .6*str*(1.0 - .85*brightGreen)*(1.0-blueDamp); 
 float greenDamp = exp(-(h-3.14159*0.8)*(h-3.14159*0.8)/(0.7*0.7)) ;
 float dampHighlights = 1.0; 
 c *= s*sat * dampHighlights*(1.0 - .1*brightGreen)*(1.0-.2*blueDamp); 
 float y2 = pow(ipt.r, .5); 
 float y3 = mix(2.0*ipt.r, ipt.r, ipt.r); 
 y2 = mix(y2, y3, .5); 
 float dd = 1.0 - 0.15*smoothstep(0.7, 0.8, ipt.r); 
 dd *= sqrt(y2); 
 float y = mix(ipt.r, y2, dd); 
 float t = ipt.r*(1.0-ipt.r); 
 y = mix(y, 1.0, -t*str) ;
 ipt.r = mix(ipt.r, y, str); 
 greenDamp += exp(-(h+3.14159*1.2)*(h+3.14159*1.2)/(0.7*0.7)) ;
 h = mix(h, h-.125, greenDamp); 
 ipt.g = c * cos(h); 
 ipt.b = c * sin(h); 
 ipt.g += (pShift*ipt.r); ipt.b += (tShift*ipt.r); lms = ipt.r * vec3(1.0000, 1.0000, 1.0000) + 
 ipt.g * vec3(0.0976,-0.1139, 0.0326) + 
 ipt.b * vec3(0.2052, 0.1332,-0.6769); 
 lms = sign(lms)*pow(abs(lms), vec3(1.0/.43)); 
 im.rgb = lms.r * vec3(5.472212058380287, -1.125241895533569, 0.029801651173470) + 
 lms.g * vec3(-4.641960098354471, 2.293170938060623, -0.193180728257140) + 
 lms.b * vec3(0.169637076827974, -0.167895202223709, 1.163647892783812); 
 c = smoothstep(0.0, 0.3, c); 
 float ydamp = smoothstep(0.0, 1.0, ipt.r); 
 im.rgb = mix(im.rgb, 0.95*im.rgb*im.rgb*im.rgb, greenDamp*ydamp*c); 
 float nn = (noise.r + noise.g + noise.b + noise.a)*0.25 - 0.5; 
 im.rgb = mix(im.rgb, im.rgb+(.03*nn), im.b); 
 im.rgb = clamp(im.rgb, 0.0, 1.0) + neg + pos; 
 return im; 
CIRandomGenerator
kernel vec4 _pf_brightenFood(__sample im, float str, float sat, float pShift, float tShift) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 vec3 lms = im.r * vec3(0.3139902162, 0.15537240628, 0.01775238698) + 
 im.g * vec3(0.63951293834, 0.75789446163, 0.1094420944) + 
 im.b * vec3(0.04649754622, 0.08670141862, 0.87256922462); 
 lms = sign(lms)*pow(abs(lms), vec3(0.43)); 
 vec3 ipt = lms.r * vec3(0.4, 4.455, 0.8056) + 
 lms.g * vec3(0.4, -4.851, 0.3572) + 
 lms.b * vec3(0.2, 0.396,-1.1628); 
 float c = sqrt(ipt.g*ipt.g+ipt.b*ipt.b); 
 float h = atan(ipt.b, ipt.g); 
 float redDamp = 1.0 - .65*exp(-(h-3.14159*.14)*(h-3.14159*.14)/(.55*.55)); float brightGreen = exp(-(h-1.735)*(h-1.735)/(0.35*0.35))*ipt.r ;
 float cc = smoothstep(0.0, 0.55, c); 
 float dampHighlights = 1.0 - smoothstep(.5, 1.0, ipt.r); 
 float s = 1.0 + .6*str*cc*redDamp*(1.0-brightGreen); 
 float dampBlue = 1.0 - smoothstep(0.5, 1.0, im.b); 
 sat = (sat >= 1.0) ? 1.0+(sat-1.0)*cc*dampHighlights*redDamp*(1.0-brightGreen) : sat; 
 float rgDamp = (1.0 - .15*(1.0-redDamp))*(1.0 - .1*brightGreen); 
 c *= s*sat*dampBlue*rgDamp; 
 float y2 = pow(ipt.r, .5); 
 float y3 = mix(2.0*ipt.r, ipt.r, ipt.r); 
 y2 = mix(y2, y3, .5); 
 float dd = 1.0 - .15*smoothstep(0.7, 0.8, ipt.r); 
 dd *= sqrt(y2); 
 float y = mix(ipt.r, y2, dd); 
 float t = ipt.r*(1.0-ipt.r); 
 y = mix(y, 1.0, -t*str) ;
 ipt.r = mix(ipt.r, y, str); 
 float hue_shift = .25*exp(-(h*h)/(.45*.45)); h += hue_shift; ipt.g = c * cos(h); 
 ipt.b = c * sin(h); 
 ipt.g += (pShift*ipt.r*redDamp); ipt.b += (tShift*ipt.r*redDamp); lms = ipt.r * vec3(1.0000, 1.0000, 1.0000) + 
 ipt.g * vec3(0.0976,-0.1139, 0.0326) + 
 ipt.b * vec3(0.2052, 0.1332,-0.6769); 
 lms = sign(lms)*pow(abs(lms), vec3(1.0/.43)); 
 im.rgb = lms.r * vec3(5.472212058380287, -1.125241895533569, 0.029801651173470) + 
 lms.g * vec3(-4.641960098354471, 2.293170938060623, -0.193180728257140) + 
 lms.b * vec3(0.169637076827974, -0.167895202223709, 1.163647892783812); 
 im.rgb = mix(im.rgb, pow(im.rgb, vec3(1.6)), smoothstep(0.915, 1.0, ipt.r)); 
 im.rgb = clamp(im.rgb, 0.0, 1.0) + neg + pos; 
 return im; 
RGON_ARRAY
 {%f , %f },
 {%f , %f }
 Line[ { 
 {%f,%f,%f},
 {%f,%f,%f}
 }] 
 %f,
 %f } 
RGON_STACK
BIN_COUNT
BIN_OFFSET
BIN_SIZE
LOW_Z
HIGH_Z
DARKTHR_Z
 rgon stack print facets of stack with  %d rgons
 {%5.2f,%5.2f,%5.2f},
 {%5.2f,%5.2f,%5.2f} 
Cross[{%f,%f,%f}, {%f,%f,%f} ] - {%f, %f, %f } 
Hue[.4],Line[{{%5.2f,%5.2f,%5.2f}, {%5.2f,%5.2f,%5.2f} }],
 rgon stack print vertices
 end rgon stack print vertices
 rgon stack print constraints
 end rgon stack print constraints
 end rgon stack print
 }] ,
list001 = { {%f,%f}
,{%f,%f}
 Show[ g01 = Graphics[{ Line[list001], Hue[.4], AbsolutePointSize[5], Map[Point, list001]}]] 
s  %f , %f, x and y {%f,%f },{%f, %f} 
Line[{{%f,%f},{%f,%f},{%f,%f},{%f,%f},{%f,%f}}] 
xmin, xmax, ymin, ymax {%f, %f}, {%f, %f} 
Polyline points
Polyline bounds
 bounds Rect (polyline printRect )
bridgeGaps currently empty for polyline pairs
topbottom region summary
inputIsSunsetSunrise
inputExposure
inputBrightness
inputHighlights
inputWhiteBalance
inputSaturation
inputBrightSat
inputConfidence
inputLowConfidence
inputHighConfidence
inputMaxFaceSize
kernel vec4 _pf_imToIPT(__sample im) 
 vec3 lms = im.r * vec3(0.3139902162, 0.15537240628, 0.01775238698) + 
 im.g * vec3(0.63951293834, 0.75789446163, 0.1094420944) + 
 im.b * vec3(0.04649754622, 0.08670141862, 0.87256922462); 
 lms = sign(lms)*pow(abs(lms), vec3(0.43)); 
 vec3 ipt = lms.r * vec3(0.4, 4.455, 0.8056) + 
 lms.g * vec3(0.4, -4.851, 0.3572) + 
 lms.b * vec3(0.2, 0.396,-1.1628); 
 return vec4(ipt, im.a); 
kernel vec4 _pf_iptToHueChroma(__sample im) 
 vec4 ihc = im; 
 float hue = atan(im.b, im.g); 
 ihc.g = (hue/3.14159 + 1.0)/2.0; 
 ihc.b = sqrt(im.g*im.g+im.b*im.b); 
 ihc.a = 1.0; 
 return ihc; 
{Exif}
BrightnessValue
{MakerApple}
semdev_debug_overlay
proxy
full
night mode
normal
Strength: %@, CaptureType: %@, BV: %@, size: %@
CITextImageGenerator
inputText
inputFontSize
kernel vec4 _pf_softExposure(__sample im) 
 float y = dot(im.rgb, vec3(0.1, 0.8, .1)); 
 float g = -0.2664*y*y + 1.2695*y; 
 im.rgb = (y > 0.0) ? im.rgb/y*g : vec3(0.0); 
 return im; 
highKey
blackPoint
CIDynamicLocalLightMapPrepare
inputLightMap
lightMap
inputGuideImage
CILLFilter
inputLightMapImage
CIBrightenSat
inputBlack
inputUnionBox
inputVignetteStrength
kernel vec4 _pf_foodVignette(__sample im, __sample vig, vec2 xy1, vec4 abc1) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, .4, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))); 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_applyFoodVignette(__sample im, __sample orig, __sample vig, float amt) 
 im.rgb = mix(.9*orig.rgb, im.rgb, amt*vig.rgb) ;
 return im; 
CITemperatureAndTint
inputTargetNeutral
CIBrightenFood
CIOverlayBlendMode
kernel vec4 _pf_highKey(__sample im, float str) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0) - 1.0; 
 im = clamp(im, 0.0, 1.0); 
 vec4 im2 = 1.0-((im-1.0)*(im-1.0)); 
 im2 = sqrt(im2); 
 float y = dot(im.rgb, vec3(.333333)); 
 float y2 = sqrt(1.0-(y-1.0)*(y-1.0)); 
 y2 = mix(y2, smoothstep(0.0, 1.0, y2), 0.5); 
 vec4 im3 = (y>0) ? im*y2/y : vec4(0.0, 0.0, 0.0, 1.0) ; 
 im3 = mix(im3, im2, .7*sqrt(y2)); 
 im3 = mix(im, im3, sqrt(y)) ; 
 im.rgb = mix(im.rgb, im3.rgb, str) + pos + neg; 
 return im; } 
kernel vec4 _pf_portraitConvertToGrayscale (__sample c) __attribute__((outputFormat(kCIFormatRh))) {
  float g = dot(c.rgb, vec3(0.333333));
  return vec4(g, 0.0, 0.0, 1.0);
kernel vec4 _pf_portraitLocalContrast(__sample im, __sample shc, float amt)
 float midAmt = amt;
 vec3 neg = min(im.rgb, 0.0);
 vec3 pos = max(im.rgb, 1.0)-1.0;
 im.rgb = clamp(im.rgb, 0.0, 1.0);
 float y = dot(im.rgb, vec3(0.3333));
 y = sqrt(y);
 y = y*(1.0-y);
 im.rgb = sqrt(im.rgb);
 float pivot = sqrt(shc.r);
 float a = midAmt*y;
 float b = -pivot*a;
 vec3 pix = im.r * vec3(0.299*a) +
 im.g * vec3(0.587*a) +
 im.b * vec3(0.114*a) +
 im.rgb + vec3(b);
 im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt);
 im.rgb = mix(im.rgb, pix, 0.8);
 im.rgb = max(im.rgb, 0.0);
 im.rgb *= im.rgb;
 im.rgb = im.rgb + neg + pos;
 return im;
kernel vec4 _pf_whitenteeth(__sample pix, __sample mask, float amt) 
 float m = mask.g; 
 vec4 modifiedPix = pow(clamp(pix,0.0, 1.0), vec4(.35)); 
 modifiedPix.b += .1; 
 modifiedPix = modifiedPix * modifiedPix; 
 modifiedPix.rgb = compare(vec3(m - .8), modifiedPix.rgb, pix.rgb); 
 vec4 displayPix = clamp(modifiedPix,0.0, 1.0); 
 displayPix.a = 1.0; 
 displayPix.rgb = mix(pix.rgb, displayPix.rgb, max(m, 0.0)); 
 displayPix.a = pix.a; 
 return mix(pix, displayPix, amt); 
kernel vec4 _pf_enrich (__sample s, float amt,vec4 params ) { 
 vec4 orig = s; 
 s = clamp(s, 0.0, 1.0); 
 float x0 = params.r; 
 float x1 = params.g; 
 float delta = params.b; 
 float pwr = params.a; 
 s = pow( s, vec4(pwr)); 
 float x2 = 1.0 - delta; 
 float m1 = 0.5/(x1-x0); 
 float b1 = - m1 * x0; 
 float m2 = (.5 - delta)/(x2 - x1); 
 float b2 = (m1-m2) * x1 + b1; 
 vec4 w = (1.0 - step(x1, s)) * (vec4(m1)*s + vec4(b1)) + step(x1, s) * (vec4(m2)*s + vec4(b2)) + step(x2,s) * ( s - (vec4(m2)*s + vec4(b2))) ; 
 w.rgb = clamp(w.rgb, 0.0, 1.0); 
 x0+= .02; 
 x1+= .0005; 
 m1 = 0.5/(x1-x0); 
 b1 = - m1 * x0; 
 m2 = (.5 - delta)/(x2 - x1); 
 b2 = (m1-m2) * x1 + b1; 
 w.r = (1.0 - step(x1, s.r)) * ((m1)*s.r + (b1)) + step(x1, s.r) * ((m2)*s.r + (b2)) + step(x2,s.r) * ( s.r - ((m2)*s.r + (b2))) ; 
 w.r = clamp(w.r, 0.0, 1.0); 
 x0-= .01; 
 x1+= .000; 
 m1 = 0.5/(x1-x0); 
 b1 = - m1 * x0; 
 m2 = (.5 - delta)/(x2 - x1); 
 b2 = (m1-m2) * x1 + b1; 
 w.b = (1.0 - step(x1, s.b)) * ((m1)*s.b + (b1)) + step(x1, s.b) * ((m2)*s.b + (b2)) + step(x2,s.b) * ( s.b - ((m2)*s.b + (b2))) ; 
 w.b = clamp(w.b, 0.0, 1.0); 
 w.rgb = w.rgb * w.rgb; 
 w.r = pow(w.r, .75); 
 w = mix(orig, w, vec4(amt) ); w.a = 1.0; 
 return w; 
kernel vec4 _pf_eyeBrightenSoftlight (__sample uCb, __sample m, float str) 
 float g = .75*(1.0-dot(uCb.rgb, vec3(.333333))); 
 vec4 uCf = vec4(g, g, g, 1.0); 
 vec4 D = compare(uCb-0.25, ((16.0*uCb-12.0)*uCb+4.0)*uCb, sqrt(uCb)); 
 vec4 Ct = clamp(uCb + (2.0*uCf-1.0) * compare(uCf - 0.5, uCb*(1.0-uCb), D-uCb), 0.0, 1.0); 
 vec4 bright = Ct; 
 uCf.rgb = mix(uCb.rgb, bright.rgb, m.r); 
 uCf.rgb = mix(uCb.rgb, uCf.rgb, str); 
 return uCf; 
kernel vec4 _pf_mixKernel1 (__sample c, __sample b, float m) 
 c.rgb = mix(c.rgb, b.rgb, m); 
 return c; 
kernel vec4 _pf_textureDiff (__sample c, __sample b) 
 c.rgb = c.rgb - b.rgb; 
 return c; 
kernel vec4 _pf_textureAdd (__sample c, __sample b, float scale) 
 c.rgb = c.rgb + scale*b.rgb; 
 return c; 
CIRingBlur
inputPointCount
-[CIPortraitEffectLight processEyesIn:withEyeBlur:landmarks:]
CIPortraitEffect.mm
CI_USE_OLD_FACE_MASK
kernel vec4 _pf_prepareDepth (__sample c, float m) 
 c.r = smoothstep(m, 0.7, 2.0*c.r); 
 return c.rrra; 
kernel vec4 _pf_mixKernel2 (__sample c, __sample b, float m) 
 c.rgb = mix(c.rgb, b.rgb, m); 
 return c; 
CIPortraitEffectLight
CIPortraitLightingStrobe
kernel vec4 _pf_prepareDepth2 (__sample c, float m) 
 c.r = smoothstep(0.0, m, 2.0*c.r); 
 return vec4(vec3(c.r), 1.0); 
kernel vec4 _pf_mixKernel3 (__sample c, __sample b, float m) 
 c.rgb = mix(c.rgb, b.rgb, m); 
 c.a = b.a; return c; 
kernel vec4 _pf_blendSingleChannelMask (__sample c, __sample b, __sample m) 
 c.rgb = mix(c.rgb, b.rgb, m.r); 
 return c; 
kernel vec4 _pf_faceVignetteContour(__sample im, __sample vig, vec2 xy1, vec4 abc1) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, .4, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))); 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_applyVignetteContour(__sample im, __sample vig, float amt) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = mix(im.rgb, pow(im.rgb, vec3(2.0)), (1.0-.6*vig.rgb)*.1); 
 im.rgb = mix(im.rgb, im.rgb*(vig.rgb), .1) + pos + neg; 
 return im; 
CIPortraitLightingContour
CIPortraitLightingNeckContour
inputChin
inputDepthThreshold
inputFocalLengthNormalized
inputAdaptiveThresholdFaceGroupRange
inputAdaptiveThresholdFaceErrorMargin
inputAdaptiveThresholdZRangeConst
inputAdaptiveThresholdZRangeLinearDepth
inputAdaptiveThresholdConstOffset
inputAdaptiveThresholdLinearDepthOffset
inputAdaptiveThresholdDoDisparityError
inputDepthDataScore
kernel vec4 _pf_prepareBlackDisparity (__sample dm, const float thresh) 
 float g = 1.0-smoothstep(0.0, thresh, 4.0*dm.r); 
 return vec4(g,g,g, 1.0); 
kernel vec4 _pf_prepareBlackDepth (__sample dm, const float thresh) 
 float g = 1.0-smoothstep(0.0, thresh, 2.0*dm.r*dm.r); 
 return vec4(g,g,g, 1.0); 
kernel vec4 _pf_applyBlackDepth (__sample im, __sample dm, float g) 
 im.rgb *= pow(dm.r, g); 
 return im; 
kernel vec4 _pf_refineBlackDepth (__sample im, __sample dm, __sample bm, __sample protect, vec3 g, __sample aft) 
 float b = smoothstep(0.0, 1.0, pow(dm.r*bm.r,g.r)+protect.r); 
 im.rgb = max(im.rgb, 0.0); 
 vec3 gamma = (g.b) > 0.0 ? vec3(1.0+g.g-g.g*b*b*dm.r) : vec3(1.0+g.g-g.g*b*b); 
 im.rgb = pow(im.rgb, gamma); 
 im.rgb = mix(vec3(0.0), im.rgb, b); 
 gamma = vec3(1.35-.35*b*aft.r); 
 im.rgb = pow(im.rgb, gamma); 
 float r = im.r/(im.r+im.g+im.b+0.00001); 
 float sat = max(min(1.0, (1.3-.9*r)), 0.0); 
 float y = dot(im.rgb, vec3(.3333333)); 
 im.rgb = mix(sat*(im.rgb-y)+y, im.rgb, b*dm.r); 
 return im; 
kernel vec4 _pf_faceVignette1(__sample im, __sample vig, vec2 xy1, vec4 abc1) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, .4, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_faceProtect(__sample im, __sample vig, vec2 xy1, vec4 abc1, float feather) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, feather, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_faceAndBodyFill_1(__sample vig, vec2 xy1, vec4 abc1, vec2 fw, vec2 xy2) 
    vec2 dc = destCoord() ; 
    float dx = xy1.x-dc.x ; 
    float dy = xy1.y-dc.y ; 
    float s = smoothstep(0.0, .15, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
    float t = .025*distance(vec2(dc.x, xy2.y), dc); 
    t = (fw.g*xy2.y < fw.g*dc.y) ? 0.0 : min(t, 1.0); 
    float u = clamp(fw.g*1.5*fw.r*dy/(dx*dx+0.0001), 0.0, 1.0); 
    vig.rgb = min(vig.rgb + vec3(s) + t + (u*u*u)+.2, 1.0); 
    return vig; 
kernel vec4 _pf_faceAndBodyFill_6(__sample vig, vec2 xy1, vec4 abc1, vec2 fw, vec2 xy2) 
    vec2 dc = destCoord() ; 
    float dx = xy1.x-dc.x ; 
    float dy = xy1.y-dc.y ; 
    float s = smoothstep(0.0, .15, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
    float t = .025*distance(vec2(xy2.x, dc.y), dc); 
    t = (fw.g*xy2.x > fw.g*dc.x) ? 0.0 : min(t, 1.0); 
    float u = clamp(-fw.g*1.5*fw.r*dx/(dy*dy+0.0001), 0.0, 1.0); 
    vig.rgb = min(vig.rgb + vec3(s) + t + (u*u*u)+.2, 1.0); 
    return vig; 
kernel vec4 _pf_applyVignette(__sample im, __sample vig, float amt) 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = mix(im.rgb, im.rgb*(vig.rgb), amt); 
 im.rgb = mix(im.rgb, im.rgb*im.rgb, (1.0-vig.rgb)*.3); 
 return im; 
kernel vec4 _pf_adaptiveNormalization2(__sample disparityImage, float dFocus, float e, float zRange, float zRangeScale, float thresholdOffset, float thresholdScale) 
 float d = disparityImage.r; 
 float zCorrected = 1.0 / max(1e-1, (d - e)); 
 float zFCorrected = thresholdScale / max(1e-1, (dFocus - e)) + thresholdOffset; 
 float zEffRange = zRange + zRangeScale * zFCorrected; 
 float v = smoothstep(zFCorrected - zEffRange, zFCorrected + zEffRange, zCorrected); 
 return vec4(v, v, v, 1.0); 
kernel vec4 _pf_adaptiveNormalizationGPU(__sample disparityImage, __sample offsets, float zRange, float zRangeScale, float thresholdOffset, float thresholdScale) 
 float d = disparityImage.r; 
 float dFocus = offsets.r; 
 float e = offsets.g; 
 float zCorrected = 1.0 / max(1e-1, (d - e)); 
 float zFCorrected = thresholdScale / max(1e-1, (dFocus - e)) + thresholdOffset; 
 float zEffRange = zRange + zRangeScale * zFCorrected; 
 float v = smoothstep(zFCorrected - zEffRange, zFCorrected + zEffRange, zCorrected); 
 return vec4(v, v, v, 1.0); 
kernel vec4 _pf_adaptiveNormalizationAbsolute(__sample disparityImage, __sample offsets, float zRange, float zRangeScale, float thresholdOffset, float thresholdScale) 
 float d = disparityImage.r; 
 float dFocus = offsets.r; 
 float e = offsets.g; 
 float zCorrected = 1.0 / max(1e-1, (d - e)); 
 float zFCorrected = thresholdScale / max(1e-1, (dFocus - e)) + thresholdOffset; 
 float zEffRange = zRange + zRangeScale * zFCorrected; 
 float v = smoothstep(zFCorrected - zEffRange, zFCorrected + zEffRange, zCorrected); 
 zFCorrected = thresholdScale / max(1e-1, (dFocus - e)) + .25*thresholdOffset ; 
 zEffRange = zRange + zRangeScale * zFCorrected; 
 float v2 = smoothstep(zFCorrected - .04, zFCorrected + .04, zCorrected); 
 v = (1.75*v + v2)/2.75; 
 return vec4(v, v, v, 1.0); 
kernel vec4 _pf_invertRed(__sample rNormalized) __attribute__((outputFormat(kCIFormatRh))) 
 return vec4(1.0 - rNormalized.r, 0.0, 0.0, 1.0); 
kernel vec4 _pf_blendDepth(__sample depth, __sample tightDepth, __sample im, __sample blur, __sample weight) 
  float d = distance(im.rgb, blur.rgb); 
  float g = mix(tightDepth.r, depth.r, weight.r); 
  g += (d*weight.r*(1.0-dot(im.rgb, vec3(.333333)))); 
  g = clamp(g, 0.0, 1.0); 
  return vec4(g, g, g, 1.0); 
kernel vec4 _pf_thresholdMatte(__sample matte, __sample blurMatte, float low, float high) 
 float m = smoothstep(low, high, matte.r)*blurMatte.r; 
 matte.rgb *= m; 
 return matte; 
kernel vec4 _pf_thresholdAndApplyMatte(__sample im, __sample matte, __sample m2, vec4 params, float edgeGamma) 
 float low = params.x; float high = params.y; float gamma = params.z; float gain = params.w; float m = smoothstep(low, high, pow(matte.r, gamma+edgeGamma*m2.r)); 
 im.rgb *= m; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = pow(im.rgb, vec3(1.0+gain-gain*matte.r)); 
 im.rgb = mix(.5*im.rgb*im.rgb, im.rgb, 1.0-m2.r); 
 float r = im.r/(im.r+im.g+im.b+0.00001); 
 float sat = max(min(1.0, (1.0-r)), 0.0); 
 float y = dot(im.rgb, vec3(.3333333)); 
 im.rgb = mix(sat*(im.rgb-y)+y, im.rgb, m); 
 return im; 
Regions
RegionList
Type
Focus
CI_GPU_OFFSET_CALCULATOR
CIPortraitEffectContour
CIConfidenceThreshold
CI_OVERRIDE_MAX_NUM_VERTICES
CIPortraitPrepareStage
inputThresholdImage
float _computeZFromFaceRect(vec2 faceSize,float focalLengthNormalized, float marginError) 
  float kAverageFaceDiagonalBitragionBreadthMeters = 0.22f;  
  float d = length(faceSize) * marginError; 
  return (kAverageFaceDiagonalBitragionBreadthMeters  * focalLengthNormalized ) / d; 
kernel vec4 _pf_disparityError(__sample s0,__sample s1,__sample s2,__sample s3, 
                            vec4 faceSizes01,vec4 faceSizes23, 
                            vec4 valid,vec4 params,float marginError,float doDisparityError, __sample focusDisparity) 
   float kFaceDetectionRangeCloseMeters = params.x; 
   float kFaceDetectionRangeFarMeters   = params.y; 
   float faceGroupRange                 = params.z; 
    float focalLengthNormalized          = params.w; 
   float focusDisparityValue = focusDisparity.r; 
   float outDisparityOffsetError = 0.0; 
   vec4 faceAverageDisparities = vec4( s0.r, s1.r, s2.r, s3.r ); 
   if ( doDisparityError > 0.0 ) { 
      vec4 faceTrueZ = valid; 
      faceTrueZ.x = valid.x > 0.0 ? _computeZFromFaceRect(faceSizes01.xy, focalLengthNormalized, marginError) : -1.0; 
      faceTrueZ.y = valid.y > 0.0 ? _computeZFromFaceRect(faceSizes01.zw, focalLengthNormalized, marginError) : -1.0; 
      faceTrueZ.z = valid.z > 0.0 ? _computeZFromFaceRect(faceSizes23.xy, focalLengthNormalized, marginError) : -1.0; 
      faceTrueZ.w = valid.w > 0.0 ? _computeZFromFaceRect(faceSizes23.zw, focalLengthNormalized, marginError) : -1.0; 
      vec4 faceTrueDisparity = vec4(1.0) / faceTrueZ; 
      bool R = valid.x > 0.0 && (faceTrueZ.r >= kFaceDetectionRangeCloseMeters) && (faceTrueZ.r <= kFaceDetectionRangeFarMeters); 
      bool G = valid.y > 0.0 && (faceTrueZ.g >= kFaceDetectionRangeCloseMeters) && (faceTrueZ.g <= kFaceDetectionRangeFarMeters); 
      bool B = valid.z > 0.0 && (faceTrueZ.b >= kFaceDetectionRangeCloseMeters) && (faceTrueZ.b <= kFaceDetectionRangeFarMeters); 
      bool A = valid.w > 0.0 && (faceTrueZ.a >= kFaceDetectionRangeCloseMeters) && (faceTrueZ.a <= kFaceDetectionRangeFarMeters); 
      vec4 e = compare( vec4(R, G, B, A) - vec4(0.01), vec4(0.0), faceAverageDisparities - faceTrueDisparity); 
      float eSum = e.r + e.g + e.b + e.a; 
      int countFacesForDisparityError = int(R) + int(G) + int(B) + int(A); 
      outDisparityOffsetError = countFacesForDisparityError > 0 ? eSum / float(countFacesForDisparityError) : 0.0; 
   } 
   float focusDepth = 1.0 / max(1e-1, (focusDisparityValue - outDisparityOffsetError)); 
   vec4 faceDepth   = vec4(1.0) / max( vec4(1e-1), faceAverageDisparities - vec4(outDisparityOffsetError) ); 
   float faceDisparityFarBackground = 1000000.0; 
   bool haveIdx = false; 
   float depthPlusRange = focusDepth + faceGroupRange; 
   if ( valid.x > 0.0 && faceDepth.x < depthPlusRange && faceAverageDisparities.x < faceDisparityFarBackground ) { 
      faceDisparityFarBackground = faceAverageDisparities.x; 
      haveIdx = true; 
   } 
   if ( valid.y > 0.0 && faceDepth.y < depthPlusRange && faceAverageDisparities.y < faceDisparityFarBackground ) { 
      faceDisparityFarBackground = faceAverageDisparities.y; 
      haveIdx = true; 
   } 
   if ( valid.z > 0.0 && faceDepth.z < depthPlusRange && faceAverageDisparities.z < faceDisparityFarBackground ) { 
      faceDisparityFarBackground = faceAverageDisparities.z; 
      haveIdx = true; 
   } 
   if ( valid.w > 0.0 && faceDepth.w < depthPlusRange && faceAverageDisparities.w < faceDisparityFarBackground ) { 
      faceDisparityFarBackground = faceAverageDisparities.w; 
      haveIdx = true; 
   } 
   return vec4(haveIdx ? faceDisparityFarBackground : focusDisparityValue, outDisparityOffsetError, 0.0, 1.0); 
-[CIPortraitSkinMask outputImage]
CIPortraitSkinMask.mm
+[CIPortraitSkinMaskProcessor processWithInputs:arguments:output:error:]
CGPointMakeWithVisionDictionaryRepresentationAndTransform( pointDictionary, faceRectInBuffer, &leftEye )
CGPointMakeWithVisionDictionaryRepresentationAndTransform( pointDictionary, faceRectInBuffer, &rightEye )
CGRectMakeWithVisionDictionaryRepresentation( faceLandmarkDictionary[@"faceBoundingBox"], &faceBoundingBox)
leftEyePoints
rightEyePoints
leftEyePoints.count == 8
rightEyePoints.count == 8
CGPointMakeWithVisionDictionaryRepresentationAndTransform( leftEyePoints[i], faceRectInBuffer, &pnt)
CGPointMakeWithVisionDictionaryRepresentationAndTransform( rightEyePoints[i], faceRectInBuffer, &pnt)
+[CIPortraitSkinMaskProcessor roiForInput:arguments:outputRect:]
PFBoxBlur3_7
PFSobelHV
CIMorphologicalMax5Mono
CIConfidenceThresholdProcessor
CIConfidenceThreshold
CIPortraitPrepareStage
CIConfidenceMap
CIPortraitLightingSide
CIPortraitLightingFront
CIPortraitLightingStrobe
CIPortraitLightingContour
CIPortraitLightingSpot
CIPortraitLightingNeckContour
CIPortraitLightingStudio
CIPortraitLightingStrobeV2
CIPortraitLightingContourV2
CIPortraitLightingEdge
PortraitFilters
CameraImaging
CIPortraitFaceMask
CIPortraitFaceMaskProcessorKernel
CISRGBtoIPT
CIIPTtoSRGB
CIHueChromaHistProcessor
CIAveColorProcessor
CIColorGradientProcessor
CISmartGradient
CIPortraitContour
CIDynamicGuidedFilter
CIDynamicLocalLightMapPrepare
CILLFilter
PortraitEffetcPrewarm
CIPortraitEffectV2
CIPortraitEffectLightV2
CIPortraitEffectStudioV2
CIPortraitEffectContourV2
CIPortraitEffectStageV2
CIPortraitEffectStageMonoV2
CIPortraitEffectStageWhite
FaceLandmarks
ComputedFaceData
LightingFacePoints
CIPortraitToothMask
CIPortraitToothMaskProcessor
CPUFaceMask
CIBrightenSat
CIBrightenFood
Rgon
NSCopying
NSCoding
RgonStack
Polyline
PolylinePair
TopBottomRegion
CIDynamicRender
CIDynamicFood
CIHighKey
CIPortraitLocalContrast
CIPortraitEffect
CIPortraitEffectLight
CIPortraitEffectCommercial
CIPortraitEffectStudio
CIPortraitEffectContour
CIPortraitEffectBlack
CIPortraitEffectStage
CIPortraitEffectBlackoutMono
CIPortraitEffectStageMono
CIPortraitSkinMask
CIPortraitSkinMaskProcessor
@16@0:8
v24@0:8@16
@"CIImage"
B48@0:8@16@24@32^@40
i16@0:8
B16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}60@0:8i16@20{CGRect={CGPoint=dd}{CGSize=dd}}28
i20@0:8i16
@"CIVector"
@"NSNumber"
@24@0:8@16
v20@0:8i16
f16@0:8
v20@0:8f16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@"NSDictionary"
@32@0:8@16f24f28
@40@0:8@16@24@32
@"LightingFacePoints"
@"NSData"
@20@0:8f16
v44@0:8@16@24@32B40
v28@0:8@16B24
@"NSArray"
v16@0:8
@32@0:8@16@24
@36@0:8@16@24i32
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
^{CGPath=}16@0:8
v24@0:8^{CGPath=}16
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
[4{CGPoint="x"d"y"d}]
[7{CGPoint="x"d"y"d}]
[5{CGPoint="x"d"y"d}]
[6{CGPoint="x"d"y"d}]
[11{CGPoint="x"d"y"d}]
[9{CGPoint="x"d"y"d}]
[3{CGPoint="x"d"y"d}]
{CGPoint="x"d"y"d}
@"ComputedFaceData"
@"Polyline"
@"PolylinePair"
^{CGPath=}
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
^{CGPoint=dd}16@0:8
v24@0:8^{CGPoint=dd}16
d16@0:8
v24@0:8d16
v20@0:8B16
[65{CGPoint="x"d"y"d}]
[10{CGPoint="x"d"y"d}]
[20{CGPoint="x"d"y"d}]
^{CGPoint=dd}
@"Rgon"
[2{CGPoint="x"d"y"d}]
i64@0:8*16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32
i72@0:8r*16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32[4{CGPoint=dd}]64
i164@0:8r*16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32*64Q72{CGRect={CGPoint=dd}{CGSize=dd}}80{CGRect={CGPoint=dd}{CGSize=dd}}112^{CGPoint=dd}144Q152C160
i72@0:8^{MetalFaceMaskEyeQuads_t=IIC[16{MetalFaceMaskQuad_t=}]}16*24Q32{CGRect={CGPoint=dd}{CGSize=dd}}40
{CPUColorCube="data"[32768C]}
{MetalFaceMaskCubeInputScaling_t="offset""scale"}
@36@0:8@16@24f32
@24@0:8^{_NSZone=}16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
^f20@0:8f16
i24@0:8f16f20
f24@0:8i16f20
f36@0:8i16f20i24@28
v24@0:8^f16
v28@0:8f16f20f24
i36@0:8f16f20^i24i32
i36@0:8f16f20f24^i28
f20@0:8i16
f24@0:8f16f20
f24@0:8@16
v32@0:8i16i20[2f]24
{?=ff}24@0:8i16i20
B32@0:8@16@24
^[7f]16@0:8
v24@0:8^[7f]16
q16@0:8
v24@0:8q16
^f16@0:8
[32[7f]]
^[7f]
v40@0:8d16d24d32
i28@0:8f16f20f24
f28@0:8f16f20f24
i36@0:8f16f20f24f28f32
i44@0:8f16f20f24f28f32f36B40
v52@0:8@16f24@28f36i40^f44
@"NSMutableArray"
@40@0:8f16f20{CGPoint=dd}24
B24@0:8f16f20
{CGPoint=dd}24@0:8d16
{CGPoint=dd}20@0:8f16
v24@0:8f16f20
I16@0:8
v20@0:8I16
@"NSMutableData"
@52@0:8i16{CGRect={CGPoint=dd}{CGSize=dd}}20
{?={CGPoint=dd}{CGPoint=dd}}16@0:8
{?=ddddd}24@0:8@16
@36@0:8@16f24i28f32
Q40@0:8@16@24@32
B20@0:8i16
333333
333333
ffffff
333333
ffffff
333333
333333
ffffff
ffffff
333333
333333
333333
333333
ffffff
ffffff
ffffff
333333
ffffff
333333
333333
ffffff
333333
>ffffff
=333333
?ffffff
@ffffff
?333333
?ffffff
?333333
?333333
f@es-8R
?333333
?333333
@333333
?333333
333>
?ff&?
?333333
?ffffff
@333333
~?333333
ffffff
MbP?
MbP?
333333
?ffffff
Ga>33s?
emptyImage
extent
numberWithInt:
dictionaryWithObjects:forKeys:count:
imageByClampingToExtent
arrayWithObjects:count:
applyWithExtent:roiCallback:arguments:options:
imageByCroppingToRect:
outputImage
inputImage
setInputImage:
T@"CIImage",&,VinputImage
objectAtIndexedSubscript:
objectForKeyedSubscript:
CGRectValue
region
baseAddress
processWithInputs:arguments:output:error:
outputFormat
synchronizeInputs
roiForInput:arguments:outputRect:
formatForInputAtIndex:
PFKernelWithString:
floatValue
imageByApplyingTransform:
imageByApplyingFilter:
imageByApplyingFilter:withInputParameters:
transitionDepthsKernel
applyWithExtent:arguments:options:
thresholdKernel
vectorWithCGRect:
vectorWithX:Y:
customAttributes
inputFocusRect
setInputFocusRect:
inputScale
setInputScale:
T@"CIVector",C,N,VinputFocusRect
T@"NSNumber",C,N,VinputScale
convertToHalfFloat
applyWithExtent:arguments:
renormalize01
renormalizeThreshold
vectorWithX:Y:Z:
computeBand
protectInterior
filterWithName:withInputParameters:
denormalize
vectorWithX:Y:Z:W:
invertImage
normalizeToPhysicalDepth
foreground
filterCut
boxBlur3Mono
inputDisparityImage
setInputDisparityImage:
inputThresholdImage
setInputThresholdImage:
inputMaxNumVertices
setInputMaxNumVertices:
inputSigmaS
setInputSigmaS:
inputSigmaRLuma
setInputSigmaRLuma:
inputSigmaRChroma
setInputSigmaRChroma:
inputLambda
setInputLambda:
inputMaxNumIterations
setInputMaxNumIterations:
inputBandRange
setInputBandRange:
inputThresholdOffset
setInputThresholdOffset:
inputFilterCut
setInputFilterCut:
inputFeatherBandRange
setInputFeatherBandRange:
inputAdaptiveThresholdRange
setInputAdaptiveThresholdRange:
inputSigmaFallout
setInputSigmaFallout:
T@"CIImage",&,VinputDisparityImage
T@"CIImage",&,VinputThresholdImage
T@"NSNumber",C,N,VinputMaxNumVertices
T@"NSNumber",C,N,VinputSigmaS
T@"NSNumber",C,N,VinputSigmaRLuma
T@"NSNumber",C,N,VinputSigmaRChroma
T@"NSNumber",C,N,VinputLambda
T@"NSNumber",C,N,VinputMaxNumIterations
T@"CIVector",&,VinputBandRange
T@"NSNumber",C,N,VinputThresholdOffset
T@"NSNumber",C,N,VinputFilterCut
T@"NSNumber",C,N,VinputFeatherBandRange
T@"NSNumber",C,N,VinputAdaptiveThresholdRange
T@"NSNumber",C,N,VinputSigmaFallout
colorSpace
imageYCC444:matrix:fullRange:colorSpace:
_confidenceExtractRed
extractLuminance:
format
bytesPerRow
intValue
_kickLightKernel_pos
_kickLightKernel_neg
numberWithFloat:
inputWidth
setInputWidth:
inputStrength
setInputStrength:
inputRotate
setInputRotate:
inputPt1
setInputPt1:
inputPt2
setInputPt2:
inputPt3
setInputPt3:
inputPt4
setInputPt4:
inputPt5
setInputPt5:
inputPt6
setInputPt6:
inputOrientation
setInputOrientation:
inputCenterBottom
setInputCenterBottom:
T@"CIImage",&,N,VinputImage
T@"CIVector",&,N,VinputPt1
T@"CIVector",&,N,VinputPt2
T@"CIVector",&,N,VinputPt3
T@"CIVector",&,N,VinputPt4
T@"CIVector",&,N,VinputPt5
T@"CIVector",&,N,VinputPt6
T@"NSNumber",&,N,VinputWidth
T@"NSNumber",&,N,VinputStrength
T@"NSNumber",&,N,VinputRotate
T@"NSNumber",&,N,VinputOrientation
T@"NSNumber",&,N,VinputCenterBottom
_dualLightKernel
inputCenter1
setInputCenter1:
inputCenter2
setInputCenter2:
inputBottom1
setInputBottom1:
inputBottom2
setInputBottom2:
inputWidth1
setInputWidth1:
inputWidth2
setInputWidth2:
inputHeight1
setInputHeight1:
inputHeight2
setInputHeight2:
inputRotate1
setInputRotate1:
inputRotate2
setInputRotate2:
inputBrighten
setInputBrighten:
inputContrast
setInputContrast:
T@"CIVector",&,N,VinputCenter1
T@"CIVector",&,N,VinputCenter2
T@"CIVector",&,N,VinputBottom1
T@"CIVector",&,N,VinputBottom2
T@"NSNumber",&,N,VinputWidth1
T@"NSNumber",&,N,VinputWidth2
T@"NSNumber",&,N,VinputHeight1
T@"NSNumber",&,N,VinputHeight2
T@"NSNumber",&,N,VinputBrighten
T@"NSNumber",&,N,VinputRotate1
T@"NSNumber",&,N,VinputRotate2
T@"NSNumber",&,N,VinputContrast
_strobeKernel
_extractRed
doubleValue
imageByApplyingGaussianBlurWithSigma:
_contourLightKernel
inputCenter
setInputCenter:
inputEyes
setInputEyes:
inputHeight
setInputHeight:
T@"CIVector",&,N,VinputCenter
T@"CIVector",&,N,VinputEyes
T@"NSNumber",&,N,VinputHeight
T@"NSNumber",&,N,VinputScale
_portraitSpotKernel
inputDarken
setInputDarken:
T@"NSNumber",&,N,VinputDarken
_neckContourKernel
inputChin
setInputChin:
inputFaceOrientation
setInputFaceOrientation:
T@"CIVector",&,N,VinputChin
T@"NSNumber",&,N,VinputFaceOrientation
_extractRedStudio
_cheapEdgePreserve
_studioLightKernel
inputBlur
setInputBlur:
T@"NSNumber",&,N,VinputBlur
_faceContourMask
_darken
numberWithDouble:
kernelWithString:fromMetalLibraryData:
bundleWithIdentifier:
URLForResource:withExtension:
dataWithContentsOfURL:
rectValue
valueWithRect:
sanityCheckStatus
setSanityCheckStatus:
imageWidthScale
setImageWidthScale:
imageHeightScale
setImageHeightScale:
coreImageROIrect
setCoreImageROIrect:
T{CGRect={CGPoint=dd}{CGSize=dd}}
count
applyWithExtent:inputs:arguments:error:
inputFaceLandmarks
setInputFaceLandmarks:
_inputImage
_inputFaceLandmarks
T@"CIImage",&,N,V_inputImage
T@"NSDictionary",&,N,V_inputFaceLandmarks
initWithFaceLandmarks:forImageRect:
dataWithLength:
mutableBytes
bytes
allowPartialOutputRegion
initWithLength:
faceData
skinSampleRgon
boundsFloatRect
skinSeedPointCount
skinSeedPoints
headPerimeter
teethSeedPoints
leftIrisSeedPoints
rightIrisSeedPoints
eyebrowRightTopLine
boundsPath
eyebrowLeftTopLine
noseTipPerimeterPath
leftEyePair
rightEyePair
teethPair
faceBounds
rightEye
leftEye
mouthCenter
faceOrientationIndex
AdjustForPointX:Y:
CalculateVertices
CalculateEdges
setSkinSampleRgon:
setAdjustmentRect:
setHeadRect:
betweenTheEyes
setSkinSeedPointCount:
CalculateAndReturnVertices:
containsPointX:Y:
setBinSize:
setZDarkThr:
AdjustForPointX:Y:Z:
zDarkThr
containsPointPlanarConditionalX2:Y:Z:epsilonDark:epsilonLight:epsilonMid:shouldPrint:
setPerservesAlpha:
_srgbToIPT
boolValue
_rectToHueChroma
inputReturnHueChroma
_hueChromaToRect
_iptToSRGB
inputIsHueChroma
objectAtIndex:
_scaleHueZeroOne
contextWithOptions:
render:toBitmap:rowBytes:bounds:format:colorSpace:
colorWithRed:green:blue:alpha:colorSpace:
imageWithColor:
_scaleHuePi
imageWithBitmapData:bytesPerRow:size:format:colorSpace:
imageBySettingAlphaOneInExtent:
findPeakHue_Renderless:chromaMin:hueRange:
findPeakHue:chromaMin:hueRange:
inputHueRange
inputChromaMin
inputMaxDimension
inputReturnSmartColor
imageByInsertingIntermediate
_drawTriangle
leftCheekContour
leftCheekStrobe
imageByCompositingOverImage:
rightCheekContour
rightCheekStrobe
leftChinContour
leftNoseContour
rightChinContour
rightNoseContour
leftLipContour
rightLipContour
neckContour1
neckContourLeft
neckContourRight
_protectEyes
inputOrigImage
T@"LightingFacePoints",&,N,VinputFaceLandmarks
metalCommandBuffer
device
filterDescriptorWithWidth:height:arrayLength:kernelSpatialDiameter:kernelTemporalDiameter:epsilon:sourceChannels:guideChannels:preallocateIntermediates:
initWithDevice:filterDescriptor:
metalTexture
addObject:
encodeToCommandBuffer:sourceTextureArray:guidanceTexture:constraintsTextureArray:numberOfIterations:destinationTextureArray:
inputLightMap
inputLightMapWidth
inputLightMapHeight
inputGuideImage
inputGuidedFilterEpsilon
_polyKernel
_shadowKernel
inputLightMapImage
inputLocalLight
inputSmartShadows
length
initWithImageProvider:width:height:format:colorSpace:options:
countByEnumeratingWithState:objects:count:
setObject:forKey:
setValue:forKey:
imageWithCVPixelBuffer:options:
filterWithName:
inputKeys
containsObject:
imageWithCVPixelBuffer:
initWithPixelBuffer:
setColorSpace:
getFaceFeatures:
prepareRender:fromRect:toDestination:atPoint:error:
run:withContext:withFaceScales:withProxyRendering:
prewarmWithContext:andProxyRendering:
initWithBitmapData:width:height:bytesPerRow:format:
initWithRed:green:blue:alpha:
width
height
previewCubeName
bundleForClass:
pathForResource:ofType:
standbyCubeName
backgroundPreviewCubeName
prewarm:
prewarmFullSizeRender:
previewCubePath
standbyCubePath
backgroundPreviewCubePath
cubeColorSpaceName
_defaultVersion
_maxVersion
inputFaceMask
setInputFaceMask:
inputTeethMask
setInputTeethMask:
inputHairMask
setInputHairMask:
inputBlurMap
setInputBlurMap:
inputDisparity
setInputDisparity:
inputMatte
setInputMatte:
inputFaceLandmarkArray
setInputFaceLandmarkArray:
inputRenderProxy
setInputRenderProxy:
inputSpillCorrectedRatioImage
setInputSpillCorrectedRatioImage:
inputGenerateSpillMatte
setInputGenerateSpillMatte:
T@"CIImage",&,N,VinputFaceMask
T@"CIImage",&,N,VinputTeethMask
T@"CIImage",&,N,VinputHairMask
T@"CIImage",&,N,VinputBlurMap
T@"CIImage",&,N,VinputDisparity
T@"CIImage",&,N,VinputMatte
T@"NSArray",&,N,VinputFaceLandmarkArray
T@"NSNumber",&,N,VinputRenderProxy
T@"CIImage",&,N,VinputSpillCorrectedRatioImage
T@"NSNumber",&,N,VinputGenerateSpillMatte
setInputSmooth:
setInputEnrich:
setInputTeeth:
setInputLocalContrast:
colorWithRed:green:blue:alpha:
initWithFaceLandmarkDictionary:forImageRect:
vectorWithCGPoint:
leftEyeOutline
rightEyeOutline
_eyeBlurV2
noseTip
_protectEyesNose
_featherEdge
maskForLandmarks:withFilterNamed:
_textureDiff
_textureAdd
_whitenTeeth
imageByInsertingIntermediate:
_imageByRenderingToIntermediate
_eyeBrightenV2
_eyeBrightenSoftlight
eyeBlurForLandmarks:
faceMaskForLandmarks:
faceRect
protectEyesNose:withFaceMask:withOrientation:
processSkinIn:withFaceMask:
processTeethIn:withFaceMask:
processTeethIn:withTeethMask:
processEyesIn:withEyeBlur:landmarks:
_enrichV2
imageForLandmarks:
enrichImage:
getDraftMode:
getRefinedMatteMode:
getRenderSpillCache:
setDefaults
skinMaskForLandmarks:
teethMaskForLandmarks:
inputSmooth
inputEnrich
inputTeeth
inputLocalContrast
T@"NSNumber",&,N,VinputSmooth
T@"NSNumber",&,N,VinputEnrich
T@"NSNumber",&,N,VinputTeeth
T@"NSNumber",&,N,VinputEyes
T@"NSNumber",&,N,VinputLocalContrast
setInputKickLight:
setInputFaceLight:
setInputDepthThreshold:
centerNose
faceWidth
faceHeight
_faceVignetteStudio
leftKickLights
rightKickLights
bottomShadow
centerChin
leftNose
rightNose
noseStrobe
_applyFaceProtectStudio
_prepareDepth
inputKickLight
inputFaceLight
inputDepthThreshold
T@"NSNumber",&,N,VinputKickLight
T@"NSNumber",&,N,VinputFaceLight
T@"NSNumber",&,N,VinputDepthThreshold
setInputContour:
addObjectsFromArray:
_faceVignette
_transparentBorder
_applyTransparentBorder
_applyFaceProtect
_blendSingleChannelMask
_applyVignette
inputContour
T@"NSNumber",&,N,VinputContour
setInputUseAbsoluteDisparity:
setInputSharpenRadius:
setInputGrainAmount:
depthData
depthDataAccuracy
_getRefinedMatte
_applyRefinedMatte
thresholdMatte
thresholdAndApplyMatte
_applyVignetteStage
_CIPrepareBlackDepth
_CIPrepareBlackDisparity
_CIApplyBlackDepth
_CIApplyStageNoFeather
_CIApplyStageNoFeatherWithSpillRatio
_CIRefineBlackDepth
_faceProtect
invertRed
blendDepth
inputUseAbsoluteDisparity
inputSharpenRadius
inputGrainAmount
T@"NSNumber",&,N,VinputUseAbsoluteDisparity
T@"NSNumber",&,N,VinputSharpenRadius
T@"NSNumber",&,N,VinputGrainAmount
thresholdWhiteMatte
thresholdAndApplyWhiteBG
_CIPrepareWhiteDepth
_applyWhiteNoFeather
_getRefinedWhiteMatte
_applyRefinedWhiteMatte
numberWithUnsignedLong:
loadArchive:
init
setFaceData:
setLeftToRightVec:
leftToRightVec
setUpVec:
setNoseTipPerimeterPath:
setHeadPerimeter:
initWithMaxsize:segmentDelta:andAxis:
setMouthPerimeterLinePair:
mouthPerimeterLinePair
accomodatePoint:
bottom
bridgeGapsLinear
expandWithToleranceTop:bottom:
extrapolateAndJoinTopAndBottom
constructBezierWithToleranceTop:bottom:
setLeftEyePair:
setRightEyePair:
setTeethPair:
setS0:
setS1:
constructBezierWithToleranceOutside:andInside:
setEyebrowRightTopLine:
setEyebrowLeftTopLine:
setMouthTopLine:
setMouthBottomLine:
setNosePair:
dealloc
imageRect
setImageRect:
mouthTopLine
mouthBottomLine
nosePair
upVec
eyebrowLeft
eyebrowRight
mouthTop
mouthBottom
upperLipBottom
lowerLipTop
leftEyeUpper
rightEyeUpper
leftEyeLowerR2L
rightEyeLowerR2L
leftSideFace
rightSideFace
leftTopFace
rightTopFace
topFace
bottomFace
noseOutline
noseRightSide
noseLeftSide
noseCenterline
polylineDelta
_faceData
_eyebrowRightTopLine
_eyebrowLeftTopLine
_mouthTopLine
_mouthBottomLine
_leftEyePair
_rightEyePair
_mouthPerimeterLinePair
_teethPair
_nosePair
_noseTipPerimeterPath
_headPerimeter
_leftToRightVec
_upVec
_imageRect
T{CGRect={CGPoint=dd}{CGSize=dd}},V_imageRect
T@"ComputedFaceData",&,V_faceData
T@"Polyline",&,V_eyebrowRightTopLine
T@"Polyline",&,V_eyebrowLeftTopLine
T@"Polyline",&,V_mouthTopLine
T@"Polyline",&,V_mouthBottomLine
T@"PolylinePair",&,V_leftEyePair
T@"PolylinePair",&,V_rightEyePair
T@"PolylinePair",&,V_mouthPerimeterLinePair
T@"PolylinePair",&,V_teethPair
T@"PolylinePair",&,V_nosePair
T^{CGPath=},V_noseTipPerimeterPath
T^{CGPath=},V_headPerimeter
T{CGPoint=dd},V_leftToRightVec
T{CGPoint=dd},V_upVec
faceIndex
setFaceIndex:
setSkinSeedPoints:
setTeethSeedPoints:
setRightIrisSeedPoints:
setLeftIrisSeedPoints:
neckSeedPoints
setNeckSeedPoints:
setIOD:
adjustmentRect
headRect
setFaceBounds:
hasLeftEyePosition
setHasLeftEyePosition:
hasRightEyePosition
setHasRightEyePosition:
hasMouthPosition
setHasMouthPosition:
setLeftEye:
setRightEye:
setBetweenTheEyes:
setMouthCenter:
faceCenter
setFaceCenter:
leftRightVec
setLeftRightVec:
eyeTiltAngle
setEyeTiltAngle:
setFaceOrientationIndex:
skinSeedPointArray
teethSeedPointArray
leftIrisSeedPointArray
rightIrisSeedPointArray
neckSeedPointArray
_hasLeftEyePosition
_hasRightEyePosition
_hasMouthPosition
_faceIndex
_skinSeedPointCount
_eyeTiltAngle
_faceOrientationIndex
_skinSeedPoints
_teethSeedPoints
_rightIrisSeedPoints
_leftIrisSeedPoints
_neckSeedPoints
_iOD
_skinSampleRgon
_leftEye
_rightEye
_betweenTheEyes
_mouthCenter
_faceCenter
_leftRightVec
_adjustmentRect
_headRect
_faceBounds
Ti,V_faceIndex
T^{CGPoint=dd},V_skinSeedPoints
Ti,V_skinSeedPointCount
T^{CGPoint=dd},V_teethSeedPoints
T^{CGPoint=dd},V_rightIrisSeedPoints
T^{CGPoint=dd},V_leftIrisSeedPoints
T^{CGPoint=dd},V_neckSeedPoints
Td,V_iOD
T{CGRect={CGPoint=dd}{CGSize=dd}},V_adjustmentRect
T{CGRect={CGPoint=dd}{CGSize=dd}},V_headRect
T{CGRect={CGPoint=dd}{CGSize=dd}},V_faceBounds
TB,V_hasLeftEyePosition
TB,V_hasRightEyePosition
TB,V_hasMouthPosition
T{CGPoint=dd},V_leftEye
T{CGPoint=dd},V_rightEye
T{CGPoint=dd},V_betweenTheEyes
T{CGPoint=dd},V_mouthCenter
T{CGPoint=dd},V_faceCenter
T{CGPoint=dd},V_leftRightVec
Tf,V_eyeTiltAngle
T@"Rgon",&,N,V_skinSampleRgon
Tf,V_faceOrientationIndex
rightContour
leftContour
chinSpot
noseProtect
leftEyeHeight
leftEyeWidth
rightEyeHeight
rightEyeWidth
noseWidth
noseHeight
setFaceRect:
T{CGRect={CGPoint=dd}{CGSize=dd}},VfaceRect
imageTransformForOrientation:
dataWithBytes:length:
dictionaryWithDictionary:
setObject:forKeyedSubscript:
getBytes:length:
clearOutputMask:WithBytesPerRow:OutputRegion:
findToothMaskUsingInputImage:InputBytesPerRow:InputRegion:OutputMask:OutputBytesPerRow:OutputRegion:TeethBounds:SeedPoints:NumberOfSeedPoints:FillValue:
trainSkinMaskUsingInputImage:InputBytesPerRow:InputRegion:QuadRegion:
findSkinMaskUsingInputImage:InputBytesPerRow:InputRegion:OutputMask:OutputBytesPerRow:OutputRegion:FaceBounds:SeedPoints:NumberOfSeedPoints:FillValue:
drawEyeMaskUsingQuads:OutputMask:OutputBytesPerRow:OutputRegion:
lumaDilateRadius
setLumaDilateRadius:
lumaErodeRadius
setLumaErodeRadius:
chromaDilateRadius
setChromaDilateRadius:
chromaErodeRadius
setChromaErodeRadius:
_colorCube
_tempColorCube
_inputScalingForCube
_lumaDilateRadius
_lumaErodeRadius
_chromaDilateRadius
_chromaErodeRadius
Ti,N,V_lumaDilateRadius
Ti,N,V_lumaErodeRadius
Ti,N,V_chromaDilateRadius
Ti,N,V_chromaErodeRadius
_brightenSat
inputSat
inputPShift
inputTShift
_brightenFood
setRgonPtr:
setPointerToRgonArray:
decodeBytesForKey:returnedLength:
encodeBytes:length:forKey:
allocWithZone:
rgonPtr
Area
getValue:
recalculateMaxMins
CalculateFromVertices
CommonCenterForIndex:
XCenter
YCenter
MeanVertexDistFromX:Y:
setAspectRatio:
setMaxAxisIndex:
DistToPointX:Y:
Diameter
MinDiameter
createWithCollapsedOrphans2
IntersectionOfEdge:withEdge:resultPoint:
OutsideReturnFirstEdgeExcludingX:Y:
copy
UnionWith:
CollapseOrphans
newInterpolatedRgonFrom:withRgon:param:
copyWithZone:
encodeWithCoder:
initWithCoder:
Reset
vertexAtClockHour:
dASide:movesds:
dASide:movesds:retaining:pointsFromArray:
DirectionalDilateByAmount:xDirection:yDirection:
translateByAmount:xDirection:yDirection:
dentRgonInwardByAmount:xDirection:yDirection:
Dilate:
containsPointX:Y:inArray:ofCount:
pointX:Y:isOutsideBorderlinesInArray:ofCount:
containsPointX:Y:withTolerance:returnIndex:
Radius
AspectIndex
DiameterAtFacetCountMeasuredFromVertical:
RoundToPercent:
DistanceFromRgon:
DistanceBetweenCenters:
Density
Perimeter
AspectRatio
PrintVertices
PrintVerticesWithZCoord:
PrintConstraints
ShrinkByAmount:
intersectionEdge:withEdge:
unionRgonOf:withRgon:
IntersectionRgonOf:withRgon:
DistanceCenterToRGon:
maxAxisIndex
aspectRatio
ymax
setYmax:
ymin
setYmin:
xmax
setXmax:
xmin
setXmin:
currentArea
setCurrentArea:
setCount:
pointCount
setPointCount:
pointerToRgonArray
enclosedPoints
rgonArray
verticesUpToDate
maxDiameter
minDiameter
minAxisIndex
oblongness
lastFaceFlunked
_pointerToRgonArray
_enclosedPoints
T^[7f],VrgonPtr
T^f,V_pointerToRgonArray
Ti,VmaxAxisIndex
Tf,VaspectRatio
Tf,Vymax
Tf,Vymin
Tf,Vxmax
Tf,Vxmin
Tf,VcurrentArea
Tq,VpointCount
Td,Vcount
T@"NSArray",R,V_enclosedPoints
initWithCapacity:
decodeObjectForKey:
decodeIntegerForKey:
decodeDoubleForKey:
encodeObject:forKey:
encodeInteger:forKey:
encodeDouble:forKey:
array
containsPointX:Y:Z:
DistToPointX:Y:Z:
PrintFacets
test0
containsPointPlanarX:Y:Z:
containsPointPlanarConditionalX:Y:Z:epsilonDark:epsilonLight:
normalVectorForRgon1:withZ1:rgon2:withZ2:atIndex:placedInto:
zMin
setZMin:
zMax
setZMax:
zMinindex
setZMinindex:
zMaxindex
setZMaxindex:
binSize
binCount
binOffset
stack
Td,VzMin
Td,VzMax
Td,VbinSize
Ti,VzMinindex
Ti,VzMaxindex
Ti,VzDarkThr
xyFromS:
liesAbovePointX:Y:
liesBelowPointX:Y:
printPoints
printBounds
printRect
bridgeGapsMinimum
xyFromS2:
lengthenStart:end:
seglength
setSeglength:
nsegs
setNsegs:
axisV
setAxisV:
normV
setNormV:
xyBoundsRect
setXyBoundsRect:
arclength
isempty
sdelta
maxsize
yyData
T{CGPoint=dd},VaxisV
T{CGPoint=dd},VnormV
T{CGRect={CGPoint=dd}{CGSize=dd}},VxyBoundsRect
Td,Vs0
Td,Vs1
Td,Vseglength
TI,Vnsegs
T^{CGPath=},R,VboundsPath
initWithSegments:boundsRect:
adjustForX:Y:
npoints
createTopBottomRegion
normVtop
setNormVtop:
normVbottom
setNormVbottom:
_top
_bottom
T@"Polyline",R,&,V_top
T@"Polyline",R,&,V_bottom
T{CGPoint=dd},VnormVtop
T{CGPoint=dd},VnormVbottom
setIsempty:
smoothWithSize:
raiseTopBy:
lowerBottomBy:
boundsRect
printSummary
setLength:
xdatamin
xdatamax
topData
bottomData
Tf,Vlength
T^f,R
TB,Visempty
properties
objectForKey:
setNumberStyle:
setMaximumFractionDigits:
stringFromNumber:
stringWithFormat:
imageByApplyingTransform:highQualityDownsample:
sceneLuminance:
captureType:
calcColorStats:
smartToneStatistics
localLightStatisticsNoProxy
_softExposure
writeDebugData:
overlayText:strength:captureType:bv:
inputSkyMask
setInputSkyMask:
inputIsSunsetSunrise
setInputIsSunsetSunrise:
setInputLocalLight:
inputShadows
setInputShadows:
inputExposure
setInputExposure:
inputBrightness
setInputBrightness:
inputHighlights
setInputHighlights:
inputWhiteBalance
setInputWhiteBalance:
inputSaturation
setInputSaturation:
inputBrightSat
setInputBrightSat:
inputConfidence
setInputConfidence:
inputLowConfidence
setInputLowConfidence:
inputHighConfidence
setInputHighConfidence:
inputMaxFaceSize
setInputMaxFaceSize:
inputFaceBoxArray
setInputFaceBoxArray:
T@"CIImage",&,N,VinputSkyMask
T@"NSNumber",&,N,VinputIsSunsetSunrise
T@"NSNumber",&,N,VinputLocalLight
T@"NSNumber",&,N,VinputShadows
T@"NSNumber",&,N,VinputExposure
T@"NSNumber",&,N,VinputBrightness
T@"NSNumber",&,N,VinputHighlights
T@"NSNumber",&,N,VinputWhiteBalance
T@"NSNumber",&,N,VinputSaturation
T@"NSNumber",&,N,VinputBrightSat
T@"NSNumber",&,N,VinputConfidence
T@"NSNumber",&,N,VinputLowConfidence
T@"NSNumber",&,N,VinputHighConfidence
T@"NSNumber",&,N,VinputMaxFaceSize
T@"NSArray",&,N,VinputFaceBoxArray
_imageByApplyingGamma:
_foodVignette
inputBoundingBoxArray
setInputBoundingBoxArray:
inputUnionBox
setInputUnionBox:
inputVignetteStrength
setInputVignetteStrength:
T@"NSArray",&,N,VinputBoundingBoxArray
T@"NSNumber",&,N,VinputUnionBox
T@"NSNumber",&,N,VinputVignetteStrength
_highKey
valueWithBytes:objCType:
unarchivedObjectOfClass:fromData:error:
setWithObjects:
unarchivedObjectOfClasses:fromData:error:
archivedDataWithRootObject:requiringSecureCoding:error:
_convertToGrayscale
_kernelLocalContrast
writeToTIFF:
checkFeaturesDictionary:
_mixKernel
processSkinIn:withSkinMask:
_enrich
inputDepthMap
setInputDepthMap:
T@"CIImage",&,N,VinputDepthMap
imageByApplyingOrientation:
setInputFocalLengthNormalized:
setInputDepthDataScore:
setInputAdaptiveThresholdFaceGroupRange:
setInputAdaptiveThresholdFaceErrorMargin:
setInputAdaptiveThresholdZRangeConst:
setInputAdaptiveThresholdZRangeLinearDepth:
setInputAdaptiveThresholdConstOffset:
setInputAdaptiveThresholdLinearDepthOffset:
setInputAdaptiveThresholdDoDisparityError:
isEqualToString:
inputAdaptiveThresholdFaceGroupRange
inputAdaptiveThresholdFaceErrorMargin
inputAdaptiveThresholdDoDisparityError
setDefaultsAbsoluteDisparity
valueForKey:
portraitScore
_faceAndBodyFill_orient1
_faceAndBodyFill_orient6
_getFocusRect:
inputFocalLengthNormalized
_offsetImage:inputDisparity:thresholdImage:
_maxNumVerticesForImage:sigmaLuma:sigmaSpace:
integerValue
adaptiveNormalizationAbsolute
inputAdaptiveThresholdZRangeConst
inputAdaptiveThresholdZRangeLinearDepth
inputAdaptiveThresholdConstOffset
inputAdaptiveThresholdLinearDepthOffset
adaptiveNormalizationGPU
adaptiveNormalization2
inputFullSizeImage
setInputFullSizeImage:
inputMinimumEffectLevel
setInputMinimumEffectLevel:
inputBackgroundSeparationLikehood
setInputBackgroundSeparationLikehood:
inputDepthDataScore
T@"CIImage",&,N,VinputFullSizeImage
T@"NSNumber",C,N,VinputFocalLengthNormalized
T@"NSNumber",C,N,VinputAdaptiveThresholdFaceGroupRange
T@"NSNumber",C,N,VinputAdaptiveThresholdFaceErrorMargin
T@"NSNumber",C,N,VinputAdaptiveThresholdZRangeConst
T@"NSNumber",C,N,VinputAdaptiveThresholdZRangeLinearDepth
T@"NSNumber",C,N,VinputAdaptiveThresholdConstOffset
T@"NSNumber",C,N,VinputAdaptiveThresholdLinearDepthOffset
T@"NSNumber",C,N,VinputAdaptiveThresholdDoDisparityError
T@"NSNumber",C,N,VinputMinimumEffectLevel
T@"NSNumber",C,N,VinputBackgroundSeparationLikehood
T@"NSNumber",C,N,VinputDepthDataScore
workingColorSpace
cameraCalibrationData
intrinsicMatrix
intrinsicMatrixReferenceDimensions
allowSRGBTranferFuntionOnInputAtIndex:
{CGRect={CGPoint=dd}{CGSize=dd}}44@?0i8{CGRect={CGPoint=dd}{CGSize=dd}}12
inputFocusRect
fullROI
v8@?0
10.13
inputNeedsGammaCorrection
inputScale
kernel vec4 _pf_transitionDepths(__sample edges,__sample depthLo) { float v = float((edges.r) > 0.5)*depthLo.r; return vec4(v,v,v,1.0); }
PFSobelHV
CIMorphologyMaximum
inputMaxNumVertices
inputSigmaS
inputSigmaRLuma
inputSigmaRChroma
inputLambda
inputMaxNumIterations
inputBandRange
inputThresholdOffset
inputFilterCut
inputFeatherBandRange
inputAdaptiveThresholdRange
inputSigmaFallout
kernel vec4 _pf_renormalize01(__sample a,__sample b) { float zmin = b.r; float zmax = b.g; float v = (a.r - zmin)/(zmax-zmin); return vec4(v,v,v,1.0); }
kernel vec4 _pf_featherBand(__sample image,__sample threshold,__sample mm,vec3 params) { 
  float zMin = mm.r;
  float zMax = mm.g;
  float zRange = zMax - zMin;
  float lowerBandOffset  = -params.y * zRange;
  float upperBandOffset  = -params.x * zRange;
  float featherBandRange =  params.z * zRange;
  float bandRange = upperBandOffset - lowerBandOffset;
  float bandCenter = threshold.r + lowerBandOffset + bandRange / 2.0;
  float band = abs(image.r - bandCenter) - bandRange / 2.0;
  band = 1.0 - smoothstep(0.0, featherBandRange, band);
   return vec4(band,band,band,1.0);
kernel vec4 _pf_protectInterior(__sample C,__sample band) { 
   float v = max(min(C.r - band.r * 0.5,0.999),1e-4);
   return vec4(v,v,v,1.0);
kernel vec4 _pf_invertImage(__sample a) { float v = 1.0 - a.r; return vec4(v,v,v,1.0); }
kernel vec4 _pf_normalizeToPhysicalDepth(__sample threshold,__sample mm,float thresholdOffset) { float v = threshold.r + thresholdOffset *(1.0 -threshold.r)/(mm.g-mm.r);  return vec4(v,v,v,1.0); }
kernel vec4 _pf_foreground(__sample mask,__sample threshold) { float v = (mask.r < threshold.r) ? mask.r : 0.0; return vec4(v,v,v,1.0); }
kernel vec4 _pf_filterCut(__sample mask,__sample threshold,float filterCut) {
  float v = min(1.0, mask.r * filterCut / threshold.r);
  return vec4(v,v,v,1.0); }
kernel vec4 _pf_bb3Mono(sampler a) { 
   float r = 0.0;
   vec2 dc = destCoord();
   r += sample(a,samplerTransform(a, dc + vec2(-1.0, -1.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2(-1.0,  0.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2(-1.0,  1.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2( 0.0, -1.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2( 0.0,  0.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2( 0.0,  1.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2( 1.0, -1.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2( 1.0,  0.0))).r;
   r += sample(a,samplerTransform(a, dc + vec2( 1.0,  1.0))).r;
   r *= 0.111111111;
   return vec4(r,r,r,1.0);
kernel vec4 _pf_denormalize(__sample image, __sample minMaxImage)
    float v = image.r;
    float maxV = minMaxImage.g;
    float minV = minMaxImage.r;
    v = v * (maxV - minV) + minV;
    return vec4(v,v,v,1.0);
kernel vec4 _pf_confidenceConvertToHalfFloat (__sample c) __attribute__((outputFormat(kCIFormatRGBAh))) {
  return c;
kernel vec4 _pf_renormalizeThreshold(__sample threshold,__sample disparityMinMax) { 
  float minV = disparityMinMax.x; 
  float maxV = disparityMinMax.y; 
  float range = maxV - minV; 
  float absoluteThreshold = threshold.r; 
  float v = (absoluteThreshold - minV) / max(0.0001,range); 
  return vec4(v,v,v,1.0); 
CIAreaMinMaxRed
CIConfidenceMap
CILinearToSRGBToneCurve
PortraitFastBilateralSolver
inputConfidenceMapImage
PFBoxBlur3_7
CIColorMatrix
inputRVector
inputGVector
inputBVector
kernel vec4 _pf_confidenceExtractRed (__sample c) __attribute__((outputFormat(kCIFormatRh))) {
  return vec4(c.r, 0.0, 0.0, 1.0);
CISRGBToneCurveToLinear
CIGaussianBlur
kernel vec4 _pf_boxBlur3_7_H(sampler image)
    vec2 dc = destCoord();
    float c =  sample(image, samplerTransform(image, dc + vec2(-7.0, 0.0))).r * 0.0005;
         c += sample(image, samplerTransform(image, dc + vec2(-6.0, 0.0))).r * 0.0032;
         c += sample(image, samplerTransform(image, dc + vec2(-5.0, 0.0))).r * 0.0128;
         c += sample(image, samplerTransform(image, dc + vec2(-4.0, 0.0))).r * 0.0352;
         c += sample(image, samplerTransform(image, dc + vec2(-3.0, 0.0))).r * 0.0736;
         c += sample(image, samplerTransform(image, dc + vec2(-2.0, 0.0))).r * 0.1216;
         c += sample(image, samplerTransform(image, dc + vec2(-1.0, 0.0))).r * 0.1632;
         c += sample(image, samplerTransform(image, dc + vec2( 0.0, 0.0))).r * 0.1797;
         c += sample(image, samplerTransform(image, dc + vec2( 1.0, 0.0))).r * 0.1632;
         c += sample(image, samplerTransform(image, dc + vec2( 2.0, 0.0))).r * 0.1216;
         c += sample(image, samplerTransform(image, dc + vec2( 3.0, 0.0))).r * 0.0736;
         c += sample(image, samplerTransform(image, dc + vec2( 4.0, 0.0))).r * 0.0352;
         c += sample(image, samplerTransform(image, dc + vec2( 5.0, 0.0))).r * 0.0128;
         c += sample(image, samplerTransform(image, dc + vec2( 6.0, 0.0))).r * 0.0032;
         c += sample(image, samplerTransform(image, dc + vec2( 7.0, 0.0))).r * 0.0005;
        
    return vec4(c,c,c,1.0);
kernel vec4 _pf_boxBlur3_7_V(sampler image)
    vec2 dc = destCoord();
    float c =  sample(image, samplerTransform(image, dc + vec2(0.0, -7.0))).r * 0.0005;
         c += sample(image, samplerTransform(image, dc + vec2(0.0,-6.0))).r * 0.0032;
         c += sample(image, samplerTransform(image, dc + vec2(0.0,-5.0))).r * 0.0128;
         c += sample(image, samplerTransform(image, dc + vec2(0.0,-4.0))).r * 0.0352;
         c += sample(image, samplerTransform(image, dc + vec2(0.0,-3.0))).r * 0.0736;
         c += sample(image, samplerTransform(image, dc + vec2(0.0,-2.0))).r * 0.1216;
         c += sample(image, samplerTransform(image, dc + vec2(0.0,-1.0))).r * 0.1632;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 0.0))).r * 0.1797;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 1.0))).r * 0.1632;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 2.0))).r * 0.1216;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 3.0))).r * 0.0736;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 4.0))).r * 0.0352;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 5.0))).r * 0.0128;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 6.0))).r * 0.0032;
         c += sample(image, samplerTransform(image, dc + vec2(0.0, 7.0))).r * 0.0005;
        
    return vec4(c,c,c,1.0);
kernel vec4 _pf_sobelHV(sampler image)        {
            vec2 dc = destCoord();
    float c0 = sample(image, samplerTransform(image, dc + vec2(-1.0,1.0))).r;
    float c1 = sample(image, samplerTransform(image, dc + vec2( 0.0,1.0))).r;
    float c2 = sample(image, samplerTransform(image, dc + vec2( 1.0,1.0))).r;
    float c3 = sample(image, samplerTransform(image, dc + vec2(-1.0,0.0))).r;
    float c5 = sample(image, samplerTransform(image, dc + vec2( 1.0,0.0))).r;
    float c6 = sample(image, samplerTransform(image, dc + vec2(-1.0,-1.0))).r;
    float c7 = sample(image, samplerTransform(image, dc + vec2( 0.0,-1.0))).r;
    float c8 = sample(image, samplerTransform(image, dc + vec2( 1.0,-1.0))).r;
    float h = abs((c0 + 2.0 * c1 + c2) - (c6 + 2.0 * c7 + c8));
    float v = abs((c0 + 2.0 * c3 + c6) - (c2 + 2.0 * c5 + c8));
    float total = (h + v);
    return vec4(total, total, total, 1.0);
kernel vec4 _pf_h9(sampler a)  { 
   float m = 0.0;
   vec2 dc = destCoord();
   for(int i = -4; i <= 4; i++) {
      m = max(m, sample(a,samplerTransform(a, dc + vec2(float(i), 0.0))).r);
   }
   return vec4(m,m,m,1.0);
kernel vec4 _pf_v7(sampler a)  { 
   float m = 0.0;
   vec2 dc = destCoord();
   for(int i = -3; i <= 3; i++) {
      m = max(m, sample(a,samplerTransform(a, dc + vec2(float(i), 0.0))).r);
   }
   return vec4(m,m,m,1.0);
kernel vec4 _pf_dilateRem(sampler a,sampler o) { 
   float m = sample(a, samplerCoord(a)).r;
   vec2 dc = destCoord();
   for(int i = -3; i<= 3; i++) {
      m = max(m, sample(o,samplerTransform(o, dc + vec2(float(i), 4.0))).r);
   }
   for(int i = -3; i<= 3; i++) {
      m = max(m, sample(o,samplerTransform(o, dc + vec2(float(i), -4.0))).r);
   }
   m = max(m, sample(o,samplerTransform(o, dc + vec2( 0.0, 5.0))).r);
   m = max(m, sample(o,samplerTransform(o, dc + vec2( 0.0,-5.0))).r);
   m = max(m, sample(o,samplerTransform(o, dc + vec2( 5.0, 0.0))).r);
   m = max(m, sample(o,samplerTransform(o, dc + vec2(-5.0, 0.0))).r);
   return vec4(m,m,m,1.0);
kernel vec4 _pf_sobelHVGeoMean(sampler image)        {
            vec2 dc = destCoord();
    float c0 = sample(image, samplerTransform(image, dc + vec2(-1.0,1.0))).r;
    float c1 = sample(image, samplerTransform(image, dc + vec2( 0.0,1.0))).r;
    float c2 = sample(image, samplerTransform(image, dc + vec2( 1.0,1.0))).r;
    float c3 = sample(image, samplerTransform(image, dc + vec2(-1.0,0.0))).r;
    float c5 = sample(image, samplerTransform(image, dc + vec2( 1.0,0.0))).r;
    float c6 = sample(image, samplerTransform(image, dc + vec2(-1.0,-1.0))).r;
    float c7 = sample(image, samplerTransform(image, dc + vec2( 0.0,-1.0))).r;
    float c8 = sample(image, samplerTransform(image, dc + vec2( 1.0,-1.0))).r;
    float h = (c0 + 2.0 * c1 + c2) - (c6 + 2.0 * c7 + c8);
    float v = (c0 + 2.0 * c3 + c6) - (c2 + 2.0 * c5 + c8);
    float total = sqrt(max(0.0000001,h*h + v*v));
    return vec4(total, total, total, 1.0);
kernel vec4 _pf_invertImages(__sample c) { float v = c.r; v = 1.0 - min(1.0,v); v = max(min(v,1.0),0.0001); return vec4(v,v,v,1.0); }
kernel vec4 _pf_dilateDisparityEdgeDetectLuminance(sampler image, vec2 ninj,sampler lumImage){
    float m = 0.0, n = 0.0;
    vec2 dc = destCoord();
    
    int i;
    for(i = -int(ninj.x); i <= int(ninj.x); i++) {
        float v = sample(image, samplerTransform(image, dc + vec2(float(i),0.0))).r;
        n = max(v,n);
    }
    for(i = -int(ninj.y); i <= int(ninj.y); i++) {
        float v = sample(image, samplerTransform(image, dc + vec2(0.0,float(i)))).r;
        m = max(v,m);
    }
    float r = m + n;
    float c0 = sample(lumImage, samplerTransform(lumImage, dc + vec2(-1.0,1.0))).r;
    float c1 = sample(lumImage, samplerTransform(lumImage, dc + vec2( 0.0,1.0))).r;
    float c2 = sample(lumImage, samplerTransform(lumImage, dc + vec2( 1.0,1.0))).r;
    float c3 = sample(lumImage, samplerTransform(lumImage, dc + vec2(-1.0,0.0))).r;
    float c5 = sample(lumImage, samplerTransform(lumImage, dc + vec2( 1.0,0.0))).r;
    float c6 = sample(lumImage, samplerTransform(lumImage, dc + vec2(-1.0,-1.0))).r;
    float c7 = sample(lumImage, samplerTransform(lumImage, dc + vec2( 0.0,-1.0))).r;
    float c8 = sample(lumImage, samplerTransform(lumImage, dc + vec2( 1.0,-1.0))).r;
    float h = abs((c0 + 2.0 * c1 + c2) - (c6 + 2.0 * c7 + c8));
    float v = abs((c0 + 2.0 * c3 + c6) - (c2 + 2.0 * c5 + c8));
    float total = h + v;
    float result = max(total, r);
    return vec4(result,result,result,1.0);
10.12
inputStrength
inputWidth
inputRotate
inputOrientation
inputCenterBottom
kernel vec4 _pf_kickLightKernel_pos(__sample im, vec2 xy1, vec4 abc1, vec2 xy2, vec4 abc2, vec2 xy3, vec4 abc3, vec2 xy4, vec4 abc4, float str) 
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
    dx = xy2.x-destCoord().x ; 
    dy = xy2.y-destCoord().y ; 
    float g = exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy)); 
    dx = xy3.x-destCoord().x ; 
    dy = xy3.y-destCoord().y ; 
    float ss = exp(-(abc3.r*dx*dx +2.0*abc3.g*dx*dy +abc3.b*dy*dy)); 
    dx = xy4.x-destCoord().x ; 
    dy = xy4.y-destCoord().y ; 
    float gg = exp(-(abc4.r*dx*dx +2.0*abc4.g*dx*dy +abc4.b*dy*dy)); 
    vec3 orig = im.rgb; 
    vec3 neg = min(im.rgb, 0.0); 
    vec3 pos = max(im.rgb, 1.0)-1.0; 
    im.rgb = clamp(im.rgb, 0.0, 1.0); 
    vec3 m = 1.0-im.rgb; 
    float a = 0.6; 
    vec4 result = im; 
    result.rgb = 1.0 - (pow(m, vec3(str))+a*( ((str-1.0)*m*(1.0-m*m))/(str*str))); 
    im.rgb = pow(im.rgb, vec3(1.0-((min(str, 2.95)-1.0)/2.6))); 
    result.rgb = mix(im.rgb, result.rgb, .85); 
    result.rgb = mix(orig, result.rgb+neg+pos, (s+g+ss+gg)); 
    return result; 
kernel vec4 _pf_kickLightKernel_neg(__sample im, vec2 xy1, vec4 abc1, vec2 xy2, vec4 abc2, vec2 xy3, vec4 abc3, vec2 xy4, vec4 abc4, float str) 
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
    dx = xy2.x-destCoord().x ; 
    dy = xy2.y-destCoord().y ; 
    float g = exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy)); 
    dx = xy3.x-destCoord().x ; 
    dy = xy3.y-destCoord().y ; 
    float ss = exp(-(abc3.r*dx*dx +2.0*abc3.g*dx*dy +abc3.b*dy*dy)); 
    dx = xy4.x-destCoord().x ; 
    dy = xy4.y-destCoord().y ; 
    float gg = exp(-(abc4.r*dx*dx +2.0*abc4.g*dx*dy +abc4.b*dy*dy)); 
    vec3 neg = min(im.rgb, 0.0); 
    vec3 pos = max(im.rgb, 1.0)-1.0; 
    im.rgb = clamp(im.rgb, 0.0, 1.0); 
    vec4 orig = im; 
    float lum = max(max(im.r, im.g), im.b); 
    vec3 gamma = compare(vec3(lum)-.001, vec3(0.0), pow(im.rgb, vec3(1.0-str*min(s+g+ss+gg, 1.0)))); 
    im.rgb = mix(gamma, mix(orig.rgb, orig.rgb*lum, -str*min(s+g+ss+gg, 1.0)), 0.3) ;
    im.rgb = mix(orig.rgb, im.rgb, 4.0*lum*(1.0-lum)) + pos + neg; 
    return im; 
inputBrighten
inputContrast
kernel vec4 _pf_dualLightKernel(__sample im, vec2 xy1, vec4 abc1, vec2 xy2, vec4 abc2, vec3 mcb) 
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
    dx = xy2.x-destCoord().x ; 
    dy = xy2.y-destCoord().y ; 
    float g = exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy)); 
    float contrast = .1*mcb.g*g; 
    vec3 neg = min(im.rgb, 0.0); 
    vec3 pos = max(im.rgb, 1.0)-1.0; 
    im.rgb = clamp(im.rgb, 0.0, 1.0); 
    vec3 orig = im.rgb; 
    float lum = (dot(im.rgb, vec3(.333333))); 
    float y = sqrt(lum); 
    vec3 light = vec3((1.0-y)*g-mcb.b*.4*(1.0-lum)*s); 
    float yy = compare(light.r, pow(lum, 1.0+abc1.a*light.r), pow(lum, 1.0+abc2.a*light.r)); 
    yy = mix(yy, 0.5, -(y*(1.0-y))*contrast); 
    im.rgb = lum > 0.0 ? im.rgb*yy/lum : vec3(0.0); 
    im.rgb = mix(orig.rgb, im.rgb, mcb.r) + pos + neg; 
    return im; 
kernel vec4 _pf_strobeKernel(__sample im, vec2 xy1, vec4 abc1, float str) 
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
    vec3 orig = im.rgb; 
    float lum = (dot(im.rgb, vec3(.333333))); 
    float y = sqrt(lum); 
    vec3 light = vec3(.4*(1.0-lum)*s); 
    float yy = pow(lum, 1.0-abc1.a*light.r); 
    im.rgb = lum > 0.0 ? im.rgb*yy/lum : vec3(0.0); 
    im.rgb = mix(orig.rgb, im.rgb, str); 
    return im; 
kernel vec4 _pf_contourExtractRed (__sample c) __attribute__((outputFormat(kCIFormatRh))) {
  return vec4(c.r, 0.0, 0.0, 1.0);
kernel vec4 _pf_contourLightKernel (__sample back, __sample fore, vec4 xy1, vec4 abc1, vec4 eyes, float str, float radius )
    fore = vec4(fore.r, fore.r, fore.r, 1.0);
    fore = max(fore, 0.0); 
    vec3 neg = min(back.rgb, 0.0); 
    vec3 pos = max(back.rgb, 1.0)-1.0; 
    back = clamp(back, 0.0, 1.0); 
    vec4 DCb = compare(0.25 - back, sqrt(back), ((16.0 * back - 12.0) * back + 4.0) * back);
    vec4 B  = back + (2.0 * fore - 1.0) * compare(0.5 - fore, DCb - back, back * (1.0 - back));
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = str*exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
    dx = eyes.x-destCoord().x ;
    dy = eyes.y-destCoord().y ;
    float le = .8*str*exp(-(dx*dx + dy*dy)/(2.0*radius)); 
    dx = eyes.z-destCoord().x ;
    dy = eyes.w-destCoord().y ;
    float re = .8*str*exp(-(dx*dx + dy*dy)/(2.0*radius)); 
    dx = xy1.z-destCoord().x ;
    dy = xy1.w-destCoord().y ;
    float chin = .5*str*exp(-(dx*dx + dy*dy)/(1.0*radius)); 
    B = mix(pow(B, vec4(1.6)), B, smoothstep(0.1, .7, fore.r+chin)) ;
    vec4 im = back; 
    im.rgb = mix(im.rgb, B.rgb, smoothstep(0.0,0.75,(s - re -le +chin))) + pos + neg; 
    return im; 
inputDarken
kernel vec4 _pf_portraitSpotKernel (__sample c, vec4 xy1, vec4 abc1, vec2 darken )
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
  vec3 orig = c.rgb; 
  vec3 neg = min(c.rgb, 0.0); 
  vec3 pos = max(c.rgb, 1.0)-1.0; 
  c.rgb = clamp(c.rgb, 0.0, 1.0); 
  vec3 m = 1.0-c.rgb; 
  float a = 0.6; 
  vec4 result = c; 
  float gamma = abc1.w; 
  result.rgb = 1.0 - (pow(m, vec3(gamma))+a*( ((gamma-1.0)*m*(1.0-m*m))/(gamma*gamma))); 
  c.rgb = pow(c.rgb, vec3(1.0-((min(gamma, 2.95)-1.0)/2.6))); 
  result.rgb = darken.g*mix(c.rgb, result.rgb, .85); 
  result.rgb = mix(darken.r*orig, result.rgb+neg+pos, s); 
  return result; 
inputFaceOrientation
kernel vec4 _pf_neckContour(__sample im, vec4 xy1, vec4 abc1, vec4 abc2, float str) 
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = -smoothstep(0.0, .1, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
    dx = xy1.z-destCoord().x ; 
    dy = xy1.w-destCoord().y ; 
    float ss = smoothstep(0.0, .1, exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy))) ; 
    s = clamp(ss+s, 0.0, 1.0); 
    im.rgb = mix(im.rgb, .85*im.rgb, str*s); 
    im.rgb = mix(im.rgb, im.rgb*im.rgb, .6*str*s); 
    return im; 
kernel vec4 _pf_contourExtractRedStudio (__sample c) __attribute__((outputFormat(kCIFormatRh))) {
  return vec4(c.r, 0.0, 0.0, 1.0);
kernel vec4 _pf_studioLightKernel (__sample back, __sample fore, vec4 xy1, vec4 abc1, vec4 eyes, float str, float radius )
 fore = vec4(fore.r, fore.r, fore.r, 1.0);
 fore = max(fore, 0.0); 
 fore = pow(fore, vec4(.65)); 
 vec3 neg = min(back.rgb, 0.0); 
 vec3 pos = max(back.rgb, 1.0)-1.0; 
 back = clamp(back, 0.0, 1.0); 
 vec4 DCb = compare(0.25 - back, sqrt(back), ((16.0 * back - 12.0) * back + 4.0) * back);
 vec4 B = back + (2.0 * fore - 1.0) * compare(0.5 - fore, DCb - back, back * (1.0 - back));
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = str*exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
 dx = eyes.x-destCoord().x ;
 dy = eyes.y-destCoord().y ;
 float le = .8*str*exp(-(dx*dx + dy*dy)/(2.0*radius)); 
 dx = eyes.z-destCoord().x ;
 dy = eyes.w-destCoord().y ;
 float re = .8*str*exp(-(dx*dx + dy*dy)/(2.0*radius)); 
 dx = xy1.z-destCoord().x ;
 dy = xy1.w-destCoord().y ;
 float chin = .5*str*exp(-(dx*dx + dy*dy)/(1.0*radius)); 
 B = mix(pow(B, vec4(1.6)), B, smoothstep(0.1, .7, fore.r+chin)) ;
 vec4 im = back; 
 im.rgb = mix(im.rgb, B.rgb, smoothstep(0.0,0.75,(s - re -le +chin))) + pos + neg; 
 return im; 
kernel vec4 _pf_cheapEdgePreserveStudio (__sample i, __sample b) 
 float d = 1.0*distance(i.rgb, b.rgb); b = mix(b, i, d); 
 return b; 
kernel vec4 _pf_strobeKernelV2(__sample im, vec2 xy1, vec4 abc1, float str) 
    float dx = xy1.x-destCoord().x ; 
    float dy = xy1.y-destCoord().y ; 
    float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
    vec3 orig = im.rgb; 
    float lum = (dot(im.rgb, vec3(.333333))); 
    float y = sqrt(lum); 
    vec3 light = vec3(.4*(1.0-lum)*s); 
    float yy = pow(lum, 1.0-abc1.a*light.r); 
    im.rgb = lum > 0.0 ? im.rgb*yy/lum : vec3(0.0); 
    im.rgb = mix(orig.rgb, im.rgb, str*lum); 
    return im; 
inputBlur
kernel vec4 _pf_contourExtractRedV2 (__sample c) __attribute__((outputFormat(kCIFormatRh))) {
 return vec4(c.r, 0.0, 0.0, 1.0);
kernel vec4 _pf_contourLightKernelV2 (__sample back, __sample fore, vec4 xy1, vec4 abc1, vec4 eyes, float str, float radius )
 fore.r = pow(fore.r, .85); 
 fore = vec4(fore.r, fore.r, fore.r, 1.0);
 fore = max(fore, 0.0); 
 vec3 neg = min(back.rgb, 0.0); 
 vec3 pos = max(back.rgb, 1.0)-1.0; 
 back = clamp(back, 0.0, 1.0); 
 vec4 DCb = compare(0.25 - back, sqrt(back), ((16.0 * back - 12.0) * back + 4.0) * back);
 vec4 B = back + (2.0 * fore - 1.0) * compare(0.5 - fore, DCb - back, back * (1.0 - back));
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = str*exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
 dx = eyes.x-destCoord().x ;
 dy = eyes.y-destCoord().y ;
 float le = .8*str*exp(-(dx*dx + dy*dy)/(2.0*radius)); 
 dx = eyes.z-destCoord().x ;
 dy = eyes.w-destCoord().y ;
 float re = .8*str*exp(-(dx*dx + dy*dy)/(2.0*radius)); 
 dx = xy1.z-destCoord().x ;
 dy = xy1.w-destCoord().y ;
 float chin = .5*str*exp(-(dx*dx + dy*dy)/(1.0*radius)); 
 B = mix(pow(B, vec4(1.6)), B, smoothstep(0.1, .7, fore.r+chin)) ;
 vec4 im = back; 
 im.rgb = mix(im.rgb, B.rgb, pow(fore.r, 0.35)*smoothstep(0.0,0.75,(s - re -le +chin))); 
 im.rgb = mix(back.rgb, im.rgb, pow(fore.r, .15)) + pos + neg; 
 return im; 
kernel vec4 _pf_cheapEdgePreserveContourV2 (__sample i, __sample b) 
 float d = 1.25*distance(i.rgb, b.rgb); b = mix(b, i, d); 
 return b; 
kernel vec4 _pf_faceContourMask(__sample im, vec4 xy1, vec4 abc1, vec4 abc2) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = 1.75*exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
 float g = exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy)); 
 g = clamp(g-s, 0.0, 1.0); 
 g = smoothstep(0.0, 0.18, g); 
 return vec4(g,g,g,1.0); 
kernel vec4 _pf_darkenContour(__sample im, float str) 
 im = clamp(im, 0.0, 1.0); 
 vec4 im2 = 1.0 - sqrt(1.0-im*im); 
 float y = dot(im.rgb, vec3(.333333)); 
 float y2 = 1.0 - sqrt(1.0-y*y); 
 vec4 im3 = (y>0) ? im*y2/y : vec4(0.0, 0.0, 0.0, 1.0) ; 
 float s = im.r + im.g + im.b - y; 
 im3 = mix(im2, im3, s); 
 im3 = mix(im, im3, str); 
 return vec4(im3.rgb, 1.0); 
CIHighKey
CIBlendWithMask
inputBackgroundImage
inputMaskImage
com.apple.PortraitFilters
loadMetalLib_block_invoke
PortraitFilters.m
bundle
portrait_filters
metallib
metalLibData
orientation
+[CIPortraitFaceMaskProcessorKernel processWithInputs:arguments:output:error:]
CIPortraitFaceMask.mm
CGRectIsIntegral(faceROI)
+[CIPortraitFaceMaskProcessorKernel roiForInput:arguments:outputRect:]
false
sanityCheckStatus
processedImageWidth
processedImageHeight
CoreImageROIrect
faceROI
faceLandmarks
inputImageExtent
skinRgonStack
skinColorToleranceDark
skinColorToleranceLight
skinColorToleranceMid
eps2
inputReturnHueChroma
kernel vec4 _pf_srgbToIPT(__sample im) 
 vec3 lms = im.r * vec3(0.3139902162, 0.15537240628, 0.01775238698) + 
 im.g * vec3(0.63951293834, 0.75789446163, 0.1094420944) + 
 im.b * vec3(0.04649754622, 0.08670141862, 0.87256922462); 
 lms = sign(lms)*pow(abs(lms), vec3(0.43)); 
 vec3 ipt = lms.r * vec3(0.4, 4.455, 0.8056) + 
 lms.g * vec3(0.4, -4.851, 0.3572) + 
 lms.b * vec3(0.2, 0.396,-1.1628); 
 return vec4(ipt, im.a); 
kernel vec4 _pf_rectToHueChroma(__sample im) 
 vec4 ihc = im; 
 ihc.g = atan(im.b, im.g); 
 ihc.b = sqrt(im.g*im.g+im.b*im.b); 
 return ihc; 
inputIsHueChroma
kernel vec4 _pf_iptToSRGB(__sample ipt) 
 vec3 lms = ipt.r * vec3(1.0000, 1.0000, 1.0000) + 
 ipt.g * vec3(0.0976,-0.1139, 0.0326) + 
 ipt.b * vec3(0.2052, 0.1332,-0.6769); 
 lms = sign(lms)*pow(abs(lms), vec3(1.0/.43)); 
 vec3 im = lms.r * vec3(5.472212058380287, -1.125241895533569, 0.029801651173470) + 
 lms.g * vec3(-4.641960098354471, 2.293170938060623, -0.193180728257140) + 
 lms.b * vec3(0.169637076827974, -0.167895202223709, 1.163647892783812); 
 return vec4(im, ipt.a); 
kernel vec4 _pf_hueChromaToRect(__sample ihc) 
 vec4 ipt = ihc; 
 ipt.g = ihc.b * cos(ihc.g); 
 ipt.b = ihc.b * sin(ihc.g); 
 return ipt; 
chromaMin
hueRange
+[CIHueChromaHistProcessor formatForInputAtIndex:]
CISmartGradient.m
imageExtents
+[CIHueChromaHistProcessor roiForInput:arguments:outputRect:]
arguments[@"imageExtents"]
[arguments[@"imageExtents"] count] > input
+[CIAveColorProcessor formatForInputAtIndex:]
imageExtent
+[CIAveColorProcessor roiForInput:arguments:outputRect:]
arguments[@"imageExtent"]
+[CIColorGradientProcessor formatForInputAtIndex:]
+[CIColorGradientProcessor roiForInput:arguments:outputRect:]
10.15
inputReturnSmartColor
inputHueRange
inputChromaMin
inputMaxDimension
inputHeight
kernel vec4 _pf_scaleHue(__sample im, float s) 
 im.g = (im.g+s)/(2.0*s); 
 return im; 
kernel vec4 _pf_scaleHuePi(__sample im, float s) 
 im.g = im.g*2.0*s - s; 
 return im; 
CIIPTtoSRGB
CISoftCubicUpsample
CIDither
inputIntensity
CISRGBtoIPT
CIAreaAverage
float _inTriangle(vec2 p1, vec2 p2, vec2 p3){ 
 float b1 = (p1.x - p3.x) * (p2.y - p3.y) - (p2.x - p3.x) * (p1.y - p3.y); 
 return b1; 
 bool _isInTriangle(vec4 p12, vec2 p34, vec2 pt){ 
 bool b1, b2, b3 ;
 vec2 v1 = p12.xy; 
 vec2 v2 = p12.zw; 
 vec2 v3 = p34.xy; 
 b1 = _inTriangle(pt, v1, v2) < 0.0; 
 b2 = _inTriangle(pt, v2, v3) < 0.0; 
 b3 = _inTriangle(pt, v3, v1) < 0.0; 
 return ((b1 == b2) && (b2 == b3)); 
 kernel vec4 _pf_drawTriangle(__sample im, vec4 p12, vec2 p34, float str, float alpha) 
 vec2 pt = destCoord(); 
 bool ins = _isInTriangle(p12, p34, pt); 
 vec4 scaled = clamp(str*im, 0.0, 1.0); 
 float y = dot(im.rgb, vec3(.333333)); 
 float s = im.r+im.g+im.b-3.0*y; 
 s = -.333*smoothstep(0.0, .333, s) + .333; 
 scaled.rgb = s*(scaled.rgb-str*y)+str*y; 
 scaled.a = alpha * (.3*y+.7); 
 im = ins ? scaled : vec4(0.0); 
 return im; 
kernel vec4 _pf_protectEyes(__sample im, vec4 eyes, float radius) 
 vec2 pt = destCoord(); 
 float dx = eyes.x-pt.x; 
 float dy = eyes.y-pt.y; 
 float a = 1.0 - exp(-(dx*dx + dy*dy)/(2.0*radius)); 
 im *= a; dx = eyes.z-pt.x; 
 dy = eyes.w-pt.y; 
 a = 1.0 - exp(-(dx*dx + dy*dy)/(2.0*radius)); 
 im *= a; 
 return im; 
CIHardLightBlendMode
guidedFilterEpsilon
+[CIDynamicGuidedFilter formatForInputAtIndex:]
CIDynamicLocalLight.mm
+[CIDynamicGuidedFilter roiForInput:arguments:outputRect:]
inputLightMapWidth
NSNumber
inputLightMapHeight
inputGuidedFilterEpsilon
inputLocalLight
inputSmartShadows
kernel vec4 _pf_shadowKernelDynamic(__sample im, __sample adj, float str) 
 adj.r = 3.4*adj.r-1.2; 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 vec4 orig = im; 
 float y = sqrt(dot(im.rgb, vec3(.33333))); 
 float s = mix(0.0, adj.r, str); 
 vec3 gain = s > 0.0 ? vec3(0.0*s) : vec3(-2.75*s*s, -2.75*s*s, -2.5*s*s); 
 gain *= 1.0 - .9*smoothstep(.5, .7, im.b); 
 im.rgb = im.rgb*im.rgb*gain + im.rgb*(1.0-gain); 
 float m = 1.0 + 1.85*s*(max(0.1-y, 0.0))*(1.0 - .9*smoothstep(.5, 0.7, im.b)) ;
 im.rgb = (clamp(m*im.rgb, 0.0, 1.0)); 
 float midAmt = s < 0.0 ? min(s*s,1.0) : 0.0; 
 y = y*(1.0-y); 
 im.rgb = sqrt(im.rgb); 
 float pivot = .4; 
 float a = midAmt*y; 
 float b = -pivot*a; 
 vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt); 
 im.rgb = mix(im.rgb, pix, 0.8); 
 im.rgb = max(im.rgb, 0.0); 
 im.rgb *= im.rgb; 
 im.rgb = clamp(im.rgb, 0.0,1.0)+pos+neg; 
 return im; 
kernel vec4 _pf_polyKernelDynamic(__sample im, __sample adj, float str) 
 adj.r = 3.4*adj.r-1.2; 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 vec4 orig = im; 
 float y = sqrt(dot(im.rgb, vec3(.33333))); 
 float s = mix(0.0, adj.r, str); 
 vec3 gain = s > 0.0 ? vec3(1.5*s) : vec3(1.75*s, 1.75*s, 1.55*s)*(1.0-.9*smoothstep(.5, .7, im.b)); 
 im.rgb = im.rgb*im.rgb*gain + im.rgb*(1.0-gain); 
 im.rgb = (clamp(im.rgb, 0.0, 1.0)); 
 float midAmt = min(str, .5); 
 y = y*(1.0-y); 
 im.rgb = sqrt(im.rgb); 
 float pivot = max(adj.g, 0.5); 
 float a = midAmt*y; 
 float b = -pivot*a; 
 vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt); 
 im.rgb = mix(im.rgb, pix, 0.8); 
 im.rgb = max(im.rgb, 0.0); 
 im.rgb *= im.rgb; 
 im.rgb = clamp(im.rgb, 0.0,1.0)+pos+neg; 
 return im; 
-[CILLFilter outputImage]
CGRectEqualToRect([guideImage extent], [inputImage extent])
inputImage != nil
guideImage != nil
inputLocalLight != nil
CGRectEqualToRect([lightMapImage extent], [inputImage extent])
CILocalLight
_lightMapImageFromData_block_invoke
x == 0
y == 0
width == lmWidth
height == lmHeight
v56@?0^v8Q16Q24Q32Q40Q48
allPoints
faceContour
innerLips
leftEye
leftEyebrow
leftPupil
medianLine
nose
noseCrest
outerLips
rightEye
rightEyebrow
rightPupil
faceJunkinessIndex
faceOrientationIndex
faceBoundingBox
inputRenderProxy
inputDisparity
inputDepthMap
inputBlurMap
inputMatte
inputFaceMask
inputTeethMask
inputHairMask
inputFaceLandmarkArray
pf_binary_archive
pf_binary_archive_fullsize
CIPortraitEffectStudioV2
CIPortraitEffectStageMonoV2
CIPortraitEffectStageWhite
CIPortraitEffectContourV2
CIPortraitEffectStageV2
10.11
inputGenerateSpillMatte
scube
inputSmooth
inputEnrich
inputTeeth
inputEyes
inputLocalContrast
render_lighting_proxy
com.apple.coremedia
refineStageMatte
renderSpillCache
kernel vec4 _pf_whitenteethV2(__sample pix, __sample mask, float amt) 
 float m = mask.g; 
 vec4 modifiedPix = pow(clamp(pix,0.0, 1.0), vec4(.35)); 
 modifiedPix.b += .1; 
 modifiedPix = modifiedPix * modifiedPix; 
 vec4 displayPix = clamp(modifiedPix,0.0, 1.0); 
 displayPix.a = 1.0; 
 float r = clamp(1.0 - pix.r/(pix.r+pix.g+pix.b), 0.0, 1.0); 
 displayPix.rgb = mix(pix.rgb, displayPix.rgb, r*max(m, 0.0)); 
 displayPix.a = pix.a; 
 return mix(pix, displayPix, amt); 
kernel vec4 _pf_enrichV2 (__sample s, float amt,vec4 params ) { 
 vec4 orig = s; 
 s = clamp(s, 0.0, 1.0); 
 float x0 = params.r; 
 float x1 = params.g; 
 float delta = params.b; 
 float pwr = params.a; 
 s = pow( s, vec4(pwr)); 
 float x2 = 1.0 - delta; 
 float m1 = 0.5/(x1-x0); 
 float b1 = - m1 * x0; 
 float m2 = (.5 - delta)/(x2 - x1); 
 float b2 = (m1-m2) * x1 + b1; 
 vec4 w = (1.0 - step(x1, s)) * (vec4(m1)*s + vec4(b1)) + step(x1, s) * (vec4(m2)*s + vec4(b2)) + step(x2,s) * ( s - (vec4(m2)*s + vec4(b2))) ; 
 w.rgb = clamp(w.rgb, 0.0, 1.0); 
 x0+= .02; 
 x1+= .0005; 
 m1 = 0.5/(x1-x0); 
 b1 = - m1 * x0; 
 m2 = (.5 - delta)/(x2 - x1); 
 b2 = (m1-m2) * x1 + b1; 
 w.r = (1.0 - step(x1, s.r)) * ((m1)*s.r + (b1)) + step(x1, s.r) * ((m2)*s.r + (b2)) + step(x2,s.r) * ( s.r - ((m2)*s.r + (b2))) ; 
 w.r = clamp(w.r, 0.0, 1.0); 
 x0-= .01; 
 x1+= .000; 
 m1 = 0.5/(x1-x0); 
 b1 = - m1 * x0; 
 m2 = (.5 - delta)/(x2 - x1); 
 b2 = (m1-m2) * x1 + b1; 
 w.b = (1.0 - step(x1, s.b)) * ((m1)*s.b + (b1)) + step(x1, s.b) * ((m2)*s.b + (b2)) + step(x2,s.b) * ( s.b - ((m2)*s.b + (b2))) ; 
 w.b = clamp(w.b, 0.0, 1.0); 
 w.rgb = w.rgb * w.rgb; 
 w.r = pow(w.r, .75); 
 w = mix(orig, w, vec4(amt) ); w.a = 1.0; 
 return w; 
kernel vec4 _pf_eyeBrightenV2 (__sample im, __sample m, float str) 
 float y = dot(im.rgb, vec3(0.333333)); 
 vec3 bright = mix(im.rgb, 3.0*im.rgb, m.r); 
 im.rgb = mix(im.rgb, bright, y*str); 
 return im; 
kernel vec4 _pf_eyeBrightenSoftlightV2 (__sample uCb, __sample m, float str) 
 float g = .75*(1.0-dot(uCb.rgb, vec3(.333333))); 
 vec4 uCf = vec4(g, g, g, 1.0); 
 vec4 D = compare(uCb-0.25, ((16.0*uCb-12.0)*uCb+4.0)*uCb, sqrt(uCb)); 
 vec4 Ct = clamp(uCb + (2.0*uCf-1.0) * compare(uCf - 0.5, uCb*(1.0-uCb), D-uCb), 0.0, 1.0); 
 vec4 bright = Ct; 
 uCf.rgb = mix(uCb.rgb, bright.rgb, m.r); 
 uCf.rgb = mix(uCb.rgb, uCf.rgb, str); 
 return uCf; 
kernel vec4 _pf_textureDiffV2 (__sample c, __sample b, float scale) 
 vec3 fullDiff = c.rgb - b.rgb; 
 c.rgb = compare(fullDiff, scale*fullDiff, fullDiff); 
 return c; 
kernel vec4 _pf_textureAddV2 (__sample c, __sample b, float scale) 
 scale = c.r > b.r ? .5*scale : scale; 
 c.rgb = c.rgb + scale*b.rgb; 
 return c; 
kernel vec4 _pf_cheapEdgePreserveV2 (__sample i, __sample b) 
 float d = .75*distance(i.rgb, b.rgb); 
 b = mix(b, i, d); 
 return b; 
kernel vec4 _pf_protectEyesNose (__sample faceMask, vec4 eyes, vec4 abc1, vec4 abc2, vec2 centerNose, vec4 abc3) 
 vec2 d = destCoord(); 
 float dx = eyes.x-d.x; 
 float dy = eyes.y-d.y; 
 float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
 faceMask.rgb -= s; 
 dx = eyes.z-d.x; 
 dy = eyes.w-d.y; 
 s = exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy)); 
 faceMask.rgb -= s; 
 dx = centerNose.x-d.x; 
 dy = centerNose.y-d.y; 
 s = exp(-(abc3.r*dx*dx +2.0*abc3.g*dx*dy +abc3.b*dy*dy)); 
 faceMask.rgb -= s; 
 faceMask = clamp(faceMask, 0.0, 1.0); 
 return faceMask; 
kernel vec4 _pf_eyeBlurV2 (__sample faceMask, vec4 eyes, vec4 abc1, vec4 abc2, vec4 abc3, vec4 abc4) 
 vec2 d = destCoord(); 
 float dx = eyes.x-d.x; 
 float dy = eyes.y-d.y; 
 float s = exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy)); 
 faceMask.b += s; 
 faceMask.a += s; 
 dx = eyes.z-d.x; 
 dy = eyes.w-d.y; 
 s = exp(-(abc2.r*dx*dx +2.0*abc2.g*dx*dy +abc2.b*dy*dy)); 
 faceMask.b += s; 
 faceMask.a += s; 
 s = exp(-(abc4.r*dx*dx +2.0*abc4.g*dx*dy +abc4.b*dy*dy)); 
 faceMask.r += s; 
 faceMask.a += s; 
 dx = eyes.x-d.x; 
 dy = eyes.y-d.y; 
 s = exp(-(abc4.r*dx*dx +2.0*abc4.g*dx*dy +abc4.b*dy*dy)); 
 faceMask.r += s; 
 faceMask.a += s; 
 faceMask = clamp(faceMask, 0.0, 1.0); 
 return faceMask; 
kernel vec4 _pf_featherEdgeLight(__sample im, vec4 b, float t) 
 vec2 dc = destCoord(); 
 float dxl = smoothstep(0.0, t, abs(dc.x-b.x)); 
 float dxr = smoothstep(0.0, t, abs(dc.x-b.z)); 
 float dyt = smoothstep(0.0, t, abs(dc.y-b.y)); 
 float dyb = smoothstep(0.0, t, abs(dc.y-b.w)); 
 im.rgb = vec3(dxl*dxr*dyt*dyb); 
 im = clamp(im, 0.0, 1.0); 
 return im; 
inputFaceLandmarks
CIGaussianGradient
roll
inputCenter
inputRadius
inputColor0
inputColor1
CIAdditionCompositing
CIMultiplyBlendMode
CIPortraitFaceMask
CIPhotoGrain
inputAmount
inputISO
CIBlendWithBlueMask
CIMix
CIPortraitSkinMask
CIPortraitToothMask
-[CIPortraitEffectLightV2 processEyesIn:withEyeBlur:landmarks:]
CIPortraitEffectV2.mm
eyeBlur
CIBlendWithRedMask
CISharpenLuminance
inputSharpness
inputKickLight
inputFaceLight
CIStudioPreview
kernel vec4 _pf_prepareDepthV2 (__sample c, float m) 
 c.r = smoothstep(m, 0.7, 2.0*c.r); 
 return c.rrra; 
kernel vec4 _pf_faceVignetteStudioV2(__sample vig, vec2 xy1, vec4 abc1) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, .4, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))); 
 vig.rgb = min(vig.rgb + vec3(s), 1.0); 
 return vig; 
kernel vec4 _pf_applyFaceProtectStudio(__sample im, __sample fg, __sample fp, __sample vig) 
 im.rgb = mix(im.rgb, fg.rgb, (1.0-fp.r)*vig.r); 
 return im; 
CISmartToneFilter
inputShadows
CIVibrance
CIPortraitLightingSide
inputImage
inputPt1
inputPt2
inputPt3
inputPt4
inputPt5
inputPt6
CIPortraitLightingFront
inputCenter1
inputBottom1
inputCenter2
inputHeight1
inputWidth1
inputHeight2
inputWidth2
inputRotate2
CIPortraitLightingSpot
CIPortraitLightingStrobeV2
CIPortraitLightingStudio
CIExposureAdjust
inputEV
CIContourPreview
kernel vec4 _pf_prepareDepthContourV2 (__sample c, float m) 
 c.r = smoothstep(m, 0.7, 2.0*c.r); 
 return vec4(vec3(c.r), 1.0); 
kernel vec4 _pf_blendSingleChannelMaskV2 (__sample c, __sample b, __sample m) 
 c.rgb = mix(c.rgb, b.rgb, m.r); 
 return c; 
kernel vec4 _pf_faceVignetteContourV2(__sample im, __sample vig, vec2 xy1, vec4 abc1) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, .4, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))); 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_applyVignetteContourV2(__sample im, __sample fg, __sample vig, float amt) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = mix(im.rgb, pow(im.rgb, vec3(2.0)), (1.0-.6*vig.rgb)*.1); 
 im.rgb = mix(im.rgb, im.rgb*(vig.rgb), amt) + pos + neg; 
 return im; 
kernel vec4 _pf_applyFaceProtect(__sample im, __sample fg, __sample fp, __sample vig) 
 im.rgb = mix(im.rgb, fg.rgb, (1.0-fp.r)*vig.r); 
 return im; 
kernel vec4 _pf_transparentBorder(__sample im, vec3 params) 
 vec2 dc = destCoord(); 
 float d = exp(-params.b*((dc.x - params.r)*(dc.x-params.r)+(dc.y - params.g)*(dc.y - params.g))); 
 d = smoothstep(0.02, .2, d); 
 im += vec4(d); 
 im = clamp(im, 0.0, 1.0); 
 return im; 
kernel vec4 _pf_applyTransparentBorder(__sample im, __sample alphaMatte) 
 im.a = alphaMatte.a; 
 im = premultiply(im); 
 return im; 
unionRect
faceLandmarksArray
CIPortraitLightingEdge
CIPortraitContour
inputOrigImage
CIPortraitLightingContourV2
CIPortraitLocalContrast
CIStageStandby
inputUseAbsoluteDisparity
inputSharpenRadius
inputGrainAmount
kernel vec4 _pf_prepareBlackDisparityV2 (__sample dm, const float thresh) 
 float g = 1.0-smoothstep(0.0, thresh, 4.0*dm.r); 
 return vec4(g,g,g, 1.0); 
kernel vec4 _pf_prepareBlackDepthV2 (__sample dm, const float thresh) 
 float g = 1.0-smoothstep(0.0, thresh, 2.0*dm.r*dm.r); 
 return vec4(g,g,g, 1.0); 
kernel vec4 _pf_applyBlackDepthV2 (__sample im, __sample dm, float g) 
 im.rgb *= pow(dm.r, g); 
 return im; 
kernel vec4 _pf_applyStageNoFeather (__sample im, __sample dm) 
 im.rgb = mix(im.rgb*im.rgb*im.rgb, im.rgb, dm.r); 
 im.rgb = mix(vec3(0.0), im.rgb, dm.r); 
 return im; 
kernel vec4 _pf_applyStageNoFeatherSpill (__sample im, __sample spill) 
 vec3 div2 = sqrt(vec3(1.0)-(spill.rgb*spill.rgb)); 
 spill.r = div2.r>0.01? (spill.r / div2.r):0.0; 
 spill.g = div2.g>0.01? (spill.g / div2.g):0.0; 
 spill.b = div2.b>0.01? (spill.b / div2.b):0.0; 
 spill.rgb = spill.rgb*vec3(4.0); 
 spill.rgb = smoothstep(0.0, 1.0, spill.rgb); 
 im.rgb = mix(vec3(0.0), max(vec3(0.005),im.rgb), spill.rgb); 
 return im; 
kernel vec4 _pf_getRefinedMatte (__sample spill) 
 vec3 div2 = sqrt(vec3(1.0)-(spill.rgb*spill.rgb)); 
 spill.r = div2.r>0.01? (spill.r / div2.r):0.0; 
 spill.g = div2.g>0.01? (spill.g / div2.g):0.0; 
 spill.b = div2.b>0.01? (spill.b / div2.b):0.0; 
 spill.rgb = spill.rgb*vec3(4.0); 
 spill.rgb = mix(min(spill.rgb, 1.0), smoothstep(0.0, 1.0, spill.rgb), .5); 
 return vec4(spill.rgb, 1.0); 
kernel vec4 _pf_applyRefinedMatte (__sample im, __sample spill, __sample edge) 
 im.rgb = im.rgb * spill.rgb; 
 im.rgb = mix(im.rgb, im.rgb*im.rgb*im.rgb, edge.rgb); 
 return im; }
kernel vec4 _pf_refineBlackDepthV2 (__sample im, __sample dm, __sample bm, __sample protect, vec3 g, __sample aft) 
 float b = smoothstep(0.0, 1.0, pow(dm.r*bm.r,g.r)+protect.r); 
 im.rgb = max(im.rgb, 0.0); 
 vec3 gamma = (g.b) > 0.0 ? vec3(1.0+g.g-g.g*b*b*dm.r) : vec3(1.0+g.g-g.g*b*b); 
 im.rgb = pow(im.rgb, gamma); 
 im.rgb = mix(vec3(0.0), im.rgb, b); 
 gamma = vec3(1.35-.35*b*aft.r); 
 im.rgb = pow(im.rgb, gamma); 
 float r = im.r/(im.r+im.g+im.b+0.00001); 
 float sat = max(min(1.0, (1.3-.9*r)), 0.0); 
 float y = dot(im.rgb, vec3(.3333333)); 
 im.rgb = mix(sat*(im.rgb-y)+y, im.rgb, b*dm.r); 
 return im; 
kernel vec4 _pf_faceVignetteStageV2(__sample im, __sample vig, vec2 xy1, vec4 abc1) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, .4, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_faceProtectV2(__sample im, __sample vig, vec2 xy1, vec4 abc1, float feather) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, feather, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_applyVignetteStageV2(__sample im, __sample vig, float amt) 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = mix(im.rgb, im.rgb*(vig.rgb), amt); 
 im.rgb = mix(im.rgb, im.rgb*im.rgb, (1.0-vig.rgb)*.3); 
 return im; 
kernel vec4 _pf_invertRedV2(__sample rNormalized) __attribute__((outputFormat(kCIFormatRh))) 
 return vec4(1.0 - rNormalized.r, 0.0, 0.0, 1.0); 
kernel vec4 _pf_blendDepthV2(__sample depth, __sample tightDepth, __sample im, __sample blur, __sample weight) 
  float d = distance(im.rgb, blur.rgb); 
  float g = mix(tightDepth.r, depth.r, weight.r); 
  g += (d*weight.r*(1.0-dot(im.rgb, vec3(.333333)))); 
  g = clamp(g, 0.0, 1.0); 
  return vec4(g, g, g, 1.0); 
kernel vec4 _pf_thresholdMatteV2(__sample matte, __sample blurMatte, float low, float high) 
 float m = smoothstep(low, high, matte.r)*blurMatte.r; 
 matte.rgb *= m; 
 return matte; 
kernel vec4 _pf_thresholdAndApplyMatteV2(__sample im, __sample matte, __sample m2, vec4 params, float edgeGamma) 
 float low = params.x; float high = params.y; float gamma = params.z; float gain = params.w; float m = smoothstep(low, high, pow(matte.r, gamma+edgeGamma*m2.r)); 
 im.rgb *= m; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = pow(im.rgb, vec3(1.0+gain-gain*matte.r)); 
 im.rgb = mix(.5*im.rgb*im.rgb, im.rgb, 1.0-m2.r); 
 float r = im.r/(im.r+im.g+im.b+0.00001); 
 float sat = max(min(1.0, (1.0-r)), 0.0); 
 float y = dot(im.rgb, vec3(.3333333)); 
 im.rgb = mix(sat*(im.rgb-y)+y, im.rgb, m); 
 return im; 
CIDifferenceBlendMode
kernel vec4 _pf_red(__sample s) { return s.xxxw; }
CIMotionBlur
inputAngle
CICheapMorphology
CIPhotoEffectStageMono
CISmartBlackAndWhite
inputTone
kernel vec4 _pf_thresholdAndApplyWhiteBG(__sample im, __sample matte, __sample m2, float low, float high, float gamma, float gain) 
 float m = smoothstep(low, high, pow(matte.r, gamma+.5*m2.r)); 
 im.rgb = mix(vec3(1.0), im.rgb, m); 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = pow(im.rgb, vec3(1.0+gain-gain*m)); 
 im.rgb = mix(.5*im.rgb*im.rgb, im.rgb, 1.0-m2.r); 
 float r = im.r/(im.r+im.g+im.b+0.00001); 
 float sat = max(min(1.0, (1.3-.9*r)), 0.0); 
 float y = dot(im.rgb, vec3(.3333333)); 
 im.rgb = mix(sat*(im.rgb-y)+y, im.rgb, m); 
 return im; 
kernel vec4 _pf_thresholdWhiteMatte(__sample matte, __sample blurMatte, float low, float high) 
 float m = smoothstep(low, high, matte.r)*blurMatte.r; 
 matte.rgb *= m; 
 return matte; 
kernel vec4 _pf_prepareWhiteDepth (__sample dm, const float thresh) 
 float g = 1.0-smoothstep(0.0, thresh, 2.0*dm.r*dm.r); 
 return vec4(g,g,g, 1.0); 
kernel vec4 _applyWhiteNoFeather (__sample im, __sample dm) 
 im.rgb = mix(im.rgb*im.rgb*im.rgb, im.rgb, dm.r); 
 im.rgb = mix(vec3(1.0), im.rgb, dm.r); 
 return im; 
kernel vec4 _getRefinedWhiteMatte (__sample spill) 
 vec3 div2 = sqrt(vec3(1.0)-(spill.rgb*spill.rgb)); 
 spill.r = div2.r>0.01? (spill.r / div2.r):0.0; 
 spill.g = div2.g>0.01? (spill.g / div2.g):0.0; 
 spill.b = div2.b>0.01? (spill.b / div2.b):0.0; 
 spill.rgb = spill.rgb*vec3(4.0); 
 spill.rgb = mix(min(spill.rgb, 1.0), smoothstep(0.4, 1.0, spill.rgb), 1.0); 
 return vec4( spill.rgb, 1.0 ); 
kernel vec4 _applyRefinedWhiteMatte (__sample im, __sample spill, __sample edge, __sample alpha) 
 im.rgb *= spill.rgb; 
 im.rgb = mix(im.rgb, im.rgb*im.rgb*im.rgb, min(2.0*edge.r, 1.0)); 
 im.rgb = mix(vec3(1.0), im.rgb, alpha.r); 
 return im; }
loadArchive:
true
allocSpanStack:s
allocSpanStack:s->firstChunk
pushSpan:s->stackHeadChunk->next
allocSpanStack: span stack could not be allocated
spanSearch: empty span
freeSpanStack: span stack is null
seedFill: can not push span onto stack
seedFill: can not allocate span stack
-[CIPortraitToothMask outputImage]
CIPortraitToothMask.m
( imageExtentN.origin.x == 0 ) && ( imageExtentN.origin.y == 0 )
+[CIPortraitToothMaskProcessor processWithInputs:arguments:output:error:]
CGRectIsIntegral(teethROI)
CGRectMakeWithVisionDictionaryRepresentation( faceLandmarkDictionary[@"faceBoundingBox"], &faceRectInBuffer )
CGPointMakeWithVisionDictionaryRepresentationAndTransform( pointDictionary, faceRectInBuffer, &pnt1 )
+[CIPortraitToothMaskProcessor roiForInput:arguments:outputRect:]
teethROI
inputImageTransformN1
inputImageTransform1N
useMetal
-[CPUFaceMask clearOutputMask:WithBytesPerRow:OutputRegion:]
CPUFaceMask.m
outputMaskBaseAddr
-[CPUFaceMask trainSkinMaskUsingInputImage:InputBytesPerRow:InputRegion:QuadRegion:]
inputBGRAImageBaseAddr
ChromaDilation %d: minDilateLuma=%f
-[CPUFaceMask findSkinMaskUsingInputImage:InputBytesPerRow:InputRegion:OutputMask:OutputBytesPerRow:OutputRegion:FaceBounds:SeedPoints:NumberOfSeedPoints:FillValue:]
seedPoints
-[CPUFaceMask findToothMaskUsingInputImage:InputBytesPerRow:InputRegion:OutputMask:OutputBytesPerRow:OutputRegion:TeethBounds:SeedPoints:NumberOfSeedPoints:FillValue:]
-[CPUFaceMask drawEyeMaskUsingQuads:OutputMask:OutputBytesPerRow:OutputRegion:]
eyeQuads
eyeQuads->nQuads <= FACEMASK_MAX_NEYEQUADS
initBitmask:b
initBitmask:b->body
initBitmask: bitmap record can not be allocated
initBitmask: bitmap body can not be allocated
termBitmask: bitmap was null
setBitInBitmask: coordinate out of range
bitmaskBoundingBitmapRectWithSeedPoint: seed point outside bitmask
CPUFaceMask_Clear
CPUFaceMask_algorithms.c
outputMaskBaseAddr != NULL
( bounds.x >= region.x ) && ( bounds.y >= region.y ) && ( bounds.z <= region.z ) && ( bounds.w <= region.w )
simd_all( length > 0 ) && simd_all( offset >= 0 )
CPUFaceMask_MinMax
minMaxObj != NULL
inputBGRAImageBaseAddr != NULL
CPUFaceMask_PopulateCube
outputCube != NULL
CPUFaceMask_GenerateMask
spanTable != NULL
firstSpanInRows != NULL
inputCube != NULL
CPUFaceMask_GenerateToothMask
CPUFaceMask_DrawSpans
simd_all( length > 0 )
CPUFaceMask_DrawEye
eyeQuads != NULL
inputSat
inputPShift
inputTShift
kernel vec4 _pf_brightenSat(__sample im, __sample noise, float str, float sat, float pShift, float tShift) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 vec3 lms = im.r * vec3(0.3139902162, 0.15537240628, 0.01775238698) + 
 im.g * vec3(0.63951293834, 0.75789446163, 0.1094420944) + 
 im.b * vec3(0.04649754622, 0.08670141862, 0.87256922462); 
 lms = sign(lms)*pow(abs(lms), vec3(0.43)); 
 vec3 ipt = lms.r * vec3(0.4, 4.455, 0.8056) + 
 lms.g * vec3(0.4, -4.851, 0.3572) + 
 lms.b * vec3(0.2, 0.396,-1.1628); 
 float c = sqrt(ipt.g*ipt.g+ipt.b*ipt.b); 
 float h = atan(ipt.b, ipt.g); 
 float brightGreen = exp(-(h-1.735)*(h-1.735)/(0.35*0.35))*ipt.r ;
 float blueDamp = exp(-(h+1.9)*(h+1.9)/(0.75*0.75))*ipt.r ;
 blueDamp *= (1.0 - smoothstep(0.65, 0.75, c)); 
 float s = 1.0 + .6*str*(1.0 - .85*brightGreen)*(1.0-blueDamp); 
 float greenDamp = exp(-(h-3.14159*0.8)*(h-3.14159*0.8)/(0.7*0.7)) ;
 float dampHighlights = 1.0; 
 c *= s*sat * dampHighlights*(1.0 - .1*brightGreen)*(1.0-.2*blueDamp); 
 float y2 = pow(ipt.r, .5); 
 float y3 = mix(2.0*ipt.r, ipt.r, ipt.r); 
 y2 = mix(y2, y3, .5); 
 float dd = 1.0 - 0.15*smoothstep(0.7, 0.8, ipt.r); 
 dd *= sqrt(y2); 
 float y = mix(ipt.r, y2, dd); 
 float t = ipt.r*(1.0-ipt.r); 
 y = mix(y, 1.0, -t*str) ;
 ipt.r = mix(ipt.r, y, str); 
 greenDamp += exp(-(h+3.14159*1.2)*(h+3.14159*1.2)/(0.7*0.7)) ;
 h = mix(h, h-.125, greenDamp); 
 ipt.g = c * cos(h); 
 ipt.b = c * sin(h); 
 ipt.g += (pShift*ipt.r); ipt.b += (tShift*ipt.r); lms = ipt.r * vec3(1.0000, 1.0000, 1.0000) + 
 ipt.g * vec3(0.0976,-0.1139, 0.0326) + 
 ipt.b * vec3(0.2052, 0.1332,-0.6769); 
 lms = sign(lms)*pow(abs(lms), vec3(1.0/.43)); 
 im.rgb = lms.r * vec3(5.472212058380287, -1.125241895533569, 0.029801651173470) + 
 lms.g * vec3(-4.641960098354471, 2.293170938060623, -0.193180728257140) + 
 lms.b * vec3(0.169637076827974, -0.167895202223709, 1.163647892783812); 
 c = smoothstep(0.0, 0.3, c); 
 float ydamp = smoothstep(0.0, 1.0, ipt.r); 
 im.rgb = mix(im.rgb, 0.95*im.rgb*im.rgb*im.rgb, greenDamp*ydamp*c); 
 float nn = (noise.r + noise.g + noise.b + noise.a)*0.25 - 0.5; 
 im.rgb = mix(im.rgb, im.rgb+(.03*nn), im.b); 
 im.rgb = clamp(im.rgb, 0.0, 1.0) + neg + pos; 
 return im; 
CIRandomGenerator
kernel vec4 _pf_brightenFood(__sample im, float str, float sat, float pShift, float tShift) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 vec3 lms = im.r * vec3(0.3139902162, 0.15537240628, 0.01775238698) + 
 im.g * vec3(0.63951293834, 0.75789446163, 0.1094420944) + 
 im.b * vec3(0.04649754622, 0.08670141862, 0.87256922462); 
 lms = sign(lms)*pow(abs(lms), vec3(0.43)); 
 vec3 ipt = lms.r * vec3(0.4, 4.455, 0.8056) + 
 lms.g * vec3(0.4, -4.851, 0.3572) + 
 lms.b * vec3(0.2, 0.396,-1.1628); 
 float c = sqrt(ipt.g*ipt.g+ipt.b*ipt.b); 
 float h = atan(ipt.b, ipt.g); 
 float redDamp = 1.0 - .65*exp(-(h-3.14159*.14)*(h-3.14159*.14)/(.55*.55)); float brightGreen = exp(-(h-1.735)*(h-1.735)/(0.35*0.35))*ipt.r ;
 float cc = smoothstep(0.0, 0.55, c); 
 float dampHighlights = 1.0 - smoothstep(.5, 1.0, ipt.r); 
 float s = 1.0 + .6*str*cc*redDamp*(1.0-brightGreen); 
 float dampBlue = 1.0 - smoothstep(0.5, 1.0, im.b); 
 sat = (sat >= 1.0) ? 1.0+(sat-1.0)*cc*dampHighlights*redDamp*(1.0-brightGreen) : sat; 
 float rgDamp = (1.0 - .15*(1.0-redDamp))*(1.0 - .1*brightGreen); 
 c *= s*sat*dampBlue*rgDamp; 
 float y2 = pow(ipt.r, .5); 
 float y3 = mix(2.0*ipt.r, ipt.r, ipt.r); 
 y2 = mix(y2, y3, .5); 
 float dd = 1.0 - .15*smoothstep(0.7, 0.8, ipt.r); 
 dd *= sqrt(y2); 
 float y = mix(ipt.r, y2, dd); 
 float t = ipt.r*(1.0-ipt.r); 
 y = mix(y, 1.0, -t*str) ;
 ipt.r = mix(ipt.r, y, str); 
 float hue_shift = .25*exp(-(h*h)/(.45*.45)); h += hue_shift; ipt.g = c * cos(h); 
 ipt.b = c * sin(h); 
 ipt.g += (pShift*ipt.r*redDamp); ipt.b += (tShift*ipt.r*redDamp); lms = ipt.r * vec3(1.0000, 1.0000, 1.0000) + 
 ipt.g * vec3(0.0976,-0.1139, 0.0326) + 
 ipt.b * vec3(0.2052, 0.1332,-0.6769); 
 lms = sign(lms)*pow(abs(lms), vec3(1.0/.43)); 
 im.rgb = lms.r * vec3(5.472212058380287, -1.125241895533569, 0.029801651173470) + 
 lms.g * vec3(-4.641960098354471, 2.293170938060623, -0.193180728257140) + 
 lms.b * vec3(0.169637076827974, -0.167895202223709, 1.163647892783812); 
 im.rgb = mix(im.rgb, pow(im.rgb, vec3(1.6)), smoothstep(0.915, 1.0, ipt.r)); 
 im.rgb = clamp(im.rgb, 0.0, 1.0) + neg + pos; 
 return im; 
RGON_ARRAY
 {%f , %f },
 {%f , %f }
 Line[ { 
 {%f,%f,%f},
 {%f,%f,%f}
 }] 
 %f,
 %f } 
RGON_STACK
BIN_COUNT
BIN_OFFSET
BIN_SIZE
LOW_Z
HIGH_Z
DARKTHR_Z
 rgon stack print facets of stack with  %d rgons
 {%5.2f,%5.2f,%5.2f},
 {%5.2f,%5.2f,%5.2f} 
Cross[{%f,%f,%f}, {%f,%f,%f} ] - {%f, %f, %f } 
Hue[.4],Line[{{%5.2f,%5.2f,%5.2f}, {%5.2f,%5.2f,%5.2f} }],
 rgon stack print vertices
 end rgon stack print vertices
 rgon stack print constraints
 end rgon stack print constraints
 end rgon stack print
 }] ,
list001 = { {%f,%f}
,{%f,%f}
 Show[ g01 = Graphics[{ Line[list001], Hue[.4], AbsolutePointSize[5], Map[Point, list001]}]] 
s  %f , %f, x and y {%f,%f },{%f, %f} 
Line[{{%f,%f},{%f,%f},{%f,%f},{%f,%f},{%f,%f}}] 
xmin, xmax, ymin, ymax {%f, %f}, {%f, %f} 
Polyline points
Polyline bounds
 bounds Rect (polyline printRect )
bridgeGaps currently empty for polyline pairs
topbottom region summary
inputIsSunsetSunrise
inputExposure
inputBrightness
inputHighlights
inputWhiteBalance
inputSaturation
inputBrightSat
inputConfidence
inputLowConfidence
inputHighConfidence
inputMaxFaceSize
kernel vec4 _pf_imToIPT(__sample im) 
 vec3 lms = im.r * vec3(0.3139902162, 0.15537240628, 0.01775238698) + 
 im.g * vec3(0.63951293834, 0.75789446163, 0.1094420944) + 
 im.b * vec3(0.04649754622, 0.08670141862, 0.87256922462); 
 lms = sign(lms)*pow(abs(lms), vec3(0.43)); 
 vec3 ipt = lms.r * vec3(0.4, 4.455, 0.8056) + 
 lms.g * vec3(0.4, -4.851, 0.3572) + 
 lms.b * vec3(0.2, 0.396,-1.1628); 
 return vec4(ipt, im.a); 
kernel vec4 _pf_iptToHueChroma(__sample im) 
 vec4 ihc = im; 
 float hue = atan(im.b, im.g); 
 ihc.g = (hue/3.14159 + 1.0)/2.0; 
 ihc.b = sqrt(im.g*im.g+im.b*im.b); 
 ihc.a = 1.0; 
 return ihc; 
{Exif}
BrightnessValue
{MakerApple}
semdev_debug_overlay
proxy
full
night mode
normal
Strength: %@, CaptureType: %@, BV: %@, size: %@
CITextImageGenerator
inputText
inputFontSize
kernel vec4 _pf_softExposure(__sample im) 
 float y = dot(im.rgb, vec3(0.1, 0.8, .1)); 
 float g = -0.2664*y*y + 1.2695*y; 
 im.rgb = (y > 0.0) ? im.rgb/y*g : vec3(0.0); 
 return im; 
highKey
blackPoint
CIDynamicLocalLightMapPrepare
inputLightMap
lightMap
inputGuideImage
CILLFilter
inputLightMapImage
CIBrightenSat
inputBlack
inputUnionBox
inputVignetteStrength
kernel vec4 _pf_foodVignette(__sample im, __sample vig, vec2 xy1, vec4 abc1) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, .4, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))); 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_applyFoodVignette(__sample im, __sample orig, __sample vig, float amt) 
 im.rgb = mix(.9*orig.rgb, im.rgb, amt*vig.rgb) ;
 return im; 
CITemperatureAndTint
inputTargetNeutral
CIBrightenFood
CIOverlayBlendMode
kernel vec4 _pf_highKey(__sample im, float str) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0) - 1.0; 
 im = clamp(im, 0.0, 1.0); 
 vec4 im2 = 1.0-((im-1.0)*(im-1.0)); 
 im2 = sqrt(im2); 
 float y = dot(im.rgb, vec3(.333333)); 
 float y2 = sqrt(1.0-(y-1.0)*(y-1.0)); 
 y2 = mix(y2, smoothstep(0.0, 1.0, y2), 0.5); 
 vec4 im3 = (y>0) ? im*y2/y : vec4(0.0, 0.0, 0.0, 1.0) ; 
 im3 = mix(im3, im2, .7*sqrt(y2)); 
 im3 = mix(im, im3, sqrt(y)) ; 
 im.rgb = mix(im.rgb, im3.rgb, str) + pos + neg; 
 return im; } 
kernel vec4 _pf_portraitConvertToGrayscale (__sample c) __attribute__((outputFormat(kCIFormatRh))) {
  float g = dot(c.rgb, vec3(0.333333));
  return vec4(g, 0.0, 0.0, 1.0);
kernel vec4 _pf_portraitLocalContrast(__sample im, __sample shc, float amt)
 float midAmt = amt;
 vec3 neg = min(im.rgb, 0.0);
 vec3 pos = max(im.rgb, 1.0)-1.0;
 im.rgb = clamp(im.rgb, 0.0, 1.0);
 float y = dot(im.rgb, vec3(0.3333));
 y = sqrt(y);
 y = y*(1.0-y);
 im.rgb = sqrt(im.rgb);
 float pivot = sqrt(shc.r);
 float a = midAmt*y;
 float b = -pivot*a;
 vec3 pix = im.r * vec3(0.299*a) +
 im.g * vec3(0.587*a) +
 im.b * vec3(0.114*a) +
 im.rgb + vec3(b);
 im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt);
 im.rgb = mix(im.rgb, pix, 0.8);
 im.rgb = max(im.rgb, 0.0);
 im.rgb *= im.rgb;
 im.rgb = im.rgb + neg + pos;
 return im;
kernel vec4 _pf_whitenteeth(__sample pix, __sample mask, float amt) 
 float m = mask.g; 
 vec4 modifiedPix = pow(clamp(pix,0.0, 1.0), vec4(.35)); 
 modifiedPix.b += .1; 
 modifiedPix = modifiedPix * modifiedPix; 
 modifiedPix.rgb = compare(vec3(m - .8), modifiedPix.rgb, pix.rgb); 
 vec4 displayPix = clamp(modifiedPix,0.0, 1.0); 
 displayPix.a = 1.0; 
 displayPix.rgb = mix(pix.rgb, displayPix.rgb, max(m, 0.0)); 
 displayPix.a = pix.a; 
 return mix(pix, displayPix, amt); 
kernel vec4 _pf_enrich (__sample s, float amt,vec4 params ) { 
 vec4 orig = s; 
 s = clamp(s, 0.0, 1.0); 
 float x0 = params.r; 
 float x1 = params.g; 
 float delta = params.b; 
 float pwr = params.a; 
 s = pow( s, vec4(pwr)); 
 float x2 = 1.0 - delta; 
 float m1 = 0.5/(x1-x0); 
 float b1 = - m1 * x0; 
 float m2 = (.5 - delta)/(x2 - x1); 
 float b2 = (m1-m2) * x1 + b1; 
 vec4 w = (1.0 - step(x1, s)) * (vec4(m1)*s + vec4(b1)) + step(x1, s) * (vec4(m2)*s + vec4(b2)) + step(x2,s) * ( s - (vec4(m2)*s + vec4(b2))) ; 
 w.rgb = clamp(w.rgb, 0.0, 1.0); 
 x0+= .02; 
 x1+= .0005; 
 m1 = 0.5/(x1-x0); 
 b1 = - m1 * x0; 
 m2 = (.5 - delta)/(x2 - x1); 
 b2 = (m1-m2) * x1 + b1; 
 w.r = (1.0 - step(x1, s.r)) * ((m1)*s.r + (b1)) + step(x1, s.r) * ((m2)*s.r + (b2)) + step(x2,s.r) * ( s.r - ((m2)*s.r + (b2))) ; 
 w.r = clamp(w.r, 0.0, 1.0); 
 x0-= .01; 
 x1+= .000; 
 m1 = 0.5/(x1-x0); 
 b1 = - m1 * x0; 
 m2 = (.5 - delta)/(x2 - x1); 
 b2 = (m1-m2) * x1 + b1; 
 w.b = (1.0 - step(x1, s.b)) * ((m1)*s.b + (b1)) + step(x1, s.b) * ((m2)*s.b + (b2)) + step(x2,s.b) * ( s.b - ((m2)*s.b + (b2))) ; 
 w.b = clamp(w.b, 0.0, 1.0); 
 w.rgb = w.rgb * w.rgb; 
 w.r = pow(w.r, .75); 
 w = mix(orig, w, vec4(amt) ); w.a = 1.0; 
 return w; 
kernel vec4 _pf_eyeBrightenSoftlight (__sample uCb, __sample m, float str) 
 float g = .75*(1.0-dot(uCb.rgb, vec3(.333333))); 
 vec4 uCf = vec4(g, g, g, 1.0); 
 vec4 D = compare(uCb-0.25, ((16.0*uCb-12.0)*uCb+4.0)*uCb, sqrt(uCb)); 
 vec4 Ct = clamp(uCb + (2.0*uCf-1.0) * compare(uCf - 0.5, uCb*(1.0-uCb), D-uCb), 0.0, 1.0); 
 vec4 bright = Ct; 
 uCf.rgb = mix(uCb.rgb, bright.rgb, m.r); 
 uCf.rgb = mix(uCb.rgb, uCf.rgb, str); 
 return uCf; 
kernel vec4 _pf_mixKernel1 (__sample c, __sample b, float m) 
 c.rgb = mix(c.rgb, b.rgb, m); 
 return c; 
kernel vec4 _pf_textureDiff (__sample c, __sample b) 
 c.rgb = c.rgb - b.rgb; 
 return c; 
kernel vec4 _pf_textureAdd (__sample c, __sample b, float scale) 
 c.rgb = c.rgb + scale*b.rgb; 
 return c; 
CIRingBlur
inputPointCount
-[CIPortraitEffectLight processEyesIn:withEyeBlur:landmarks:]
CIPortraitEffect.mm
CI_USE_OLD_FACE_MASK
kernel vec4 _pf_prepareDepth (__sample c, float m) 
 c.r = smoothstep(m, 0.7, 2.0*c.r); 
 return c.rrra; 
kernel vec4 _pf_mixKernel2 (__sample c, __sample b, float m) 
 c.rgb = mix(c.rgb, b.rgb, m); 
 return c; 
CIPortraitEffectLight
CIPortraitLightingStrobe
kernel vec4 _pf_prepareDepth2 (__sample c, float m) 
 c.r = smoothstep(0.0, m, 2.0*c.r); 
 return vec4(vec3(c.r), 1.0); 
kernel vec4 _pf_mixKernel3 (__sample c, __sample b, float m) 
 c.rgb = mix(c.rgb, b.rgb, m); 
 c.a = b.a; return c; 
kernel vec4 _pf_blendSingleChannelMask (__sample c, __sample b, __sample m) 
 c.rgb = mix(c.rgb, b.rgb, m.r); 
 return c; 
kernel vec4 _pf_faceVignetteContour(__sample im, __sample vig, vec2 xy1, vec4 abc1) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, .4, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))); 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_applyVignetteContour(__sample im, __sample vig, float amt) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = mix(im.rgb, pow(im.rgb, vec3(2.0)), (1.0-.6*vig.rgb)*.1); 
 im.rgb = mix(im.rgb, im.rgb*(vig.rgb), .1) + pos + neg; 
 return im; 
CIPortraitLightingContour
CIPortraitLightingNeckContour
inputChin
inputDepthThreshold
inputFocalLengthNormalized
inputAdaptiveThresholdFaceGroupRange
inputAdaptiveThresholdFaceErrorMargin
inputAdaptiveThresholdZRangeConst
inputAdaptiveThresholdZRangeLinearDepth
inputAdaptiveThresholdConstOffset
inputAdaptiveThresholdLinearDepthOffset
inputAdaptiveThresholdDoDisparityError
inputDepthDataScore
kernel vec4 _pf_prepareBlackDisparity (__sample dm, const float thresh) 
 float g = 1.0-smoothstep(0.0, thresh, 4.0*dm.r); 
 return vec4(g,g,g, 1.0); 
kernel vec4 _pf_prepareBlackDepth (__sample dm, const float thresh) 
 float g = 1.0-smoothstep(0.0, thresh, 2.0*dm.r*dm.r); 
 return vec4(g,g,g, 1.0); 
kernel vec4 _pf_applyBlackDepth (__sample im, __sample dm, float g) 
 im.rgb *= pow(dm.r, g); 
 return im; 
kernel vec4 _pf_refineBlackDepth (__sample im, __sample dm, __sample bm, __sample protect, vec3 g, __sample aft) 
 float b = smoothstep(0.0, 1.0, pow(dm.r*bm.r,g.r)+protect.r); 
 im.rgb = max(im.rgb, 0.0); 
 vec3 gamma = (g.b) > 0.0 ? vec3(1.0+g.g-g.g*b*b*dm.r) : vec3(1.0+g.g-g.g*b*b); 
 im.rgb = pow(im.rgb, gamma); 
 im.rgb = mix(vec3(0.0), im.rgb, b); 
 gamma = vec3(1.35-.35*b*aft.r); 
 im.rgb = pow(im.rgb, gamma); 
 float r = im.r/(im.r+im.g+im.b+0.00001); 
 float sat = max(min(1.0, (1.3-.9*r)), 0.0); 
 float y = dot(im.rgb, vec3(.3333333)); 
 im.rgb = mix(sat*(im.rgb-y)+y, im.rgb, b*dm.r); 
 return im; 
kernel vec4 _pf_faceVignette1(__sample im, __sample vig, vec2 xy1, vec4 abc1) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, .4, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_faceProtect(__sample im, __sample vig, vec2 xy1, vec4 abc1, float feather) 
 float dx = xy1.x-destCoord().x ; 
 float dy = xy1.y-destCoord().y ; 
 float s = smoothstep(0.0, feather, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
 im.rgb = min(vig.rgb + vec3(s), 1.0); 
 return im; 
kernel vec4 _pf_faceAndBodyFill_1(__sample vig, vec2 xy1, vec4 abc1, vec2 fw, vec2 xy2) 
    vec2 dc = destCoord() ; 
    float dx = xy1.x-dc.x ; 
    float dy = xy1.y-dc.y ; 
    float s = smoothstep(0.0, .15, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
    float t = .025*distance(vec2(dc.x, xy2.y), dc); 
    t = (fw.g*xy2.y < fw.g*dc.y) ? 0.0 : min(t, 1.0); 
    float u = clamp(fw.g*1.5*fw.r*dy/(dx*dx+0.0001), 0.0, 1.0); 
    vig.rgb = min(vig.rgb + vec3(s) + t + (u*u*u)+.2, 1.0); 
    return vig; 
kernel vec4 _pf_faceAndBodyFill_6(__sample vig, vec2 xy1, vec4 abc1, vec2 fw, vec2 xy2) 
    vec2 dc = destCoord() ; 
    float dx = xy1.x-dc.x ; 
    float dy = xy1.y-dc.y ; 
    float s = smoothstep(0.0, .15, exp(-(abc1.r*dx*dx +2.0*abc1.g*dx*dy +abc1.b*dy*dy))) ; 
    float t = .025*distance(vec2(xy2.x, dc.y), dc); 
    t = (fw.g*xy2.x > fw.g*dc.x) ? 0.0 : min(t, 1.0); 
    float u = clamp(-fw.g*1.5*fw.r*dx/(dy*dy+0.0001), 0.0, 1.0); 
    vig.rgb = min(vig.rgb + vec3(s) + t + (u*u*u)+.2, 1.0); 
    return vig; 
kernel vec4 _pf_applyVignette(__sample im, __sample vig, float amt) 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = mix(im.rgb, im.rgb*(vig.rgb), amt); 
 im.rgb = mix(im.rgb, im.rgb*im.rgb, (1.0-vig.rgb)*.3); 
 return im; 
kernel vec4 _pf_adaptiveNormalization2(__sample disparityImage, float dFocus, float e, float zRange, float zRangeScale, float thresholdOffset, float thresholdScale) 
 float d = disparityImage.r; 
 float zCorrected = 1.0 / max(1e-1, (d - e)); 
 float zFCorrected = thresholdScale / max(1e-1, (dFocus - e)) + thresholdOffset; 
 float zEffRange = zRange + zRangeScale * zFCorrected; 
 float v = smoothstep(zFCorrected - zEffRange, zFCorrected + zEffRange, zCorrected); 
 return vec4(v, v, v, 1.0); 
kernel vec4 _pf_adaptiveNormalizationGPU(__sample disparityImage, __sample offsets, float zRange, float zRangeScale, float thresholdOffset, float thresholdScale) 
 float d = disparityImage.r; 
 float dFocus = offsets.r; 
 float e = offsets.g; 
 float zCorrected = 1.0 / max(1e-1, (d - e)); 
 float zFCorrected = thresholdScale / max(1e-1, (dFocus - e)) + thresholdOffset; 
 float zEffRange = zRange + zRangeScale * zFCorrected; 
 float v = smoothstep(zFCorrected - zEffRange, zFCorrected + zEffRange, zCorrected); 
 return vec4(v, v, v, 1.0); 
kernel vec4 _pf_adaptiveNormalizationAbsolute(__sample disparityImage, __sample offsets, float zRange, float zRangeScale, float thresholdOffset, float thresholdScale) 
 float d = disparityImage.r; 
 float dFocus = offsets.r; 
 float e = offsets.g; 
 float zCorrected = 1.0 / max(1e-1, (d - e)); 
 float zFCorrected = thresholdScale / max(1e-1, (dFocus - e)) + thresholdOffset; 
 float zEffRange = zRange + zRangeScale * zFCorrected; 
 float v = smoothstep(zFCorrected - zEffRange, zFCorrected + zEffRange, zCorrected); 
 zFCorrected = thresholdScale / max(1e-1, (dFocus - e)) + .25*thresholdOffset ; 
 zEffRange = zRange + zRangeScale * zFCorrected; 
 float v2 = smoothstep(zFCorrected - .04, zFCorrected + .04, zCorrected); 
 v = (1.75*v + v2)/2.75; 
 return vec4(v, v, v, 1.0); 
kernel vec4 _pf_invertRed(__sample rNormalized) __attribute__((outputFormat(kCIFormatRh))) 
 return vec4(1.0 - rNormalized.r, 0.0, 0.0, 1.0); 
kernel vec4 _pf_blendDepth(__sample depth, __sample tightDepth, __sample im, __sample blur, __sample weight) 
  float d = distance(im.rgb, blur.rgb); 
  float g = mix(tightDepth.r, depth.r, weight.r); 
  g += (d*weight.r*(1.0-dot(im.rgb, vec3(.333333)))); 
  g = clamp(g, 0.0, 1.0); 
  return vec4(g, g, g, 1.0); 
kernel vec4 _pf_thresholdMatte(__sample matte, __sample blurMatte, float low, float high) 
 float m = smoothstep(low, high, matte.r)*blurMatte.r; 
 matte.rgb *= m; 
 return matte; 
kernel vec4 _pf_thresholdAndApplyMatte(__sample im, __sample matte, __sample m2, vec4 params, float edgeGamma) 
 float low = params.x; float high = params.y; float gamma = params.z; float gain = params.w; float m = smoothstep(low, high, pow(matte.r, gamma+edgeGamma*m2.r)); 
 im.rgb *= m; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 im.rgb = pow(im.rgb, vec3(1.0+gain-gain*matte.r)); 
 im.rgb = mix(.5*im.rgb*im.rgb, im.rgb, 1.0-m2.r); 
 float r = im.r/(im.r+im.g+im.b+0.00001); 
 float sat = max(min(1.0, (1.0-r)), 0.0); 
 float y = dot(im.rgb, vec3(.3333333)); 
 im.rgb = mix(sat*(im.rgb-y)+y, im.rgb, m); 
 return im; 
Regions
RegionList
Type
Focus
CI_GPU_OFFSET_CALCULATOR
CIPortraitEffectContour
CIConfidenceThreshold
CI_OVERRIDE_MAX_NUM_VERTICES
CIPortraitPrepareStage
inputThresholdImage
float _computeZFromFaceRect(vec2 faceSize,float focalLengthNormalized, float marginError) 
  float kAverageFaceDiagonalBitragionBreadthMeters = 0.22f;  
  float d = length(faceSize) * marginError; 
  return (kAverageFaceDiagonalBitragionBreadthMeters  * focalLengthNormalized ) / d; 
kernel vec4 _pf_disparityError(__sample s0,__sample s1,__sample s2,__sample s3, 
                            vec4 faceSizes01,vec4 faceSizes23, 
                            vec4 valid,vec4 params,float marginError,float doDisparityError, __sample focusDisparity) 
   float kFaceDetectionRangeCloseMeters = params.x; 
   float kFaceDetectionRangeFarMeters   = params.y; 
   float faceGroupRange                 = params.z; 
    float focalLengthNormalized          = params.w; 
   float focusDisparityValue = focusDisparity.r; 
   float outDisparityOffsetError = 0.0; 
   vec4 faceAverageDisparities = vec4( s0.r, s1.r, s2.r, s3.r ); 
   if ( doDisparityError > 0.0 ) { 
      vec4 faceTrueZ = valid; 
      faceTrueZ.x = valid.x > 0.0 ? _computeZFromFaceRect(faceSizes01.xy, focalLengthNormalized, marginError) : -1.0; 
      faceTrueZ.y = valid.y > 0.0 ? _computeZFromFaceRect(faceSizes01.zw, focalLengthNormalized, marginError) : -1.0; 
      faceTrueZ.z = valid.z > 0.0 ? _computeZFromFaceRect(faceSizes23.xy, focalLengthNormalized, marginError) : -1.0; 
      faceTrueZ.w = valid.w > 0.0 ? _computeZFromFaceRect(faceSizes23.zw, focalLengthNormalized, marginError) : -1.0; 
      vec4 faceTrueDisparity = vec4(1.0) / faceTrueZ; 
      bool R = valid.x > 0.0 && (faceTrueZ.r >= kFaceDetectionRangeCloseMeters) && (faceTrueZ.r <= kFaceDetectionRangeFarMeters); 
      bool G = valid.y > 0.0 && (faceTrueZ.g >= kFaceDetectionRangeCloseMeters) && (faceTrueZ.g <= kFaceDetectionRangeFarMeters); 
      bool B = valid.z > 0.0 && (faceTrueZ.b >= kFaceDetectionRangeCloseMeters) && (faceTrueZ.b <= kFaceDetectionRangeFarMeters); 
      bool A = valid.w > 0.0 && (faceTrueZ.a >= kFaceDetectionRangeCloseMeters) && (faceTrueZ.a <= kFaceDetectionRangeFarMeters); 
      vec4 e = compare( vec4(R, G, B, A) - vec4(0.01), vec4(0.0), faceAverageDisparities - faceTrueDisparity); 
      float eSum = e.r + e.g + e.b + e.a; 
      int countFacesForDisparityError = int(R) + int(G) + int(B) + int(A); 
      outDisparityOffsetError = countFacesForDisparityError > 0 ? eSum / float(countFacesForDisparityError) : 0.0; 
   } 
   float focusDepth = 1.0 / max(1e-1, (focusDisparityValue - outDisparityOffsetError)); 
   vec4 faceDepth   = vec4(1.0) / max( vec4(1e-1), faceAverageDisparities - vec4(outDisparityOffsetError) ); 
   float faceDisparityFarBackground = 1000000.0; 
   bool haveIdx = false; 
   float depthPlusRange = focusDepth + faceGroupRange; 
   if ( valid.x > 0.0 && faceDepth.x < depthPlusRange && faceAverageDisparities.x < faceDisparityFarBackground ) { 
      faceDisparityFarBackground = faceAverageDisparities.x; 
      haveIdx = true; 
   } 
   if ( valid.y > 0.0 && faceDepth.y < depthPlusRange && faceAverageDisparities.y < faceDisparityFarBackground ) { 
      faceDisparityFarBackground = faceAverageDisparities.y; 
      haveIdx = true; 
   } 
   if ( valid.z > 0.0 && faceDepth.z < depthPlusRange && faceAverageDisparities.z < faceDisparityFarBackground ) { 
      faceDisparityFarBackground = faceAverageDisparities.z; 
      haveIdx = true; 
   } 
   if ( valid.w > 0.0 && faceDepth.w < depthPlusRange && faceAverageDisparities.w < faceDisparityFarBackground ) { 
      faceDisparityFarBackground = faceAverageDisparities.w; 
      haveIdx = true; 
   } 
   return vec4(haveIdx ? faceDisparityFarBackground : focusDisparityValue, outDisparityOffsetError, 0.0, 1.0); 
-[CIPortraitSkinMask outputImage]
CIPortraitSkinMask.mm
+[CIPortraitSkinMaskProcessor processWithInputs:arguments:output:error:]
CGPointMakeWithVisionDictionaryRepresentationAndTransform( pointDictionary, faceRectInBuffer, &leftEye )
CGPointMakeWithVisionDictionaryRepresentationAndTransform( pointDictionary, faceRectInBuffer, &rightEye )
CGRectMakeWithVisionDictionaryRepresentation( faceLandmarkDictionary[@"faceBoundingBox"], &faceBoundingBox)
leftEyePoints
rightEyePoints
leftEyePoints.count == 8
rightEyePoints.count == 8
CGPointMakeWithVisionDictionaryRepresentationAndTransform( leftEyePoints[i], faceRectInBuffer, &pnt)
CGPointMakeWithVisionDictionaryRepresentationAndTransform( rightEyePoints[i], faceRectInBuffer, &pnt)
+[CIPortraitSkinMaskProcessor roiForInput:arguments:outputRect:]
PFBoxBlur3_7
PFSobelHV
CIMorphologicalMax5Mono
CIConfidenceThresholdProcessor
CIConfidenceThreshold
CIPortraitPrepareStage
CIConfidenceMap
CIPortraitLightingSide
CIPortraitLightingFront
CIPortraitLightingStrobe
CIPortraitLightingContour
CIPortraitLightingSpot
CIPortraitLightingNeckContour
CIPortraitLightingStudio
CIPortraitLightingStrobeV2
CIPortraitLightingContourV2
CIPortraitLightingEdge
PortraitFilters
CameraImaging
CIPortraitFaceMask
CIPortraitFaceMaskProcessorKernel
CISRGBtoIPT
CIIPTtoSRGB
CIHueChromaHistProcessor
CIAveColorProcessor
CIColorGradientProcessor
CISmartGradient
CIPortraitContour
CIDynamicGuidedFilter
CIDynamicLocalLightMapPrepare
CILLFilter
PortraitEffetcPrewarm
CIPortraitEffectV2
CIPortraitEffectLightV2
CIPortraitEffectStudioV2
CIPortraitEffectContourV2
CIPortraitEffectStageV2
CIPortraitEffectStageMonoV2
CIPortraitEffectStageWhite
FaceLandmarks
ComputedFaceData
LightingFacePoints
CIPortraitToothMask
CIPortraitToothMaskProcessor
CPUFaceMask
CIBrightenSat
CIBrightenFood
Rgon
NSCopying
NSCoding
RgonStack
Polyline
PolylinePair
TopBottomRegion
CIDynamicRender
CIDynamicFood
CIHighKey
CIPortraitLocalContrast
CIPortraitEffect
CIPortraitEffectLight
CIPortraitEffectCommercial
CIPortraitEffectStudio
CIPortraitEffectContour
CIPortraitEffectBlack
CIPortraitEffectStage
CIPortraitEffectBlackoutMono
CIPortraitEffectStageMono
CIPortraitSkinMask
CIPortraitSkinMaskProcessor
@16@0:8
v24@0:8@16
@"CIImage"
B48@0:8@16@24@32^@40
i16@0:8
B16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}60@0:8i16@20{CGRect={CGPoint=dd}{CGSize=dd}}28
i20@0:8i16
@"CIVector"
@"NSNumber"
@24@0:8@16
v20@0:8i16
f16@0:8
v20@0:8f16
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
@"NSDictionary"
@32@0:8@16f24f28
@40@0:8@16@24@32
@"LightingFacePoints"
@"NSData"
@20@0:8f16
v44@0:8@16@24@32B40
v28@0:8@16B24
@"NSArray"
v16@0:8
@32@0:8@16@24
@36@0:8@16@24i32
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
^{CGPath=}16@0:8
v24@0:8^{CGPath=}16
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
[4{CGPoint="x"d"y"d}]
[7{CGPoint="x"d"y"d}]
[5{CGPoint="x"d"y"d}]
[6{CGPoint="x"d"y"d}]
[11{CGPoint="x"d"y"d}]
[9{CGPoint="x"d"y"d}]
[3{CGPoint="x"d"y"d}]
{CGPoint="x"d"y"d}
@"ComputedFaceData"
@"Polyline"
@"PolylinePair"
^{CGPath=}
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
^{CGPoint=dd}16@0:8
v24@0:8^{CGPoint=dd}16
d16@0:8
v24@0:8d16
v20@0:8B16
[65{CGPoint="x"d"y"d}]
[10{CGPoint="x"d"y"d}]
[20{CGPoint="x"d"y"d}]
^{CGPoint=dd}
@"Rgon"
[2{CGPoint="x"d"y"d}]
i64@0:8*16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32
i72@0:8r*16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32[4{CGPoint=dd}]64
i164@0:8r*16Q24{CGRect={CGPoint=dd}{CGSize=dd}}32*64Q72{CGRect={CGPoint=dd}{CGSize=dd}}80{CGRect={CGPoint=dd}{CGSize=dd}}112^{CGPoint=dd}144Q152C160
i72@0:8^{MetalFaceMaskEyeQuads_t=IIC[16{MetalFaceMaskQuad_t=}]}16*24Q32{CGRect={CGPoint=dd}{CGSize=dd}}40
{CPUColorCube="data"[32768C]}
{MetalFaceMaskCubeInputScaling_t="offset""scale"}
@36@0:8@16@24f32
@24@0:8^{_NSZone=}16
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
^f20@0:8f16
i24@0:8f16f20
f24@0:8i16f20
f36@0:8i16f20i24@28
v24@0:8^f16
v28@0:8f16f20f24
i36@0:8f16f20^i24i32
i36@0:8f16f20f24^i28
f20@0:8i16
f24@0:8f16f20
f24@0:8@16
v32@0:8i16i20[2f]24
{?=ff}24@0:8i16i20
B32@0:8@16@24
^[7f]16@0:8
v24@0:8^[7f]16
q16@0:8
v24@0:8q16
^f16@0:8
[32[7f]]
^[7f]
v40@0:8d16d24d32
i28@0:8f16f20f24
f28@0:8f16f20f24
i36@0:8f16f20f24f28f32
i44@0:8f16f20f24f28f32f36B40
v52@0:8@16f24@28f36i40^f44
@"NSMutableArray"
@40@0:8f16f20{CGPoint=dd}24
B24@0:8f16f20
{CGPoint=dd}24@0:8d16
{CGPoint=dd}20@0:8f16
v24@0:8f16f20
I16@0:8
v20@0:8I16
@"NSMutableData"
@52@0:8i16{CGRect={CGPoint=dd}{CGSize=dd}}20
{?={CGPoint=dd}{CGPoint=dd}}16@0:8
{?=ddddd}24@0:8@16
@36@0:8@16f24i28f32
Q40@0:8@16@24@32
B20@0:8i16
333333
333333
ffffff
333333
ffffff
333333
333333
ffffff
ffffff
333333
333333
333333
333333
ffffff
ffffff
ffffff
333333
ffffff
333333
333333
ffffff
333333
