v8@?0
com.apple.mobileslideshow
CI_DEBUG_AUTOCROP
scaleRect:inner=(%.3f,%.3f,%.3f,%.3f), size=(%.3f,%.3f), anchor=(%.3f,%.3f)
ERROR <AutoCropper>: Point should be within rect
{CGRect={CGPoint=dd}{CGSize=dd}}
AspectRatioCutoff
MinimumCroppedArea
ProximityToCenter
Face area is %f, Total is %f
Large Face!
ERROR <AutoCropper>: unrecognized aspect ratio
No Crop. Reduces area too much
Clipping to original aspect ratio
Clipping to aspect ratio 4:3
Clipping to aspect ratio 3:2
Clipping to aspect ratio 16:9
Clipping to square
Clipping to aspect ratio 5:3
Clipping to aspect ratio 5:4
MinCropPercentage
determineBestPositionWithinSize:size=%.3f,%.3f, center=%.3f,%.3f, minPercentage=%.3f, restrict=%.3f,%.3f,%.3f,%.3f
originalArea = %.2f
pos = %d, rect=(%.2f,%.2f,%.2f,%.2f), area=%.2f
    topleft=%.2f
    topcenter=%.2f
    topright=%.2f
    bottomleft=%.2f
    bottomcenter=%.2f
    bottomright=%.2f
    leftcenter=%.2f
    rightcenter=%.2f
    center=%.2f
Best is %d
Want bottom
-[CIBilateralGridHash createWithSurface:region:cropRect:sigma_s:sigma_r_luma:sigma_r_chroma:]
-[CIBilateralGridHash _computeBilateralSpaceYCC444:region:cropRect:sigma_s:sigma_r_luma:sigma_r_chroma:]
BilateralGridHash.m
t == kCVPixelFormatType_32BGRA
region.size.width == surfaceW
region.size.height == surfaceH
w > 0 && h > 0
w <= surfaceW
h <= surfaceH
-[CIBilateralSolverGPU _setupPipelineCache]
BilateralSolverGPU.m
[pipelineArray count] == COMPUTE_COUNT
v24@?0@"<MTLComputePipelineState>"8@"NSError"16
fbs_bistochastize_init
fbs_bistochastize_iter
fbs_bistochastize_final
fbs_pcg_init
fbs_pcg_iter1
fbs_pcg_iter2
fbs_pcg_iter3
fbs_slice
fbs_slice_trilinear
%3d 
copySliceOfBitmapToBitmap: bytes per sample or samples per pixel differs!
copyBitmapToSliceOfBitmap: bytes per sample or samples per pixel differs!
bitmapToBitmapDifferenceBitmapRect: source pixel configuration illegal
initBitmask:b
initBitmask:b->body
initBitmask: bitmap record can not be allocated
initBitmask: bitmap body can not be allocated
termBitmask: bitmap was null
bitmaskMinus: bitmasks have different shapes
10.10
inputBottomHeight
inputNumberOfFolds
inputFoldShadowAmount
inputTime
kernel vec2 _accordianWarpS (vec3 foldParms, vec4 dims) 
 float numFoldsX2 = foldParms.x; 
 float foldScaleH = foldParms.y; 
 float bottomHeight = dims.x; 
 float gap = dims.y; 
 vec2 dc = destCoord(); 
 float x = dc.x; 
 float y = dc.y; 
 float gapLoc = clamp((y - bottomHeight) / gap, 0.0, 1.0); 
 float gapLocSaw = 1.0 - abs(mod((numFoldsX2*gapLoc), 2.0) - 1.0); 
 float hScale = 1.0 + foldScaleH*gapLocSaw; 
 vec2 pS; 
 pS.y = min( y, max( y-gap, bottomHeight)); 
 pS.x = x * hScale; 
 return pS; 
kernel vec2 _accordianWarpT (vec3 foldParms, vec4 dims) 
 float numFoldsX2 = foldParms.x; 
 float foldScaleH = foldParms.y; 
 float bottomHeight = dims.x; 
 float gap = dims.y; 
 vec2 dc = destCoord(); 
 float x = dc.x; 
 float y = dc.y; 
 float gapLoc = clamp((y - bottomHeight) / gap, 0.0, 1.0); 
 float gapLocSaw = 1.0 - abs(mod((numFoldsX2*gapLoc), 2.0) - 1.0); 
 float hScale = 1.0 + foldScaleH*gapLocSaw; 
 vec2 pT; 
 pT.y = max( y, min ( (y-bottomHeight)*dims.z + bottomHeight, y+dims.w )); 
 pT.x = x * hScale; 
 return pT; 
kernel vec4 _accordionMix ( 
 __sample cS, __sample cT, 
 vec3 foldParms, float time, vec4 dims) 
 float numFoldsX2 = foldParms.x; 
 float foldShadeAmt = foldParms.z; 
 float bottomHeight = dims.x; 
 float gap = dims.y; 
 vec2 dc = destCoord(); 
 float y = dc.y; 
 float gapLoc = clamp((y - bottomHeight) / gap, 0.0, 1.0); 
 float shadeAmt = 1.0 - foldShadeAmt*mod((numFoldsX2*gapLoc), 1.0); 
 vec4 result = mix(cS, cT, time); 
 result.rgb *= shadeAmt; 
 return result; 
kernel vec4 _accordionFoldTransition ( 
 sampler shortImage, sampler tallImage, 
 vec3 foldParms, float time, vec4 dims) 
 float numFoldsX2 = foldParms.x; 
 float foldScaleH = foldParms.y; 
 float foldShadeAmt = foldParms.z; 
 float bottomHeight = dims.x; 
 float gap = dims.y; 
 vec2 dc = destCoord(); 
 float x = dc.x; 
 float y = dc.y; 
 float gapLoc = clamp((y - bottomHeight) / gap, 0.0, 1.0); 
 float gapLocSaw = 1.0 - abs(mod((numFoldsX2*gapLoc), 2.0) - 1.0); 
 float shadeAmt = 1.0 - foldShadeAmt*mod((numFoldsX2*gapLoc), 1.0); 
 float hScale = 1.0 + foldScaleH*gapLocSaw; 
 vec2 pS; 
 pS.y = min( y, max( y-gap, bottomHeight)); 
 pS.x = x * hScale; 
 vec4 cS = sample(shortImage, samplerTransform(shortImage, pS)); 
 vec2 pT; 
 pT.y = max( y, min ( (y-bottomHeight)*dims.z + bottomHeight, y+dims.w )); 
 pT.x = x * hScale; 
 vec4 cT = sample(tallImage, samplerTransform(tallImage, pT)); 
 vec4 result = mix(cS, cT, time); 
 result.rgb *= shadeAmt; 
 return result; 
{CGRect={CGPoint=dd}{CGSize=dd}}44@?0i8{CGRect={CGPoint=dd}{CGSize=dd}}12
10.12
10.4
{CGAffineTransform=dddddd}
kernel vec2 _tile(vec2 origin, vec4 scaling) {return fract((destCoord() - origin) * scaling.zw) * scaling.xy + origin;} 
kernel vec2 _lowq_affine(vec2 center, vec2 xvec, vec2 yvec) 
 vec2 p = destCoord(); 
 return center + vec2(dot(p, xvec), dot(p, yvec)); 
CISimpleTile
http://ns.apple.com/adjustment-settings/1.0/
AffineA
AffineB
AffineC
AffineD
AffineX
AffineY
10.14
kernel vec4 _ASGh50(sampler src) 
 vec2 dc = destCoord(); 
 vec2 srcPt = vec2(floor(floor(dc.x) * 2.0 + 0.499) + 0.5, dc.y); 
 vec2 d = samplerTransform(src, vec2(1.0, 0.0)) - samplerTransform(src, vec2(0.0)); 
 vec2 coord = samplerTransform(src, srcPt); 
 vec4 p = sample(src, coord) * 0.500106; 
 p += (sample(src, coord + d) + sample(src, coord - d)) * 0.294604; 
 p -= (sample(src, coord + d*3.0) + sample(src, coord - d*3.0)) * 0.0507232; 
 p += (sample(src, coord + d*5.0) + sample(src, coord - d*5.0)) * 0.00606636; 
 return p; 
kernel vec4 _ASGv50(sampler src) 
 vec2 dc = destCoord(); 
 vec2 srcPt = vec2(dc.x, floor(floor(dc.y) * 2.0 + 0.499) + 0.5); 
 vec2 d = samplerTransform(src, vec2(0.0, 1.0)) - samplerTransform(src, vec2(0.0)); 
 vec2 coord = samplerTransform(src, srcPt); 
 vec4 p = sample(src, coord) * 0.500106; 
 p += (sample(src, coord + d) + sample(src, coord - d)) * 0.294604; 
 p -= (sample(src, coord + d*3.0) + sample(src, coord - d*3.0)) * 0.0507232; 
 p += (sample(src, coord + d*5.0) + sample(src, coord - d*5.0)) * 0.00606636; 
 return p; 
kernel vec4 _ASGh66(sampler src) { vec2 dc = destCoord(); 
 float residue = floor(fract(dc.x/2.0)*2.0); 
 vec2 srcPt = vec2(floor(floor(dc.x) * 1.5 + 0.499) + 0.5, dc.y); 
 vec2 d = samplerTransform(src, vec2(1.0, 0.0)) - samplerTransform(src, vec2(0.0)); 
 vec2 d2 = d + d; 
 vec2 d3 = d2 + d; 
 vec2 d4 = d2 + d2; 
 vec2 coord = samplerTransform(src, srcPt); 
 vec4 s0 = sample(src, coord - d4); 
 vec4 s1 = sample(src, coord - d3); 
 vec4 s2 = sample(src, coord - d2); 
 vec4 s3 = sample(src, coord - d ); 
 vec4 s4 = sample(src, coord ); 
 vec4 s5 = sample(src, coord + d ); 
 vec4 s6 = sample(src, coord + d2); 
 vec4 s7 = sample(src, coord + d3); 
 vec4 s8 = sample(src, coord + d4); 
 vec4 index0pix = s4*0.6665609 + (s3+s5)*0.2399313 - (s2+s6)*0.0775183 + (s0+s8)*0.0043066; 
 vec4 index1pix = (s4+s5)*0.5328763 - (s2+s7)*0.0436967 + (s1+s8)*0.0108204; 
 return mix(index0pix, index1pix, residue); 
kernel vec4 _ASGv66(sampler src) 
 vec2 dc = destCoord(); 
 float residue = floor(fract(dc.y/2.0)*2.0); 
 vec2 srcPt = vec2(dc.x, floor(floor(dc.y) * 1.5 + 0.499) + 0.5); 
 vec2 d = samplerTransform(src, vec2(0.0, 1.0)) - samplerTransform(src, vec2(0.0)); 
 vec2 d2 = d + d; 
 vec2 d3 = d2 + d; 
 vec2 d4 = d2 + d2; 
 vec2 coord = samplerTransform(src, srcPt); 
 vec4 s0 = sample(src, coord - d4); 
 vec4 s1 = sample(src, coord - d3); 
 vec4 s2 = sample(src, coord - d2); 
 vec4 s3 = sample(src, coord - d ); 
 vec4 s4 = sample(src, coord ); 
 vec4 s5 = sample(src, coord + d ); 
 vec4 s6 = sample(src, coord + d2); 
 vec4 s7 = sample(src, coord + d3); 
 vec4 s8 = sample(src, coord + d4); 
 vec4 index0pix = s4*0.6665609 + (s3+s5)*0.2399313 - (s2+s6)*0.0775183 + (s0+s8)*0.0043066; 
 vec4 index1pix = (s4+s5)*0.5328763 - (s2+s7)*0.0436967 + (s1+s8)*0.0108204; 
 return mix(index0pix, index1pix, residue); 
kernel vec4 _ASGh75(sampler src) 
 vec2 dc = destCoord(); 
 float residue = floor(fract(dc.x/3.0)*3.0); 
 vec2 srcPt = vec2(floor(floor(dc.x) * 1.3333333333 + 0.5) + 0.5, dc.y); 
 vec2 d = samplerTransform(src, vec2(1.0, 0.0)) - samplerTransform(src, vec2(0.0)); 
 vec2 d2 = d + d; 
 vec2 d3 = d2 + d; 
 vec2 d4 = d2 + d2; 
 vec2 coord = samplerTransform(src, srcPt); 
 vec4 s0 = sample(src, coord - d4); 
 vec4 s1 = sample(src, coord - d3); 
 vec4 s2 = sample(src, coord - d2); 
 vec4 s3 = sample(src, coord - d ); 
 vec4 s4 = sample(src, coord ); 
 vec4 s5 = sample(src, coord + d ); 
 vec4 s6 = sample(src, coord + d2); 
 vec4 s7 = sample(src, coord + d3); 
 vec4 s8 = sample(src, coord + d4); 
 vec4 index0pix = s4*0.7502581 + (s3+s5)*0.1888096 - (s2+s6)*0.0760948 + (s1+s7)*0.0121562; 
 vec4 index1pix = -s0*0.0003689 + s1*0.0090998 - s2*0.0344513 + s4*0.6624862 + s5*0.4419191 - s6*0.0817168 + s8*0.0030319; 
 vec4 index2pix = s0*0.0030319 - s2*0.0817168 + s3*0.4419191 + s4*0.6624862 - s6*0.0344513 + s7*0.0090998 - s8*0.0003689; 
 vec4 pix = mix(index0pix, index1pix, min(residue, 1.0)); 
 return mix(pix, index2pix, max(residue - 1.0, 0.0)); 
kernel vec4 _ASGv75(sampler src) 
 vec2 dc = destCoord(); 
 float residue = floor(fract(dc.y/3.0)*3.0); 
 vec2 srcPt = vec2(dc.x, floor(floor(dc.y) * 1.3333333333 + 0.5) + 0.5); 
 vec2 d = samplerTransform(src, vec2(0.0, 1.0)) - samplerTransform(src, vec2(0.0)); 
 vec2 d2 = d + d; 
 vec2 d3 = d2 + d; 
 vec2 d4 = d2 + d2; 
 vec2 coord = samplerTransform(src, srcPt); 
 vec4 s0 = sample(src, coord - d4); 
 vec4 s1 = sample(src, coord - d3); 
 vec4 s2 = sample(src, coord - d2); 
 vec4 s3 = sample(src, coord - d ); 
 vec4 s4 = sample(src, coord ); 
 vec4 s5 = sample(src, coord + d ); 
 vec4 s6 = sample(src, coord + d2); 
 vec4 s7 = sample(src, coord + d3); 
 vec4 s8 = sample(src, coord + d4); 
 vec4 index0pix = s4*0.7502581 + (s3+s5)*0.1888096 - (s2+s6)*0.0760948 + (s1+s7)*0.0121562; 
 vec4 index1pix = -s0*0.0003689 + s1*0.0090998 - s2*0.0344513 + s4*0.6624862 + s5*0.4419191 - s6*0.0817168 + s8*0.0030319; 
 vec4 index2pix = s0*0.0030319 - s2*0.0817168 + s3*0.4419191 + s4*0.6624862 - s6*0.0344513 + s7*0.0090998 - s8*0.0003689; 
 vec4 pix = mix(index0pix, index1pix, min(residue, 1.0)); 
 return mix(pix, index2pix, max(residue - 1.0, 0.0)); 
kernel vec4 _ASGh80(sampler src) 
 vec2 dc = destCoord(); 
 float residue = floor(fract(dc.x/4.0)*4.0); 
 vec2 srcPt = vec2(floor(floor(dc.x) * 1.25 + 0.499) + 0.5, dc.y); 
 vec2 d = samplerTransform(src, vec2(1.0, 0.0)) - samplerTransform(src, vec2(0.0)); 
 vec2 d2 = d + d; 
 vec2 d3 = d2 + d; 
 vec2 d4 = d2 + d2; 
 vec2 coord = samplerTransform(src, srcPt); 
 vec4 s0 = sample(src, coord - d4); 
 vec4 s1 = sample(src, coord - d3); 
 vec4 s2 = sample(src, coord - d2); 
 vec4 s3 = sample(src, coord - d ); 
 vec4 s4 = sample(src, coord ); 
 vec4 s5 = sample(src, coord + d ); 
 vec4 s6 = sample(src, coord + d2); 
 vec4 s7 = sample(src, coord + d3); 
 vec4 s8 = sample(src, coord + d4); 
 vec4 index0pix = s4*0.8002434 + (s3+s5)*0.1531180 - (s2+s6)*0.0648618 + (s1+s7)*0.0120488 - (s0+s8)*0.0004266; 
 vec4 index1pix = -s0*0.0002116 + s1*0.0069449 - s2*0.0278111 + s4*0.7394604 + s5*0.3609697 - s6*0.0914600 + s7*0.0121077; 
 vec4 index2pix = (s4+s5)*0.5763899 - (s3+s6)*0.0786414 + (s1+s8)*0.0022716 - s0*0.0000403; 
 vec4 index3pix = s1*0.0121077 - s2*0.0914600 + s3*0.3609697 + s4*0.7394604 - s6*0.0278111 + s7*0.0069449 - s8*0.0002116; 
 vec4 pix = mix(index0pix, index1pix, min(residue, 1.0)); 
 pix = mix(pix, index2pix, max(residue - 1.0, 0.0)); 
 return mix(pix, index3pix, max(residue - 2.0, 0.0)); 
kernel vec4 _ASGv80(sampler src) 
 vec2 dc = destCoord(); 
 float residue = floor(fract(dc.y/4.0)*4.0); 
 vec2 srcPt = vec2(dc.x, floor(floor(dc.y) * 1.25 + 0.499) + 0.5); 
 vec2 d = samplerTransform(src, vec2(0.0, 1.0)) - samplerTransform(src, vec2(0.0)); 
 vec2 d2 = d + d; 
 vec2 d3 = d2 + d; 
 vec2 d4 = d2 + d2; 
 vec2 coord = samplerTransform(src, srcPt); 
 vec4 s0 = sample(src, coord - d4); 
 vec4 s1 = sample(src, coord - d3); 
 vec4 s2 = sample(src, coord - d2); 
 vec4 s3 = sample(src, coord - d ); 
 vec4 s4 = sample(src, coord ); 
 vec4 s5 = sample(src, coord + d ); 
 vec4 s6 = sample(src, coord + d2); 
 vec4 s7 = sample(src, coord + d3); 
 vec4 s8 = sample(src, coord + d4); 
 vec4 index0pix = s4*0.8002434 + (s3+s5)*0.1531180 - (s2+s6)*0.0648618 + (s1+s7)*0.0120488 - (s0+s8)*0.0004266; 
 vec4 index1pix = -s0*0.0002116 + s1*0.0069449 - s2*0.0278111 + s4*0.7394604 + s5*0.3609697 - s6*0.0914600 + s7*0.0121077; 
 vec4 index2pix = (s4+s5)*0.5763899 - (s3+s6)*0.0786414 + (s1+s8)*0.0022716 - s0*0.0000403; 
 vec4 index3pix = s1*0.0121077 - s2*0.0914600 + s3*0.3609697 + s4*0.7394604 - s6*0.0278111 + s7*0.0069449 - s8*0.0002116; 
 vec4 pix = mix(index0pix, index1pix, min(residue, 1.0)); 
 pix = mix(pix, index2pix, max(residue - 1.0, 0.0)); 
 return mix(pix, index3pix, max(residue - 2.0, 0.0)); 
kernel vec4 _ASGh60(sampler src) 
 vec2 dc = destCoord(); 
 float residue = floor(fract(dc.x/3.0)*3.0); 
 vec2 srcPt = vec2(floor(floor(dc.x) / 0.60 + 0.499) + 0.5, dc.y); 
 vec2 d = samplerTransform(src, vec2(1.0, 0.0)) - samplerTransform(src, vec2(0.0)); 
 vec2 d2 = d + d; 
 vec2 d3 = d2 + d; 
 vec2 d4 = d2 + d2; 
 vec2 coord = samplerTransform(src, srcPt); 
 vec4 s0 = sample(src, coord - d4); 
 vec4 s1 = sample(src, coord - d3); 
 vec4 s2 = sample(src, coord - d2); 
 vec4 s3 = sample(src, coord - d ); 
 vec4 s4 = sample(src, coord ); 
 vec4 s5 = sample(src, coord + d ); 
 vec4 s6 = sample(src, coord + d2); 
 vec4 s7 = sample(src, coord + d3); 
 vec4 s8 = sample(src, coord + d4); 
 vec4 index0pix = s4*0.600173 + (s3+s5)*0.270712 - (s2+s6)*0.0589776 - (s1+s7)*0.0208571 + (s0+s8)*0.00903642; 
 vec4 index1pix = s0*0.0090808 - s1*0.0486483 + s3*0.432291 + s4*0.554595 + s5*0.114843 - s6*0.0685949 + s8*0.00520863; 
 vec4 index2pix = s0*0.00520863 - s2*0.0685949 + s3*0.114843 + s4*0.554595 + s5*0.432291 - s7*0.0486483 + s8*0.0090808; 
 vec4 pix = mix(index0pix, index1pix, min(residue, 1.0)); 
 return mix(pix, index2pix, max(residue - 1.0, 0.0)); 
kernel vec4 _ASGv60(sampler src) 
 vec2 dc = destCoord(); 
 float residue = floor(fract(dc.y/3.0)*3.0); 
 vec2 srcPt = vec2(dc.x, floor(floor(dc.y) / 0.60 + 0.499) + 0.5); 
 vec2 d = samplerTransform(src, vec2(0.0, 1.0)) - samplerTransform(src, vec2(0.0)); 
 vec2 d2 = d + d; 
 vec2 d3 = d2 + d; 
 vec2 d4 = d2 + d2; 
 vec2 coord = samplerTransform(src, srcPt); 
 vec4 s0 = sample(src, coord - d4); 
 vec4 s1 = sample(src, coord - d3); 
 vec4 s2 = sample(src, coord - d2); 
 vec4 s3 = sample(src, coord - d ); 
 vec4 s4 = sample(src, coord ); 
 vec4 s5 = sample(src, coord + d ); 
 vec4 s6 = sample(src, coord + d2); 
 vec4 s7 = sample(src, coord + d3); 
 vec4 s8 = sample(src, coord + d4); 
 vec4 index0pix = s4*0.600173 + (s3+s5)*0.270712 - (s2+s6)*0.0589776 - (s1+s7)*0.0208571 + (s0+s8)*0.00903642; 
 vec4 index1pix = s0*0.0090808 - s1*0.0486483 + s3*0.432291 + s4*0.554595 + s5*0.114843 - s6*0.0685949 + s8*0.00520863; 
 vec4 index2pix = s0*0.00520863 - s2*0.0685949 + s3*0.114843 + s4*0.554595 + s5*0.432291 - s7*0.0486483 + s8*0.0090808; 
 vec4 pix = mix(index0pix, index1pix, min(residue, 1.0)); 
 return mix(pix, index2pix, max(residue - 1.0, 0.0)); 
CILanczosScaleTransform
float _asgh (float x) 
 x = abs(x); 
 if (x >= 3.0) return 0.0; 
 if (x < 1e-6) return 1.0; 
 x *= 3.141592653589793; 
 float sinc = sin(x)/x; 
 float asgw = cos(x/8.0); 
 return sinc * asgw * asgw * asgw * asgw; 
 kernel vec4 _asgDownH(sampler src, vec4 scale, float z) 
 vec2 c = destCoord() * scale.xy; 
 vec2 pm1 = vec2(floor(c.x-0.5)+0.5, c.y); 
 vec2 pm6 = pm1 - scale.zw * 5.0; 
 vec2 pm5 = pm1 - scale.zw * 4.0; 
 vec2 pm4 = pm1 - scale.zw * 3.0; 
 vec2 pm3 = pm1 - scale.zw * 2.0; 
 vec2 pm2 = pm1 - scale.zw * 1.0; 
 vec2 pp1 = pm1 + scale.zw * 1.0; 
 vec2 pp2 = pm1 + scale.zw * 2.0; 
 vec2 pp3 = pm1 + scale.zw * 3.0; 
 vec2 pp4 = pm1 + scale.zw * 4.0; 
 vec2 pp5 = pm1 + scale.zw * 5.0; 
 vec2 pp6 = pm1 + scale.zw * 6.0; 
 vec4 vm6 = sample(src, samplerTransform(src, pm6)); 
 vec4 vm5 = sample(src, samplerTransform(src, pm5)); 
 vec4 vm4 = sample(src, samplerTransform(src, pm4)); 
 vec4 vm3 = sample(src, samplerTransform(src, pm3)); 
 vec4 vm2 = sample(src, samplerTransform(src, pm2)); 
 vec4 vm1 = sample(src, samplerTransform(src, pm1)); 
 vec4 vp1 = sample(src, samplerTransform(src, pp1)); 
 vec4 vp2 = sample(src, samplerTransform(src, pp2)); 
 vec4 vp3 = sample(src, samplerTransform(src, pp3)); 
 vec4 vp4 = sample(src, samplerTransform(src, pp4)); 
 vec4 vp5 = sample(src, samplerTransform(src, pp5)); 
 vec4 vp6 = sample(src, samplerTransform(src, pp6)); 
 float wm6 = _asgh((pm6.x-c.x)/scale.x + z); 
 float wm5 = _asgh((pm5.x-c.x)/scale.x + z); 
 float wm4 = _asgh((pm4.x-c.x)/scale.x + z); 
 float wm3 = _asgh((pm3.x-c.x)/scale.x + z); 
 float wm2 = _asgh((pm2.x-c.x)/scale.x + z); 
 float wm1 = _asgh((pm1.x-c.x)/scale.x + z); 
 float wp1 = _asgh((pp1.x-c.x)/scale.x + z); 
 float wp2 = _asgh((pp2.x-c.x)/scale.x + z); 
 float wp3 = _asgh((pp3.x-c.x)/scale.x + z); 
 float wp4 = _asgh((pp4.x-c.x)/scale.x + z); 
 float wp5 = _asgh((pp5.x-c.x)/scale.x + z); 
 float wp6 = _asgh((pp6.x-c.x)/scale.x + z); 
 float wsum = wm6+wm5+wm4+wm3+wm2+wm1+wp1+wp2+wp3+wp4+wp5+wp6; 
 return (wm6*vm6 + wm5*vm5 + wm4*vm4 + wm3*vm3 + wm2*vm2 + wm1*vm1 + 
 wp6*vp6 + wp5*vp5 + wp4*vp4 + wp3*vp3 + wp2*vp2 + wp1*vp1)/wsum; 
float _asgv (float x) 
 x = abs(x); 
 if (x >= 3.0) return 0.0; 
 if (x < 1e-6) return 1.0; 
 x *= 3.141592653589793; 
 float sinc = sin(x)/x; 
 float asgw = cos(x/8.0); 
 return sinc * asgw * asgw * asgw * asgw; 
 kernel vec4 _asgDownV(sampler src, vec4 scale, float z) 
 vec2 c = destCoord() * scale.xy; 
 vec2 pm1 = vec2(c.x, floor(c.y-0.5)+0.5); 
 vec2 pm6 = pm1 - scale.zw * 5.0; 
 vec2 pm5 = pm1 - scale.zw * 4.0; 
 vec2 pm4 = pm1 - scale.zw * 3.0; 
 vec2 pm3 = pm1 - scale.zw * 2.0; 
 vec2 pm2 = pm1 - scale.zw * 1.0; 
 vec2 pp1 = pm1 + scale.zw * 1.0; 
 vec2 pp2 = pm1 + scale.zw * 2.0; 
 vec2 pp3 = pm1 + scale.zw * 3.0; 
 vec2 pp4 = pm1 + scale.zw * 4.0; 
 vec2 pp5 = pm1 + scale.zw * 5.0; 
 vec2 pp6 = pm1 + scale.zw * 6.0; 
 vec4 vm6 = sample(src, samplerTransform(src, pm6)); 
 vec4 vm5 = sample(src, samplerTransform(src, pm5)); 
 vec4 vm4 = sample(src, samplerTransform(src, pm4)); 
 vec4 vm3 = sample(src, samplerTransform(src, pm3)); 
 vec4 vm2 = sample(src, samplerTransform(src, pm2)); 
 vec4 vm1 = sample(src, samplerTransform(src, pm1)); 
 vec4 vp1 = sample(src, samplerTransform(src, pp1)); 
 vec4 vp2 = sample(src, samplerTransform(src, pp2)); 
 vec4 vp3 = sample(src, samplerTransform(src, pp3)); 
 vec4 vp4 = sample(src, samplerTransform(src, pp4)); 
 vec4 vp5 = sample(src, samplerTransform(src, pp5)); 
 vec4 vp6 = sample(src, samplerTransform(src, pp6)); 
 float wm6 = _asgv((pm6.y-c.y)/scale.y + z); 
 float wm5 = _asgv((pm5.y-c.y)/scale.y + z); 
 float wm4 = _asgv((pm4.y-c.y)/scale.y + z); 
 float wm3 = _asgv((pm3.y-c.y)/scale.y + z); 
 float wm2 = _asgv((pm2.y-c.y)/scale.y + z); 
 float wm1 = _asgv((pm1.y-c.y)/scale.y + z); 
 float wp1 = _asgv((pp1.y-c.y)/scale.y + z); 
 float wp2 = _asgv((pp2.y-c.y)/scale.y + z); 
 float wp3 = _asgv((pp3.y-c.y)/scale.y + z); 
 float wp4 = _asgv((pp4.y-c.y)/scale.y + z); 
 float wp5 = _asgv((pp5.y-c.y)/scale.y + z); 
 float wp6 = _asgv((pp6.y-c.y)/scale.y + z); 
 float wsum = wm6+wm5+wm4+wm3+wm2+wm1+wp1+wp2+wp3+wp4+wp5+wp6; 
 return (wm6*vm6 + wm5*vm5 + wm4*vm4 + wm3*vm3 + wm2*vm2 + wm1*vm1 + 
 wp6*vp6 + wp5*vp5 + wp4*vp4 + wp3*vp3 + wp2*vp2 + wp1*vp1)/wsum; 
10.5
inputCount
inputScale
CIAreaHistogram requires inputCount >= 1 and <= 2048
CIAreaHistogram area width or height is greater than 32768.
CIAreaHistogram outputData requires inputCount >= 1 and <= 256
CIExposureAdjust
CIAreaHistogram failed to allocate memory.
kernel vec4 _CIAreaHistogramScale(__sample p, float s) { 
 return floor(s * p * 255.0) / 255.0; 
CIAreaHistogram_%dbins
{CGRect={CGPoint=dd}{CGSize=dd}}40@?0{CGRect={CGPoint=dd}{CGSize=dd}}8
v24@?0@"<CIImageProcessorInput>"8@"<CIImageProcessorOutput>"16
inputPercentile
inputNormalize
inputClip
inputHard
CIAreaMinMaxRed
CIAreaHistogram
processHistogram
CIAreaHistogram.mm
!hist8
hist8
false
kernel vec4 _perc_norm_red(__sample c, __sample minmax) __attribute__((outputFormat(kCIFormatRh))) { 
 c.r = max((c.r - minmax.r) / max(minmax.g - minmax.r, 0.00001), 0.0); 
 return c; 
kernel vec4 _perc_accum_red(sampler h, float target, float bins) __attribute__((outputFormat(kCIFormatRh))) { 
 float left = 0.0; float right = 0.0; float sum = 0.0; int i = 0; for (; i < int(bins); i++) { float c = sample(h, samplerTransform(h, vec2(0.5) + vec2(i, 0))).r; 
 right += c; 
 if (right >= target) 
 break; 
 left += c; 
 } float t = target > 0.0 && right-left > 0.0 ? (target - left) / (right - left) : 0.0; 
 return vec4((float(i)+t)/bins); 
kernel vec4 _perc_denorm_red(__sample c, __sample minmax) __attribute__((outputFormat(kCIFormatRh))) { 
 c.r = minmax.r + c.r*(minmax.g-minmax.r); 
 return c; 
kernel vec4 _perc_clip_hard(__sample c, __sample p) __attribute__((outputFormat(kCIFormatRh))) { 
 c.r = c.r < p.r ? 0.0 : 1.0; 
 return c; 
kernel vec4 _perc_clip_soft(__sample c, __sample p) __attribute__((outputFormat(kCIFormatRh))) { 
 c.r = c.r < p.r ? 0.0 : c.r; 
 return c; 
-[CIBarcodeDescriptor init]
-[CIBarcodeDescriptor initWithCoder:]
-[CIQRCodeDescriptor isValid]
errorCorrectedPayload
symbolVersion
maskPattern
errorCorrectionLevel
-[CIAztecCodeDescriptor isValid]
isCompact
layerCount
codewordCount
dataCodewordCount
-[CIPDF417CodeDescriptor isValid]
rowCount
columnCount
eccVersion
com.apple.DetectedBarcode.UserActivityPayload
v40@?0@"NSUserActivity"8@16@"NSString"24@?<v@?@"NSString"@"NSData"@"NSError"B>32
Unknown CIDetectorAccuracy specified. Ignoring.
-[CIBarcodeDetector featuresInImage:options:]
CIBarcodeDetector.mm
NULL != symbologies
0 && "unreachable"
inputBarOffset
kernel vec2 _barsSwipe (vec3 ptoy, vec2 dir, float progress) 
 float y = dot(ptoy.xy,destCoord()) + ptoy.z; 
 y = abs(floor(y)); 
 y = max(progress - y, 0.0); 
 return destCoord() + y*y*dir; 
inputSigmaRange
inputSigmaSpace
inputSource
kernel vec4 _CBHorzGuided(sampler u, sampler v, float k, float colorInv, float spatialInv) __attribute__((outputFormat(kCIFormatRGBAh))) { 
 vec2 dc = destCoord(); 
 vec4 u_0 = sample(u, samplerTransform(u, dc)); 
 vec4 v_0 = sample(v, samplerTransform(v, dc)); 
 vec4 Cacc = vec4(0.0); 
 float W = 0.0; 
 int kk = int(k); 
 for (int x = -kk; x <= kk; x++) { 
 float ws = exp(-float(x*x) * spatialInv); 
 vec4 u_xy = sample(u, samplerTransform(u, dc + vec2(x,0.))); 
 vec4 v_xy = sample(v, samplerTransform(v, dc + vec2(x,0.))); 
 float r2 = dot(u_xy.rgb-u_0.rgb, u_xy.rgb-u_0.rgb); 
 float wc = exp(-r2 * colorInv); 
 float w = ws * wc * u_xy.a; 
 W += w; 
 Cacc += w * v_xy; 
 } return vec4(W < 0.00001 ? v_0.rgb : Cacc.rgb / W, v_0.a); 
kernel vec4 _CBVertGuided(sampler u, sampler v, float k, float colorInv, float spatialInv) __attribute__((outputFormat(kCIFormatRGBAh))) { 
 vec2 dc = destCoord(); 
 vec4 u_0 = sample(u, samplerTransform(u, dc)); 
 vec4 v_0 = sample(v, samplerTransform(v, dc)); 
 vec4 Cacc = vec4(0.0); 
 float W = 0.0; 
 int kk = int(k); 
 for (int y = -kk; y <= kk; y++) { 
 float ws = exp(-float(y*y) * spatialInv); 
 vec4 u_xy = sample(u, samplerTransform(u, dc + vec2(0.,y))); 
 vec4 v_xy = sample(v, samplerTransform(v, dc + vec2(0.,y))); 
 float r2 = dot(u_xy.rgb-u_0.rgb, u_xy.rgb-u_0.rgb); 
 float wc = exp(-r2 * colorInv); 
 float w = ws * wc * u_xy.a; 
 W += w; 
 Cacc += w * v_xy; 
 } return vec4(W < 0.00001 ? v_0.rgb : Cacc.rgb / W, v_0.a); 
kernel vec4 _CBHorz(sampler u, float k, float colorInv, float spatialInv) __attribute__((outputFormat(kCIFormatRGBAh))) { 
 vec2 dc = destCoord(); 
 vec4 u_0 = sample(u, samplerTransform(u, dc)); 
 vec4 Cacc = vec4(0.0); 
 float W = 0.0; 
 int kk = int(k); 
 for (int x = -kk; x <= kk; x++) { 
 float ws = exp(-float(x*x) * spatialInv); 
 vec4 u_xy = sample(u, samplerTransform(u, dc + vec2(x,0.))); 
 float r2 = dot(u_xy.rgb-u_0.rgb, u_xy.rgb-u_0.rgb); 
 float wc = exp(-r2 * colorInv); 
 float w = ws * wc * u_xy.a; 
 W += w; 
 Cacc += w * u_xy; 
 } return vec4(W < 0.00001 ? u_0.rgb : Cacc.rgb / W, u_0.a); 
kernel vec4 _CBVert(sampler u, float k, float colorInv, float spatialInv) __attribute__((outputFormat(kCIFormatRGBAh))) { 
 vec2 dc = destCoord(); 
 vec4 u_0 = sample(u, samplerTransform(u, dc)); 
 vec4 Cacc = vec4(0.0); 
 float W = 0.0; 
 int kk = int(k); 
 for (int y = -kk; y <= kk; y++) { 
 float ws = exp(-float(y*y) * spatialInv); 
 vec4 u_xy = sample(u, samplerTransform(u, dc + vec2(0.,y))); 
 float r2 = dot(u_xy.rgb-u_0.rgb, u_xy.rgb-u_0.rgb); 
 float wc = exp(-r2 * colorInv); 
 float w = ws * wc * u_xy.a; 
 W += w; 
 Cacc += w * u_xy; 
 } return vec4(W < 0.00001 ? u_0.rgb : Cacc.rgb / W, u_0.a); 
-[CIBitmapContext initWithBitmap:rowBytes:bounds:format:options:]
-[CIBitmapContext setBitmap:rowBytes:bounds:format:]
 in Simulator
-[CIBitmapContext drawImage:inRect:fromRect:]
kernel vec4 _add(__sample src, __sample dst) 
 return src + dst; 
kernel vec4 _multiply(__sample src, __sample dst) 
 return src * dst; 
kernel vec4 _min(__sample src, __sample dst) 
 return min(src, dst); 
kernel vec4 _max(__sample src, __sample dst) 
 return max(src, dst); 
kernel vec4 _clear(__sample src, __sample dst) 
 return vec4(0.0); 
kernel vec4 _src(__sample src, __sample dst) 
 return src; 
kernel vec4 _dst(__sample src, __sample dst) 
 return dst; 
kernel vec4 _srcOver(__sample src, __sample dst) 
 return src + dst*(1.0 - src.a); 
kernel vec4 _dstOver(__sample src, __sample dst) 
 return dst + src*(1.0 - dst.a); 
kernel vec4 _srcIn(__sample src, __sample dst) 
 return src*dst.a; 
kernel vec4 _dstIn(__sample src, __sample dst) 
 return dst*src.a; 
kernel vec4 _srcOut(__sample src, __sample dst) 
 return src*(1.0-dst.a); 
kernel vec4 _dstOut(__sample src, __sample dst) 
 return dst*(1.0-src.a); 
kernel vec4 _srcAtop(__sample src, __sample dst) 
 return src * dst.a + dst * (1.0 - src.a); 
kernel vec4 _dstAtop(__sample src, __sample dst) 
 return dst * src.a + src * (1.0 - dst.a); 
kernel vec4 _exclusiveOr(__sample src, __sample dst) 
 return src * (1.0 - dst.a) + dst * (1.0 - src.a); 
kernel vec4 _multiplyBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = Cb * Cs; 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _screenBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = Cb + Cs - (Cb * Cs); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _overlayBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = compare(0.5 - Cb, 2.0 * (Cs + Cb - Cs * Cb) - 1.0, 2.0 * Cb * Cs); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _darkenBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = min(Cb, Cs); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _lightenBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = max(Cb, Cs); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _colorDodgeBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = Cb / max(1.0 - Cs, vec4(0.0000001)); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _colorBurnBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = 1.0 - (1.0 - Cb) / max(Cs, vec4(0.0000001)); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _hardLightBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = compare(0.5 - Cs, 2.0 * (Cb + Cs - Cb * Cs) - 1.0, 2.0 * Cs * Cb); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _softLightBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 DCb = compare(0.25 - Cb, sqrt(Cb), ((16.0 * Cb - 12.0) * Cb + 4.0) * Cb); 
 vec4 B = Cb + (2.0 * Cs - 1.0) * compare(0.5 - Cs, DCb - Cb, Cb * (1.0 - Cb)); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _differenceBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = abs(Cb - Cs); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _exclusionBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = Cb + Cs - 2.0 * Cb * Cs; 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _hueBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 CsSort = (Cs.r > Cs.g) ? Cs : Cs.grba; 
 CsSort = (CsSort.g > CsSort.b) ? CsSort : CsSort.rbga; 
 CsSort = (CsSort.r > CsSort.g) ? CsSort : CsSort.grba; 
 vec4 CbSort = (Cb.r > Cb.g) ? Cb : Cb.grba; 
 CbSort = (CbSort.g > CbSort.b) ? CbSort : CbSort.rbga; 
 CbSort = (CbSort.r > CbSort.g) ? CbSort : CbSort.grba; 
 float bMax = CbSort.r; 
 float bMin = CbSort.b; 
 float Sb = bMax - bMin; 
 float sMax = CsSort.r; 
 float sMid = CsSort.g; 
 float sMin = CsSort.b; 
 int sMaxIdx = (sMax == Cs.r ? 0 : (sMax == Cs.g ? 1 : 2)); 
 int sMinIdx = (sMin == Cs.b ? 2 : (sMin == Cs.g ? 1 : 0)); 
 int sMidIdx = 3 - sMinIdx - sMaxIdx; 
 vec4 CsSb = Cs; 
 CsSb[sMaxIdx] = (sMax > sMin) ? Sb : 0.0; 
 CsSb[sMidIdx] = (sMax > sMin) ? (sMid - sMin) * Sb / (sMax - sMin) : 0.0; 
 CsSb[sMinIdx] = 0.0; 
 float Lb = 0.3 * Cb.r + 0.59 * Cb.g + 0.11 * Cb.b; 
 float LCsSb = 0.3 * CsSb.r + 0.59 * CsSb.g + 0.11 * CsSb.b; 
 vec4 BB = CsSb + vec4(Lb - LCsSb); 
 float l = 0.3 * BB.r + 0.59 * BB.g + 0.11 * BB.b; 
 float n = min(min(BB.r, BB.g), BB.b); 
 float x = max(max(BB.r, BB.g), BB.b); 
 vec4 B = BB; 
 B = n < 0.0 ? vec4(l) + (B - vec4(l)) * l / (l - n) : B; 
 B = x > 1.0 ? vec4(l) + (B - vec4(l)) * (1.0 - l) / (x - l) : B; 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _saturationBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 CsSort = (Cs.r > Cs.g) ? Cs : Cs.grba; 
 CsSort = (CsSort.g > CsSort.b) ? CsSort : CsSort.rbga; 
 CsSort = (CsSort.r > CsSort.g) ? CsSort : CsSort.grba; 
 vec4 CbSort = (Cb.r > Cb.g) ? Cb : Cb.grba; 
 CbSort = (CbSort.g > CbSort.b) ? CbSort : CbSort.rbga; 
 CbSort = (CbSort.r > CbSort.g) ? CbSort : CbSort.grba; 
 float sMax = CsSort.r; 
 float sMin = CsSort.b; 
 float Ss = sMax - sMin; 
 float bMax = CbSort.r; 
 float bMid = CbSort.g; 
 float bMin = CbSort.b; 
 int bMaxIdx = (bMax == Cb.r ? 0 : (bMax == Cb.g ? 1 : 2)); 
 int bMinIdx = (bMin == Cb.b ? 2 : (bMin == Cb.g ? 1 : 0)); 
 int bMidIdx = 3 - bMinIdx - bMaxIdx; 
 vec4 CbSs = Cb; 
 CbSs[bMaxIdx] = (bMax > bMin) ? Ss : 0.0; 
 CbSs[bMidIdx] = (bMax > bMin) ? (bMid - bMin) * Ss / (bMax - bMin) : 0.0; 
 CbSs[bMinIdx] = 0.0; 
 float Lb = 0.3 * Cb.r + 0.59 * Cb.g + 0.11 * Cb.b; 
 float LCbSs = 0.3 * CbSs.r + 0.59 * CbSs.g + 0.11 * CbSs.b; 
 vec4 BB = CbSs + vec4(Lb - LCbSs); 
 float l = 0.3 * BB.r + 0.59 * BB.g + 0.11 * BB.b; 
 float n = min(min(BB.r, BB.g), BB.b); 
 float x = max(max(BB.r, BB.g), BB.b); 
 vec4 B = BB; 
 B = n < 0.0 ? vec4(l) + (B - vec4(l)) * l / (l - n) : B; 
 B = x > 1.0 ? vec4(l) + (B - vec4(l)) * (1.0 - l) / (x - l) : B; 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _colorBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 float Ls = 0.3 * Cs.r + 0.59 * Cs.g + 0.11 * Cs.b; 
 float Lb = 0.3 * Cb.r + 0.59 * Cb.g + 0.11 * Cb.b; 
 vec4 BB = Cs + vec4(Lb - Ls); 
 float l = 0.3 * BB.r + 0.59 * BB.g + 0.11 * BB.b; 
 float n = min(min(BB.r, BB.g), BB.b); 
 float x = max(max(BB.r, BB.g), BB.b); 
 vec4 B = BB; 
 B = n < 0.0 ? vec4(l) + (B - vec4(l)) * l / (l - n) : B; 
 B = x > 1.0 ? vec4(l) + (B - vec4(l)) * (1.0 - l) / (x - l) : B; 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _luminosityBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 float Ls = 0.3 * Cs.r + 0.59 * Cs.g + 0.11 * Cs.b; 
 float Lb = 0.3 * Cb.r + 0.59 * Cb.g + 0.11 * Cb.b; 
 vec4 BB = Cb + vec4(Ls - Lb); 
 float l = 0.3 * BB.r + 0.59 * BB.g + 0.11 * BB.b; 
 float n = min(min(BB.r, BB.g), BB.b); 
 float x = max(max(BB.r, BB.g), BB.b); 
 vec4 B = BB; 
 B = n < 0.0 ? vec4(l) + (B - vec4(l)) * l / (l - n) : B; 
 B = x > 1.0 ? vec4(l) + (B - vec4(l)) * (1.0 - l) / (x - l) : B; 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = (fore.a < 0.000001) ? back : mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _subtractBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = Cb - Cs; 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _divideBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = Cb / max(Cs,vec4(0.0000001)); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _linearBurnBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = Cb + Cs - 1.0; 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _linearDodgeBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = Cb + Cs; 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _vividLightBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 epsilon = vec4(0.0000001); 
 vec4 lo = 1.0 - ((1.0 - Cb) / max(2.0 * Cs, epsilon)); 
 vec4 hi = Cb / max(2.0 * (1.0 - Cs), epsilon); 
 vec4 B = compare(0.5 - Cs, hi, lo); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _linearLightBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = Cb + 2.0 * Cs - 1.0; 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _pinLightBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 hi = 2.0 * Cs; 
 vec4 lo = hi - 1.0; 
 vec4 B = compare(Cb - lo, lo, compare(Cb - hi, Cb, hi)); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _hardMixBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 vec4 B = compare(1.0 - Cb - Cs, vec4(1.0), vec4(0.0)); 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _darkerColorBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 float Ls = 0.3 * Cs.r + 0.59 * Cs.g + 0.11 * Cs.b; 
 float Lb = 0.3 * Cb.r + 0.59 * Cb.g + 0.11 * Cb.b; 
 vec4 B = Ls > Lb ? Cb : Cs; 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _lighterColorBlendMode (__sample fore, __sample back) 
 vec4 Cs = unpremultiply(fore); 
 vec4 Cb = unpremultiply(back); 
 float Ls = 0.3 * Cs.r + 0.59 * Cs.g + 0.11 * Cs.b; 
 float Lb = 0.3 * Cb.r + 0.59 * Cb.g + 0.11 * Cb.b; 
 vec4 B = Ls < Lb ? Cb : Cs; 
 vec4 Cr = clamp(B, vec4(0.0), vec4(1.0)); 
 Cr = mix(Cs, Cr, back.a); 
 Cr.a = 1.0; 
 Cr = mix(back, Cr, fore.a); 
 return Cr; 
kernel vec4 _plusDarker(__sample src, __sample dst) 
 vec4 R = src + dst; 
 R.rgb = R.a - R.rgb; 
 R = clamp(R, vec4(0.0), vec4(1.0)); 
 R.rgb = R.a - R.rgb; 
 return R; 
kernel vec4 _plusLighter(__sample src, __sample dst) 
 return src + dst; 
kernel vec4 _hueBlendMode_v0 (__sample pCf, __sample pCb) 
 vec4 uCf = unpremultiply(pCf); vec4 uCb = unpremultiply(pCb); vec4 uCfSort = (uCf.r > uCf.g) ? uCf : uCf.grba; 
 uCfSort = (uCfSort.g > uCfSort.b) ? uCfSort : uCfSort.rbga; 
 uCfSort = (uCfSort.r > uCfSort.g) ? uCfSort : uCfSort.grba; 
 vec4 uCbSort = (uCb.r > uCb.g) ? uCb : uCb.grba; 
 uCbSort = (uCbSort.g > uCbSort.b) ? uCbSort : uCbSort.rbga; 
 uCbSort = (uCbSort.r > uCbSort.g) ? uCbSort : uCbSort.grba; 
 vec4 Ct = (uCfSort.b+0.00001 > uCfSort.r) ? uCbSort.rbba : (uCf - uCfSort.b) * (uCbSort.r - uCbSort.b) / (uCfSort.r - uCfSort.b) + uCbSort.b; 
 Ct.a = uCb.a; 
 vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a); 
 Ct = mix(uCf, Ct, uCb.a); 
 Ct.a = 1.0; 
 return mix(Cb, Ct, uCf.a); 
kernel vec4 _saturationBlendMode_v0 (__sample pCf, __sample pCb) 
 vec4 uCf = unpremultiply(pCf); vec4 uCb = unpremultiply(pCb); vec4 uCfSort = (uCf.r > uCf.g) ? uCf : uCf.grba; 
 uCfSort = (uCfSort.g > uCfSort.b) ? uCfSort : uCfSort.rbga; 
 uCfSort = (uCfSort.r > uCfSort.g) ? uCfSort : uCfSort.grba; 
 float fL = (uCfSort.r + uCfSort.b) * 0.5; 
 float cmax = uCfSort.r; 
 float cmin = uCfSort.b; 
 vec4 uCbSort = (uCb.r > uCb.g) ? uCb : uCb.grba; 
 uCbSort = (uCbSort.g > uCbSort.b) ? uCbSort : uCbSort.rbga; 
 uCbSort = (uCbSort.r > uCbSort.g) ? uCbSort : uCbSort.grba; 
 float bL = (uCbSort.r + uCbSort.b) * 0.5; 
 float d = cmax - cmin; 
 float dv = (fL < 0.5) ? (cmax + cmin) : (2.0 - (cmax + cmin)); 
 float s = d / max(dv, 0.000001); 
 float mmax = (bL <= 0.5) ? (bL + bL*s) : (bL + s - bL*s); 
 float mmin = bL * 2.0 - mmax; 
 vec4 Ct = (uCbSort.b+0.00001 > uCbSort.r) ? vec4(mmax,mmin,mmin,1.0) : (uCb - uCbSort.b) * (mmax - mmin) / (uCbSort.r - uCbSort.b) + mmin; 
 Ct.a = uCb.a; 
 vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a); 
 Ct = mix(uCf, Ct, uCb.a); 
 Ct.a = 1.0; 
 return mix(Cb, Ct, uCf.a); 
kernel vec4 _colorBlendMode_v0 (__sample pCf, __sample pCb) 
 vec4 uCf = unpremultiply(pCf); vec4 uCb = unpremultiply(pCb); vec4 uCfSort = (uCf.r > uCf.g) ? uCf : uCf.grba; 
 uCfSort = (uCfSort.g > uCfSort.b) ? uCfSort : uCfSort.rbga; 
 uCfSort = (uCfSort.r > uCfSort.g) ? uCfSort : uCfSort.grba; 
 float fL = (uCfSort.r + uCfSort.b) * 0.5; 
 float cmax = uCfSort.r; 
 float cmin = uCfSort.b; 
 vec4 uCbSort = (uCb.r > uCb.g) ? uCb : uCb.grba; 
 uCbSort = (uCbSort.g > uCbSort.b) ? uCbSort : uCbSort.rbga; 
 uCbSort = (uCbSort.r > uCbSort.g) ? uCbSort : uCbSort.grba; 
 float bL = (uCbSort.r + uCbSort.b) * 0.5; 
 float d = cmax - cmin; 
 float dv = (fL < 0.5) ? (cmax + cmin) : (2.0 - (cmax + cmin)); 
 float s = d / max(dv, 0.000001); 
 float mmax = (bL <= 0.5) ? (bL + bL*s) : (bL + s - bL*s); 
 float mmin = bL * 2.0 - mmax; 
 vec4 Ct = (uCf - uCfSort.b) * (mmax - mmin) / (uCfSort.r - uCfSort.b) + mmin; 
 Ct = (mmin+0.00001 > mmax) ? vec4(mmin) : Ct; 
 Ct.a = uCb.a; 
 vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a); 
 Ct = mix(uCf, Ct, uCb.a); 
 Ct.a = 1.0; 
 return mix(Cb, Ct, uCf.a); 
kernel vec4 _luminosityBlendMode_v0 (__sample pCf, __sample pCb) 
 vec4 uCf = unpremultiply(pCf); vec4 uCb = unpremultiply(pCb); vec4 uCbSort = (uCb.r > uCb.g) ? uCb : uCb.grba; 
 uCbSort = (uCbSort.g > uCbSort.b) ? uCbSort : uCbSort.rbga; 
 uCbSort = (uCbSort.r > uCbSort.g) ? uCbSort : uCbSort.grba; 
 float fL = (uCbSort.r + uCbSort.b) * 0.5; 
 float cmax = uCbSort.r; 
 float cmin = uCbSort.b; 
 vec4 uCfSort = (uCf.r > uCf.g) ? uCf : uCf.grba; 
 uCfSort = (uCfSort.g > uCfSort.b) ? uCfSort : uCfSort.rbga; 
 uCfSort = (uCfSort.r > uCfSort.g) ? uCfSort : uCfSort.grba; 
 float bL = (uCfSort.r + uCfSort.b) * 0.5; 
 float d = cmax - cmin; 
 float dv = (fL < 0.5) ? (cmax + cmin) : (2.0 - (cmax + cmin)); 
 float s = d / max(dv, 0.000001); 
 float mmax = (bL <= 0.5) ? (bL + bL*s) : (bL + s - bL*s); 
 float mmin = bL * 2.0 - mmax; 
 vec4 Ct = (uCb - uCbSort.b) * (mmax - mmin) / (uCbSort.r - uCbSort.b) + mmin; 
 Ct = (mmin+0.00001 > mmax) ? vec4(mmin) : Ct; 
 Ct.a = uCf.a; 
 vec4 Cf = vec4(uCf.rgb * uCf.a, uCf.a); 
 Ct = mix(uCb, Ct, uCf.a); 
 Ct.a = 1.0; 
 return mix(Cf, Ct, uCb.a); 
kernel vec4 _linearBurnBlendMode_v0 (__sample pCf, __sample pCb) 
 vec4 uCf = unpremultiply(pCf); vec4 uCb = unpremultiply(pCb); vec4 Ct = clamp(uCb - (1.0 - uCf*uCf.a), 0.0, 1.0); 
 vec4 Cb = vec4(uCb.rgb * uCb.a, uCb.a); 
 Ct = mix(uCf, Ct, uCb.a); 
 Ct.a = 1.0; 
 return mix(Cb, Ct, uCf.a); 
12.0
kernel vec4 _mix (__sample f, __sample b, float k) { return mix(b,f,k); }
kernel vec4 _blendWithMask (__sample f, __sample b, __sample m) { return mix(b,f,m.g); }
kernel vec4 _blendWithMaskB0 (__sample f, __sample m) { return f*m.g; }
10.13
kernel vec4 _blendWithRedMask (__sample f, __sample b, __sample m) { return mix(b,f,m.r); }
kernel vec4 _blendWithRedMaskB0 (__sample f, __sample m) { return f*m.r; }
kernel vec4 _blendWithBlueMask (__sample f, __sample b, __sample m) { return mix(b,f,m.b); }
kernel vec4 _blendWithBlueMaskB0 (__sample f, __sample m) { return f*m.b; }
10.9
kernel vec4 _blendWithAlphaMask (__sample f, __sample b, __sample m) { return mix(b,f,m.a); }
kernel vec4 _blendWithAlphaMaskB0 (__sample f, __sample m) { return f*m.a; }
kernel vec4 _bloom (__sample s, __sample b, float k) { return mix(s, max(s,b), k); }
kernel vec4 _gloom (__sample s, __sample b, float k) { return mix(s, min(s,b), k); }
kernel vec4 _boxBlur3x3(sampler i) 
 vec2 dc = destCoord(); 
 vec4 c; 
 c = sample(i, samplerTransform(i,dc + vec2(1.0,1.0))); 
 c += sample(i, samplerTransform(i,dc + vec2(1.0,-.5))) * 2.0; 
 c += sample(i, samplerTransform(i,dc + vec2(-.5,1.0))) * 2.0; 
 c += sample(i, samplerTransform(i,dc + vec2(-.5,-.5))) * 4.0; 
 return c / 9.0; 
kernel vec4 _boxBlur3(sampler i, vec2 dir) 
 vec2 dc = destCoord(); 
 vec4 c; 
 c = sample(i, samplerTransform(i,dc - dir)); 
 c += sample(i, samplerTransform(i,dc + 0.5*dir)) * 2.0; 
 return c / 3.0; 
kernel vec4 _boxBlur5(sampler i, vec2 dir) 
 vec2 dc = destCoord(); 
 vec4 c; 
 c = sample(i, samplerTransform(i,dc - 1.5*dir)) * 0.4; 
 c += sample(i, samplerTransform(i,dc)) * 0.2; 
 c += sample(i, samplerTransform(i,dc + 1.5*dir)) * 0.4; 
 return c; 
kernel vec4 _boxBlur7(sampler i, vec2 dir) 
 vec2 dc = destCoord(); 
 vec4 c; 
 c = sample(i, samplerTransform(i,dc - 2.5*dir)); 
 c += sample(i, samplerTransform(i,dc - dir)) * 0.5; 
 c += sample(i, samplerTransform(i,dc + 0.5*dir)); 
 c += sample(i, samplerTransform(i,dc + 2.5*dir)); 
 return c / 3.5; 
kernel vec4 _boxBlur9(sampler i, vec2 dir) 
 vec2 dc = destCoord(); 
 vec4 c; 
 c = sample(i, samplerTransform(i,dc - 3.5*dir)); 
 c += sample(i, samplerTransform(i,dc - 1.5*dir)); 
 c += sample(i, samplerTransform(i,dc)) * 0.5; 
 c += sample(i, samplerTransform(i,dc + 1.5*dir)); 
 c += sample(i, samplerTransform(i,dc + 3.5*dir)); 
 return c / 4.5; 
kernel vec4 _boxBlur11(sampler i, vec2 dir) 
 vec2 dc = destCoord(); 
 vec4 c; 
 c = sample(i, samplerTransform(i,dc - 4.5*dir)); 
 c += sample(i, samplerTransform(i,dc - 2.5*dir)); 
 c += sample(i, samplerTransform(i,dc - dir)) * 0.5; 
 c += sample(i, samplerTransform(i,dc + 0.5*dir)); 
 c += sample(i, samplerTransform(i,dc + 2.5*dir)); 
 c += sample(i, samplerTransform(i,dc + 4.5*dir)); 
 return c / 5.5; 
kernel vec4 _boxBlur13(sampler i, vec2 dir) 
 vec2 dc = destCoord(); 
 vec4 c; 
 c = sample(i, samplerTransform(i,dc - 5.5*dir)); 
 c += sample(i, samplerTransform(i,dc - 3.5*dir)); 
 c += sample(i, samplerTransform(i,dc - 1.5*dir)); 
 c += sample(i, samplerTransform(i,dc)) * 0.5; 
 c += sample(i, samplerTransform(i,dc + 1.5*dir)); 
 c += sample(i, samplerTransform(i,dc + 3.5*dir)); 
 c += sample(i, samplerTransform(i,dc + 5.5*dir)); 
 return c / 6.5; 
kernel vec4 _boxCombine7 (sampler blur, vec2 off) 
 vec2 dc = destCoord(); 
 vec4 c = sample(blur, samplerTransform(blur, dc - 3.0*off)) 
 + sample(blur, samplerTransform(blur, dc - 2.0*off)) 
 + sample(blur, samplerTransform(blur, dc - off)) 
 + sample(blur, samplerTransform(blur, dc)) 
 + sample(blur, samplerTransform(blur, dc + off)) 
 + sample(blur, samplerTransform(blur, dc + 2.0*off)) 
 + sample(blur, samplerTransform(blur, dc + 3.0*off)); 
 return c / 7.0; 
kernel vec4 _boxCombine5 (sampler blur, vec2 off) 
 vec2 dc = destCoord(); 
 vec4 c = sample(blur, samplerTransform(blur, dc - 2.0*off)) 
 + sample(blur, samplerTransform(blur, dc - off)) 
 + sample(blur, samplerTransform(blur, dc)) 
 + sample(blur, samplerTransform(blur, dc + off)) 
 + sample(blur, samplerTransform(blur, dc + 2.0*off)); 
 return c * 0.2; 
kernel vec4 _boxCombine3 (sampler blur, vec2 off) 
 vec2 dc = destCoord(); 
 vec4 c = sample(blur, samplerTransform(blur, dc)) 
 + sample(blur, samplerTransform(blur, dc - off)) 
 + sample(blur, samplerTransform(blur, dc + off)); 
 return c / 3.0; 
kernel vec4 _boxCombine2 (sampler img, sampler blur, vec4 parms) 
 vec2 off = parms.xy; 
 float kc = parms.w; 
 float kb = parms.z; 
 vec2 dc = destCoord(); 
 return kc * sample(img, samplerTransform(img, dc)) 
 + kb * sample(blur, samplerTransform(blur, dc - off)) 
 + kb * sample(blur, samplerTransform(blur, dc + off)); 
kernel vec2 _bumpDistortion(vec4 parms) 
 float d0 = clamp(distance(destCoord(), parms.zw) * -parms.x + 1.0, 0.0, 1.0); 
 d0 = ((d0 * -2.0 + 3.0) * d0 * d0) * parms.y + 1.0; 
 return (destCoord() - parms.zw) * d0 + parms.zw; 
kernel vec2 _bumpDistortionLinear(vec4 edgeFunc, vec4 vec) 
 float eFunc = dot(vec4(destCoord(), 1.0, 0.0), edgeFunc); 
 float r0 = clamp(1.0 - abs(eFunc), 0.0, 1.0); 
 r0 = ((r0 * -2.0 + 3.0) * r0 * r0) * vec.z + 1.0; 
 return destCoord() + (eFunc * (r0 - 1.0) * vec.xy); 
scaled Average Camera Travel Distance = %f
scaled Max Registration Error Integral = %f
scaled Mean peak registration error / Max peak registration error = %f
scaled Beginning vs. End AEMatrix difference vs. Average of Adjacent AE Matrix Differences = %f
scaled In-out ratio = %f
scaled Max inner distance = %f
scaled Average registration error skewness = %f
Sequence classified as NON-ACTION due to complete lack of local motion (%f, threshold %f)
Non-Linear SVM Action classifier called with:
Average Camera Travel Distance = %f
Max Registration Error Integral = %f
Mean peak registration error / Max peak registration error = %f
Beginning vs. End AEMatrix difference vs. Average of Adjacent AE Matrix Differences = %f
In-out ratio = %f
Max inner distance = %f
Average registration error skewness = %f
PREDICTION: --- %s --- (value = %f)
ACTION
NON-ACTION
true
FCRSetupParamLoadModelFiles
    orientation = %d
Number of HW faces = %d - calculating rect
   hwFaceRect: (%.3f,%.3f,%.3f,%.3f), hasLeftEye = %d, hasRightEye = %d
   face %d = (%.3f,%.3f,%.3f,%.3f)
   fcrect  = (%.3f,%.3f,%.3f,%.3f)
   inserting prev face (hw%d,sw=%d) = (%.3f,%.3f,%.3f,%.3f) padding=(%.3f,%.3f)
  needFaceCore = %d
setting faces ROI to (%.3f,%.3f,%.3f,%.3f)
q24@?0@"FCRFace"8@"FCRFace"16
Face detection error
extractDetails error: %s
face %d: rect = %.3f,%.3f,%.3f,%.3f, leftOpen=%d,rightOpen=%d
  #faces = %d
calculateFaceFocus:
   adding rect: %.3f,%.3f,%.3f,%.3f
   focusScore = %d, %.3f
AdjustFaceIds: Examining '%s'
faceStat.id = %d
    rename found: %d mapped to %d
    new id: %d mapped to %d
    no id: assigning %d
    map found: %d maps to %d
       entry exists with same id: %d
%d faces so far unmatched:
    face %d
    %d overlaps with %d by %.3f %% : 
    matched!  mapping %d to %d
    not matched
      no match found for id %d - adding face
  prevConfig has %d entries
Found mapping!
   mapping not found for %d, mapping to itself
removing config entry: %d
Timestamp
  face ID = %d, timestamp = %.6f
FaceID
Rect
Width
Height
    inserting at index %d, count=%d
  extractFacesFromMetadata
extractFaceMetadata: invalid properties
AccumulatedFaceMetadata
  accumulatedFaceMetadata = %x
adding %d faces
Regions
regions exist
RegionList
  num regions = %d
    latestFaceTimestamp = %.6f
addFacesToImageStat: timestamp = %.6f, lastFaceIndex=%d
    imageTimestamp > latestFaceTimestamp
RollAngle
YawAngle
LeftEyeX
LeftEyeY
LeftEyeWidth
LeftEyeHeight
LeftEyeBlinkLevel
RightEyeX
RightEyeY
RightEyeWidth
RightEyeHeight
RightEyeBlinkLevel
SmileLevel
      found face id %d, timestamp=%.6f, x=%.3f,y=%.3f,w=%.3f,h=%.3f
    adding face id %d, timestamp %.6f
    face id %d, timestamp %.6f - delta = %.6f, perhaps should use FaceCore
FaceInfoArray:
hwId = %d (lastSeen=%d, ctr=%.3f,%.3f size=%.3f,%.3f), swId = %d (lastSeen=%d, ctr=%.3f,%.3f size=%.3f,%.3f)
2.006 -   May 13, 2015
1.021 - Aug 1, 2013
BurstSet_AlgorithmVersion
Image_FacesArray
Image_ISPFacesArray
Image_ImageScore
Image_Timestamp
Image_YUVData
ImageYUVWidth
ImageYUVHeight
ImageYData
ImageUVData
ImageYUVBytesPerRow
Image_TimeReceived
Image_TimeQueued
Image_TimeConverted
Image_TimeStartedAnalysis
Image_TimeStartedFaceDetection
Image_TimeDoneFaceDetection
Image_TimeDoneFaceBlinkDetection
Image_TimeDoneFaceFocusScore
Image_TimeDoneAnalysis
ImageFace_ID
ImageFaceX
ImageFaceY
ImageFaceW
ImageFaceH
ImageFaceFocusScore
ImageFaceLeftEyeOpen
ImageFaceRightEyeOpen
ImageFaceSmiling
ImageFaceLeftEyePosX
ImageFaceLeftEyePosY
ImageFaceRightEyePosX
ImageFaceRightEyePosY
ImageFaceTimestamp
ImageFaceRollAngle
ImageFaceYawAngle
ImageFaceLeftEyeBlinkScore
ImageFaceRightEyeBlinkScore
ImageFaceSmileScore
ImageFaceSmallFace
ImageSet_Version
ImageSetVersion_Default
ImageSetVersion_Latest
BurstSet_TimeDoneCapturing
BurstSet_TimeDone
BurstSet_Setting_MaxNumPendingFrames
BurstSet_Setting_DisableAnalysis
BurstSet_Setting_DisableFaceCore
BurstSet_Setting_DummyAnalysisCount
BurstSet_Setting_ForceFaceDetection
BurstSet_Setting_EnableDumpYUV
BurstSet_IsAction
BurstSet_IsPortrait
BurstSet_CoverImage
kern.osversion
BURST ANALYSIS VERSION = %s (%s)
   initWithBurstImageSet - Error: stats not found
inpaintingResourceDescriptor
processingResolutions
+[InpaintingMultiresolutionFilter performMultiresolutionInpaintingPipelineOnImage:usingMask:boundingBox:additionalParameters:espressoResources:executionContext:]
InpaintingMultiresolutionFilter.mm
processingResolutions.count == 2
blendingRadius
(unknown)
unable to locate resource bundle
InpaintingFiltersError
unable to locate resource "%@" of type "%@" in %@
CGRect({%.1f, %.1f}, {%.1f, %.1f})
burst_mode_logging
staccato_mode_logging
burst_max_pending_frames
burst_disable_analysis
burst_force_face_detection
burst_dummy_analysis
burst_disable_facecore
burst_use_fixed_image
burst_fixed_image_filename
burst_dump_yuv
staccato_yuv_dump
burst_use_version
com.apple.camera
/var/mobile/Library/Caches/com.apple.camera
burstSets
com.apple.burstAnalyzer
dd-MM-yyyy'_'HH-mm-ss'_burstLog.txt'
com.apple.staccato_dump
counter.bin
BurstDoc_AllImageStats
BurstDoc_AllImageIdentifiers
BurstDoc_BestImageIds
BurstDoc_LogFile
Computing action selection threshold
Mean non-zero actions = %f, std dev = %f
ACTION SELECTION THRESHOLD = %f
Examining image, id=%s, timestamp = %.6f, done=%d
Not processing frames, imageStat.timestamp = %.6f, latestFaceTimestamp = %.6f
LeftEyeFeaturesOffset
RightEyeFeaturesOffset
SmileFeaturesOffset
BlinkFeaturesSize
SmileFeaturesSize
burstimage_%06d.yuv
Image_FaceRectROI
Image_Width
Image_Height
Image_AEAverage
Image_AETarget
Image_AEStable
Image_AFStable
Image_Orientation
Image_AEMatrix
Error!  Done adding, but there are still frames left!
Adding image: %s
Image %d:%s has emotional score %d
Image %d:%s has been emotionally rejected.
Skipping projection computation because data isn't present
LOOKING FOR FALSE-POSITIVE FACES...
Analyzing %s...
REMOVING false-positive face with ID = %d
Keeping face with ID = %d
Collapsing %s
*_*_* GARBAGE DETECTOR FOR %s *_*_*
Travel = %f, maxSkewness = %f, avgSkewness = %f, blur = %f, avgBlur = %f, stdBlur = %f
hasFaces = %d
notBlurry = %d
veryBlurry = %d
potentiallyBlurry = %d
poorRegistration = %d
suspectRegistration = %d
******Image %s classified as garbage.
**** Image %s classified as garbage by association.
Score for %s:%d is %f 
with action score %f and center bias %f (isGarbage=%d)
NEW BEST
Cover photo PORTRAIT selection score for %d:%s = %f (unbiased = %f)
Cover photo ACTION selection score for %d:%s = %f
%s:   # faces = %d, avgH = %f
    face id=%d, rect=%.3f,%.3f,%.3f,%.3f, focus=%.3f, faceScore=%.3f, leftEyeOpen=%d, rightEyeOpen=%d
Performing emotional rejection of face images in cluster %d:
Items in next cluster:
Image %s is classified as garbage for portrait mode, no sharp faces.
Checking temporal order: %d vs. %d
Removing %d:%s
All items in one cluster.
Images without faces = %d, threshold = %d, total # = %d
Classified as portrait mode. Affects cover photo selection.
all costs within valid region: 
mean = %f, std = %f
First average cost = %f
Second average cost = %f
--Invalidating two outliers from the start of the burst
--Invalidating one outlier from the start of the burst
Last average cost = %f
Second-to-last average cost = %f
--Invalidating two outliers from the end of the burst
--Invalidating one outlier from the end of the burst
Number of images too few after invalidation at the endpoints. Return one selection.
Result of three-way division: finalCost: %f, inOutRatio: %f
Classified as non-action.
Classified as action.
Between %d and %d: 
motion: %f
Action mean = %f, action std = %f, action threshold = %f
Local statistics for divider %03d
 with score %f:
 noise threshold = %f, high threshold = %f (mean %f, std %f)
Overall mean divider score = %f
clusterDividerArraySize = %d
Locally-maximal divider %d not considered due to being potential noise (%f vs %f,%f)
Locally-maximal divider %d not considered due to lack of any motion: %f
Locally-maximal divider %d not considered due to being potential noise (nearby peak).
local maxima size: %ld
divider %d
Re-running three-way division with minClusterSize = %d, maxClusterSize = %d
Strongest local maxima: %d and %d
Expanding main peak to include divider %d
Adding action-based cluster boundaries.
Cluster %d is too small for action-based cluster boundaries
Action statistics for cluster %d: mean %f std %f threshold %f
Adding ACTION DIVIDER at location %d
***Finding three way division:
firstValidImage = %d, lastValidImage = %d
NEW BEST: largestInnerDistance = %f, bestRatio = %f
Divider1 = %d, Divider2 = %d
RECURSING: (%d->%d) becomes (%d->%d)
Clustering costs: maxInner = %f, inOutRatio = %f
Threshold for dupes: %f
Distance between selections %d and %d: %f, %f
Selection score of %d is %f... isGarbage = %d
Choosing candidate %d from a series of dupes
Throwing away all dupes due to garbage classification
Keeping candidate %d
Tossing out the %s on %d
trash
reject
All images are garbage. Picking the middle selection = %s.
Image_ImageROIGridStartX
Image_ImageROIGridStartY
Image_ImageROIGridEndX
Image_ImageROIGridEndY
Original ROI = %d,%d -> %d,%d
Smoothed ROI = %d,%d -> %d,%d
Sharpness ROI for %s updated to (%d,%d)->(%d,%d)
%s REGISTERED AGAINST %s
Registration result: tx = %d, ty = %d
----------REGISTRATION ERROR INTEGRAL 
Row interval: (%d->%d)
Column interval: (%d->%d)
sensedROI = (%d,%d)->(%d,%d)
referenceROI = (%d,%d)->(%d,%d)
Registration rejected due to ROI too large or too small.
Registration in favor of face detection ROI.
Registration rejected due to skewness, which can indicate a bad registration result.
Registration rejected due to insufficient local motion.
----------------------- facecore count = %d, numHWFaces = %d
Limited ROI = (%d,%d)->(%d,%d)
Computing sharpness over grid points (%d,%d)->(%d,%d)
After collapse avgHorzDiffY = %f, blurExtent = %f
Num HW faces = %d, facecore faces = %d
combined normalized focus score for face core detections = %f
Limited sharpness score = %f, with number of faces = %d
Thumbnail selection score computation for %s
Average facial focus score = %f
Initial score (no faces) = %f (isGarbage = %d)
Action selection score = %f
Registration error stats: mean=%f, stdDev=%f, skewness=%f, maxValue=%f
Insufficient peak error for ROI computation %f (threshold %f)
Peak rejection threshold = %f (mean = %f, std = %f)
Starting ROI construction at %d->%d
ThumbnailCluster - adding %s
[CIBurstThumbnailCluster initWithImageData] : metadata parsing error
[CIBurstThumbnailCluster initWithImageData] : no error
initWithCGImage: %dx%d
Error with VTPixelTransferSessionTransferImage:%d
kernel vec4 _white(__sample src) 
 return vec4(src.a); 
kernel vec4 _cmyk_convert(__sample src, vec2 ucrgcr) 
 vec4 pix = src; 
 vec3 v = 1.0 - pix.rgb; 
 float f = min(min(v.r,v.g),v.b) * ucrgcr.y; 
 float sblack = f * f; 
 float removed = sblack * ucrgcr.x; 
 pix.rgb = v - vec3(removed); 
 pix.a = sblack; 
 return pix; 
kernel vec4 _cmyk_cyan(__sample sofar, __sample cmyksrc, vec2 center, vec4 mtx, float con) 
 vec2 pt = destCoord() - center; 
 pt = vec2(dot(pt, mtx.xy),dot(pt, mtx.zw)); 
 pt = fract(pt + center) * 6.2831853; 
 float g = (sin(pt.x) + sin(pt.y)) * 0.25 * (0.995 - 1.0 / con) + 0.5; 
 float f = clamp((cmyksrc.r - g) * con + 0.5, 0.0, 1.0); 
 vec4 ink = mix(vec4(1.0), vec4(0.0,1.0,1.0,1.0), f); 
 return clamp(ink * sofar, 0.0, 1.0); 
kernel vec4 _cmyk_magenta(__sample sofar, __sample cmyksrc, vec2 center, vec4 mtx, float con) 
 vec2 pt = destCoord() - center; 
 pt = vec2(dot(pt, mtx.xy),dot(pt, mtx.zw)); 
 pt = fract(pt + center) * 6.2831853; 
 float g = (sin(pt.x) + sin(pt.y)) * 0.25 * (0.995 - 1.0 / con) + 0.5; 
 float f = clamp((cmyksrc.g - g) * con + 0.5, 0.0, 1.0); 
 vec4 ink = mix(vec4(1.0), vec4(1.0,0.0,1.0,1.0), f); 
 return clamp(ink * sofar, 0.0, 1.0); 
kernel vec4 _cmyk_yellow(__sample sofar, __sample cmyksrc, vec2 center, vec4 mtx, float con) 
 vec2 pt = destCoord() - center; 
 pt = vec2(dot(pt, mtx.xy),dot(pt, mtx.zw)); 
 pt = fract(pt + center) * 6.2831853; 
 float g = (sin(pt.x) + sin(pt.y)) * 0.25 * (0.995 - 1.0 / con) + 0.5; 
 float f = clamp((cmyksrc.b - g) * con + 0.5, 0.0, 1.0); 
 vec4 ink = mix(vec4(1.0), vec4(1.0,1.0,0.0,1.0), f); 
 return clamp(ink * sofar, 0.0, 1.0); 
kernel vec4 _cmyk_black(__sample sofar, __sample cmyksrc, vec2 center, vec4 mtx, float con) 
 vec2 pt = destCoord() - center; 
 pt = vec2(dot(pt, mtx.xy),dot(pt, mtx.zw)); 
 pt = fract(pt + center) * 6.2831853; 
 float g = (sin(pt.x) + sin(pt.y)) * 0.25 * (0.995 - 1.0 / con) + 0.5; 
 float f = clamp((cmyksrc.a - g) * con + 0.5, 0.0, 1.0); 
 vec4 ink = mix(vec4(1.0), vec4(0.0,0.0,0.0,1.0), f); 
 return clamp(ink * sofar, 0.0, 1.0); 
inputWidth
inputSharpness
inputGCR
inputUCR
inputAVCameraCalibrationData
Calibration Data object of type AVCameraCalibrationData
inputUseInverseLookUpTable
Use Inverse Look Up Table
lookUpTableLength
inputExtent
lookUpTable
opticalCenter
kernel vec4 _radialLensDistortion(sampler src, sampler lut, vec4 params) { vec2 opticalCenter = vec2(params.x, params.y); float r_max = params.z; float lutSize = params.w - 1.0; float r_point = distance(destCoord(), opticalCenter); float mag = sample(lut, samplerTransform(lut, vec2(lutSize*r_point/r_max + .5, .5))).x; vec2 v_point = destCoord() - opticalCenter; vec2 warpedCoord = (v_point + mag*v_point) + opticalCenter; vec4 c = sample(src, samplerTransform(src, warpedCoord)); return c; }
kernel vec4 _cheapBlur(sampler src, vec2 parms) 
 vec2 dc = destCoord(); 
 vec2 offA = parms * vec2(-1.0, 4.0); 
 vec2 offB = parms * vec2( 4.0, 1.0); 
 vec4 sul = sample(src, samplerTransform(src, dc + offA)); 
 vec4 sur = sample(src, samplerTransform(src, dc + offB)); 
 vec4 sdl = sample(src, samplerTransform(src, dc - offB)); 
 vec4 sdr = sample(src, samplerTransform(src, dc - offA)); 
 vec4 sc = sample(src, samplerCoord (src)); 
 return 0.181818181818182 * sc + 0.204545454545455 * (sur + sul + sdr + sdl); 
kernel vec4 _lerp(__sample src0, __sample src1, float factor) { return mix(src1, src0, factor); }
inputPasses
inputSampling
kernel vec4 _box4(sampler src) 
 vec2 d = destCoord() * 4.0; 
 vec4 q0 = sample(src, samplerTransform(src, d + vec2(-1.0, -1.0))); 
 vec4 q1 = sample(src, samplerTransform(src, d + vec2(-1.0, +1.0))); 
 vec4 q2 = sample(src, samplerTransform(src, d + vec2(+1.0, -1.0))); 
 vec4 q3 = sample(src, samplerTransform(src, d + vec2(+1.0, +1.0))); 
 return 0.25*(q0+q1+q2+q3); 
kernel vec4 _box6(sampler src) 
 vec2 d = destCoord() * 6.0; 
 vec4 q0 = sample(src, samplerTransform(src, d + vec2(-2.0, -2.0))); 
 vec4 q1 = sample(src, samplerTransform(src, d + vec2( 0.0, -2.0))); 
 vec4 q2 = sample(src, samplerTransform(src, d + vec2(+2.0, -2.0))); 
 vec4 q3 = sample(src, samplerTransform(src, d + vec2(-2.0, 0.0))); 
 vec4 q4 = sample(src, samplerTransform(src, d + vec2( 0.0, 0.0))); 
 vec4 q5 = sample(src, samplerTransform(src, d + vec2(+2.0, 0.0))); 
 vec4 q6 = sample(src, samplerTransform(src, d + vec2(-2.0, +2.0))); 
 vec4 q7 = sample(src, samplerTransform(src, d + vec2( 0.0, +2.0))); 
 vec4 q8 = sample(src, samplerTransform(src, d + vec2(+2.0, +2.0))); 
 return (1.0/9.0)*(q0+q1+q2+q3+q4+q5+q6+q7+q8); 
kernel vec4 _cross4(sampler src, float weight) 
 vec2 d = destCoord(); 
 vec4 q0 = sample(src, samplerTransform(src, d)); 
 vec4 q1 = sample(src, samplerTransform(src, d - vec2(+0.5, +1.5))); 
 vec4 q2 = sample(src, samplerTransform(src, d + vec2(+0.5, +1.5))); 
 vec4 q3 = sample(src, samplerTransform(src, d - vec2(+1.5, -0.5))); 
 vec4 q4 = sample(src, samplerTransform(src, d + vec2(+1.5, -0.5))); 
 q1 = 0.23*(q1+q2+q3+q4) + 0.08*q0; 
 return mix(q0,q1, weight); 
inputAmount
kernel vec4 _checker (vec2 center, __color c0, __color c1, vec3 parms) 
 vec2 d0 = destCoord() - center; 
 d0 = fract(d0 * parms.x); 
 d0 = min (1.0 - d0, d0); 
 d0 = clamp (d0 * parms.y + parms.z, 0.0, 1.0); 
 d0 = (d0 * -2.0 + 3.0) * d0 * d0; 
 float d1 = 2.0 * min (d0.x, d0.y) + 1.0 - (d0.x + d0.y); 
 return mix(c1, c0, d1); 
inputColor0
inputColor1
kernel vec4 _circle (vec4 parms, __color color) 
 float d = parms.z - length (destCoord() - parms.xy); 
 return clamp (d * parms.w + .5, 0.0, 1.0) * color; 
inputEdgeBlur
inputColor
kernel vec2 _circleSplash(vec2 center, float radius) 
 vec2 r0; 
 float r1, r2; 
 r0 = destCoord() - center; 
 r1 = dot (r0, r0); 
 r2 = inversesqrt (r1); 
 r1 = r1 * r2; 
 r0 = r0 * r2; 
 r1 = min(r1, radius); 
 r0 = r0 * r1 + center; 
 return r0; 
kernel vec2 _circularWrap(vec2 center, float b, float c, float d, float minAngle) 
 vec2 p; 
 vec2 t0 = destCoord() - center; 
 float d0 = dot(t0, t0); 
 float d1 = inversesqrt(d0); 
 float r = d0 * d1; 
 vec2 u = t0 * d1; 
 vec2 x_ = abs(u); 
 vec2 t = 0.00119152193164364 + (1.149637430629571 + (-0.6987144230270900 + 0.9002138006758336 * x_) * x_) * x_; 
 vec2 thetas = compare(u, -t, t); 
 thetas.x = (u.y < 0.0) ? (thetas.x - 1.5707963) : (1.5707963 - thetas.x); 
 thetas.y = (u.x < 0.0) ? (3.1415927 - thetas.y) : thetas.y; 
 vec2 abss = abs(u); 
 float theta = (abss.x < abss.y) ? thetas.x : thetas.y; 
 theta = fract((theta - minAngle) * 0.15915494) * 6.2831853; 
 p.x = theta * c + d; 
 p.y = r + b; 
 return p; 
Calling Alloc on %@ is not allowed
-[CIColor initWithRed:green:blue:alpha:colorSpace:]
%g %g %g %g
green
blue
alpha
<CIColor %p 
%s%g
v16@?0^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}8
UIColor
colorWithCIColor:
inputStrength
inputWarmth
inputDamping
kernel vec4 _colorbalance (__sample pix, __color clr, vec4 params) 
 pix.rgb = pix.r * vec3(0.299, 0.595716, 0.211456) + 
 pix.g * vec3(0.587, -0.274453, -0.522591) + 
 pix.b * vec3(0.114, -0.321263, 0.311135); 
 clr.rgb /= max(clr.a, 0.00001); 
 clr.rgb = pow(max(clr.rgb, 0.0), vec3(0.25)); 
 clr.rgb = clr.r * vec3(0.299, 0.595716, 0.211456) + 
 clr.g * vec3(0.587, -0.274453, -0.522591) + 
 clr.b * vec3(0.114, -0.321263, 0.311135); 
 pix.gb += params.z * (params.xy - clr.gb) * pow(pix.r, params.w); 
 pix.rgb = pix.r * vec3(1.0) + 
 pix.g * vec3(0.956296, -0.272122, -1.10699) + 
 pix.b * vec3(0.621024, -0.647381, 1.70461); 
 return pix; 
kernel vec4 _colorClamp (__sample c, vec4 lo, vec4 hi) { return clamp(c,lo,hi); }
kernel vec4 _colorClampAP(__sample c, vec4 lo, vec4 hi) { return clamp(c,lo,hi); }
inputMinComponents
inputMaxComponents
inputCubeDimension
inputCubeData
kernel vec4 _colorcube_denorm (__sample im, sampler2D cube, vec4 dims) 
 im.rgb = clamp(im.rgb, 0.0001, 0.9999); 
 im.rgb *= dims.x; 
 float flr = floor(im.b); 
 vec2 xy = (0.5 + im.rg); 
 float pageA = flr; 
 float pageB = min(pageA+1.0, dims.x); 
 vec4 sLo = texture2D(cube, xy + vec2(0.0, pageA * (dims.x + 1.0))); 
 vec4 sHi = texture2D(cube, xy + vec2(0.0, pageB * (dims.x + 1.0))); 
 return mix(sLo, sHi, im.b - flr) * im.a; 
kernel vec4 _colorcube (__sample im, sampler2D cube, vec4 dims) 
 im.rgb = clamp(im.rgb, 0.0001, 0.9999); 
 im.rgb *= dims.x; 
 float flr = floor(im.b); 
 vec2 xy = (0.5 + im.rg) * dims.zw; 
 xy.y += flr * dims.z; 
 vec4 sLo = texture2D(cube, xy); 
 xy.y += dims.z; 
 vec4 sHi = texture2D(cube, xy); 
 return mix(sLo, sHi, im.b - flr) * im.a; 
kernel vec4 _colorcubeopaque_denorm (__sample im, sampler2D cube, vec4 dims) 
 im.rgb = clamp(im.rgb, 0.0001, 0.9999); 
 im.rgb *= dims.x; 
 float flr = floor(im.b); 
 vec2 xy = (0.5 + im.rg); 
 float pageA = flr; 
 float pageB = min(pageA+1.0, dims.x); 
 vec3 sLo = texture2D(cube, xy + vec2(0.0, pageA * (dims.x + 1.0))).rgb; 
 vec3 sHi = texture2D(cube, xy + vec2(0.0, pageB * (dims.x + 1.0))).rgb; 
 im.rgb = mix(sLo, sHi, im.b - flr); 
 return im; 
kernel vec4 _colorcubeopaque (__sample im, sampler2D cube, vec4 dims) 
 im.rgb = clamp(im.rgb, 0.0001, 0.9999); 
 im.rgb *= dims.x; 
 float flr = floor(im.b); 
 vec2 xy = (0.5 + im.rg) * dims.zw; 
 xy.y += flr * dims.z; 
 vec3 sLo = texture2D(cube, xy).rgb; 
 xy.y += dims.z; 
 vec3 sHi = texture2D(cube, xy).rgb; 
 im.rgb = mix(sLo, sHi, im.b - flr); 
 return im; 
CIColorCube
v56@?0^v8Q16Q24Q32Q40Q48
CIColorCube inputCubeDimension must be from 2 through %d.
CIColorCube inputCubeData must be of type NSData.
CIColorCube inputCubeData is not of the expected length.
inputColorSpace
CIColorCubeWithColorSpace inputColorSpace must be an RGB CGColorSpaceRef
inputCube0Data
inputCube1Data
CIColorCube inputCube0Data must be of type NSData.
CIColorCube inputCube1Data must be of type NSData.
CIColorCube inputCube0Data is not of the expected length.
CIColorCube inputCube1Data is not of the expected length.
CIColorCubeWithColorSpace
CIBlendWithMask
inputBackgroundImage
inputMaskImage
inputCurvesData
inputCurvesDomain
kernel vec4 _colorcurves (__sample im, sampler2D table, vec2 domain, vec2 normalizer) 
 im.rgb = (im.rgb - domain.x) / (domain.y - domain.x); 
 im.rgb = clamp(im.rgb, 0.0001, 0.9999); 
 return vec4( 
 texture2D(table, vec2(normalizer.x * im.r + normalizer.y, 0.5)).r, 
 texture2D(table, vec2(normalizer.x * im.g + normalizer.y, 0.5)).g, 
 texture2D(table, vec2(normalizer.x * im.b + normalizer.y, 0.5)).b, 
 im.a); 
CIColorCurves
CIColorCurves inputCurvesData must be of type NSData.
CIColorCurves inputCurvesData is not of the expected length.
CIColorCurves inputCurvesDomain must be of type CIVector and count 2.
CIColorCurves inputCurvesDomain X must be less than Y.
CIColorCurves inputColorSpace must be an RGB CGColorSpaceRef
11.0
inputThreshold
NSNumber
kernel vec4 _colorThreshold(__sample c, float t) { c.rgb = compare(c.rgb - t, vec3(0.0), vec3(1.0)); return c; }
kernel vec4 _otsu(sampler hist, float bins) 
 int histCount = int(bins); 
 vec4 total = vec4(0.0); 
 vec4 sum1 = vec4(0.0); 
 for (int i = 0; i<histCount; i++) 
 vec4 hist_at_i = sample(hist, samplerTransform(hist, vec2(i+0.5, 0.5))); 
 total += hist_at_i; 
 sum1 += hist_at_i * float(i); 
 vec4 level = vec4(0.0); 
 vec4 sumB = vec4(0.0); 
 vec4 wB = vec4(0.0); 
 vec4 maximum = vec4(0.0); 
 for (int i = 0; i<histCount; i++) 
 vec4 hist_at_i = sample(hist, samplerTransform(hist, vec2(i+0.5, 0.5))); 
 vec4 wF = total - wB; 
 vec4 wFwB = wB * wF; 
 vec4 md = total*sumB - wB*sum1; 
 vec4 val = md * md / wFwB; 
 if (-wFwB.r >= 0.0) val.r = -1.0; if (-wFwB.g >= 0.0) val.g = -1.0; if (-wFwB.b >= 0.0) val.b = -1.0; if (val.r >= maximum.r) level.r = float(i); if (val.g >= maximum.g) level.g = float(i); if (val.b >= maximum.b) level.b = float(i); maximum = max(maximum,val); 
 wB += hist_at_i; 
 sumB += hist_at_i * float(i); 
 vec4 result = level / (bins-1.0); result.a = 1.0; return result; }
kernel vec4 _otsuThresh(__sample i, __sample o) 
 i.rgb = compare(i.rgb-o.rgb, vec3(0.0), vec3(1.0)); return i; 
kernel vec4 _colorMonochrome (__sample img, __color color, float intensity) 
 float c1 = dot(img.rgb, vec3(0.2125, 0.7154, 0.0721)); 
 vec4 low = 2.0 * c1 * color; 
 vec4 high = 1.0 - 2.0 * ((1.0 - c1) * (vec4(1.0) - color)); 
 vec4 lt = vec4(lessThan(vec4(c1 - 0.5), vec4(0.0))); 
 vec4 pix = mix(img, mix(high, low, lt), intensity); 
 img.rgb = pix.rgb; 
 return img; 
10.15
inputPerceptual
float _PA_distance(vec4 c) { return dot(c,c); } 
 kernel vec4 _palettize(sampler image, sampler palette, float K) { 
 vec4 img = sample(image, samplerTransform(image, destCoord())); 
 vec4 minp = sample(palette, samplerTransform(palette, vec2(0.5, 0.5))); 
 float mind = _PA_distance(img-minp); 
 for (float m = 1.0f; m < K; m += 1.0f) { 
 vec4 pal = sample(palette, samplerTransform(palette, vec2(0.5+m, 0.5))); 
 float d = _PA_distance(img-pal); 
 if (d < mind) { 
 mind = d; 
 minp = pal; 
 return vec4(minp.rgb, img.a); 
-[CIPalettize outputImage]
CILinearToSRGBToneCurve
CISRGBToneCurveToLinear
kernel vec4 _ddither(__sample c, __sample n, float amount) 
 float nn = (n.r + n.g + n.b + n.a)*0.25 - 0.5; 
 c.rgb = c.rgb + amount*nn; 
 return c; 
CIRandomGenerator
inputSoftness
kernel vec4 _shadowdesat(__sample u, float shadow, float amount, float feather) { 
 float Y = dot(u.rgb, vec3(0.299, 0.587, 0.114)); 
 float mask = 1.0 - smoothstep(feather*shadow, shadow, Y); 
 return vec4(mix(u.rgb, vec3(Y), mask * amount), u.a); 
kernel vec4 _colorMap (sampler src, sampler map, float scale) 
 vec4 s = unpremultiply(sample(src, samplerCoord(src))); 
 float n = clamp(dot(s.rgb, vec3(0.2125, 0.7154, 0.0721)), 0.0, 1.0); 
 return s.a * sample(map, samplerTransform(map, vec2(n*scale + 0.5, 0.5))); 
%s requires the inputGradientImage to be finite
-[CIColorMap outputImage]
inputChannelIndex
inputShouldNormalize
inputColorMapIndex
kernel vec4 _ciSingleChannelColorMap(sampler s,sampler lut) __attribute__((outputFormat(kCIFormatRh))) { 
 float v = clamp(sample(s, samplerCoord(s)).x, 0.0, 1.0); 
 float vInt = (256.0 - 1.0) * v; 
 vec2 xy = samplerTransform(lut, vec2(vInt, 0.5)); 
 return sample(lut, xy); }
kernel vec4 _ciExtractChannel(__sample s,float nF) __attribute__((outputFormat(kCIFormatRh))) {
 int n = int(nF); 
 return vec4(n == 0 ? s.x : n == 1 ? s.y : n == 2 ? s.z : s.w, 0.0, 0.0, 1.0); 
CISingleChannelColorMap_%d
-[CISingleChannelColorMap outputImage]_block_invoke
CIColorMap.mm
(x+width) <= CICOLORMAP_NUM_COLORS_PER_MAP
-[CISingleChannelColorMap outputImage]
image
CIAreaMinMaxRedNormalize
inputRVector
inputGVector
inputBVector
inputAVector
inputBiasVector
CIColorMatrix
kernel vec4 _colorPolynomial (__sample c, vec4 cf0, vec4 cf1, vec4 cf2, vec4 cf3) 
 return cf0 + c * (cf1 + c * (cf2 + c * cf3)); 
kernel vec4 _colorPolynomialRGB (__sample c, vec4 cf0, vec4 cf1, vec4 cf2, vec4 cf3) 
 float a = c.a; 
 c = cf0 + c * (cf1 + c * (cf2 + c * cf3)); 
 c.a = a; 
 return c; 
inputRedCoefficients
inputGreenCoefficients
inputBlueCoefficients
inputAlphaCoefficients
kernel vec4 _colorPolynomialInverse (__sample x, vec4 a, vec4 b, vec4 c, vec4 d) 
 vec4 c2 = c*c; 
 vec4 c3 = c*c*c; 
 vec4 t = 27.0*d*d*(x-a) + 9.0*b*c*d - 2.0*c3; 
 vec4 threeBDmC2 = 3.0*b*d - c2; t = sqrt(t*t + 4.0*threeBDmC2*threeBDmC2*threeBDmC2) + t; 
 t = pow(t*0.5, vec4(1.0 / 3.0)); 
 vec4 result3rd = t/(3.0*d) - (b - c2/(3.0*d))/t - c/(3.0*d); 
 vec4 result2nd = (-b + sqrt(b*b - 4.0*c*(a - x))) / (2.0 * c); 
 vec4 result1st = (x - a) / b; 
 vec4 result = x; 
 if (d.r == 0 && c.r == 0) 
 result.r = result1st.r; 
 else if (d.r == 0.0) 
 result.r = result2nd.r; 
 else 
 result.r = result3rd.r; 
 if (d.g == 0.0 && c.g == 0.0) 
 result.g = result1st.g; 
 else if (d.g == 0.0) 
 result.g = result2nd.g; 
 else 
 result.g = result3rd.g; 
 if (d.b == 0.0 && c.b == 0.0) 
 result.b = result1st.b; 
 else if (d.b == 0.0) 
 result.b = result2nd.b; 
 else 
 result.b = result3rd.b; 
 if (d.a == 0.0 && c.a == 0.0) 
 result.a = result1st.a; 
 else if (d.a == 0) 
 result.a = result2nd.a; 
 else 
 result.a = result3rd.a; 
 return result; 
kernel vec4 _colorPolynomialInverseRGB (__sample x, vec4 a, vec4 b, vec4 c, vec4 d) 
 vec4 c2 = c*c; 
 vec4 c3 = c*c*c; 
 vec4 t = 27.0*d*d*(x-a) + 9.0*b*c*d - 2.0*c3; 
 vec4 threeBDmC2 = 3.0*b*d - c2; t = sqrt(t*t + 4.0*threeBDmC2*threeBDmC2*threeBDmC2) + t; 
 t = pow(t*0.5, vec4(1.0 / 3.0)); 
 vec4 result3rd = t/(3.0*d) - (b - c2/(3.0*d))/t - c/(3.0*d); 
 vec4 result2nd = (-b + sqrt(b*b - 4.0*c*(a - x))) / (2.0 * c); 
 vec4 result1st = (x - a) / b; 
 vec4 result = x; 
 if (d.r == 0 && c.r == 0) 
 result.r = result1st.r; 
 else if (d.r == 0.0) 
 result.r = result2nd.r; 
 else 
 result.r = result3rd.r; 
 if (d.g == 0.0 && c.g == 0.0) 
 result.g = result1st.g; 
 else if (d.g == 0.0) 
 result.g = result2nd.g; 
 else 
 result.g = result3rd.g; 
 if (d.b == 0.0 && c.b == 0.0) 
 result.b = result1st.b; 
 else if (d.b == 0.0) 
 result.b = result2nd.b; 
 else 
 result.b = result3rd.b; 
 return result; 
kernel vec4 _colorCrossPolynomial (__sample c, vec3 pr, vec3 pg, vec3 pb, 
 vec3 prr, vec3 pgg, vec3 pbb, 
 vec3 prg, vec3 pgb, vec3 pbr, vec3 p1) 
 c.rgb = c.r * pr + c.g * pg + c.b * pb + 
 c.r * c.r * prr + c.g * c.g * pgg + c.b * c.b * pbb + 
 c.r * c.g * prg + c.g * c.b * pgb + c.b * c.r * pbr + p1; 
 return c; 
inputLevels
kernel vec4 _colorPosterize (__sample src, vec2 factors) 
 src.rgb = floor(src.rgb * factors.x + 0.5) * factors.y; 
 return src; 
kernel vec4 _fusionDelta(__sample image,vec3 addBlur,vec3 removeBlur,float apertureScaling) {
 float additiveTerm = clamp( addBlur.x * image.x + addBlur.y , 0.0, 1.0 ); 
 float subtractiveTerm = clamp( removeBlur.x * image.x + removeBlur.y, 0.0, 1.0 ); 
 float delta = additiveTerm - subtractiveTerm; 
 delta *= (delta > 0.0 ? abs(addBlur.z) : abs(removeBlur.z)) * apertureScaling; 
 return vec4(delta,delta,delta,1.0);
inputApertureScaling
kernel vec4 _fusionTwoImages(__sample person,__sample hair, 
 vec3 additive,vec3 subtractive, 
 float protectBodyStrength,float apertureScaling) 
 float additiveTerm = clamp( additive.x * hair.x + additive.y, 0.0f, 1.0f); 
 float subtractiveTerm = clamp( subtractive.x * hair.x + subtractive.y, 0.0f, 1.0f); 
 float delta = additiveTerm - subtractiveTerm; 
 float nonHairAlpha = protectBodyStrength * max(0.0f, (person.x - hair.x)); 
 float fusionData = delta * (1.0f - nonHairAlpha); 
 fusionData *= (fusionData > 0.0f ? abs(additive.z) : abs(subtractive.z)) * apertureScaling; 
 return vec4(fusionData,fusionData,fusionData,1.0f); 
kernel vec4 _sobelEdges(sampler src, float scale) 
 vec2 coord = destCoord(); 
 vec2 sc = samplerTransform(src, coord); 
 vec2 dx = samplerTransform(src, coord + vec2(1.0, 0.0)) - sc; 
 vec2 dy = samplerTransform(src, coord + vec2(0.0, 1.0)) - sc; 
 vec2 d = dx + dy; 
 vec4 pix3 = sample(src, sc + d); 
 vec4 pix7 = sample(src, sc - d); 
 d = dx - dy; 
 vec4 pix9 = sample(src, sc + d); 
 vec4 pix1 = sample(src, sc - d); 
 vec4 pix2 = sample(src, sc + dy); 
 vec4 pix8 = sample(src, sc - dy); 
 vec4 pix6 = sample(src, sc + dx); 
 vec4 pix4 = sample(src, sc - dx); 
 vec4 pix5 = sample(src, sc); 
 vec4 gx = (pix3 + 2.0*pix6 + pix9) - (pix1 + 2.0*pix4 + pix7); 
 vec4 gy = (pix1 + 2.0*pix2 + pix3) - (pix7 + 2.0*pix8 + pix9); 
 vec4 g2 = gx*gx + gy*gy; 
 pix5 = vec4(pix5.rgb/max(pix5.a,0.00001), pix5.a); 
 pix5.rgb = sqrt(g2).rgb * scale; 
 return vec4(pix5.rgb*pix5.a, pix5.a); 
kernel vec4 _noiseComicReduction(sampler src, vec2 offset, vec3 weight, vec3 intensity) 
 vec2 c = destCoord(); 
 vec4 cn = sample(src, samplerTransform(src, c)); 
 vec4 t0 = sample(src, samplerTransform(src, c + vec2(0.0, -offset.x))); 
 vec4 t1 = sample(src, samplerTransform(src, c + vec2(0.0, offset.x))); 
 vec4 t2 = sample(src, samplerTransform(src, c + vec2(-offset.x, 0.0))); 
 vec4 t3 = sample(src, samplerTransform(src, c + vec2(offset.x, 0.0))); 
 vec4 t4 = sample(src, samplerTransform(src, c + vec2(offset.y, offset.y))); 
 vec4 t5 = sample(src, samplerTransform(src, c + vec2(offset.y, -offset.y))); 
 vec4 t6 = sample(src, samplerTransform(src, c + vec2(-offset.y, -offset.y))); 
 vec4 t7 = sample(src, samplerTransform(src, c + vec2(-offset.y, offset.y))); 
 t0 = (t0 + t1 + t2 + t3) * weight.x + (t4 + t5 + t6 + t7) * weight.y + cn * weight.z; 
 vec4 d = abs(t0 - cn); 
 float s = intensity.x + intensity.y * (d.r + d.g + d.b); 
 s = clamp(s, intensity.z, 1.0); 
 return mix(cn, t0, s); 
kernel vec4 _colorControls(__sample src, float threshold, float contrast) 
 vec4 pix = vec4(src.rgb/max(src.a,0.00001), src.a); 
 float f = clamp((dot(pix.rgb, vec3(0.2125, 0.7154, 0.0721)) - threshold) * contrast + 0.5, 0.0, 1.0); 
 return vec4(0.0, 0.0, 0.0, f); 
inputNRSharpness
inputNRNoiseLevel
inputEdgeIntensity
inputContrast
kernel vec4 _spotColor(__sample src, 
 __color cclr1, __color rclr1, 
 __color cclr2, __color rclr2, 
 __color cclr3, __color rclr3, 
 vec4 closeness, vec4 contrast) 
 vec4 pix = vec4(src.rgb/max(src.a,0.00001), src.a); 
 float dist = length(pix.rgb - cclr1.rgb); 
 float alpha = clamp((closeness.x - dist) * contrast.x + 0.5, 0.0, 1.0); 
 vec4 result1 = rclr1 * alpha; 
 dist = length(pix.rgb - cclr2.rgb); 
 alpha = clamp((closeness.y - dist) * contrast.y + 0.5, 0.0, 1.0); 
 vec4 result2 = rclr2 * alpha; 
 dist = length(pix.rgb - cclr3.rgb); 
 alpha = clamp((closeness.z - dist) * contrast.z + 0.5, 0.0, 1.0); 
 vec4 result3 = rclr3 * alpha; 
 pix = result1 + (1.0 - result1.a) * vec4(1.0); 
 pix = result2 + (1.0 - result2.a) * pix; 
 return result3 + (1.0 - result3.a) * pix; 
inputCloseness1
inputContrast1
inputCenterColor1
CIColor
inputReplacementColor1
inputCloseness2
inputContrast2
inputCenterColor2
inputReplacementColor2
inputCloseness3
inputContrast3
inputCenterColor3
inputReplacementColor3
CISpotColor
CICMYKHalftone
CILineOverlay
output_color_space
working_color_space
working_format
software_renderer
quality
high_quality_downsample
output_premultiplied
kCIContextCacheIntermediates
priority_request_high
priority_request_low
disable_software_fallback
color_cube_size
share_context
default_CGImage_format
parametric_color_matching
inline_affine_matrices
kCIContextEnableBlending
kCIContextUseMetalRenderer
kCIContextAllowLowPower
kCIContextAllowClampToAlpha
kCIContextAllowHalfPrecision
kCIContextIntermediateMemoryTarget
kCIContextName
kCIContextHLGOpticalScale
kCIContextLossyCompressedIntermediates
metallib
Failed to load %@.metallib for prewarming
CISingletonContext
-[CIContext setObject:forKey:]
-[CIContext objectForKey:]
-[CIContext initWithOptions:]
CoreUI
v12@?0B8
-[CIContext initWithEAGLContext:options:]
-[CIContext render:toBitmap:rowBytes:bounds:format:colorSpace:]
-[CIContext render:]
-[CIContext drawImage:inRect:fromRect:]
-[CIContext render:toTexture:target:bounds:colorSpace:]
-[CIContext render:toMTLTexture:commandBuffer:bounds:colorSpace:]
-[CIContext flatten:fromRect:format:colorSpace:]
<%@: %p (%s %d)
%@ MTLDevice=%p
%@ bounds=[empty]
%@ bounds=[%g %g %g %g]
%@    withCGContext: %p
%@    withGLContext: %p
    name: %s
    cache intermediates: %s
%@    priority: default
%@    priority: high
%@    priority: low
%@    workingSpace: %@
%@    workingFormat: %s
%@    lossyIntermediates: true
%@    downsampleQuality: %@
High
+[CIContext(Internal) internalContextWithEAGLContext:options:]
kCIFormatBGRA8, kCIFormatRGBA8, kCIFormatRGBAh or nil
+[CIContext(Internal) internalContextWithMTLCommandQueue:options:]
kCIFormatBGRA8, kCIFormatRGBA8, kCIFormatRGBAh, kCIFormatRGBAf or nil
CoreImage <%@>
 from 
set_context_options
com.apple.CoreImage
com.apple.CoreImage-Internal
-[CIContext(createCGImage) _createCGImage:fromRect:format:colorSpace:deferred:error:]
-[CIContext(createCGImage) createCGImage:fromRect:format:]
-[CIContext(createCGImage) createCGImage:fromRect:format:colorSpace:]
-[CIContext(createCGImage) createCGImage:fromRect:format:colorSpace:deferred:error:]
v48@?0{CGRect={CGPoint=dd}{CGSize=dd}}8@"NSError"40
create_cgimage
v48@?0r^v8Q16Q24Q32Q40
Could not access surface.
Singular matrix cannot be inverted!
com.apple.coreimage.deferred
Cannot create a CGImageProvider for %s
CGImageProviderCallbackQueue
kCGImageProviderPrefersBandedDecoding
kCGImageProviderPreferedBandHeight
failed mprotect
kCGImageSurfaceFormatRequest
kCGImageSurfaceBytesPerRowAlignmentRequest
kCIImageRepresentationHDRGainMapImage
-[CIContext(ImageRepresentation) _TIFFRepresentationOfImage:format:colorSpace:options:error:]
public.tiff
-[CIContext(ImageRepresentation) _PNGRepresentationOfImage:format:colorSpace:options:error:]
public.png
kCIImageRepresentationAVDepthData
kCIImageRepresentationDepthImage
kCIImageRepresentationDisparityImage
kCIImageRepresentationAVPortraitEffectsMatte
kCIImageRepresentationPortraitEffectsMatteImage
kCIImageRepresentationAVSemanticSegmentationMattes
kCIImageRepresentationSemanticSegmentationSkinMatteImage
kCIImageRepresentationSemanticSegmentationHairMatteImage
kCIImageRepresentationSemanticSegmentationTeethMatteImage
kCIImageRepresentationSemanticSegmentationGlassesMatteImage
kCIImageRepresentationSemanticSegmentationSkyMatteImage
public.jpeg
-[CIContext(ImageRepresentation) _HEIFRepresentationOfImage:format:colorSpace:options:error:]
public.heic
-[CIContext(ImageRepresentation) HEIF10RepresentationOfImage:colorSpace:options:error:]
requires an image with a finite non-empty extent.
unsupported colorspace.
failed to create a CVPixelBuffer.
failed to create a PhotoCompressionSession.
-[CIContext(ImageRepresentation) writeTIFFRepresentationOfImage:toURL:format:colorSpace:options:error:]
failed to create data representation.
failed to write TIFF data to file.
-[CIContext(ImageRepresentation) writePNGRepresentationOfImage:toURL:format:colorSpace:options:error:]
failed to write PNG data to file.
failed to write JPEG data to file.
-[CIContext(ImageRepresentation) writeHEIFRepresentationOfImage:toURL:format:colorSpace:options:error:]
failed to write HEIC data to file.
kCGImageAuxiliaryDataTypeSemanticSegmentationSkinMatte
kCGImageAuxiliaryDataTypeSemanticSegmentationHairMatte
kCGImageAuxiliaryDataTypeSemanticSegmentationTeethMatte
kCGImageAuxiliaryDataTypeSemanticSegmentationGlassesMatte
kCGImageAuxiliaryDataTypeSemanticSegmentationSkyMatte
kCGImageAuxiliaryDataTypeHDRGainMap
kCGImageAuxiliaryDataInfoData
kCGImageAuxiliaryDataInfoDataDescription
BytesPerRow
PixelFormat
kCGImageAuxiliaryDataTypePortraitEffectsMatte
PortraitEffectsMatteVersion
portraitEffectsMatte
portraitEffectsMatte:PortraitEffectsMatteVersion
kCGImageAuxiliaryDataInfoMetadata
CINonLocalizedDescriptionKey
OSStatus soft_CMPhotoCompressionSessionCreate(CFAllocatorRef, CFDictionaryRef, CMPhotoCompressionSessionRef *)
CIContext_ImageReps.mm
CMPhotoCompressionSessionCreate
void *CMPhotoLibrary()
/System/Library/PrivateFrameworks/CMPhoto.framework/CMPhoto
/System/Library/PrivateFrameworks/CMPhoto.framework/Contents/MacOS/CMPhoto
NSString *getkCMPhotoCompressionContainerOption_Format()
kCMPhotoCompressionContainerOption_Format
NSString *getkCMPhotoCompressionContainerOption_ImageCountHint()
kCMPhotoCompressionContainerOption_ImageCountHint
NSString *getkCMPhotoCompressionContainerOption_BackingType()
kCMPhotoCompressionContainerOption_BackingType
OSStatus soft_CMPhotoCompressionSessionOpenEmptyContainer(CMPhotoCompressionSessionRef, CFDictionaryRef)
CMPhotoCompressionSessionOpenEmptyContainer
NSString *getkCMPhotoCompressionOption_ImageOrientation()
kCMPhotoCompressionOption_ImageOrientation
NSString *getkCMPhotoCompressionOption_QualityControllerType()
kCMPhotoCompressionOption_QualityControllerType
NSString *getkCMPhotoQualityControllerParameter_QualityValue()
kCMPhotoQualityControllerParameter_QualityValue
NSString *getkCMPhotoCompressionOption_QualityControllerParameters()
kCMPhotoCompressionOption_QualityControllerParameters
OSStatus soft_CMPhotoCompressionSessionAddImage(CMPhotoCompressionSessionRef, CFDictionaryRef, CFTypeRef, CMItemIndex *)
CMPhotoCompressionSessionAddImage
OSStatus soft_CMPhotoCompressionSessionAddMetadataFromImageProperties(CMPhotoCompressionSessionRef, CMItemIndex, CFDictionaryRef, CFDictionaryRef)
CMPhotoCompressionSessionAddMetadataFromImageProperties
OSStatus soft_CMPhotoCompressionSessionCloseContainerAndCopyBacking(CMPhotoCompressionSessionRef, CMPhotoImageContainerBackingType *, size_t *, CFTypeRef *)
CMPhotoCompressionSessionCloseContainerAndCopyBacking
image extent must be finite and non-empty.
canCreateDataRepresentation
-[CIContext(CIDepthBlurEffect) depthBlurEffectFilterForImageData:options:]
Orientation
-[CIContext(CIDepthBlurEffect) depthBlurEffectFilterForImageURL:options:]
nose
faceContour
-[CIContext(CIDepthBlurEffect) _performFaceDetection:image:orientation:filter:]
CIContext_SDOF.mm
nGoodFaces <= DBE_MAX_NUM_GOOD_FACES
inputLeftEyePositions
inputRightEyePositions
inputNosePositions
inputChinPositions
-[CIContext(CIDepthBlurEffect) depthBlurEffectFilterForImage:disparityImage:portraitEffectsMatte:hairSemanticSegmentation:glassesMatte:gainMap:orientation:options:]
CIDepthBlurEffect
inputMatteImage
inputHairImage
inputGlassesImage
inputGainMap
inputAuxDataMetadata
depthBlurEffect:SimulatedAperture
inputAperture
inputCalibrationData
inputLumaNoiseScale
inputFocusRect
inputWeights
inputBias
CIConvolutionWeights
CIConvolution3X3 expects inputWeights to be a length-9 CIVector
CIConvolution5X5 expects inputWeights to be a length-25 CIVector
CIConvolution7X7 expects inputWeights to be a length-49 CIVector
kernel vec4 _convrgb3x3sym (sampler image, vec4 parms) 
 vec2 dc = destCoord(); 
 vec2 dA = parms.xy; 
 vec2 dB = vec2(-dA.y, dA.x); 
 vec4 center = sample(image, samplerTransform(image, dc)); 
 vec4 sum = sample(image, samplerTransform(image, dc + dB)) 
 + sample(image, samplerTransform(image, dc + dA)) 
 + sample(image, samplerTransform(image, dc - dA)) 
 + sample(image, samplerTransform(image, dc - dB)); 
 return vec4(sum.rgb * parms.z + parms.w, center.a); 
kernel vec4 _conv3x3sym (sampler image, vec4 parms) 
 vec2 dc = destCoord(); 
 vec2 dA = parms.xy; 
 vec2 dB = vec2(-dA.y, dA.x); 
 vec4 sum = sample(image, samplerTransform(image, dc + dB)) 
 + sample(image, samplerTransform(image, dc + dA)) 
 + sample(image, samplerTransform(image, dc - dA)) 
 + sample(image, samplerTransform(image, dc - dB)); 
 return sum * parms.z + parms.w; 
kernel vec4 _convrgb3x3 (sampler image, vec4 w0, vec4 w1, vec4 w2) 
 vec2 dc = destCoord(); 
 vec4 sum = w2.yyyy; 
 vec2 delta = w2.zw; 
 vec4 center = sample(image, samplerTransform(image, dc)); 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delta.y))) * w0.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, -delta.y))) * w0.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delta.y))) * w0.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, 0.0))) * w0.w; 
 sum += center * w1.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, 0.0))) * w1.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, delta.y))) * w1.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, delta.y))) * w1.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, delta.y))) * w2.x; 
 return vec4(sum.rgb, center.a); 
kernel vec4 _conv3x3 (sampler image, vec4 w0, vec4 w1, vec4 w2) 
 vec2 dc = destCoord(); 
 vec4 sum = w2.yyyy; 
 vec2 delta = w2.zw; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delta.y))) * w0.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, -delta.y))) * w0.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delta.y))) * w0.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, 0.0))) * w0.w; 
 sum += sample(image, samplerTransform(image, dc )) * w1.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, 0.0))) * w1.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, delta.y))) * w1.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, delta.y))) * w1.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, delta.y))) * w2.x; 
 return sum; 
kernel vec4 _convolution9 (sampler image, vec4 w0, vec4 w1, vec4 w2) 
 vec2 dc = destCoord(); 
 vec4 sum = w2.yyyy; 
 vec2 delta = w2.zw; 
 sum += sample(image, samplerTransform(image, dc - delta*4.0)) * w0.x; 
 sum += sample(image, samplerTransform(image, dc - delta*3.0)) * w0.y; 
 sum += sample(image, samplerTransform(image, dc - delta*2.0)) * w0.z; 
 sum += sample(image, samplerTransform(image, dc - delta )) * w0.w; 
 sum += sample(image, samplerTransform(image, dc )) * w1.x; 
 sum += sample(image, samplerTransform(image, dc + delta )) * w1.y; 
 sum += sample(image, samplerTransform(image, dc + delta*2.0)) * w1.z; 
 sum += sample(image, samplerTransform(image, dc + delta*3.0)) * w1.w; 
 sum += sample(image, samplerTransform(image, dc + delta*4.0)) * w2.x; 
 return sum; 
kernel vec4 _convolution7 (sampler image, vec4 w0, vec4 w1, vec4 w2) 
 vec2 dc = destCoord(); 
 vec4 sum = w2.yyyy; 
 vec2 delta = w2.zw; 
 sum += sample(image, samplerTransform(image, dc - delta*3.0)) * w0.y; 
 sum += sample(image, samplerTransform(image, dc - delta*2.0)) * w0.z; 
 sum += sample(image, samplerTransform(image, dc - delta )) * w0.w; 
 sum += sample(image, samplerTransform(image, dc )) * w1.x; 
 sum += sample(image, samplerTransform(image, dc + delta )) * w1.y; 
 sum += sample(image, samplerTransform(image, dc + delta*2.0)) * w1.z; 
 sum += sample(image, samplerTransform(image, dc + delta*3.0)) * w1.w; 
 return sum; 
kernel vec4 _convolutionrgb9 (sampler image, vec4 w0, vec4 w1, vec4 w2) 
 vec2 dc = destCoord(); 
 vec4 sum = w2.yyyy; 
 vec2 delta = w2.zw; 
 vec4 center = sample(image, samplerTransform(image, dc)); 
 sum += sample(image, samplerTransform(image, dc - delta*4.0)) * w0.x; 
 sum += sample(image, samplerTransform(image, dc - delta*3.0)) * w0.y; 
 sum += sample(image, samplerTransform(image, dc - delta*2.0)) * w0.z; 
 sum += sample(image, samplerTransform(image, dc - delta )) * w0.w; 
 sum += center * w1.x; 
 sum += sample(image, samplerTransform(image, dc + delta )) * w1.y; 
 sum += sample(image, samplerTransform(image, dc + delta*2.0)) * w1.z; 
 sum += sample(image, samplerTransform(image, dc + delta*3.0)) * w1.w; 
 sum += sample(image, samplerTransform(image, dc + delta*4.0)) * w2.x; 
 return vec4(sum.rgb, center.a); 
kernel vec4 _convolutionrgb7 (sampler image, vec4 w0, vec4 w1, vec4 w2) 
 vec2 dc = destCoord(); 
 vec4 sum = w2.yyyy; 
 vec2 delta = w2.zw; 
 vec4 center = sample(image, samplerTransform(image, dc)); 
 sum += sample(image, samplerTransform(image, dc - delta*3.0)) * w0.y; 
 sum += sample(image, samplerTransform(image, dc - delta*2.0)) * w0.z; 
 sum += sample(image, samplerTransform(image, dc - delta )) * w0.w; 
 sum += center * w1.x; 
 sum += sample(image, samplerTransform(image, dc + delta )) * w1.y; 
 sum += sample(image, samplerTransform(image, dc + delta*2.0)) * w1.z; 
 sum += sample(image, samplerTransform(image, dc + delta*3.0)) * w1.w; 
 return sum; 
kernel vec4 _convolution5 (sampler image, vec4 w0, vec4 w1) 
 vec2 dc = destCoord(); 
 vec4 sum = w1.yyyy; 
 vec2 delta = w1.zw; 
 sum += sample(image, samplerTransform(image, dc - delta*2.0)) * w0.x; 
 sum += sample(image, samplerTransform(image, dc - delta )) * w0.y; 
 sum += sample(image, samplerTransform(image, dc )) * w0.z; 
 sum += sample(image, samplerTransform(image, dc + delta )) * w0.w; 
 sum += sample(image, samplerTransform(image, dc + delta*2.0)) * w1.x; 
 return sum; 
kernel vec4 _convolution3 (sampler image, vec4 w0, vec4 w1) 
 vec2 dc = destCoord(); 
 vec4 sum = w1.yyyy; 
 vec2 delta = w1.zw; 
 sum += sample(image, samplerTransform(image, dc - delta )) * w0.y; 
 sum += sample(image, samplerTransform(image, dc )) * w0.z; 
 sum += sample(image, samplerTransform(image, dc + delta )) * w0.w; 
 return sum; 
kernel vec4 _convolutionrgb5 (sampler image, vec4 w0, vec4 w1) 
 vec2 dc = destCoord(); 
 vec4 sum = w1.yyyy; 
 vec2 delta = w1.zw; 
 vec4 center = sample(image, samplerTransform(image, dc)); 
 sum += sample(image, samplerTransform(image, dc - delta*2.0)) * w0.x; 
 sum += sample(image, samplerTransform(image, dc - delta )) * w0.y; 
 sum += center * w0.z; 
 sum += sample(image, samplerTransform(image, dc + delta )) * w0.w; 
 sum += sample(image, samplerTransform(image, dc + delta*2.0)) * w1.x; 
 return vec4(sum.rgb, center.a); 
kernel vec4 _convolutionrgb3 (sampler image, vec4 w0, vec4 w1) 
 vec2 dc = destCoord(); 
 vec4 sum = w1.yyyy; 
 vec2 delta = w1.zw; 
 vec4 center = sample(image, samplerTransform(image, dc)); 
 sum += sample(image, samplerTransform(image, dc - delta )) * w0.y; 
 sum += center * w0.z; 
 sum += sample(image, samplerTransform(image, dc + delta )) * w0.w; 
 return vec4(sum.rgb, center.a); 
kernel vec4 _convolutionrgb5x5 (sampler image, vec4 w0, vec4 w1, vec4 w2, vec4 w3, vec4 w4, vec4 w5, vec4 w6) 
 vec2 dc = destCoord(); 
 vec4 sum = w6.yyyy; 
 vec2 delta = w6.zw; 
 vec2 delt2 = 2.0 * delta; 
 vec4 center = sample(image, samplerTransform(image, dc)); 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delt2.y))) * w0.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delt2.y))) * w0.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, -delt2.y))) * w0.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delt2.y))) * w0.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delt2.y))) * w1.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delta.y))) * w1.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delta.y))) * w1.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, -delta.y))) * w1.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delta.y))) * w2.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delta.y))) * w2.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, 0.0))) * w2.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, 0.0))) * w2.w; 
 sum += center * w3.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, 0.0))) * w3.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, 0.0))) * w3.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, delta.y))) * w3.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, delta.y))) * w4.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, delta.y))) * w4.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, delta.y))) * w4.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, delta.y))) * w4.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, delt2.y))) * w5.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, delt2.y))) * w5.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, delt2.y))) * w5.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, delt2.y))) * w5.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, delt2.y))) * w6.x; 
 return vec4(sum.rgb, center.a); 
kernel vec4 _convolution5x5 (sampler image, vec4 w0, vec4 w1, vec4 w2, vec4 w3, vec4 w4, vec4 w5, vec4 w6) 
 vec2 dc = destCoord(); 
 vec4 sum = w6.yyyy; 
 vec2 delta = w6.zw; 
 vec2 delt2 = 2.0 * delta; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delt2.y))) * w0.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delt2.y))) * w0.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, -delt2.y))) * w0.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delt2.y))) * w0.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delt2.y))) * w1.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delta.y))) * w1.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delta.y))) * w1.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, -delta.y))) * w1.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delta.y))) * w2.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delta.y))) * w2.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, 0.0))) * w2.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, 0.0))) * w2.w; 
 sum += sample(image, samplerTransform(image, dc )) * w3.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, 0.0))) * w3.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, 0.0))) * w3.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, delta.y))) * w3.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, delta.y))) * w4.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, delta.y))) * w4.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, delta.y))) * w4.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, delta.y))) * w4.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, delt2.y))) * w5.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, delt2.y))) * w5.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, delt2.y))) * w5.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, delt2.y))) * w5.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, delt2.y))) * w6.x; 
 return sum; 
kernel vec4 _convolutionrgb7x7 (sampler image, vec4 w0, vec4 w1, vec4 w2, vec4 w3, vec4 w4, vec4 w5, vec4 w6, vec4 w7, vec4 w8, vec4 w9, vec4 w10, vec4 w11, vec4 w12) 
 vec2 dc = destCoord(); 
 vec4 sum = w12.yyyy; 
 vec2 delta = w12.zw; 
 vec2 delt2 = 2.0 * delta; 
 vec2 delt3 = 3.0 * delta; 
 vec4 center = sample(image, samplerTransform(image, dc)); 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, -delt3.y))) * w0.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delt3.y))) * w0.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delt3.y))) * w0.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, -delt3.y))) * w0.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delt3.y))) * w1.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delt3.y))) * w1.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, -delt3.y))) * w1.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, -delt2.y))) * w1.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delt2.y))) * w2.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delt2.y))) * w2.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, -delt2.y))) * w2.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delt2.y))) * w2.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delt2.y))) * w3.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, -delt2.y))) * w3.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, -delta.y))) * w3.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delta.y))) * w3.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delta.y))) * w4.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, -delta.y))) * w4.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delta.y))) * w4.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delta.y))) * w4.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, -delta.y))) * w5.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, 0.0))) * w5.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, 0.0))) * w5.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, 0.0))) * w5.w; 
 sum += center * w6.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, 0.0))) * w6.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, 0.0))) * w6.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, 0.0))) * w6.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, delta.y))) * w7.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, delta.y))) * w7.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, delta.y))) * w7.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, delta.y))) * w7.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, delta.y))) * w8.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, delta.y))) * w8.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, delta.y))) * w8.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, delt2.y))) * w8.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, delt2.y))) * w9.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, delt2.y))) * w9.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, delt2.y))) * w9.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, delt2.y))) * w9.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, delt2.y))) * w10.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, delt2.y))) * w10.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, delt3.y))) * w10.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, delt3.y))) * w10.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, delt3.y))) * w11.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, delt3.y))) * w11.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, delt3.y))) * w11.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, delt3.y))) * w11.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, delt3.y))) * w12.x; 
 return vec4(sum.rgb, center.a); 
kernel vec4 _convolution7x7 (sampler image, vec4 w0, vec4 w1, vec4 w2, vec4 w3, vec4 w4, vec4 w5, vec4 w6, vec4 w7, vec4 w8, vec4 w9, vec4 w10, vec4 w11, vec4 w12) 
 vec2 dc = destCoord(); 
 vec4 sum = w12.yyyy; 
 vec2 delta = w12.zw; 
 vec2 delt2 = 2.0 * delta; 
 vec2 delt3 = 3.0 * delta; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, -delt3.y))) * w0.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delt3.y))) * w0.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delt3.y))) * w0.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, -delt3.y))) * w0.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delt3.y))) * w1.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delt3.y))) * w1.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, -delt3.y))) * w1.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, -delt2.y))) * w1.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delt2.y))) * w2.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delt2.y))) * w2.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, -delt2.y))) * w2.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delt2.y))) * w2.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delt2.y))) * w3.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, -delt2.y))) * w3.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, -delta.y))) * w3.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, -delta.y))) * w3.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, -delta.y))) * w4.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, -delta.y))) * w4.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, -delta.y))) * w4.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, -delta.y))) * w4.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, -delta.y))) * w5.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, 0.0))) * w5.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, 0.0))) * w5.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, 0.0))) * w5.w; 
 sum += sample(image, samplerTransform(image, dc )) * w6.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, 0.0))) * w6.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, 0.0))) * w6.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, 0.0))) * w6.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, delta.y))) * w7.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, delta.y))) * w7.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, delta.y))) * w7.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, delta.y))) * w7.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, delta.y))) * w8.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, delta.y))) * w8.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, delta.y))) * w8.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, delt2.y))) * w8.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, delt2.y))) * w9.x; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, delt2.y))) * w9.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, delt2.y))) * w9.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, delt2.y))) * w9.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, delt2.y))) * w10.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, delt2.y))) * w10.y; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt3.x, delt3.y))) * w10.z; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delt2.x, delt3.y))) * w10.w; 
 sum += sample(image, samplerTransform(image, dc + vec2(-delta.x, delt3.y))) * w11.x; 
 sum += sample(image, samplerTransform(image, dc + vec2( 0.0, delt3.y))) * w11.y; 
 sum += sample(image, samplerTransform(image, dc + vec2( delta.x, delt3.y))) * w11.z; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt2.x, delt3.y))) * w11.w; 
 sum += sample(image, samplerTransform(image, dc + vec2( delt3.x, delt3.y))) * w12.x; 
 return sum; 
inputOpacity
kernel vec4 _copyMachineTransition (__sample src0, __sample src1, vec3 parms2, vec4 multiplier, vec4 color, vec3 parms) 
 vec4 v = vec4(destCoord(), parms.x, 1.0); 
 float k = clamp(dot(v, multiplier), 0.0, 1.0); 
 float j = clamp(min(k * parms2.x + parms2.y, k * parms2.z), 0.0, 1.0) * parms.y; 
 k = max(k, parms.z); 
 return j * color + mix(src0, src1, k); 
CIMLFilter
CIMLFilterModelError
CoreMLModel failed to apply on the input image
CoreMLModel gave an empty or incompatible output
prediction_model
No or invalid CoreMLModel was given to the filter
inputHeight
inputName
outputName
model
softmax
inputType
inputFormat
+[CICoreMLProcessorImageArray processWithInputs:arguments:output:error:]
inputHeadIndex
inputSoftmaxNormalization
MLFeatureValue
Class getMLFeatureValueClass()_block_invoke
CICoreML.h
Unable to find class %s
void *CoreMLLibrary()
/System/Library/Frameworks/CoreML.framework/CoreML
/System/Library/Frameworks/CoreML.framework/Contents/MacOS/CoreML
v16@?0^v8
MLMultiArray
Class getMLMultiArrayClass()_block_invoke
dimensions
inputRectangle
CropX
CropY
CropW
CropH
kernel vec4 _crystallize(sampler src, sampler noise, vec2 cellSize, vec2 offset) 
 float tSize = 256.; 
 vec4 u1, u2, u3, u4; 
 vec2 t0 = destCoord(); 
 vec2 cellCorner = (floor(t0 * cellSize.y - 0.5) + 0.5) * cellSize.x + 0.5; 
 vec2 t1 = cellCorner * cellSize.y + offset; 
 t1 = t1 + vec2(-.5,-.5); 
 vec2 t2 = t1 + vec2(1.0, 0.0); 
 vec2 t3 = t1 + vec2(0.0, 1.0); 
 vec2 t4 = t1 + vec2(1.0, 1.0); 
 vec4 c1 = sample(noise, samplerTransform(noise, mod(t1, tSize))); 
 vec4 c2 = sample(noise, samplerTransform(noise, mod(t2, tSize))); 
 vec4 c3 = sample(noise, samplerTransform(noise, mod(t3, tSize))); 
 vec4 c4 = sample(noise, samplerTransform(noise, mod(t4, tSize))); 
 u1.xy = cellCorner; 
 u2.xy = u1.xy + vec2(cellSize.x, 0.0); 
 u3.xy = u1.xy + vec2(0.0, cellSize.x); 
 u4.xy = u1.xy + vec2(cellSize.x, cellSize.x); 
 float cellSize3 = cellSize.x * 0.65; 
 u1.xy += (c1.rg - 0.5) * cellSize3; 
 u2.xy += (c2.rg - 0.5) * cellSize3; 
 u3.xy += (c3.rg - 0.5) * cellSize3; 
 u4.xy += (c4.rg - 0.5) * cellSize3; 
 vec2 d0 = t0 - u1.xy; 
 u1.z = dot(d0,d0); 
 d0 = t0 - u2.xy; 
 u2.z = dot(d0,d0); 
 d0 = t0 - u3.xy; 
 u3.z = dot(d0,d0); 
 d0 = t0 - u4.xy; 
 u4.z = dot(d0,d0); 
 vec4 desc = vec4(u1.z - u2.z); 
 vec4 v1 = compare(desc, u1, u2); 
 vec4 v2 = compare(desc, u2, u1); 
 desc = vec4(u3.z - u4.z); 
 vec4 v3 = compare(desc, u3, u4); 
 vec4 v4 = compare(desc, u4, u3); 
 desc = vec4(v1.z - v3.z); 
 u1 = compare(desc, v1, v3); 
 u2 = compare(desc, v3, v1); 
 desc = vec4(v2.z - v4.z); 
 u3 = compare(desc, v2, v4); 
 desc = vec4(u2.z - u3.z); 
 u2 = compare(desc, u2, u3); 
 float alpha = clamp((sqrt(u2.z) - sqrt(u1.z)) * 0.5 + 0.5, 0.0, 1.0); 
 vec4 p1 = sample(src, samplerTransform(src, u1.xy)); 
 vec4 p2 = sample(src, samplerTransform(src, u2.xy)); 
 return mix(p2, p1, alpha); 
kernel vec4 _tiltShift(sampler image,sampler blurM,sampler blurL,vec2 p0,vec2 p1,vec2 sizes) 
 vec2 pt = samplerCoord(image); 
 vec4 col0 = sample(image, pt); 
 vec4 colMed = sample(blurM, samplerCoord(blurM)); 
 vec4 colLarge = sample(blurL, samplerCoord(blurL)); 
 float denom = (p1.x-p0.x)*(p1.x-p0.x) + (p1.y-p0.y)*(p1.y-p0.y); 
 float s = ((p0.y-pt.y)*(p1.x-p0.x)-(p0.x-pt.x)*(p1.y-p0.y) ) / denom; 
 float dist = abs(s)*sqrt(denom) / sizes.y; 
 dist *= 2.0; 
 float w0 = smoothstep(0.0, 1.0, 1.0 - 2.0*dist); 
 float wL = smoothstep(0.0, 1.0, -1.0 + 2.0*dist); 
 float wM = 1.0 - (w0 + wL); 
 return w0*col0 + wM*colMed + wL*colLarge; 
kernel vec4 _distanceColored(sampler image,vec2 p0,vec2 p1) 
 vec2 pt = samplerCoord(image); 
 float denom = (p1.x-p0.x)*(p1.x-p0.x) + (p1.y-p0.y)*(p1.y-p0.y); 
 float s = ((p0.y-pt.y)*(p1.x-p0.x)-(p0.x-pt.x)*(p1.y-p0.y) ) / denom; 
 float dist = abs(s)*sqrt(denom) / samplerSize(image).y; 
 dist *= 2.0; 
 float val = dist; 
 return vec4(val,val,val,1.0); 
kernel vec4 _alphaNormalize(__sample image) 
 vec4 col = image; 
 col.rgb /= col.a; 
 col.a = 1.0; 
 return col; 
CIColorControls
inputSaturation
inputImage
CIUnsharpMask
inputRadius
inputIntensity
CIDiscBlur
10.6
inputUnsharpMaskRadius
inputUnsharpMaskIntensity
inputPoint0
inputPoint1
initWithCameraCalibrationDataDictionary:error:
AVDepthData
Class getAVDepthDataClass(void)_block_invoke
CIDepthUtils.m
void *AVFoundationLibrary(void)
/System/Library/Frameworks/AVFoundation.framework/AVFoundation
/System/Library/Frameworks/AVFoundation.framework/Contents/MacOS/AVFoundation
AVCameraCalibrationData
Class getAVCameraCalibrationDataClass(void)_block_invoke
AVPortraitEffectsMatte
Class getAVPortraitEffectsMatteClass(void)_block_invoke
AVSemanticSegmentationMatte
Class getAVSemanticSegmentationMatteClass(void)_block_invoke
ForceVision
ForceFaceCore
[CIDetector detectorOfType:context:options:] failed because type %@ is unknown.
CIDetectorTypeFace
CIDetectorTypeRectangle
CIDetectorTypeQRCode
CIDetectorTypeText
CIDetectorAccuracy
CIDetectorAccuracyLow
CIDetectorAccuracyHigh
CIDetectorMinFeatureSize
CIDetectorMaxFeatureCount
CIDetectorTracking
CIDetectorNumberOfAngles
CIDetectorImageOrientation
CIDetectorBetterEyeLocs
CIDetectorEyeBlink
CIDetectorSmile
CIDetectorFocalLength
CIDetectorAspectRatio
CIDetectorDetectDiacritics
CIDetectorReturnSubFeatures
CITextDetectorMinimizeFalseDetections
CIDetectorExtraCharacters
CIDetectorLanguage
CIDetectorLanguageNone
CIDetectorLanguageASCII
CIDetectorLanguageEnglish
CIDetectorLanguageDanish
CIDetectorLanguageDutch
CIDetectorLanguageFrench
CIDetectorLanguageGerman
CIDetectorLanguageIcelandic
CIDetectorLanguageItalian
CIDetectorLanguageNorwegian
CIDetectorLanguagePortuguese
CIDetectorLanguageSpanish
CIDetectorLanguageSwedish
/System/Library/PrivateFrameworks/Quagga.framework
Unable to load Quagga from %s
ACBSConfigCreate
ACBSConfigFree
ACBSConfigSetMaxQRModuleSamples
ACBSCreateFrameInfoBySearchingForBarcodesInCVPixelBuffer
ACBSConfigSetSymbologiesEnabled
ACBSCreateSymbolDescriptorFromBasicDescriptorWithDefaultPayloadEncoding
SymbolDescriptionArray
CodeProperties
CodeLocation
ErrorCorrectionLevel
BarcodeRawData
BarcodeString
BarcodeType
QRMASK
SymbolVersion
kernel vec4 _convolutionAdd_1(sampler src, sampler sums, vec2 offset1, float weight1) 
 vec4 sum = sample(sums, samplerCoord(sums)); 
 vec2 coord = destCoord(); 
 vec4 pix1 = sample(src, samplerTransform(src, coord + offset1)); 
 return sum + pix1 * weight1; 
kernel vec4 _convolutionAdd_2(sampler src, sampler sums, vec2 offset1, vec2 offset2, vec2 weight1) 
 vec4 sum = sample(sums, samplerCoord(sums)); 
 vec2 coord = destCoord(); 
 vec4 pix1 = sample(src, samplerTransform(src, coord + offset1)); 
 vec4 pix2 = sample(src, samplerTransform(src, coord + offset2)); 
 return sum + pix1 * weight1.x + pix2 * weight1.y; 
kernel vec4 _convolutionAdd_3(sampler src, sampler sums, vec2 offset1, vec2 offset2, vec2 offset3, vec3 weight1) 
 vec4 sum = sample(sums, samplerCoord(sums)); 
 vec2 coord = destCoord(); 
 vec4 pix1 = sample(src, samplerTransform(src, coord + offset1)); 
 vec4 pix2 = sample(src, samplerTransform(src, coord + offset2)); 
 vec4 pix3 = sample(src, samplerTransform(src, coord + offset3)); 
 return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z; 
kernel vec4 _convolutionAdd_4(sampler src, sampler sums, vec4 offset12, vec4 offset34, vec4 weight1) 
 vec4 sum = sample(sums, samplerCoord(sums)); 
 vec2 coord = destCoord(); 
 vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy)); 
 vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw)); 
 vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy)); 
 vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw)); 
 return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w; 
kernel vec4 _convolutionAdd_5(sampler src, sampler sums, vec4 offset12, vec4 offset34, vec2 offset5, vec4 weight1, float weight2) 
 vec4 sum = sample(sums, samplerCoord(sums)); 
 vec2 coord = destCoord(); 
 vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy)); 
 vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw)); 
 vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy)); 
 vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw)); 
 vec4 pix5 = sample(src, samplerTransform(src, coord + offset5)); 
 return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2; 
kernel vec4 _convolutionAdd_6(sampler src, sampler sums, vec4 offset12, vec4 offset34, vec4 offset56, vec4 weight1, vec2 weight2) 
 vec4 sum = sample(sums, samplerCoord(sums)); 
 vec2 coord = destCoord(); 
 vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy)); 
 vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw)); 
 vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy)); 
 vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw)); 
 vec4 pix5 = sample(src, samplerTransform(src, coord + offset56.xy)); 
 vec4 pix6 = sample(src, samplerTransform(src, coord + offset56.zw)); 
 return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2.x + pix6 * weight2.y; 
kernel vec4 _convolutionAdd_7(sampler src, sampler sums, vec4 offset12, vec4 offset34, vec4 offset56, vec2 offset7, vec4 weight1, vec3 weight2) 
 vec4 sum = sample(sums, samplerCoord(sums)); 
 vec2 coord = destCoord(); 
 vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy)); 
 vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw)); 
 vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy)); 
 vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw)); 
 vec4 pix5 = sample(src, samplerTransform(src, coord + offset56.xy)); 
 vec4 pix6 = sample(src, samplerTransform(src, coord + offset56.zw)); 
 vec4 pix7 = sample(src, samplerTransform(src, coord + offset7)); 
 return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2.x + pix6 * weight2.y + pix7 * weight2.z; 
kernel vec4 _convolutionAdd_8(sampler src, sampler sums, vec4 offset12, vec4 offset34, vec4 offset56, vec4 offset78, vec4 weight1, vec4 weight2) 
 vec4 sum = sample(sums, samplerCoord(sums)); 
 vec2 coord = destCoord(); 
 vec4 pix1 = sample(src, samplerTransform(src, coord + offset12.xy)); 
 vec4 pix2 = sample(src, samplerTransform(src, coord + offset12.zw)); 
 vec4 pix3 = sample(src, samplerTransform(src, coord + offset34.xy)); 
 vec4 pix4 = sample(src, samplerTransform(src, coord + offset34.zw)); 
 vec4 pix5 = sample(src, samplerTransform(src, coord + offset56.xy)); 
 vec4 pix6 = sample(src, samplerTransform(src, coord + offset56.zw)); 
 vec4 pix7 = sample(src, samplerTransform(src, coord + offset78.xy)); 
 vec4 pix8 = sample(src, samplerTransform(src, coord + offset78.zw)); 
 return sum + pix1 * weight1.x + pix2 * weight1.y + pix3 * weight1.z + pix4 * weight1.w + pix5 * weight2.x + pix6 * weight2.y + pix7 * weight2.z + pix8 * weight2.w; 
inputRingAmount
inputRingSize
inputPointCount
down
conv3
conv5
conv7
add4
add8and8
add4and8
add8
CISoftCubicUpsample
CIConvolution3X3
CIConvolution5X5
CIConvolution7X7
add4and4
kernel vec4 _downhalf (sampler i) 
 vec2 dc = destCoord() * 2.0; 
 vec4 s = sample(i, samplerTransform(i,dc+vec2(-1.,0.))); 
 s += sample(i, samplerTransform(i,dc+vec2(1.,0.))); 
 s += sample(i, samplerTransform(i,dc+vec2(0.,1.))); 
 s += sample(i, samplerTransform(i,dc+vec2(0.,-1.))); 
 return s * 0.25; 
kernel vec4 _box3 (sampler image, float r) 
 vec4 rr = vec4(-r,0.0,r,0.0); 
 vec2 dc = destCoord(); 
 vec4 c = vec4(0.0); 
 c += sample(image, samplerTransform(image,dc+rr.xx)); 
 c += sample(image, samplerTransform(image,dc+rr.xy)); 
 c += sample(image, samplerTransform(image,dc+rr.xz)); 
 c += sample(image, samplerTransform(image,dc+rr.yx)); 
 c += sample(image, samplerTransform(image,dc+rr.yy)); 
 c += sample(image, samplerTransform(image,dc+rr.yz)); 
 c += sample(image, samplerTransform(image,dc+rr.zx)); 
 c += sample(image, samplerTransform(image,dc+rr.zy)); 
 c += sample(image, samplerTransform(image,dc+rr.zz)); 
 return c / 9.0; 
kernel vec4 _add4 (sampler a, sampler b, vec2 pt, vec2 w) 
 vec4 p = vec4(pt,-pt); 
 vec2 dc = destCoord(); 
 vec4 c = vec4(0.0); 
 c += sample(b, samplerTransform(b,dc+p.xy)); 
 c += sample(b, samplerTransform(b,dc+p.yz)); 
 c += sample(b, samplerTransform(b,dc+p.zw)); 
 c += sample(b, samplerTransform(b,dc+p.wx)); 
 c *= w.y; 
 c += sample(a, samplerCoord(a)) * w.x; 
 return c; 
kernel vec4 _add8 (sampler a, sampler b, vec2 pt, vec2 w) 
 vec4 p = vec4(pt,-pt); 
 vec2 dc = destCoord(); 
 vec4 c = vec4(0.0); 
 c += sample(b, samplerTransform(b,dc+p.xy)); 
 c += sample(b, samplerTransform(b,dc+p.yz)); 
 c += sample(b, samplerTransform(b,dc+p.zw)); 
 c += sample(b, samplerTransform(b,dc+p.wx)); 
 c += sample(b, samplerTransform(b,dc+p.yx)); 
 c += sample(b, samplerTransform(b,dc+p.zy)); 
 c += sample(b, samplerTransform(b,dc+p.wz)); 
 c += sample(b, samplerTransform(b,dc+p.xw)); 
 c *= w.y; 
 c += sample(a, samplerCoord(a)) * w.x; 
 return c; 
kernel vec4 _add4and4 (sampler a, sampler b, vec4 pt, vec4 w) 
 vec4 p = vec4(pt.xy,-pt.xy); 
 vec2 dc = destCoord(); 
 vec4 c = vec4(0.0); 
 c += (sample(b, samplerTransform(b,dc+p.xy)) + sample(b, samplerTransform(b,dc+p.yz)) + sample(b, samplerTransform(b,dc+p.zw)) + sample(b, samplerTransform(b,dc+p.wx))) * w.y; 
 p = vec4(pt.zw,-pt.zw); 
 c += (sample(b, samplerTransform(b,dc+p.xy)) + sample(b, samplerTransform(b,dc+p.yz)) + sample(b, samplerTransform(b,dc+p.zw)) + sample(b, samplerTransform(b,dc+p.wx))) * w.z; 
 c += sample(a, samplerCoord(a)) * w.x; 
 return c; 
kernel vec4 _add4and8 (sampler a, sampler b, vec4 pt, vec4 w) 
 vec4 p = vec4(pt.xy,-pt.xy); 
 vec2 dc = destCoord(); 
 vec4 c = vec4(0.0); 
 c += (sample(b, samplerTransform(b,dc+p.xy)) + sample(b, samplerTransform(b,dc+p.yz)) + sample(b, samplerTransform(b,dc+p.zw)) + sample(b, samplerTransform(b,dc+p.wx))) * w.y; 
 p = vec4(pt.zw,-pt.zw); 
 c += (sample(b, samplerTransform(b,dc+p.xy)) + sample(b, samplerTransform(b,dc+p.yz)) + sample(b, samplerTransform(b,dc+p.zw)) + sample(b, samplerTransform(b,dc+p.wx)) + sample(b, samplerTransform(b,dc+p.yx)) + sample(b, samplerTransform(b,dc+p.zy)) + sample(b, samplerTransform(b,dc+p.wz)) + sample(b, samplerTransform(b,dc+p.xw))) * w.z; 
 c += sample(a, samplerCoord(a)) * w.x; 
 return c; 
kernel vec4 _add8and8 (sampler a, sampler b, vec4 pt, vec4 w) 
 vec4 p = vec4(pt.xy,-pt.xy); 
 vec2 dc = destCoord(); 
 vec4 c = vec4(0.0); 
 c += (sample(b, samplerTransform(b,dc+p.xy)) + sample(b, samplerTransform(b,dc+p.yz)) + sample(b, samplerTransform(b,dc+p.zw)) + sample(b, samplerTransform(b,dc+p.wx)) + sample(b, samplerTransform(b,dc+p.yx)) + sample(b, samplerTransform(b,dc+p.zy)) + sample(b, samplerTransform(b,dc+p.wz)) + sample(b, samplerTransform(b,dc+p.xw))) * w.y; 
 p = vec4(pt.zw,-pt.zw); 
 c += (sample(b, samplerTransform(b,dc+p.xy)) + sample(b, samplerTransform(b,dc+p.yz)) + sample(b, samplerTransform(b,dc+p.zw)) + sample(b, samplerTransform(b,dc+p.wx)) + sample(b, samplerTransform(b,dc+p.yx)) + sample(b, samplerTransform(b,dc+p.zy)) + sample(b, samplerTransform(b,dc+p.wz)) + sample(b, samplerTransform(b,dc+p.xw))) * w.z; 
 c += sample(a, samplerCoord(a)) * w.x; 
 return c; 
kernel vec4 _ringAvg8 (sampler b, vec4 pts) 
 vec4 p = vec4(pts.xy,-pts.xy); 
 vec2 dc = destCoord(); 
 vec4 c = vec4(0.0); 
 c += sample(b, samplerTransform(b,dc+p.xy)); 
 c += sample(b, samplerTransform(b,dc+p.yz)); 
 c += sample(b, samplerTransform(b,dc+p.zw)); 
 c += sample(b, samplerTransform(b,dc+p.wx)); 
 c += sample(b, samplerTransform(b,dc+p.yx)); 
 c += sample(b, samplerTransform(b,dc+p.zy)); 
 c += sample(b, samplerTransform(b,dc+p.wz)); 
 c += sample(b, samplerTransform(b,dc+p.xw)); 
 return c / 8.0; 
kernel vec4 _ringAvg16 (sampler b, vec4 pts) 
 vec4 p = vec4(pts.xy,-pts.xy); 
 vec2 dc = destCoord(); 
 vec4 c = vec4(0.0); 
 c += sample(b, samplerTransform(b,dc+p.xy)); 
 c += sample(b, samplerTransform(b,dc+p.yz)); 
 c += sample(b, samplerTransform(b,dc+p.zw)); 
 c += sample(b, samplerTransform(b,dc+p.wx)); 
 c += sample(b, samplerTransform(b,dc+p.yx)); 
 c += sample(b, samplerTransform(b,dc+p.zy)); 
 c += sample(b, samplerTransform(b,dc+p.wz)); 
 c += sample(b, samplerTransform(b,dc+p.xw)); 
 p = vec4(pts.zw,-pts.zw); 
 c += sample(b, samplerTransform(b,dc+p.xy)); 
 c += sample(b, samplerTransform(b,dc+p.yz)); 
 c += sample(b, samplerTransform(b,dc+p.zw)); 
 c += sample(b, samplerTransform(b,dc+p.wx)); 
 c += sample(b, samplerTransform(b,dc+p.yx)); 
 c += sample(b, samplerTransform(b,dc+p.zy)); 
 c += sample(b, samplerTransform(b,dc+p.wz)); 
 c += sample(b, samplerTransform(b,dc+p.xw)); 
 return c / 16.0; 
kernel vec4 _ringAvg24 (sampler b, vec4 pts, vec2 pts2) 
 vec4 p = vec4(pts.xy,-pts.xy); 
 vec2 dc = destCoord(); 
 vec4 c = vec4(0.0); 
 c += sample(b, samplerTransform(b,dc+p.xy)); 
 c += sample(b, samplerTransform(b,dc+p.yz)); 
 c += sample(b, samplerTransform(b,dc+p.zw)); 
 c += sample(b, samplerTransform(b,dc+p.wx)); 
 c += sample(b, samplerTransform(b,dc+p.yx)); 
 c += sample(b, samplerTransform(b,dc+p.zy)); 
 c += sample(b, samplerTransform(b,dc+p.wz)); 
 c += sample(b, samplerTransform(b,dc+p.xw)); 
 p = vec4(pts.zw,-pts.zw); 
 c += sample(b, samplerTransform(b,dc+p.xy)); 
 c += sample(b, samplerTransform(b,dc+p.yz)); 
 c += sample(b, samplerTransform(b,dc+p.zw)); 
 c += sample(b, samplerTransform(b,dc+p.wx)); 
 c += sample(b, samplerTransform(b,dc+p.yx)); 
 c += sample(b, samplerTransform(b,dc+p.zy)); 
 c += sample(b, samplerTransform(b,dc+p.wz)); 
 c += sample(b, samplerTransform(b,dc+p.xw)); 
 p = vec4(pts2.xy,-pts2.xy); 
 c += sample(b, samplerTransform(b,dc+p.xy)); 
 c += sample(b, samplerTransform(b,dc+p.yz)); 
 c += sample(b, samplerTransform(b,dc+p.zw)); 
 c += sample(b, samplerTransform(b,dc+p.wx)); 
 c += sample(b, samplerTransform(b,dc+p.yx)); 
 c += sample(b, samplerTransform(b,dc+p.zy)); 
 c += sample(b, samplerTransform(b,dc+p.wz)); 
 c += sample(b, samplerTransform(b,dc+p.xw)); 
 return c / 24.0; 
kernel vec4 _ringAvg32 (sampler b, vec4 pts, vec4 pts2) 
 vec4 p = vec4(pts.xy,-pts.xy); 
 vec2 dc = destCoord(); 
 vec4 c = vec4(0.0); 
 c += sample(b, samplerTransform(b,dc+p.xy)); 
 c += sample(b, samplerTransform(b,dc+p.yz)); 
 c += sample(b, samplerTransform(b,dc+p.zw)); 
 c += sample(b, samplerTransform(b,dc+p.wx)); 
 c += sample(b, samplerTransform(b,dc+p.yx)); 
 c += sample(b, samplerTransform(b,dc+p.zy)); 
 c += sample(b, samplerTransform(b,dc+p.wz)); 
 c += sample(b, samplerTransform(b,dc+p.xw)); 
 p = vec4(pts.zw,-pts.zw); 
 c += sample(b, samplerTransform(b,dc+p.xy)); 
 c += sample(b, samplerTransform(b,dc+p.yz)); 
 c += sample(b, samplerTransform(b,dc+p.zw)); 
 c += sample(b, samplerTransform(b,dc+p.wx)); 
 c += sample(b, samplerTransform(b,dc+p.yx)); 
 c += sample(b, samplerTransform(b,dc+p.zy)); 
 c += sample(b, samplerTransform(b,dc+p.wz)); 
 c += sample(b, samplerTransform(b,dc+p.xw)); 
 p = vec4(pts2.xy,-pts2.xy); 
 c += sample(b, samplerTransform(b,dc+p.xy)); 
 c += sample(b, samplerTransform(b,dc+p.yz)); 
 c += sample(b, samplerTransform(b,dc+p.zw)); 
 c += sample(b, samplerTransform(b,dc+p.wx)); 
 c += sample(b, samplerTransform(b,dc+p.yx)); 
 c += sample(b, samplerTransform(b,dc+p.zy)); 
 c += sample(b, samplerTransform(b,dc+p.wz)); 
 c += sample(b, samplerTransform(b,dc+p.xw)); 
 p = vec4(pts2.zw,-pts2.zw); 
 c += sample(b, samplerTransform(b,dc+p.xy)); 
 c += sample(b, samplerTransform(b,dc+p.yz)); 
 c += sample(b, samplerTransform(b,dc+p.zw)); 
 c += sample(b, samplerTransform(b,dc+p.wx)); 
 c += sample(b, samplerTransform(b,dc+p.yx)); 
 c += sample(b, samplerTransform(b,dc+p.zy)); 
 c += sample(b, samplerTransform(b,dc+p.wz)); 
 c += sample(b, samplerTransform(b,dc+p.xw)); 
 return c / 32.0; 
inputShadowRadius
inputShadowDensity
inputShadowOffset
kernel vec4 _disintegrateWithMask (__sample t0, __sample t1, 
 __sample m0, __sample m1, __sample m2, __sample m3, 
 vec4 param) 
 float shadowRadiusInv = param.y; 
 float shadowDensity = param.z; 
 float time = param.w; 
 float ramp = 1.0 / (max(abs(m1.r-m0.r), abs(m2.r-m0.r)) + 0.001); 
 float shadow = (time - m3.r) * shadowRadiusInv * ramp + time; 
 shadow = clamp(shadow, 0.0, 1.0); 
 shadow = shadowDensity*(shadow-1.0) + 1.0; 
 t0.rgb = t0.rgb * (param.x*time + 1.0); 
 t1.rgb = t1.rgb * (param.x*time + 1.0 - param.x) * shadow; 
 float s = clamp((time - m0.r) * ramp + time, 0.0, 1.0); 
 return mix(t0, t1, s); 
kernel vec4 _disintegrateWithMaskG (sampler s0, sampler s1, sampler m, vec2 offset, vec4 param) 
 float shadowRadiusInv = param.y; 
 float shadowDensity = param.z; 
 float time = param.w; 
 vec4 t0 = sample(s0, samplerCoord(s0)); 
 vec4 t1 = sample(s1, samplerCoord(s1)); 
 vec2 d = destCoord(); 
 vec4 m0 = sample(m, samplerTransform(m, d)); 
 vec4 m1 = sample(m, samplerTransform(m, d + vec2(1.0, 0.0))); 
 vec4 m2 = sample(m, samplerTransform(m, d + vec2(0.0, 1.0))); 
 vec4 m3 = sample(m, samplerTransform(m, d - offset)); 
 float ramp = 1.0 / (max(abs(m1.r-m0.r), abs(m2.r-m0.r)) + 0.001); 
 float shadow = (time - m3.r) * shadowRadiusInv * ramp + time; 
 shadow = clamp(shadow, 0.0, 1.0); 
 shadow = shadowDensity*(shadow-1.0) + 1.0; 
 t0.rgb = t0.rgb * (param.x*time + 1.0); 
 t1.rgb = t1.rgb * (param.x*time + 1.0 - param.x) * shadow; 
 float s = clamp((time - m0.r) * ramp + time, 0.0, 1.0); 
 return mix(t0, t1, s); 
inputMaskBoundingBox
inputFaceBoundingBoxes
inputInpaintingProcessingResolutions
inputInpaintingBlendingRadius
inputInpaintingMode
inp_gen_eds2_00_q16.espresso|SS*
inp_fcs_eds2_00_q16_s30.espresso|SS*
contentPaddingFactor
contentPaddingMaxExtraSidePixels
maxElongatedMaskEdgeSize
maxElongatedMaskRelativeMaskAreaSize
maxTiledMaskEdgeSize
-[CIInpaintingFilter outputImage]
Input image and input mask have to be the same size, image: %@, mask: %@
inputPropagateKernel
inputSmoothSigma
inputPropogateMinWeightSum
inputPropogateSigmaLuma
inputPropogateSigmaChroma
kernel vec4 _CIInitialConversionRGB(sampler image,vec2 scale)
vec2 sp = destCoord() * scale;
    vec4 b0b3, c0c3, a0a3, d0d3;
    b0b3 = sample(image, samplerTransform(image, sp + vec2(-2.0, 0.0)));
    c0c3 = sample(image, samplerTransform(image, sp + vec2( 2.0, 0.0)));
    a0a3 = sample(image, samplerTransform(image, sp + vec2( 0.0, 2.0)));
    d0d3 = sample(image, samplerTransform(image, sp + vec2( 0.0,-2.0)));
    vec4 g = abs(c0c3 - b0b3) + abs(d0d3 - a0a3);
    vec4 outPix = sample(image, samplerTransform(image, sp));
    outPix.w  = min(max(g.x, max(g.y,g.z)), 1.0);
    return outPix;
kernel vec4 _CIPyramidGenerateLevel(sampler inYuva)
    vec2 gid2 = destCoord() * 2.0;
    vec4 pix_0_0 = sample(inYuva, samplerTransform(inYuva, gid2 + vec2(-0.5, -0.5)));
    vec4 pix_1_0 = sample(inYuva, samplerTransform(inYuva, gid2 + vec2(-0.5,  0.5)));
    vec4 pix_0_1 = sample(inYuva, samplerTransform(inYuva, gid2 + vec2( 0.5, -0.5)));
    vec4 pix_1_1 = sample(inYuva, samplerTransform(inYuva, gid2 + vec2( 0.5,  0.5)));
    
    if (pix_1_0.w > pix_0_0.w) pix_0_0 = pix_1_0;
    if (pix_0_1.w > pix_0_0.w) pix_0_0 = pix_0_1;
    if (pix_1_1.w > pix_0_0.w) pix_0_0 = pix_1_1;
    
    return pix_0_0;
float _local_yuvWeightG(vec4 pix1,vec4 pix2,vec2 sigmaLumaChmaRecip)
    vec3 yuv = pix1.xyz - pix2.xyz;
    yuv.xyz = (yuv.xyz * yuv.xyz) * sigmaLumaChmaRecip.xyy;
    return exp(-(yuv.x+yuv.y+yuv.z));
kernel vec4 _CIPropagateDisparity(sampler inDispMap,sampler yuv0,sampler yuv1,vec4 params)
    int   radius        = int(params.x); 
    vec2  sigmaLCRecip  = params.yz;
    float pmws          = params.w; 
    vec2  dc            = destCoord();
    vec2 gidHalf = floor(0.5*dc) + vec2(0.5);
    vec4  ref           = sample(yuv0, samplerTransform(yuv0, dc));
    float sow           = 0.0;
    float sowd          = 0.0;
    
    for (int y = -radius; y <= radius; y++) {
        for (int x = -radius; x <= radius; x++) {
        
 vec2 p  = vec2(float(x),float(y));
            vec4 p2 = sample(yuv1,      samplerTransform(yuv1,      gidHalf + p));
            float d = sample(inDispMap, samplerTransform(inDispMap, gidHalf + p)).r;
            float w = _local_yuvWeightG(ref, p2, sigmaLCRecip);
            sow+= w; sowd+= w * d;
        }
    }
    float alt = sample(inDispMap, samplerTransform(inDispMap, gidHalf)).r;
    float rc = (sow < pmws) ? alt : (sowd / sow);
return vec4(rc,rc,rc,1.0);
float _local_yuvWeight(vec4 pix1,vec4 pix2,vec2 sigmaLumaChmaRecip)
    vec3 yuv = pix1.xyz - pix2.xyz;
    yuv.xyz = (yuv.xyz * yuv.xyz) * sigmaLumaChmaRecip.xyy;
    return exp(-(yuv.x+yuv.y+yuv.z));
kernel vec4 _CIPropagateDisparityR1(sampler inDispMap,sampler yuv0,sampler yuv1,vec4 params)
    vec2  sigmaLCRecip  = params.yz;
    float pmws          = params.w; 
    vec2  dc            = destCoord();
    vec2 gidHalf = floor(0.5*dc) + vec2(0.5);
    vec4  ref           = sample(yuv0, samplerTransform(yuv0, dc));
    float sow           = 0.0;
    float sowd          = 0.0;
    
    vec4 p;
    float d, w;
    p = sample(yuv1,      samplerTransform(yuv1,      gidHalf + vec2(-1.0, -1.0)));
    d = sample(inDispMap, samplerTransform(inDispMap, gidHalf + vec2(-1.0, -1.0))).r;
    w = _local_yuvWeight(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * d;
    p = sample(yuv1,      samplerTransform(yuv1,      gidHalf + vec2( 0.0, -1.0)));
    d = sample(inDispMap, samplerTransform(inDispMap, gidHalf + vec2( 0.0, -1.0))).r;
    w = _local_yuvWeight(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * d;
    p = sample(yuv1,      samplerTransform(yuv1,      gidHalf + vec2( 1.0, -1.0)));
    d = sample(inDispMap, samplerTransform(inDispMap, gidHalf + vec2( 1.0, -1.0))).r;
    w = _local_yuvWeight(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * d;
    p = sample(yuv1,      samplerTransform(yuv1,      gidHalf + vec2(-1.0, 0.0)));
    d = sample(inDispMap, samplerTransform(inDispMap, gidHalf + vec2(-1.0, 0.0))).r;
    w = _local_yuvWeight(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * d;
    p = sample(yuv1,      samplerTransform(yuv1,      gidHalf + vec2( 0.0, 0.0)));
    d = sample(inDispMap, samplerTransform(inDispMap, gidHalf + vec2( 0.0, 0.0))).r;
    w = _local_yuvWeight(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * d;
    float alt = d;
    p = sample(yuv1,      samplerTransform(yuv1,      gidHalf + vec2( 1.0, 0.0)));
    d = sample(inDispMap, samplerTransform(inDispMap, gidHalf + vec2( 1.0, 0.0))).r;
    w = _local_yuvWeight(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * d;
    p = sample(yuv1,      samplerTransform(yuv1,      gidHalf + vec2(-1.0, 1.0)));
    d = sample(inDispMap, samplerTransform(inDispMap, gidHalf + vec2(-1.0, 1.0))).r;
    w = _local_yuvWeight(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * d;
    p = sample(yuv1,      samplerTransform(yuv1,      gidHalf + vec2( 0.0, 1.0)));
    d = sample(inDispMap, samplerTransform(inDispMap, gidHalf + vec2( 0.0, 1.0))).r;
    w = _local_yuvWeight(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * d;
    p = sample(yuv1,      samplerTransform(yuv1,      gidHalf + vec2( 1.0, 1.0)));
    d = sample(inDispMap, samplerTransform(inDispMap, gidHalf + vec2( 1.0, 1.0))).r;
    w = _local_yuvWeight(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * d;
    float rc = (sow < pmws) ? alt : (sowd / sow);
return vec4(rc,rc,rc,1.0);
float _local_yuvWeightC(vec4 pix1,vec4 pix2,vec2 sigmaLumaChmaRecip)
    vec3 yuv = pix1.xyz - pix2.xyz;
    yuv.xyz = (yuv.xyz * yuv.xyz) * sigmaLumaChmaRecip.xyy;
    return exp(-(yuv.x+yuv.y+yuv.z));
kernel vec4 _CIPropagateDisparityR1C(sampler image,sampler yuv0,vec4 params)
    vec2  sigmaLCRecip  = params.yz;
    float pmws          = params.w; 
    vec2  dc            = destCoord();
    vec2 gidHalf = floor(0.5*dc) + vec2(0.5);
    vec4  ref           = sample(yuv0, samplerTransform(yuv0, dc));
    float sow           = 0.0;
    float sowd          = 0.0;
    
    vec4 p;
    float w;
    p = sample(image, samplerTransform(image, gidHalf + vec2(-1.0, -1.0)));
    w = _local_yuvWeightC(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * p.a;
    p = sample(image, samplerTransform(image, gidHalf + vec2( 0.0, -1.0)));
    w = _local_yuvWeightC(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * p.a;
    p = sample(image, samplerTransform(image, gidHalf + vec2( 1.0, -1.0)));
    w = _local_yuvWeightC(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * p.a;
    p = sample(image, samplerTransform(image, gidHalf + vec2(-1.0, 0.0)));
    w = _local_yuvWeightC(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * p.a;
    p = sample(image, samplerTransform(image, gidHalf));
    w = _local_yuvWeightC(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * p.a;
    float alt = p.a;
    p = sample(image, samplerTransform(image, gidHalf + vec2( 1.0, 0.0)));
    w = _local_yuvWeightC(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * p.a;
    p = sample(image, samplerTransform(image, gidHalf + vec2(-1.0, 1.0)));
    w = _local_yuvWeightC(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * p.a;
    p = sample(image, samplerTransform(image, gidHalf + vec2( 0.0, 1.0)));
    w = _local_yuvWeightC(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * p.a;
    p = sample(image, samplerTransform(image, gidHalf + vec2( 1.0, 1.0)));
    w = _local_yuvWeightC(ref, p, sigmaLCRecip);
    sow+= w; sowd+= w * p.a;
    float rc = (sow < pmws) ? alt : (sowd / sow);
return vec4(rc,rc,rc,1.0);
float _local_yuvWeightG2(vec4 pix1,vec4 pix2,vec2 sigmaLumaChmaRecip)
    vec3 yuv = pix1.xyz - pix2.xyz;
    yuv.xyz = (yuv.xyz * yuv.xyz) * sigmaLumaChmaRecip.xyy;
    return exp(-(yuv.x+yuv.y+yuv.z));
kernel vec4 _CIPropagateDisparityRC(sampler image,sampler yuv0,vec4 params)
    int   radius        = int(params.x); 
    vec2  sigmaLCRecip  = params.yz;
    float pmws          = params.w; 
    vec2  dc            = destCoord();
    vec2 gidHalf = floor(0.5*dc) + vec2(0.5);
    vec4  ref           = sample(yuv0, samplerTransform(yuv0, dc));
    float sow           = 0.0;
    float sowd          = 0.0;
    
    for (int y = -radius; y <= radius; y++) {
        for (int x = -radius; x <= radius; x++) {
            vec4  p = sample(image, samplerTransform(image, gidHalf + vec2(float(x), float(y))));
            float w = _local_yuvWeightG2(ref, p, sigmaLCRecip);
            sow+= w; sowd+= w * p.a;
        }
    }
    float alt = sample(image, samplerTransform(image, gidHalf)).r;
    float rc = (sow < pmws) ? alt : (sowd / sow);
return vec4(rc,rc,rc,1.0);
kernel vec4 _CISmoothDisparity(sampler inDisp, vec3 params)
    float wSide      = params.x;
    float wDiag      = params.y;
    float denomRecip = params.z;
    vec2  dc         = destCoord();
   vec4 g0, g1, g2;
   g0.x = sample(inDisp, samplerTransform(inDisp, dc + vec2(-1.0, 0.0))).x;
   g0.y = sample(inDisp, samplerTransform(inDisp, dc                  )).x;
   g0.z = sample(inDisp, samplerTransform(inDisp, dc + vec2( 0.0, 1.0))).x;
   g0.w = sample(inDisp, samplerTransform(inDisp, dc + vec2(-1.0, 1.0))).x;
   g1.y = sample(inDisp, samplerTransform(inDisp, dc + vec2( 1.0, 0.0))).x;
   g1.z = sample(inDisp, samplerTransform(inDisp, dc + vec2( 1.0, 1.0))).x;
   g2.x = sample(inDisp, samplerTransform(inDisp, dc + vec2(-1.0,-1.0))).x;
   g2.y = sample(inDisp, samplerTransform(inDisp, dc + vec2( 0.0,-1.0))).x;
   float g3   = sample(inDisp, samplerTransform(inDisp, dc + vec2( 1.5,-1.5))).x;
   float  v = (g0.y + (g0.x + g0.z + g1.y + g2.y) * wSide + (g0.w + g1.z + g2.x + g3) * wDiag) * denomRecip;
    return vec4(v,v,v,1.0);
/tmp/yuvImageUsingConstants.tiff
kernel_InitialConversion
doubleOutput
/tmp/initialConversion-Metal.tiff
/tmp/initialConversion-CI.tiff
kernel_UpscaleShiftmap
scaleFactors
/tmp/upsampledShiftmap-Metal.tiff
/tmp/upsampledShiftmap-CI.tiff
kernel_PyramidGenerateLevel
/tmp/pyramidLevel1-Metal.tiff
/tmp/pyramidLevel1-CI.tiff
kernel_SmoothDisparity
config
/tmp/smoothDisparity-Metal.tiff
/tmp/smoothDisparity-CI.tiff
kernel vec4 _combineImages(__sample s0,__sample s1) { return vec4(s0.xyz,s1.r); }
kernel_PropagateDisparity
halfOutput
identity
/tmp/propagateDisparity_%d-%s.tiff
Metal
/tmp/inputToDisparity.tiff
/tmp/smoothed-Metal.tiff
/tmp/smoothed-CI.tiff
i16@?0@"NSDictionary"8
CI_SAVE_IMAGES
CI_METAL_SDOF
CIDisparityRefinement-saveImageWithKeywords
Can't save nil image
infinite rect can't save image
kernel vec4 _gray(__sample s) { return s.rrra; }
inputNumIterations
kernel vec4 _CIBoxBlur5Min(sampler i) __attribute__((outputFormat(kCIFormatRh)))
  vec2 dc = destCoord(); 
     vec4 c = vec4(0.0); 
     
     vec4 center = sample(i, samplerCoord(i)); 
     
     c += sample(i, samplerTransform(i,dc + vec2(-1.5, 1.5))) * 0.16; 
     c += sample(i, samplerTransform(i,dc + vec2( 0.0, 1.5))) * 0.08; 
     c += sample(i, samplerTransform(i,dc + vec2(+1.5, 1.5))) * 0.16; 
     c += sample(i, samplerTransform(i,dc + vec2(-1.5, 0.0))) * 0.08; 
     c += center * 0.04;
     c += sample(i, samplerTransform(i,dc + vec2(+1.5, 0.0))) * 0.08; 
  c += sample(i, samplerTransform(i,dc + vec2(-1.5,-1.5))) * 0.16; 
     c += sample(i, samplerTransform(i,dc + vec2( 0.0,-1.5))) * 0.08; 
     c += sample(i, samplerTransform(i,dc + vec2( 1.5,-1.5))) * 0.16; 
     
  c = min (c,center);
     c.bg = vec2(0.0);
     c.a = center.a;
     c.a = 1.0;
     
     return c;
/tmp/inputToBoxBlur.tiff
/tmp/outputFromBoxBlur.tiff
CIDisparitySmoothing
Failed to initialize CIDisparitySmoothing: %@; %@
kernel vec4 _displaceFromImage (sampler src, sampler image, float k) 
 vec2 dc = destCoord(); 
 float E = sample(image, samplerTransform(image,dc+vec2(1.0,0.0))).r; 
 float S = sample(image, samplerTransform(image,dc+vec2(0.0,-1.0))).r; 
 float C = sample(image, samplerTransform(image,dc)).r; 
 return sample(src, samplerTransform(src, dc + k * vec2(E-C, S-C))); 
kernel vec4 _disolve (__sample src0, __sample src1, float factor) { return mix(src1, src0, factor); }
kernel vec4 _fadeDissolve (__sample src, float factor) { return src*factor; }
CIAreaAverage
CICheapBilateral
CIDesaturateShadows
CIContrastEnhancer
inputLocal
inputGreyscale
CIDocumentEnhancer
kernel vec4 _CElumaToR(__sample c) __attribute__((outputFormat(kCIFormatRh)))
 float Y = dot(c.rgb, vec3(0.299, 0.587, 0.114)); 
 return vec4(Y,0.0,0.0,1.0); 
kernel vec4 _DEcomputeInversionMask(__sample c, __sample cminmax, float maxSaturation, float minRange) __attribute__((outputFormat(kCIFormatRh))) {
 float range = cminmax.g - cminmax.r; 
 float mean = (cminmax.g + cminmax.r)/2.0; 
 float vmin = min(min(c.r,c.g),c.b); 
 float vmax = max(max(c.r,c.g),c.b); 
 vec3 Y = vec3(0.299, 0.587, 0.114); 
 float luma = dot(c.rgb, Y); 
 float mask = (vmax / vmin > maxSaturation || luma > mean || range < minRange) ? 1.0 : 0.0; 
 float hardBit = 1.0; 
 return vec4(vec3(mask), hardBit); 
kernel vec4 _DEmax4(sampler image, vec2 bound) {
 vec2 d = 2.0*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2(-0.5,-0.5))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2(+0.5,-0.5))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2(-0.5,+0.5))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2(+0.5,+0.5))); 
 p0 = (d.x+0.5 < bound.x) ? max(p0, p1) : p0; 
 p2 = (d.x+0.5 < bound.x) ? max(p2, p3) : p2; 
 p0 = (d.y+0.5 < bound.y) ? max(p0, p2) : p0; 
 return p0; 
kernel vec4 _DEcreateForegroundMask(__sample c, __sample downMax, __sample meanMax, vec4 params) {
 float threshMin = params.x; 
 float threshMaxOverMin = params.y; 
 float cutoff = params.z; 
 float epsChroma = params.w; 
 float cmincomp = min(c.r, min(c.g, c.b)); 
 float cmaxcomp = max(c.r, max(c.g, c.b)); 
 float luminance = dot(downMax.rgb, vec3(0.3333333)); 
 vec3 Y = vec3(0.299, 0.587, 0.114); 
 vec3 Cb = vec3(-0.168736, -0.331264, 0.5); 
 vec3 Cr = vec3(0.5, -0.418688, -0.081312); 
 vec3 YCbCr_c = vec3(dot(c.rgb,Y), dot(c.rgb,Cb), dot(c.rgb,Cr)); 
 vec3 YCbCr_bg = vec3(dot(downMax.rgb,Y), dot(meanMax.rgb,Cb), dot(meanMax.rgb,Cr)); 
 float dchromaticity = length(YCbCr_c.yz-YCbCr_bg.yz); 
 if (cmincomp < threshMin * luminance || cmaxcomp/cmincomp > threshMaxOverMin || dchromaticity > epsChroma) 
 c *= 0.0; 
 return c; 
kernel vec4 _DEnormalizeAlpha(__sample c) { return c * smoothstep(0.001, 0.1, c.a) / max(c.a,0.0001); }
kernel vec4 _DEWash(__sample c, __sample w) { return c / (0.000001 + w); }
kernel vec4 _DE_compinv(__sample u) __attribute__((outputFormat(kCIFormatRh))) { 
 return vec4(dot(vec3(1.0)-u.rgb, vec3(1.0/3.0)), 0., 0., 1.); 
kernel vec4 _DEconditionalFilter(__sample c, __sample d, __sample mask, float threshold) { return mask.r > threshold ? c : d; 
kernel vec4 _DE_sub(__sample u, __sample v) __attribute__((outputFormat(kCIFormatRh))) { vec3 Y = vec3(0.299, 0.587, 0.114); float Yu = dot(Y,u.rgb); float Yv = dot(Y,v.rgb); return vec4(Yv-Yu, 0., 0., 1.0); }
kernel vec4 _DE_scaleAdd(__sample u, __sample Yv, float s) { vec3 Y = vec3(0.299, 0.587, 0.114); vec3 Cb = vec3(-0.168736, -0.331264, 0.5); vec3 Cr = vec3(0.5, -0.418688, -0.081312); vec3 yR = vec3(1., 0., 1.4); vec3 yG = vec3(1., -0.344136, -0.714136); vec3 yB = vec3(1., 1.772, 0.); vec3 cu = vec3(dot(u.rgb,Y), dot(u.rgb,Cb), dot(u.rgb,Cr)); cu.x -= s * Yv.x; cu = vec3(dot(cu,yR), dot(cu,yG), dot(cu,yB)); cu = clamp(cu, 0.0, u.a); return vec4(cu.rgb, u.a); }
kernel vec4 _CEcomp_minmax(__sample c) __attribute__((outputFormat(kCIFormatRGh)))
 float lov = min(min(c.r,c.g),c.b); 
 float hiv = max(max(c.r,c.g),c.b); 
 return vec4(lov,hiv,0.0,1.0); 
kernel vec4 _DEminmax4(sampler image, vec2 bound) __attribute__((outputFormat(kCIFormatRGh))) {
 vec2 d = 2.0*destCoord(); 
 vec2 p0 = sample(image, samplerTransform(image, d + vec2(-0.5,-0.5))).rg; 
 vec2 p1 = sample(image, samplerTransform(image, d + vec2(+0.5,-0.5))).rg; 
 vec2 p2 = sample(image, samplerTransform(image, d + vec2(-0.5,+0.5))).rg; 
 vec2 p3 = sample(image, samplerTransform(image, d + vec2(+0.5,+0.5))).rg; 
 p0.r = (d.x+0.5 < bound.x) ? min(p0.r, p1.r) : p0.r; 
 p2.r = (d.x+0.5 < bound.x) ? min(p2.r, p3.r) : p2.r; 
 p0.r = (d.y+0.5 < bound.y) ? min(p0.r, p2.r) : p0.r; 
 p0.g = (d.x+0.5 < bound.x) ? max(p0.g, p1.g) : p0.g; 
 p2.g = (d.x+0.5 < bound.x) ? max(p2.g, p3.g) : p2.g; 
 p0.g = (d.y+0.5 < bound.y) ? max(p0.g, p2.g) : p0.g; 
 return vec4(p0, 0.0, 1.0); 
kernel vec4 _CEstretch(__sample c, __sample lohi, float amount) 
 float lov = lohi.r; 
 float hiv = lohi.g; 
 return vec4(mix(c.rgb, clamp((c.rgb-lov)/max(0.00001, hiv-lov), 0., 1.), amount), c.a); 
/tmp/ED_gradMap.png
/tmp/ED_anchors.png
/tmp/ED_edgeDrawing.png
/tmp/ED_linesExtracted.png
/tmp/ED_linesMerged.png
EDLINES_DEBUG
kernel vec2 _droste(vec2 center, vec2 r, float logScale, vec2 rotzoom, vec2 innerSizeHalved) 
 vec2 c = destCoord() - center; 
 float theta = atan(c.y, c.x) + rotzoom.x; 
 vec2 polar = vec2(0.5 * log(dot(c,c)), theta); 
 vec2 rotated = vec2( polar.x * r.x - polar.y * r.y, dot(polar, r.yx)); 
 vec2 coord = exp(rotated.x) * cossin(rotated.y); 
 coord *= rotzoom.y; 
 float d0 = max(abs(coord.x)/innerSizeHalved.x, 
 abs(coord.y)/innerSizeHalved.y); 
 float myMod; { 
 float a = log(d0); 
 float b = logScale; 
 myMod = a - b*floor(a/b); 
 float d1 = exp(myMod); 
 coord *= ( d1 / d0 ); 
 return coord + center; 
inputInsetPoint0
inputInsetPoint1
inputPeriodicity
inputStrands
inputRotation
inputZoom
_drr_noise
CIBoxBlur
+[PercentileClipProcessor_RGBA8_CPU formatForInputAtIndex:]
CIDualRedEyeFilters.mm
threshold
area
centerOffsetLeft
centerOffsetRight
interPeakMinRepair
abortMaxCenterDist
densityRadius
minDensity
maxRelDensity
minGobalLocalMeanDiff
percentileRepair
percentileSpecular
percentRepair
percentSpecular
centerExtentLeft
centerExtentRight
+[PercentileClipProcessor_RGBA8_CPU processWithInputs:arguments:output:error:]
minInterDispersion
maxInterDispersion
areaMaxRatio
tuning
+[ConvexFillProcessor processWithInputs:arguments:output:error:]
kThreshold
kAreaThresholdHi
kAreaThresholdLo
kSplatArea
+[CISeedFillProcessor processWithInputs:arguments:output:error:]
fabs(inputCenter.region.size.width-1.0) <= 0.0001 && fabs(inputCenter.region.size.height-1.0) <= 0.0001
CIAreaRedCentroid
kernel vec4 _drr_cdintersect(__sample f, __sample c, __sample a, float denorm) __attribute__((outputFormat(kCIFormatRh))) { vec2 p = destCoord(); return f * (dot(p-c.xy,p-c.xy) <= a.x * denorm ? 1.0 : 0.0); }
kernel vec4 _drr_cdmeasure(__sample a, __sample aI) __attribute__((outputFormat(kCIFormatRh))) { return 1.0 - abs(a-aI)/max(a+aI,0.0001); }
kernel vec4 _drr_spec(__sample img, __sample c, __sample specular, float specularScale, float specthreshold, float debugBit) { float y = 0.5*(c.r+c.g+c.b-min(min(c.r,c.g),c.b)); float specularSmoothstep = 0.6; float s = min(1.0, specularScale*y); s = smoothstep(0.0, specularSmoothstep, s); specular.r = min(1.0, 1.25*specular.r); vec3 spec = vec3(s); img.rgb = specular.r > specthreshold ? mix(img.rgb, spec, specular.r) : img.rgb; return img; }
kernel vec4 _drr_spec_debug(__sample img, __sample c, __sample specular, float specularScale, float specthreshold, float debugBit) { float y = 0.5*(c.r+c.g+c.b-min(min(c.r,c.g),c.b)); float specularSmoothstep = 0.6; float s = min(1.0, specularScale*y); s = smoothstep(0.0, specularSmoothstep, s); specular.r = min(1.0, 1.25*specular.r); vec3 spec = vec3(s); img.rgb = specular.r > specthreshold ? mix(img.rgb, spec, specular.r) : img.rgb; if (debugBit < 1.0) return img; else if (debugBit < 2.0) img.gb *= 0.0; else if (debugBit < 3.0) img.rb *= 0.0; return img; }
kernel vec4 _drr_repair(__sample img, __sample c, __sample m, __sample avg, __sample noise, float brightness, float noiseAmount, float whiteCutoff, float chroma) { float mixer = m.r; vec3 Y = vec3(0.299, 0.587, 0.114); float nn = noise.r; avg.rgb += 2.0*noiseAmount*nn; vec3 source = c.rgb; c.rgb += noiseAmount*nn; float rg = max(0.,img.r-img.g)/max(0.0001,img.r+img.g); float rb = max(0.,img.r-img.b)/max(0.0001,img.r+img.b); float redness = max(0.25,0.5*(rg+rb)); redness = smoothstep(0.1, 0.6, redness); vec3 replacementRed = 0.5*brightness*vec3(min(c.b, c.g)); vec3 replacementWhite = 2.0*brightness*avg.rgb; vec3 replacement = mix(replacementWhite, replacementRed, redness); float Lrep = dot(replacement, Y); float Lavg = dot(avg.rgb, Y); replacement = mix(replacement, avg.rgb * Lrep * Lavg, chroma); replacement = max(0.06*avg.rgb, replacement); float n = dot(img.rgb, Y); float whiteness = smoothstep(0.01+whiteCutoff, 1.01, n); replacement.rgb = mix(replacement.rgb, vec3(n), whiteness); mixer *= 1.0-whiteness; img.rgb = mix(img.rgb, replacement, mixer); img.rgb = mix(source, img.rgb, m.r); return img; }
kernel vec4 _drr_recovery(__sample img, __sample c, __sample avg, __sample avgRaw, float recovery) { float mixer = 0.0; float n = dot(c.rgb, vec3(1.0/3.0)); float highlightNeutrality = 0.0; float cmixer = recovery*(1.0-smoothstep(0.0, 0.2, mixer)) * smoothstep(0.6, 0.95, min(min(img.r,img.g),img.b)); vec3 highlightReplacement = mix(c.rgb, vec3(n), highlightNeutrality) * avg.rgb / avgRaw.rgb; img.rgb = min(img.rgb, mix(img.rgb, highlightReplacement, cmixer)); return img; }
CheapRandomness
inputDither
CIColorClamp
CIAreaRedRadialCentroid
inputCenter
inputRadialMode
inputMinWeight
ExifOrientation
WouldAutoFlashTurnOn
PortType
DeviceModelName
NormalizedSNR
TuningParametersByPortType
CIDualRedEyeRepairRGBAh
redeye_archive
@"<MTLTexture>"8@?0
-[CIDualRedEyeRepairSession prewarm]_block_invoke
CIDualRedEyeRepair.m
-[CIDualRedEyeRepairSession prewarm]
CIRedEyeRaw
inputPrimary
inputSecondary
kUseFaceSegmentationMask
inputUseFaceSegmentationMask
-[CIDualRedEyeRepairSession dumpInputs]
-[CIDualRedEyeRepairSession validateRenderState]
-[CIDualRedEyeRepairSession validateSetPrimary]
kMinPrimaryDimension
kAutoFlashOverrideSNRThreshold
-[CIDualRedEyeRepairSession validateRepair]
not nil
-[CIDualRedEyeRepairSession redEyeFaceFromObservation:exifOrientation:]
kMinLandmarkConfidenceThreshold
kMaxFaceJunkinessThreshold
kMinIsotropy
kMinLandmarkArea
kSessionTuningOutsetROILong
kSessionTuningOutsetROIShort
kRegionOutset
kForceFaceSegmentationPupils
kUseFaceSegmentation
kMinLaplacianVariance
inputOriginLeft
inputOriginRight
inputSize
inputOrientationHint
inputAxisLongLeft
inputAxisLongRight
inputAxisShortLeft
inputAxisShortRight
inputPupilCenterLeft
inputPupilCenterRight
inputSkinMask
inputScleraMask
inputIrisMask
-[CIDualRedEyeRepairSession repairFace:filter:]
kRenderFullRect
-[CIDualRedEyeRepairSession setPrimary:observations:metadata:]
kMaxFaceCount
q24@?0@8@16
-[CIDualRedEyeRepairSession _repairPrimaryWithSecondary:to:]
-repair
-[CIDualRedEyeRepairSession dumpSecondary]
-raw
-[CIDualRedEyeRepairSession dumpObservation:index:]
%@-%d
-observation
.archive
kernel vec4 _drr_extract_iris(__sample iris, __sample sclera, __sample skin, float thresholdIris, float thresholdSclera, float thresholdSkin) { float i = step(thresholdIris, iris.r); float s = 1.0 - step(thresholdSclera, sclera.r); float k = 1.0 - step(thresholdSkin, skin.r); iris.rgb = vec3(i*s*k); return iris; }
kernel vec4 _drr_extract_skin(__sample skin, float threshold) { float s = 1.0 - smoothstep(threshold, threshold + 0.05, skin.r); skin.rgb = vec3(s); return skin; }
-[CIRedEyeRaw outputImage]
kernel vec4 _drr_boost(__sample c, float s) { 
 return vec4(s*c.rgb, c.a); 
RedPupilLocalizer
inputIterations
inputDecay
inputGamma
inputLocalizationRadius
inputDebug
inputAxisLong
inputAxisShort
inputPupilCenter
inputSearchAxisLong
inputSearchAxisShort
RadialFalloffFilter
inputFalloff
inputAnisotropic
HistoClip_RGBA8_CPU
inputPercentileRepair
inputPercentileSpecular
inputPercentRepair
inputPercentSpecular
inputInterPeakMinRepair
inputMinimum
inputMaxArea
inputMaxAreaRatio
inputCenterLeft
inputCenterRight
inputCenterExtentLeft
inputCenterExtentRight
inputCenterOffsetLeft
inputCenterOffsetRight
inputAbortMaxCenterDist
inputMinDensity
inputMaxRelDensity
inputDensityRadius
inputDetectionLeft
inputDetectionRight
inputMinInterDispersion
inputMaxInterDispersion
inputMinGobalLocalMeanDiff
inputTuning
CIBlendWithRedMask
CICircularityDescriptor
inputCentroid
CIConvexFill
inputAreaThresholdLoHi
inputSplat
CIMorphologyMaximum
CIMorphologyMinimum
RedEyeRecolor
inputMask
inputNoiseAmount
inputBrightness
inputRecovery
inputWhiteCutoff
inputChroma
kernel vec4 _rer_glint(__sample original, __sample current, float whiteCutoff) { 
 float u = min(min(original.r, original.g), original.b); 
 float glint = smoothstep(whiteCutoff, 1.0, u); 
 return mix(current, original, glint); 
RedEyeSpecular
inputSpecularMask
inputSpecularThreshold
inputSpecIntensity
inputDebugFlag
kernel vec4 _drr_threshold(__sample s, __sample m, float threshold) { 
 return s * step(threshold, m.r); 
N841
D321
D331
D331p
PortTypeBackTelephoto
D421
D431
N104
Tuning
RedEye
inputOrientationScale
inputRefilterSpace
inputRefilterRange
inputDetectRed
inputDetectWhite
inputMidSpectrumWhiteOffsetsX
inputMidSpectrumWhiteOffsetsY
inputCentroidIterations
inputCentroidRadius
inputCentroidRadiusSmall
inputCentroidGamma
inputSearchLong
inputSearchShort
inputFalloffRepair
inputRadiusRepair
inputRepairPercentile
inputRepairPercent
inputClipMin
inputClosingDilation
inputClosingErosion
inputRepairDarken
inputRepairChroma
inputRepairDither
inputCutoff
inputTargetClosing
inputFeathering
inputFSmooth
inputFlooding
inputRecover
inputParam
inputParam2
inputParam3
inputParam4
inputFalloffSpecular
inputRadiusSpecular
inputSpecular
inputSpecArea
inputSpecAreaScale
inputSpecMin
inputCenterSpecRad
inputGlintThreshold
inputSpecularCutoff
inputFalloffDensity
inputAbortDensityLo
inputAbortDensityDiff
inputRadiusDensity
inputInterPeakMin
inputCircularity
inputIntersect
inputSkinThreshold
inputSkinThresholdMed
inputScleraThreshold
inputMinMaskDiff
inputDetectionThresholdIrisSmall
inputDetectionThresholdScleraSmall
inputDetectionThresholdSkinSmall
inputScleraProtectionThresholdIrisSmall
inputScleraProtectionThresholdScleraSmall
inputScleraProtectionThresholdSkinSmall
inputSkinProtectionThresholdSmall
inputDetectionThresholdIrisMedium
inputDetectionThresholdScleraMedium
inputDetectionThresholdSkinMedium
inputScleraProtectionThresholdIrisMedium
inputScleraProtectionThresholdScleraMedium
inputScleraProtectionThresholdSkinMedium
inputSkinProtectionThresholdMedium
inputDetectionThresholdIrisLarge
inputDetectionThresholdScleraLarge
inputDetectionThresholdSkinLarge
inputScleraProtectionThresholdIrisLarge
inputScleraProtectionThresholdScleraLarge
inputScleraProtectionThresholdSkinLarge
inputSkinProtectionThresholdLarge
inputRepairSource
inputSpecMax
inputShowMask
+[CIDualRedEyeRepairTuning repairParametersForTuning:]
+[CIDualRedEyeRepairTuning sessionParametersForTuning:]
Session
-[CIDualRedEyeRepairTuning updateWithCaptureSetup:portType:]
input
Repair
updatedTuningFromSetup
%@%@%@
kernel vec4 _resp_previs(__sample iris, __sample sclera, float thresholdSclera) { float s = 1.0 - (sclera.r > thresholdSclera ? 1.0 : 0.0); float p = iris.r; iris.rgb = vec3(s * p); return iris; }
repairROIforEyePoints
focusStatsForRegion
YYYY_MM_dd__HH_mm_ss_SSS
%@__IMG__%@__redeye%@
/tmp/
.tiff
.420f
DualReEye_dumpLinearPNG
inputSpatialSigma
inputLumaSigma
kernel vec4 _jointBilateral (sampler small, sampler guide, vec4 parms) 
 vec2 dc = destCoord(); 
 vec2 smallCenter = samplerCoord(small); 
 vec2 guideCenter = samplerCoord(guide); 
 vec2 smallDelta = samplerTransform(small, dc+vec2(1.0)) - smallCenter; 
 vec2 guideDelta = samplerTransform(guide, dc+vec2(1.0)) - guideCenter; 
 vec4 I0 = sample(small, smallCenter); 
 float IE0 = sample(guide, guideCenter).r; 
 vec4 sumFGI = vec4(0.0); 
 float sumFG = 0.0; 
 float x,y; 
 float w=2.0; 
 for (x=-w;x<=w;x++) 
 for (y=-w;y<=w;y++) 
 vec2 xy = vec2(x,y) * parms.zw; 
 float G = exp(-(x*x+y*y)*parms.y); 
 vec4 I = sample(small, smallCenter + xy*smallDelta); 
 float IE = sample(guide, guideCenter + xy*guideDelta).g; 
 float F = exp(-((IE - IE0)*(IE - IE0))*parms.x); 
 sumFG += F*G; 
 sumFGI += F*G*I; 
 return sumFG<0.001 ? I0 : sumFGI/sumFG; 
kernel vec4 _jointBilateralRG (sampler combo, vec4 parms) 
 vec2 dc = destCoord(); 
 vec2 comboCenter = samplerCoord(combo); 
 vec2 comboDelta = samplerTransform(combo, dc+vec2(1.0)) - comboCenter; 
 vec4 c = sample(combo, comboCenter); 
 vec2 I0 = c.zw; 
 float IE0 = c.r; 
 vec2 sumFGI = vec2(0.0); 
 float sumFG = 0.0; 
 float x,y; 
 float w=2.0; 
 for (x=-w;x<=w;x++) 
 for (y=-w;y<=w;y++) 
 vec2 xy = vec2(x,y) * parms.zw; 
 float G = exp(-(x*x+y*y)*parms.y); 
 vec4 c = sample(combo, comboCenter + xy*comboDelta); 
 vec2 I = c.zw; 
 float IE = c.g; 
 float F = exp(-((IE - IE0)*(IE - IE0))*parms.x); 
 sumFG += F*G; 
 sumFGI += F*G*I; 
 return vec4(sumFG<0.001 ? I0 : sumFGI/sumFG, 0.0, 1.0); 
kernel vec4 _guideCombine (__sample g, __sample gb) __attribute__((outputFormat(kCIFormatRGh))) 
 return vec4(g.r, gb.r, 0.0, 1.0); 
kernel vec4 _guideCombine4 (__sample guide, __sample guideblurred, __sample map) 
 return vec4(guide.r, guideblurred.r, map.rg); 
kernel vec4 _guideMono (__sample g) __attribute__((outputFormat(kCIFormatRh))) 
 return vec4(clamp(dot(g.rgb, vec3(0.3333)),0.0,1.0), 0.0, 0.0, 1.0); 
CIGaussianBlurXY
inputSigmaX
inputSigmaY
kernel vec4 _edgeWork(__sample src, __sample blurred) 
 return vec4(clamp((src.r - blurred.r) * 1000.0, 0.0, 1.0)); 
kernel vec4 _edgeWorkContrast(__sample src, float contrast) 
 return clamp((src - 0.5) * contrast + 0.5, 0.0, 1.0); 
kernel vec4 _edges(sampler src, float scale) 
 vec2 dc = destCoord(); 
 vec4 r0 = sample (src, samplerTransform(src, dc + vec2(0.0,-1.0))); 
 vec4 r3 = sample (src, samplerTransform(src, dc + vec2(1.0,-1.0))); 
 vec4 r2 = sample (src, samplerTransform(src, dc + vec2(1.0, 0.0))); 
 vec4 r1 = sample (src, samplerCoord(src)); 
 r3 = r1 - r3; 
 r2 = r0 - r2; 
 r2 = (r3 * r3 + r2 * r2) * scale; 
 return vec4(r2.rgb, r1.a); 
kernel vec4 _gabor(sampler i) __attribute__((outputFormat(kCIFormatRGh))) 
 vec2 dc = destCoord(); 
 vec4 s2 = sample(i, samplerTransform(i, dc+vec2(-1.0, 2.0))); 
 vec4 s3 = sample(i, samplerTransform(i, dc+vec2(-1.0, 3.0))); 
 vec4 s4 = sample(i, samplerTransform(i, dc+vec2( 1.0, 2.0))); 
 vec4 s6 = sample(i, samplerTransform(i, dc+vec2(-2.0, 1.0))); 
 vec4 s7 = sample(i, samplerTransform(i, dc+vec2(-1.0, 1.0))); 
 vec4 s8 = sample(i, samplerTransform(i, dc+vec2( 0.0, 1.0))); 
 vec4 s9 = sample(i, samplerTransform(i, dc+vec2( 1.0, 1.0))); 
 vec4 s10 = sample(i, samplerTransform(i, dc+vec2( 2.0, 1.0))); 
 vec4 s11 = sample(i, samplerTransform(i, dc+vec2(-2.0, 0.0))); 
 vec4 s12 = sample(i, samplerTransform(i, dc+vec2(-1.0, 0.0))); 
 vec4 s14 = sample(i, samplerTransform(i, dc+vec2( 1.0, 0.0))); 
 vec4 s15 = sample(i, samplerTransform(i, dc+vec2( 2.0, 0.0))); 
 vec4 s16 = sample(i, samplerTransform(i, dc+vec2(-2.0,-1.0))); 
 vec4 s17 = sample(i, samplerTransform(i, dc+vec2(-1.0,-1.0))); 
 vec4 s18 = sample(i, samplerTransform(i, dc+vec2( 0.0,-1.0))); 
 vec4 s19 = sample(i, samplerTransform(i, dc+vec2( 1.0,-1.0))); 
 vec4 s20 = sample(i, samplerTransform(i, dc+vec2( 2.0,-1.0))); 
 vec4 s22 = sample(i, samplerTransform(i, dc+vec2(-1.0,-2.0))); 
 vec4 s23 = sample(i, samplerTransform(i, dc+vec2(-1.0,-3.0))); 
 vec4 s24 = sample(i, samplerTransform(i, dc+vec2( 1.0,-2.0))); 
 float kC = 0.0090; 
 float kB = 0.1764, kE = 0.0180; 
 float kA = 0.5447, kD = 0.0445; 
 vec4 i2 = s2 - s24; 
 vec4 i3 = s3 - s23; 
 vec4 i4 = s4 - s22; 
 vec4 i6 = s6 - s20; 
 vec4 i7 = s7 - s19; 
 vec4 i8 = s8 - s18; 
 vec4 i9 = s9 - s17; 
 vec4 i10 = s10 - s16; 
 vec4 i11 = s11 - s15; 
 vec4 i12 = s12 - s14; 
 vec4 x = kA*(-i12) + kB*(-i7 + i9) + kC*(-i2 + i4) + kD*(-i11) + kE*(-i6 + i10); 
 vec4 y = kA*(i8) + kB*( i7 + i9) + kC*(i6 + i10) + kD*(i3) + kE*(i2 + i4); 
 vec4 mag = x*x + y*y; 
 vec4 result = vec4(x.r, y.r, 0.0, 1.0); 
 float maxMag = mag.r; 
 if (mag.g > maxMag) { result.r = x.g; result.g = y.g; maxMag = mag.g; } 
 if (mag.b > maxMag) { result.r = x.b; result.g = y.b; maxMag = mag.b; } 
 if (mag.a > maxMag) { result.r = x.a; result.g = y.a; } 
 return result; 
CI_ENABLE_SUBDIVIDE_ROI
CI_MAX_TEXTURE_SIZE
CI_IOSURFACE_WRAPPING
CI_IOSURFACE_INTERMEDIATES
CI_LOSSLESS_COMPRESSED_INTERMEDIATES
CI_LOSSY_COMPRESSED_INTERMEDIATES
CI_LOG_FILE
stderr
stdout
oslog
%s/%s
CI_PRINT_TIME
context
CI_PRINT_TREE
CI_PRINT_TREE options flags:
%3d  initial graph %s
(set)
%3d  optimized graph %s
%3d  program graph %s
 dump-inputs %s
dump-inputs
 dump-intermediates %s
dump-intermediates
 dump-raw-intermediates %s
dump-raw-intermediates
 dump-bmtl-intermediates %s
dump-bmtl-intermediates
 dump-outputs %s
dump-outputs
 dump-timing %s
dump-timing
context==
context!=
 context==<name|number> (set %s)
 context==<name|number>
 context!=<name|number> (set %s)
 context!=<name|number>
(set frame-%d)
 frame-<number> %s
(set %s)
 <dot|pdf|png> %s
dump-rois
frame-
graphviz
CI_PRINT_PROGRAM
CI_NO_CM
CI_FORCE_IS_BACKGROUND
CI_FORCE_GPU_PRIORITY
CI_INPUT_CACHE_SIZE
CI_ENABLE_KERNEL_CACHE
CI_ENABLE_HALF_KERNELS
CI_ASYNC_KERNEL_COMPILE
CI_INTERMEDIATE_CACHE_SIZE
CI_INTERMEDIATE_SRGB_TEXTURES
CI_INPUT_SRGB_TEXTURES
CI_OUTPUT_SRGB_TEXTURES
CI_RECYCLE_OPENGL_TEXTURES
CI_RECYCLE_METAL_TEXTURES
CI_USE_INFLIGHT_INTERMEDIATES
CI_WORKING_FORMAT
BGRA8
RGBA8
RGBAh
RGBAf
CI_ENABLE_METAL_GPU
CI_ENABLE_METAL_DAG
CI_ENABLE_FUNCTION_STITCHING
CI_USE_ARCHIVED_KERNELS
CI_STORE_PROGRAM_LIBRARIES
CI_ENABLE_METAL_CONVERT
CI_ENABLE_METAL_BLIT
CI_ENABLE_METAL_LABEL
CI_ENABLE_METAL_DEBUG
CI_ENABLE_METAL_CAPTURE
CI_ENABLE_METAL_IMAGEBLOCKS
CI_ENABLE_WRITE_420
CI_AUTOTEST_ROI
CI_EDIT_RED_EYE_VERSION
CI_DISABLE_MERGING
CI_DISABLE_MERGING_PRE_GENERAL
CI_DISABLE_MERGING_POST_GENERAL
CI_LOG_TEXTURE_CACHE
CI_LIMIT_SAMPLERS
CI_LIMIT_RENDER
CI_NO_RENDER
CI_LOG_SURFACE_CACHE
CI_LOG_IMAGE_PROVIDER
CI_NAME_SURFACES
CI_RENDER_MB_LIMIT
CI_SURFACE_CACHE_CAPACITY
CI_TEMP_DIR
/tmp
CI_KDEBUG
CI_DISABLE_CRUFT_COMPATABILITY
CI_FORCE_INSERT_NOOPS
CI_MAX_CL_COMPLEXITY
CI_MAX_PROGRAM_DEPTH
CI_MAX_PROGRAM_INPUT_TEXTURES
CI_DEBUG_CONTEXT_COLOR
CI_DISABLE_WORKAROUND
CI_GRAPH_ALLOW_REORDER
CI_GRAPH_FORCE_CROP
CI_FLIP_IMAGE_PROCESSOR
CI_CACHE_PROGRAM_GRAPH
Progam Graph cache disabled when using CI_PRINT_TREE dump_timing
CI_GRAPHVIZ_INTERNAL
FOSL_DUMP_GRAPH
FOSL_PRINT_GRAPH
FOSL_PRINT_KERNEL_AST
CI_DISABLE_REDEYE_SEARCH
CI_LOG_DUALRED
com.apple.coremedia
inputOrigI
inputOrigQ
kernel vec4 _facebalance (__sample pix, vec2 delta) 
 pix.rgb = pix.r * vec3(0.299, 0.595716, 0.211456) + 
 pix.g * vec3(0.587, -0.274453, -0.522591) + 
 pix.b * vec3(0.114, -0.321263, 0.311135); 
 float chroma2 = min(1.0, 4.0*(pix.g*pix.g + pix.b*pix.b)); 
 pix.gb += delta * pow(chroma2,0.2) * (1.0-chroma2*chroma2); 
 pix.rgb = pix.r * vec3(1.0) + 
 pix.g * vec3(0.956296, -0.272122, -1.10699) + 
 pix.b * vec3(0.621024, -0.647381, 1.70461); 
 return pix; 
FaceBalanceOrigI
FaceBalanceOrigQ
FaceBalanceStrength
FaceBalanceWarmth
http://ns.adobe.com/camera-raw-settings/1.0/
IncrementalTemperature
IncrementalTint
HasSettings
AlreadyApplied
Shadows
kernel vec4 _CIFaceMaskApply(sampler blurValImage,vec4 cx,vec4 cy,
                             vec4 cdx,vec4 cdy,float blurMapAspectRatio,
                             sampler paramImage,vec2 imageSizeInverted,vec2 p) {
vec4 chinThetaLimit = vec4(p.x);
float chinThetaMultip = p.y;
    vec4 k0 = sample(paramImage, samplerTransform(paramImage,vec2(0.5,0.5)));
    vec4 k1 = sample(paramImage, samplerTransform(paramImage,vec2(1.5,0.5)));
    vec4 k2 = sample(paramImage, samplerTransform(paramImage,vec2(2.5,0.5)));
    vec4 k3 = sample(paramImage, samplerTransform(paramImage,vec2(3.5,0.5)));
    float k4 = sample(paramImage, samplerTransform(paramImage,vec2(4.5,0.5))).x;
    
    vec2 samplePos = destCoord() * imageSizeInverted;
    
    vec4 faceDistX = samplePos.x - cx;
    vec4 faceDistY = blurMapAspectRatio * (samplePos.y - cy);
    vec4 faceDist = sqrt(faceDistX * faceDistX + faceDistY * faceDistY);
    float blurVal = sample(blurValImage, samplerCoord(blurValImage)).x;
    blurVal = blurVal * blurVal;
vec4 faceDistXr = cdx * faceDistX + cdy * faceDistY;
vec4 faceDistYr = cdx * faceDistY - cdy * faceDistX;
vec4 faceDistRatio = abs(faceDistYr) / (abs(faceDistXr) + 1e-10);
 vec4 approxTheta = 1.066 * faceDistRatio - 0.276 * faceDistRatio * faceDistRatio;
approxTheta = max(chinThetaLimit, approxTheta);
bool chinMaskX = false, chinMaskY = false, chinMaskZ = false, chinMaskW = false;
chinMaskX =  (faceDistRatio.x < 1.5574) && (faceDistXr.x >= 0.0) && ((cdx.x != 0.0) || (cdy.x != 0.0));
chinMaskY =  (faceDistRatio.y < 1.5574) && (faceDistXr.y >= 0.0) && ((cdx.y != 0.0) || (cdy.y != 0.0));
chinMaskZ =  (faceDistRatio.z < 1.5574) && (faceDistXr.z >= 0.0) && ((cdx.z != 0.0) || (cdy.z != 0.0));
chinMaskW =  (faceDistRatio.w < 1.5574) && (faceDistXr.w >= 0.0) && ((cdx.w != 0.0) || (cdy.w != 0.0));
vec4 blurAddScaling = vec4(0.0); 
blurAddScaling.x = chinMaskX ? chinThetaMultip * approxTheta.x : 1.0;
blurAddScaling.y = chinMaskY ? chinThetaMultip * approxTheta.y : 1.0;
blurAddScaling.z = chinMaskZ ? chinThetaMultip * approxTheta.z : 1.0;
blurAddScaling.w = chinMaskW ? chinThetaMultip * approxTheta.w : 1.0;
vec4 blurAddPerFace = faceDist * k0 + k1;
blurAddPerFace.x += faceDist.x >= k3.x ?  faceDist.x * k2.x - k2.x* k3.x: 0.0;
blurAddPerFace.y += faceDist.y >= k3.y ?  faceDist.y * k2.y - k2.y* k3.y: 0.0;
blurAddPerFace.z += faceDist.z >= k3.z ?  faceDist.z * k2.z - k2.z* k3.z: 0.0;
blurAddPerFace.w += faceDist.w >= k3.w ?  faceDist.w * k2.w - k2.w* k3.w: 0.0;
blurAddPerFace.x *= blurAddPerFace.x > 0.0 ? blurAddScaling.x : 1.0;
blurAddPerFace.y *= blurAddPerFace.y > 0.0 ? blurAddScaling.y : 1.0;
blurAddPerFace.z *= blurAddPerFace.z > 0.0 ? blurAddScaling.z : 1.0;
blurAddPerFace.w *= blurAddPerFace.w > 0.0 ? blurAddScaling.w : 1.0;
float blurAdd = min(min(blurAddPerFace.x, blurAddPerFace.y), min(blurAddPerFace.z, blurAddPerFace.w));
float newBlurVal = clamp(blurVal + blurAdd, 0.0, max(k4, blurVal));
 newBlurVal = sqrt(newBlurVal);
 return vec4(newBlurVal, 0.0, 0.0, 1.0);
chinThetaLimit
chinThetaMultip
/tmp/inputFaceMask-CI.tiff
/tmp/outputFaceMask-CI.tiff
_modifyFaceMask
-[CIFaceMaskDelta outputImage]
CIFaceMask.m
float __selectFFF(float a,float b,float c) { return bool(c) ? b : a; }
        
vec4 __select(vec4 a,vec4 b,vec4 c) { 
   vec4 r;
   r.x = __selectFFF(a.x, b.x, c.x);
   r.y = __selectFFF(a.y, b.y, c.y);
   r.z = __selectFFF(a.z, b.z, c.z);
   r.w = __selectFFF(a.w, b.w, c.w);
   return r;
vec4 _computeFaceMaskParams(vec4 facesLeftEyeX,
vec4 facesLeftEyeY,
vec4 facesCentreX,
vec4 facesCentreY,
vec4 facesRightEyeX,
vec4 facesRightEyeY,
vec4 leftEyeBlur,
vec4 rightEyeBlur,
                           vec4 chinX,
                           vec4 chinY,
                           vec4 param1,
                           vec4 param2,
                           vec4 param3,
                           vec4 param4,
                           vec2 dc,
                           vec4 facesValid)
    float maxBlur = param1.x;
    float facesCapMultip = param1.y;
    float facesMaxBlurOnEyes = param1.z;
    float facesMaxBlurDistFromFocus = param1.w;
    float facesLinearBlurGrowthM = param2.x;
    float facesLinearBlurGrowthC = param2.y;
    float facesEyeToEyebrowRatio = param2.z;
    float facesDistToBlurScaling = param2.w;
    float facesGainMultip = param3.x;
    float imageAspectRatio = param3.y;
    float chinVectorSnapping = param4.x;
    float apertureScaling = param4.y;
    
    
    leftEyeBlur  = compare (facesValid, vec4(1.0), leftEyeBlur * leftEyeBlur * maxBlur );
    rightEyeBlur = compare (facesValid, vec4(1.0), rightEyeBlur * rightEyeBlur * maxBlur );
    
    vec4 minBlurForEyes = min( leftEyeBlur, rightEyeBlur );
    float overallMinBlur = min( min( minBlurForEyes.x, minBlurForEyes.y ), min( minBlurForEyes.z, minBlurForEyes.w ) );
    bool anyFaceValid = overallMinBlur < (apertureScaling * facesMaxBlurOnEyes);
    vec4 faceValid;
faceValid.x = float((minBlurForEyes.x - overallMinBlur) < (apertureScaling * facesMaxBlurDistFromFocus));
faceValid.y = float((minBlurForEyes.y - overallMinBlur) < (apertureScaling * facesMaxBlurDistFromFocus));
faceValid.z = float((minBlurForEyes.z - overallMinBlur) < (apertureScaling * facesMaxBlurDistFromFocus));
faceValid.w = float((minBlurForEyes.w - overallMinBlur) < (apertureScaling * facesMaxBlurDistFromFocus));
if ( bool(facesValid.x) && bool(faceValid.x) )
facesValid.x = 1.0;
if ( bool(facesValid.y) && bool(faceValid.y) )
facesValid.y = 1.0;
if ( bool(facesValid.z) && bool(faceValid.z) )
facesValid.z = 1.0;
if ( bool(facesValid.w) && bool(faceValid.w) )
faceValid.w = 1.0;
    if ( anyFaceValid && bool(facesValid.x) )
    
facesValid.x = 1.0;
    if ( anyFaceValid && bool(facesValid.y) )
    
facesValid.y = 1.0;
    if ( anyFaceValid && bool(facesValid.z) )
    
facesValid.z = 1.0;
    if ( anyFaceValid && bool(facesValid.w) )
    
facesValid.w = 1.0;
    
    vec4 leftEyeDistanceX  = facesLeftEyeX - facesCentreX;
    vec4 leftEyeDistanceY  = imageAspectRatio * (facesLeftEyeY - facesCentreY);
    vec4 rightEyeDistanceX = facesRightEyeX - facesCentreX;
    vec4 rightEyeDistanceY = imageAspectRatio * (facesRightEyeY - facesCentreY);
    vec4 leftEyeDistance   = sqrt(leftEyeDistanceX * leftEyeDistanceX + leftEyeDistanceY * leftEyeDistanceY);
    vec4 rightEyeDistance  = sqrt(rightEyeDistanceX * rightEyeDistanceX + rightEyeDistanceY * rightEyeDistanceY);
    vec4 faceRadius = max(leftEyeDistance, rightEyeDistance) * facesEyeToEyebrowRatio;
vec4 chinDeltaX = chinX - facesCentreX;
vec4 chinDeltaY = imageAspectRatio * (chinY - facesCentreY);
vec4 chinDeltaNorm0 = max(abs(chinDeltaX), abs(chinDeltaY));
vec4 chinDeltaNorm2 = sqrt(chinDeltaX*chinDeltaX + chinDeltaY*chinDeltaY);
vec4 chinDeltaNormR = chinDeltaNorm0 / max(chinDeltaNorm2, 1e-10);
vec4 chinVectorInhibition = 1.0 - clamp( chinVectorSnapping * ( 1.0 - 3.4142 * (chinDeltaNormR - 0.70711) ), 0.0, 1.0 );
    vec4 maxBlurToAdd = compare(facesValid, vec4(1.0), chinVectorInhibition *( facesLinearBlurGrowthM * faceRadius + facesLinearBlurGrowthC));
        maxBlurToAdd = __select( vec4(1.0),chinVectorInhibition *( facesLinearBlurGrowthM * faceRadius + facesLinearBlurGrowthC), facesValid );
    vec4 blur2AddOnLeftEye = min( maxBlurToAdd , faceRadius * facesDistToBlurScaling * ( leftEyeDistance - faceRadius ) );
    vec4 blur2AddOnRightEye = min( maxBlurToAdd , faceRadius * facesDistToBlurScaling * ( rightEyeDistance - faceRadius ) );
    vec4 multip = min( vec4(facesCapMultip), max( abs(leftEyeBlur / blur2AddOnLeftEye), abs(rightEyeBlur / blur2AddOnRightEye)) );
    
    vec4 facesKM = apertureScaling * chinVectorInhibition * faceRadius * facesDistToBlurScaling;
    vec4 facesK0 = facesKM * facesGainMultip * facesGainMultip * multip;
    vec4 facesK1 = -faceRadius * facesK0;
    vec4 facesK2 = facesKM - facesK0;
    vec4 facesK3 = faceRadius;
    float  facesK4 = apertureScaling * min(min(maxBlurToAdd.x, maxBlurToAdd.y), min(maxBlurToAdd.z, maxBlurToAdd.w));
    if ( dc.x < 1.0 )
            return __select(vec4(0.0), facesK0 / maxBlur, facesValid);
    else if ( dc.x < 2.0 )
            return __select(vec4(1.0), facesK1 / maxBlur, facesValid);
    else if ( dc.x < 3.0 )
            return __select(vec4(0.0), facesK2 / maxBlur, facesValid);
    else if ( dc.x < 4.0 )
    
return compare(facesValid, vec4(0.0), facesK3);
    return vec4(anyFaceValid ? facesK4 / maxBlur : 0.0, 0.0, 0.0, 0.0);
kernel vec4 _faceMaskCalculator(sampler image,
vec4 lex,
vec4 ley,
vec4 cx,
vec4 cy,
vec4 rex,
vec4 rey,
       vec4 chinx,vec4 chiny,
        vec4 param1,
        vec4 param2,
        vec4 param3,
        vec4 param4,
        vec4 facesValid)
vec4 leftEyeBlur, rightEyeBlur;
   vec2 imageSize = param3.zw;
    
leftEyeBlur.x = facesValid.x > 0.0 ? sample(image, samplerTransform(image, vec2(lex.x, ley.x))).x : 1.0;
leftEyeBlur.y = facesValid.y > 0.0 ? sample(image, samplerTransform(image, vec2(lex.y, ley.y))).x : 1.0;
leftEyeBlur.z = facesValid.z > 0.0 ? sample(image, samplerTransform(image, vec2(lex.z, ley.z))).x : 1.0;
leftEyeBlur.w = facesValid.w > 0.0 ? sample(image, samplerTransform(image, vec2(lex.w, ley.w))).x : 1.0;
    
rightEyeBlur.x = facesValid.x > 0.0 ? sample(image, samplerTransform(image, vec2(rex.x, rey.x))).x : 1.0;
rightEyeBlur.y = facesValid.y > 0.0 ? sample(image, samplerTransform(image, vec2(rex.y, rey.y))).x : 1.0;
rightEyeBlur.z = facesValid.z > 0.0 ? sample(image, samplerTransform(image, vec2(rex.z, rey.z))).x : 1.0;
rightEyeBlur.w = facesValid.w > 0.0 ? sample(image, samplerTransform(image, vec2(rex.w, rey.w))).x : 1.0;
    
return _computeFaceMaskParams(lex / imageSize.x,
 ley / imageSize.y,
 cx / imageSize.x,
 cy / imageSize.y,
 rex / imageSize.x,
 rey / imageSize.y,
 leftEyeBlur,
 rightEyeBlur,
 chinx / imageSize.x,
 chiny / imageSize.y,
                            param1, param2, param3, param4, destCoord(), facesValid);
_FMCalculator
chinVectorSnapping
CIFaceMask_calc
CIFaceMask_apply
Failed to initialize %@: %@; %@
face0CentreX
face0CentreY
face0LeftEyeX
face0LeftEyeY
face0RightEyeX
face0RightEyeY
face0ChinX
face0ChinY
face1CentreX
face1CentreY
face1LeftEyeX
face1LeftEyeY
face1RightEyeX
face1RightEyeY
face1ChinX
face1ChinY
face2CentreX
face2CentreY
face2LeftEyeX
face2LeftEyeY
face2RightEyeX
face2RightEyeY
face2ChinX
face2ChinY
face3CentreX
face3CentreY
face3LeftEyeX
face3LeftEyeY
face3RightEyeX
face3RightEyeY
face3ChinX
face3ChinY
v16@?0@"<MTLCommandBuffer>"8
CIFaceUtils-segmentationCentroid
CIVision.h
void *VisionLibrary()
/System/Library/Frameworks/Vision.framework/Vision
/System/Library/Frameworks/Vision.framework/Contents/MacOS/Vision
NSString *getVNImageOptionImageOrientation()
VNImageOptionImageOrientation
VNGenerateFaceSegmentsRequest
Class getVNGenerateFaceSegmentsRequestClass()_block_invoke
VNFaceObservation
Class getVNFaceObservationClass()_block_invoke
VNImageRequestHandler
Class getVNImageRequestHandlerClass()_block_invoke
Face
Rectangle
QRCode
Text
bounds
topLeft
topRight
bottomLeft
bottomRight
symbolDescriptor
Crashed in [CIFilter dealloc] releasing the value of %s for %s.
If a CIFilter subclass releases an ivar%s, it must be set to nil afterwards.
 (e.g. in its dealloc method)
dealloc
__WrappedNSNumber
outputImage
CIRequiresKeyedArchiver
CoreImage requires keyed archiving.
CICS_%@
CI_%@
-[CIFilter encodeWithCoder:]_block_invoke
CIName
CIVersion
CIUserInfo
-[CIFilter initWithCoder:]_block_invoke
<%s: %p
 %s=%s
<%s: %p>
    version=%s
    %s=%s
-[CIFilter apply:arguments:options:]
regionOf:destRect:userInfo:
regionOf:destRect:
DGCurvesFilter
PXSoftProofingFilter
-[CIFilter apply:arguments:options:]_block_invoke
PX_CIF_Noise
input%@
%@,%@=%@
%@,%@="%s"
%@,%@=nil
CIAffineTransform
CICrop
+[CIFilter(Private) _propertyArrayFromFilters:inputImageExtent:]
CIFilter.mm
affineFilter != nil || cropFilter != nil
CropAngle
CropTop
CropBottom
CropLeft
CropRight
HasCrop
Filters
CIRedEyeCorrections
CIFaceBalance
CIVibrance
CIToneCurve
CIHighlightShadowAdjust
+[CIFilter(Private) _filterArrayFromProperties:]
CIAttributeFilterName
CIAttributeFilterDisplayName
CIAttributeDescription
CIAttributeFilterAvailable_Mac
CIAttributeFilterAvailable_iOS
CIAttributeReferenceDocumentation
CIAttributeFilterCategories
CIAttributeClass
CIAttributeType
CIAttributeMin
CIAttributeMax
CIAttributeSliderMin
CIAttributeSliderMax
CIAttributeDefault
CIAttributeIdentity
CIAttributeName
CIAttributeDisplayName
CIUIParameterSet
CIUISetBasic
CIUISetIntermediate
CIUISetAdvanced
CIUISetDevelopment
CIAttributeTypeTime
CIAttributeTypeScalar
CIAttributeTypeDistance
CIAttributeTypeAngle
CIAttributeTypeBoolean
CIAttributeTypeInteger
CIAttributeTypeCount
CIAttributeTypePosition
CIAttributeTypeOffset
CIAttributeTypePosition3
CIAttributeTypeRectangle
CIAttributeTypeColor
CIAttributeTypeOpaqueColor
CIAttributeTypeImage
CIAttributeTypeGradient
CIAttributeTypeTransform
inputDepthImage
inputDisparityImage
inputTransform
inputAspectRatio
inputAngle
inputRefraction
inputEV
inputGradientImage
inputShadingImage
inputTargetImage
__inputVersion
CICategoryDistortionEffect
CICategoryGeometryAdjustment
CICategoryCompositeOperation
CICategoryLightingEffect
CICategoryHalftoneEffect
CICategoryColorAdjustment
CICategoryColorEffect
CICategoryTransition
CICategoryTileEffect
CICategoryGenerator
CICategoryGradient
CICategoryStylize
CICategorySharpen
CICategoryBlur
CICategoryVideo
CICategoryStillImage
CICategoryInterlaced
CICategoryNonSquarePixels
CICategoryHighDynamicRange
CICategoryApplePrivate
CICategoryReduction
CICategoryBuiltIn
CICategoryFilterGenerator
CICategoryXMPSerializable
extent
definition
user_info
color_space
cs_deviceGray
cs_deviceRGB
cs_deviceCMYK
Can't wrap anymore classes without some additional macro magic.
%@ will *not* be wrapped.
wrappedOutputImage%d
No input on filter %@ named %@
inputOriginalFilter
inputOutputImage
CI_ENABLE_FILTER_INTERPOSING
CIFilterAddedNotification
CIConstructorKey
CIAccordionFoldTransition
CIAdditionCompositing
CIAffineClamp
CIAffineTile
CIAppleSmithGossettScale
CIASG50Percent
CIASG60Percent
CIASG66Percent
CIASG75Percent
CIASG80Percent
CIAreaMaximum
CIAreaMaximumAlpha
CIAreaMinimum
CIAreaMinimumAlpha
CIAreaMinMax
CIAreaMinMaxNormalize
CIColumnAverage
CIBicubicScaleTransform
CIRowAverage
CIBarsSwipeTransition
CIBlendWithBlueMask
CIBlendWithAlphaMask
CIBloom
CIBokehBlur
CIBumpDistortion
CIBumpDistortionLinear
CICheatBlur
CICheapBlur
CICheapMorphology
CICheckerboardGenerator
CICircleGenerator
CICircleSplashDistortion
CICircularScreen
CICircularWrap
CIClamp
CIColorAbsoluteDifference
CIColorThreshold
CIColorThresholdOtsu
CIColorBalance
CIColorBlendMode
CIColorBurnBlendMode
CIColorCrossPolynomial
CIColorCubesMixedWithMask
CIColorDodgeBlendMode
CIColorInvert
CIColorMap
CIColorMonochrome
CIColorPolynomial
CIColorPolynomialInverse
CIColorPosterize
CIComicEffect
CIConstantColorGenerator
CIConvolution9Horizontal
CIConvolution9Vertical
CIConvolutionRGB3X3
CIConvolutionRGB5X5
CIConvolutionRGB7X7
CIConvolutionRGB9Horizontal
CIConvolutionRGB9Vertical
CICopyMachineTransition
CICoreMLModelFilter
CICrystallize
CIDarkenBlendMode
CIDepthEffectApplyBlurMap
CIDepthEffectMakeBlurMap
CIDepthOfField
CIDepthToDisparity
CIDifferenceBlendMode
CIDisintegrateWithMaskTransition
CIDisparityRefinement
CIDisparityToDepth
CIDisplacementDistortion
CIDissolveTransition
CIDither
CIDivideBlendMode
CIDotScreen
CIDroste
CIEdges
CIEdgePreserveUpsampleFilter
CIEdgeWork
CIEightfoldReflectedTile
CIExclusionBlendMode
CIFalseColor
CIFlashTransition
CIFourfoldReflectedTile
CIFourfoldRotatedTile
CIFourfoldTranslatedTile
CIGaborGradients
CIGammaAdjust
CIGaussianBlur
CIGaussianGradient
CIGlideReflectedTile
CIGloom
CIGlassDistortion
CIGlassLozenge
CIGuidedFilter
CIHardLightBlendMode
CIHardMixBlendMode
CIHatchedScreen
CIHeightFieldFromMask
CIHexagonalPixellate
CIHistogramDisplayFilter
CIHoleDistortion
CIHueAdjust
CIHueBlendMode
CIHueSaturationValueGradient
CISampleNearest
CIIntegralImage
CIKaleidoscope
CILabDeltaE
CILenticularHaloGenerator
CILightTunnel
CILightenBlendMode
CILinearLightBlendMode
CILineScreen
CILinearBurnBlendMode
CILinearDodgeBlendMode
CILinearGradient
CILuminosityBlendMode
CIMaskToAlpha
CIMaximumComponent
CIMaximumCompositing
CIMedianFilter
CIMeshGenerator
CIMinimumComponent
CIMinimumCompositing
CIMirror
CIMix
CIModTransition
CIMorphologyRectangleMinimum
CIMorphologyRectangleMaximum
CIMorphologyGradient
CIMorphologyLaplacian
CIMotionBlur
CIMultiplyBlendMode
CIMultiplyCompositing
CINinePartStretched
CINinePartTiled
CINoiseReduction
CIOpacity
CIOpTile
CIOverlayBlendMode
CIPaperWash
CIPageCurlTransition
CIPageCurlWithShadowTransition
CIParallelogramTile
CIPercentileRed
CIPerspectiveTile
CIPerspectiveTransform
CIPerspectiveTransformWithExtent
CIPerspectiveCorrection
CIPersonSegmentation
CIPhotoEffectNoir
CIPhotoEffectChrome
CIPhotoEffectFade
CIPhotoEffectInstant
CIPhotoEffectMono
CIPhotoEffectProcess
CIPhotoEffectTonal
CIPhotoEffectTransfer
CIPinLightBlendMode
CIPinchDistortion
CIPixellate
CIPointillize
CIPremultiply
CIProSharpenEdges
CIPseudoMedian
CIRadialGradient
CIRectangleGenerator
CIRippleTransition
CIRingBlur
CIRoundedRectangleGenerator
CISaliencyMapFilter
CISaturationBlendMode
CIScreenBlendMode
CISepiaTone
CIShadedMaterial
CISharpenLuminance
CISixfoldReflectedTile
CISixfoldRotatedTile
CISkyAndGrassAdjust
CISmartColorFilter
CISmartToneFilter
CISmoothLinearGradient
CISpotLight
CISoftLightBlendMode
CISourceAtopCompositing
CISourceInCompositing
CISourceOutCompositing
CISourceOverCompositing
CIStarShineGenerator
CIStraightenFilter
CIStretch
CIStretchCrop
CIStripesGenerator
CISubtractBlendMode
CISunbeamsGenerator
CISwipeTransition
CITemperatureAndTint
CIThermal
CITorusLensDistortion
CITriangleKaleidoscope
CITriangleTile
CITwelvefoldReflectedTile
CITwirlDistortion
CIUnpremultiply
CIVariableBoxBlur
CIVignette
CIVignetteEffect
CIVividLightBlendMode
CIVortexDistortion
CIWhitePointAdjust
CIWrapMirror
CIXRay
CIZoomBlur
CUIScaleClampFilter
CUIOuterBevelEmbossFilter
CUIOuterGlowOrShadowFilter
CUIInnerBevelEmbossFilter
CUIInnerGlowOrShadowFilter
CUIShapeEffectBlur1
CIPlusDarkerCompositing
CIPlusLighterCompositing
CIMaskedVariableBlur
CISmartBlackAndWhite
CIPhotoGrain
CITextImageGenerator
CIAttributedTextImageGenerator
CIKMeans
CIPalettize
CIPaletteCentroid
CIPerspectiveRotate
CIKeystoneCorrectionCombined
CIKeystoneCorrectionHorizontal
CIKeystoneCorrectionVertical
CIMattingSolver
CIFocalPlane
CICameraCalibrationLensCorrection
CIInpaintingFilter
CISingleChannelColorMap
v16@?0@"NSString"8
[CIFilter registerFilterName:constructor:classAttributes:] needs a name parameter.
[CIFilter registerFilterName:constructor:classAttributes:] registration of '%@' should provide a contructor object or class.
[CIFilter registerFilterName:constructor:classAttributes:] registration of '%@' should not provide a contructor class that is just [CIFilter class].
filterWithName:
[CIFilter registerFilterName:constructor:classAttributes:] registration of '%@' needs a constructor object or class that implements filterWithName:
[CIFilter registerFilterName:constructor:classAttributes:] registration of '%@' needs a constructor object or class that overrides filterWithName:
Categories
.description
Descriptions
[CIFilter unregisterFilterName:] needs a name parameter.
http://developer.apple.com/library/ios/documentation/GraphicsImaging/Reference/CoreImageFilterReference/index.html#//apple_ref/doc/filter/ci/%@
Keys
%@.%@
<none>
%@.%@.description
+[CIFilterClassAttributes classAttributesForClass:]
+[CIFilterClassCategories classCategoriesForClass:]
com.apple.coreimage.nscache.CIFilterClassDefaults
+[CIFilterClassInfo classInfoForClass:]
output
<%@: inputKeys=%@ inputClasses=%@ outputKeys=%@>
CI_FILTERS_DIR
/CoreImage
cifilter
CIFilterList
The filter '%@' in %@ has already been registered so this bundle will be ignored.
The filter '%@' in the bundle at %@ has already been registered.
The filter '%@' is not implemented in the bundle at %@.
The filter '%@' in the bundle at %@ is not a subclass of CIFilter so it will not be registered.
com.apple.coreimage.CIFilterRegistryIsolation
customAttributes
%@ -customAttributes is not supported on iOS. Implement +customAttributes instead.
iIsSlLqQBfdcC
NSObject
<CIFilterShape: %p extent [infinite]>
<CIFilterShape: %p extent [empty]>
<CIFilterShape: %p extent [%g %g %g %g]>
inputMaxStriationRadius
inputStriationStrength
inputStriationContrast
inputFadeThreshold
kernel vec4 _flashColor (__sample r1, __sample r0, vec2 center, __color color, __sample noise, vec4 parms, vec2 parms2) 
 vec2 delta = destCoord() - center; 
 float len = length(delta); 
 float len2 = dot(delta,delta); 
 float mask = clamp(1.0 - len * parms.z, 0.0, 1.0); 
 float n = clamp(noise.x, 0.0, noise.a); 
 n = n * parms2.x + parms2.y; 
 vec4 flash = color * parms.y / len2 + n; 
 vec4 r2 = clamp(flash * mask, 0.0, 1.0); 
 r1 = clamp(r1 + r2, 0.0, 1.0); 
 return mix(r1, r0, parms.w); 
kernel vec2 _flashGeom (vec2 center) 
 vec2 delta = destCoord() - center; 
 float len = length(delta); 
 return (delta * 100.0 / len) + vec2(128.0); 
inputZeroShiftPercentile
inputAlphaThreshold
inputAmplitude
inputExponent
inputMinFactor
inputMaxFactor
kernel vec4 _disparityRefinementPreprocessing(__sample disparity,__sample alpha,__sample lm,vec4 config0,vec4 config1) { float alpha_val = alpha.x; float d = disparity.x; float zeroShift = lm.x; float d_factor = clamp( config0.x * exp( -pow(max(0.0001,abs(d - zeroShift)) , config0.y) / config0.z ) , config0.w, config1.x); if ( alpha_val > config1.y ) { d -= (d - zeroShift) * d_factor; } return vec4(d, 0.0, 0.0, 1.0); }
kernel vec4 _disparityRefinementPreprocessingPow2(__sample disparity,__sample alpha,__sample lm,vec4 config0,vec4 config1) { float alpha_val = alpha.x; float d = disparity.x; float zeroShift = lm.x; float v = max(0.0001,abs(d - zeroShift)); float d_factor = clamp( config0.x * exp( -(v*v) / config0.z ) , config0.w, config1.x); if ( alpha_val > config1.y ) { d -= (d - zeroShift) * d_factor; } return vec4(d, 0.0, 0.0, 1.0); }
-[CIGVNode contentInsertSize]
CIGVNode.m
-[CIGVNode contentCornerSize]
<%@: %p, label=%@, color=%d shape=%d>
Menlo-Regular
Courier
-[CGRenderer _colorForNodeColor:]
CIGVRenderer.mm
-[CGRenderer _drawNodeContent:]
%p to %p
Apple, Inc.
digraph %s {
rankdir=BT;
n%p [
style=filled, shape=%s, color=black, fillcolor="%s"
label=<<table border="0" cellborder="0" cellspacing="0">
<tr><td valign='middle'><font face='Menlo'>[%s]</font></td></tr>
<br/>
<tr><td valign='middle' balign='left'><font face='Menlo'>%s</font></td></tr>
</table>>
n%p -> n%p;
#CCCCCCFF
#999999FF
#D3D3D3FF
#FFCCCCFF
#FF9999FF
#CCFFCCFF
#DDFFDDFF
#FFFF99FF
#FFFFCCFF
#CCCCFFFF
#DDDDFFFF
#FFDDFFFF
#CCFFFFFF
#DDFFFFFF
#FF88CCFF
stringForGraphvizColor
rect
hexagon
stringForGraphvizShape
CIBlurmapRefinementDistanceDelta
inputDistance
inputScalingFactor
CIFusionDelta
inputAddBlur
inputRemoveBlur
inputMaxBlur
CIFusionTwoImagesDelta
inputSecondaryImage
inputProtectStrength
_eyeProtectionFaceCalculator
_modifyBlurmap
_combineAllDeltas
-[CIModifyBlurmap outputImage]
CIBlurMapRefinement.m
calculatorKernel
modifyBlurmapKernel
combineAllDeltasKernel
inputEyeProtectionMaxFaces.intValue <= 4
eyeProtectionFaceCalculatorImage
inputPower
kernel vec4 _gaussianReduce4(sampler src, vec4 scale) 
 vec2 d = destCoord() * scale.xy; 
 vec4 q = sample(src, samplerTransform(src, d)); 
 vec4 s = q*0.249105655; 
 vec2 o = vec2(1.95019665)*scale.zw; 
 q = sample(src, samplerTransform(src, d-o)) + sample(src, samplerTransform(src, d+o)); 
 s += q*0.204995265; 
 o = vec2(3.90137021)*scale.zw; 
 q = sample(src, samplerTransform(src, d-o)) + sample(src, samplerTransform(src, d+o)); 
 s += q*0.11422973; 
 o = vec2(5.85840079)*scale.zw; 
 q = sample(src, samplerTransform(src, d-o)) + sample(src, samplerTransform(src, d+o)); 
 s += q*0.0433552031; 
 o = vec2(7.86886245)*scale.zw; 
 q = sample(src, samplerTransform(src, d-o)) + sample(src, samplerTransform(src, d+o)); 
 s += q*0.0128669748; 
 return s; 
kernel vec4 _gaussianReduce2(sampler src, vec4 scale) 
 vec2 d = destCoord() * scale.xy; 
 vec2 o1 = vec2(1.84623909)*scale.zw; 
 vec2 o2 = vec2(3.74518052)*scale.zw; 
 vec4 q1 = sample(src, samplerTransform(src, d - o2)); 
 vec4 q2 = sample(src, samplerTransform(src, d - o1)); 
 vec4 q3 = sample(src, samplerTransform(src, d)); 
 q2 += sample(src, samplerTransform(src, d + o1)); 
 q1 += sample(src, samplerTransform(src, d + o2)); 
 return 0.432290834*q3 + 0.24061645*q2 + 0.0432381327*q1; 
kernel vec4 _gaussianBlur19(sampler src, vec4 offset01, vec4 offset23, vec2 offset4, vec4 weight, vec2 weight2) 
 vec2 d = destCoord(); 
 vec4 q0 = sample(src, samplerTransform(src, d - offset4.xy)); 
 vec4 q1 = sample(src, samplerTransform(src, d - offset23.zw)); 
 vec4 q2 = sample(src, samplerTransform(src, d - offset23.xy)); 
 vec4 q3 = sample(src, samplerTransform(src, d - offset01.zw)); 
 vec4 q4 = sample(src, samplerTransform(src, d - offset01.xy)); 
 vec4 q5 = sample(src, samplerTransform(src, d + offset01.xy)); 
 vec4 q6 = sample(src, samplerTransform(src, d + offset01.zw)); 
 vec4 q7 = sample(src, samplerTransform(src, d + offset23.xy)); 
 vec4 q8 = sample(src, samplerTransform(src, d + offset23.zw)); 
 vec4 q9 = sample(src, samplerTransform(src, d + offset4.xy)); 
 return weight.x*(q4+q5) + weight.y*(q3+q6) + weight.z*(q2+q7) + weight.w*(q1+q8) + weight2.x*(q0+q9); 
kernel vec4 _gaussianBlur15(sampler src, vec4 offset01, vec4 offset23, vec4 weight) 
 vec2 d = destCoord(); 
 vec4 q0 = sample(src, samplerTransform(src, d - offset23.zw)); 
 vec4 q1 = sample(src, samplerTransform(src, d - offset23.xy)); 
 vec4 q2 = sample(src, samplerTransform(src, d - offset01.zw)); 
 vec4 q3 = sample(src, samplerTransform(src, d - offset01.xy)); 
 vec4 q4 = sample(src, samplerTransform(src, d + offset01.xy)); 
 vec4 q5 = sample(src, samplerTransform(src, d + offset01.zw)); 
 vec4 q6 = sample(src, samplerTransform(src, d + offset23.xy)); 
 vec4 q7 = sample(src, samplerTransform(src, d + offset23.zw)); 
 return weight.x*(q3+q4) + weight.y*(q2+q5) + weight.z*(q1+q6) + weight.w*(q0+q7); 
kernel vec4 _gaussianBlur13 (sampler image, vec2 delta, vec4 w, vec4 w2) 
 vec2 sc = samplerCoord(image); 
 vec2 del = samplerTransform(image, destCoord() + delta) - sc; 
 vec4 sum = vec4(0.0); 
 sum += sample(image, sc - del*6.0) * w2.z; 
 sum += sample(image, sc + del*6.0) * w2.z; 
 sum += sample(image, sc - del*5.0) * w2.y; 
 sum += sample(image, sc + del*5.0) * w2.y; 
 sum += sample(image, sc - del*4.0) * w2.x; 
 sum += sample(image, sc + del*4.0) * w2.x; 
 sum += sample(image, sc - del*3.0) * w.w; 
 sum += sample(image, sc + del*3.0) * w.w; 
 sum += sample(image, sc - del*2.0) * w.z; 
 sum += sample(image, sc + del*2.0) * w.z; 
 sum += sample(image, sc - del ) * w.y; 
 sum += sample(image, sc + del ) * w.y; 
 sum += sample(image, sc ) * w.x; 
 return sum; 
kernel vec4 _gaussianBlur11(sampler src, vec4 offset01, vec4 offset2, vec4 weight) 
 vec2 d = destCoord(); 
 vec4 q1 = sample(src, samplerTransform(src, d - offset2.xy)); 
 vec4 q2 = sample(src, samplerTransform(src, d - offset01.zw)); 
 vec4 q3 = sample(src, samplerTransform(src, d - offset01.xy)); 
 vec4 q4 = sample(src, samplerTransform(src, d + offset01.xy)); 
 vec4 q5 = sample(src, samplerTransform(src, d + offset01.zw)); 
 vec4 q6 = sample(src, samplerTransform(src, d + offset2.xy)); 
 return weight.x*(q3+q4) + weight.y*(q2+q5) + weight.z*(q1+q6); 
kernel vec4 _gaussianBlur9 (sampler image, vec2 delta, vec4 w) 
 vec2 sc = samplerCoord(image); 
 vec2 del = samplerTransform(image, destCoord() + delta) - sc; 
 vec4 sum = vec4(0.0); 
 float wLast = 0.5 - (w.x*0.5 + w.y + w.z + w.w); 
 sum += sample(image, sc - del*4.0) * wLast; 
 sum += sample(image, sc + del*4.0) * wLast; 
 sum += sample(image, sc - del*3.0) * w.w; 
 sum += sample(image, sc + del*3.0) * w.w; 
 sum += sample(image, sc - del*2.0) * w.z; 
 sum += sample(image, sc + del*2.0) * w.z; 
 sum += sample(image, sc - del ) * w.y; 
 sum += sample(image, sc + del ) * w.y; 
 sum += sample(image, sc ) * w.x; 
 return sum; 
kernel vec4 _gaussianBlur7(sampler src, vec4 offset01, vec2 weight) 
 vec2 d = destCoord(); 
 vec4 q2 = sample(src, samplerTransform(src, d - offset01.zw)); 
 vec4 q3 = sample(src, samplerTransform(src, d - offset01.xy)); 
 vec4 q4 = sample(src, samplerTransform(src, d + offset01.xy)); 
 vec4 q5 = sample(src, samplerTransform(src, d + offset01.zw)); 
 return weight.x*(q3+q4) + weight.y*(q2+q5); 
kernel vec4 _gaussianBlur5 (sampler image, vec2 delta, vec4 w) 
 vec2 sc = samplerCoord(image); 
 vec2 del = samplerTransform(image, destCoord() + delta) - sc; 
 vec4 sum = vec4(0.0); 
 sum += sample(image, sc - del*2.0) * w.z; 
 sum += sample(image, sc + del*2.0) * w.z; 
 sum += sample(image, sc - del ) * w.y; 
 sum += sample(image, sc + del ) * w.y; 
 sum += sample(image, sc ) * w.x; 
 return sum; 
kernel vec4 _gaussianBlur3(sampler src, vec4 offset0) 
 vec2 d = destCoord(); 
 return (sample(src, samplerTransform(src, d - offset0.xy)) + sample(src, samplerTransform(src, d + offset0.xy))) * 0.5; 
_shader
_roiMethods
_insetRects
_scaleFactors
_class
shader name not specified.
_regions
couldn't find data for %@
don't know how to decode value for %@
read write texture unexpected.
Couldn't find texture at index %lu with name %@
halfInput
roiForInput:arguments:outputRect:
inputTexture
kernel vec4 _glassDistort (sampler tex0, sampler tex1, 
 vec2 scale_plus_unit, vec2 off0, vec2 off1, 
 vec2 off2, vec2 unit_to_glass, float height_factor) 
 vec2 dc = destCoord(); 
 vec2 dcscaled = dc * scale_plus_unit; 
 vec2 t0g = fract(dcscaled + off0) * unit_to_glass + vec2(.5); 
 vec2 t1g = fract(dcscaled + off1) * unit_to_glass + vec2(.5); 
 vec2 t2g = fract(dcscaled + off2) * unit_to_glass + vec2(.5); 
 float tcen = sample(tex1, samplerTransform(tex1, t0g)).r; 
 float tdx = sample(tex1, samplerTransform(tex1, t1g)).r; 
 float tdy = sample(tex1, samplerTransform(tex1, t2g)).r; 
 vec2 p = dc + vec2(tdx-tcen, tdy-tcen) * height_factor; 
 return sample(tex0, samplerTransform(tex0, p)); 
kernel vec4 _radialGradient (vec4 params, __color c0, __color c1) 
 highp float t = distance(destCoord(),params.xy) * params.z + params.w; 
 return mix(c0, c1, clamp(t, 0.0, 1.0)); 
inputRadius0
inputRadius1
kernel vec4 _linearGradient (vec2 p0, vec2 p1, __color c0, __color c1, float d1Inv) 
 highp float t = dot(p1 - p0, destCoord() - p0) * d1Inv; 
 return mix(c0, c1, clamp(t, 0.0, 1.0)); 
kernel vec4 _smoothLinearGradient (vec2 p0, vec2 p1, __color c0, __color c1, float d1Inv) 
 highp float t = dot(p1 - p0, destCoord() - p0) * d1Inv; 
 return mix(c0, c1, smoothstep(0.0, 1.0, t)); 
kernel vec4 _gaussianGradient (vec3 params, __color c0, __color c1) 
 highp float d = min(distance(destCoord(), params.xy) * params.z, 1.0); 
 d = (d * -2.0 + 3.0) * d * d; 
 return mix(c0, c1, d); 
kernel vec4 _hsvwheel (vec4 params) 
 float value = params.x; 
 float radius = params.y; 
 float invradius = params.z; 
 float smoothness = params.w; 
 vec2 p = destCoord() - vec2(radius); 
 float len = length(p); 
 float H = atan(p.y,p.x) * 3.0 / 3.1415926; 
 H = p.x == 0.0 ? p.y > 0.0 ? 1.5 : -1.5 : H; float S = clamp(len * invradius, 0.0, 1.0); 
 vec4 c = vec4(H, H-2.0, H+2.0, 0.0); 
 c = clamp(abs(3.0-abs(c))-1.0, 0.0, 1.0); 
 c = mix(c, smoothstep(0.0,1.0,c), smoothness); 
 c = mix(vec4(1.0), c, S); 
 c.a = 1.0; 
 c.rgb *= value; 
 return c * clamp(radius - len, 0.0, 1.0); 
float __noise(float seed, vec2 dc) 
 float x = (13.0*dc.x + 1111.0)/(17.0 + seed); 
 float y = (11.0*dc.y + 7777.0)/(19.0 - seed); 
 float m = 37.0; 
 float n = x; 
 n = mod(y*n + y, m); 
 n = mod(y*n + x, m); 
 n = mod(x*n, m); 
 n = mod(x*n, m); 
 return n/m; 
 kernel vec4 _hsvwheeldithered (vec4 params, float dither) 
 float value = params.x; 
 float radius = params.y; 
 float invradius = params.z; 
 float smoothness = params.w; 
 vec2 p = destCoord() - vec2(radius); 
 float len = length(p); 
 float H = atan(p.y,p.x) * 3.0 / 3.1415926; 
 H = p.x == 0.0 ? p.y > 0.0 ? 1.5 : -1.5 : H; float S = clamp(len * invradius, 0.0, 1.0); 
 vec4 c = vec4(H, H-2.0, H+2.0, 0.0); 
 c = clamp(abs(3.0-abs(c))-1.0, 0.0, 1.0); 
 c = mix(c, smoothstep(0.0,1.0,c), smoothness); 
 c = mix(vec4(1.0), c, S); 
 c.a = 1.0; 
 c.rgb *= value; 
 c.rgb += (__noise(0.0, floor(destCoord())) - 0.5)*dither; 
 return c * clamp(radius - len, 0.0, 1.0); 
+[CIHueSaturationValueGradient customAttributes]
CIGradient.mm
inputValue
GVGraph
GraphVisualizer is not available.
CIGVDumpToFile
CIGraphviz.m
CI Render Graph
inputEpsilon
kernel vec4 _boxFilter3(sampler a) __attribute__((outputFormat(kCIFormatRGBAf)))
{ vec2 dc = destCoord(); 
  vec4 v0 = sample(a, samplerTransform(a, dc + vec2(-0.5, +0.5))) * (4.0/9.0); 
  vec4 v1 = sample(a, samplerTransform(a, dc + vec2( 1.0,  0.5))) * (2.0/9.0); 
  vec4 v2 = sample(a, samplerTransform(a, dc + vec2(-0.5, -1.0))) * (2.0/9.0); 
  vec4 v3 = sample(a, samplerTransform(a, dc + vec2( 1.0, -1.0))) * (1.0/9.0); 
  return (v0 + v1 + v2 + v3); 
kernel vec4 _multiplyImages(__sample a,__sample b) __attribute__((outputFormat(kCIFormatRGBAf)))  { return a * b; }
kernel vec4 _subtractImages(__sample a,__sample b) { return a - b; }
kernel vec4 _computeAB(__sample var_I_A,__sample var_I_B,__sample cov_Ip,__sample meanIP,float eps) 
var_I_A.x  += eps; 
var_I_B.xz += eps; 
vec2 r1r2    = var_I_A.yz / var_I_A.xx;
var_I_B.xyz -= r1r2.xxy * var_I_A.yzz;
cov_Ip.yz   -= r1r2     * cov_Ip.xx;
r1r2.x     = var_I_B.y / var_I_B.x;
var_I_B.z -= r1r2.x * var_I_B.y;
cov_Ip.z  -= r1r2.x * cov_Ip.y;
cov_Ip.z  /= var_I_B.z;
cov_Ip.y   = (cov_Ip.y - var_I_B.y * cov_Ip.z) / var_I_B.x;
cov_Ip.x   = (cov_Ip.x - var_I_A.y * cov_Ip.y - var_I_A.z * cov_Ip.z) / var_I_A.x;
cov_Ip.w   = meanIP.w - dot(cov_Ip.xyz, meanIP.xyz);
return cov_Ip;
kernel vec4 _finalResult(__sample ab,__sample I) 
  float v = dot(ab.rgb, I.rgb) + ab.w;
  return vec4(v,v,v,1.0);
kernel vec4 _combineRGB_and_A(__sample a,__sample b) 
{ return vec4(a.xyz, b.r);  }
kernel vec4 _swizzleXXX1(__sample a) { return vec4(a.xxx,1.0); } 
kernel vec4 _swizzleYYZ1(__sample a) { return vec4(a.yyz,1.0); } 
kernel vec4 _swizzleYZZ1(__sample a) { return vec4(a.yzz,1.0); } 
kernel vec4 _dotscreen (__sample s, vec3 params, vec4 mtx) 
 vec2 pt = destCoord() - params.xy; 
 pt = vec2(dot(pt, mtx.xy), dot(pt, mtx.zw)); 
 pt = fract(pt + params.xy) * 6.2831853; 
 float g = (sin(pt.x) + sin(pt.y)) * 0.25 * (0.995 - 1.0 / params.z) + 0.5; 
 float l = dot(s.rgb, vec3(0.2125, 0.7154, 0.0721)); 
 s.rgb = vec3(clamp((l - g) * params.z + 0.5, 0.0, 1.0) * s.a); 
 return s; 
kernel vec4 _hatchedscreen (__sample s, vec3 params, vec4 mtx) 
 vec2 pt = destCoord() - params.xy; 
 pt = vec2(dot(pt, mtx.xy), dot(pt, mtx.zw)); 
 pt = fract(pt.xy + params.xy); 
 pt = min(vec2(1.0) - pt, pt) * 2.0; 
 float g = min(pt.x, pt.y * .5 + .5); 
 float l = dot(s.xyz, vec3(.2125, .7154, .0721)); 
 s.rgb = vec3(clamp((l - g) * params.z + 0.5, 0.0, 1.0) * s.a); 
 return s; 
kernel vec4 _linescreen (__sample s, vec3 params, vec4 mtx) 
 vec2 pt = destCoord() - params.xy; 
 pt = vec2(dot(pt, mtx.xy), dot(pt, mtx.zw)); 
 pt = fract(pt.xy + params.xy); 
 float g = min(1.0 - pt.x, pt.x) * 2.0; 
 float l = dot(s.xyz, vec3(.2125, .7154, .0721)); 
 s.rgb = vec3(clamp((l - g) * params.z + 0.5, 0.0, 1.0) * s.a); 
 return s; 
kernel vec4 _circularscreen (__sample s, vec4 params) 
 float d = length(destCoord() - params.xy); 
 d = fract(d * params.z); 
 d = min(1.0 - d, d); 
 d = dot(s.rgb, vec3(.2125, .7154, .0721)) - d * 2.0; 
 d = clamp(d * params.w + .5, 0.0, 1.0); 
 s.rgb = vec3(d) * s.a; 
 return s; 
kernel vec4 _resetalpha(__sample src, __sample mask) 
 src.a = mask.a; 
 return src; 
10.7
inputShadowAmount
inputHighlightAmount
kernel vec4 _highlightsAndShadows2(__sample pix, __sample blur, vec4 params) 
 float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max( 0.001, pix.r + pix.g + pix.b); 
 float shadAmt = params.x * pow(min(rgbFactor, 1.0), 1.0-params.x); 
 vec3 shadExp = mix(pow(vec3(2.0), (-shadAmt - blur.rgb)), vec3(1.0), params.z); 
 float blurLum2 = max(0.0, max(max(blur.r, blur.g), blur.b)); 
 float blurLum = sqrt(blurLum2); 
 float kGain = 0.5 + 0.5*smoothstep(0.5, 1.0, params.x); 
 float newGain = shadAmt; 
 vec3 neg = min(pix.rgb, 0.0); 
 vec3 shad = (1.0+newGain)*pow(max(pix.rgb, 0.0)*kGain, shadExp)*2.0; 
 vec3 ycc = pix.r * vec3(0.299, 0.596, 0.212) + 
 pix.g * vec3(0.587, -0.2755, -0.523) + 
 pix.b * vec3(0.114, -0.321, 0.311); 
 float Y = pow(max(ycc.r, 0.0)*kGain, shadExp.r)*2.0; 
 vec3 shad2 = Y * vec3(1.00048, 0.999864, 0.999446) + 
 ycc.g * vec3(0.955558, -0.271545, -1.10803) + 
 ycc.b * vec3(0.619549, -0.646786, 1.70542); 
 shad = mix(shad, shad2, 0.35); 
 shad = mix(pix.rgb, shad, (smoothstep(0.0, 0.1+shadAmt, sqrt(blurLum)))); 
 shad = mix(shad, pix.rgb, blurLum); 
 vec3 high = sign(pix.rgb)*pow(abs(pix.rgb)*params.w, vec3((2.0 - params.y))); 
 Y = dot(high, vec3(0.299, 0.587, 0.114)); 
 float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
 float kHighMix = 1.0 + (1.0-min(1.0, params.y+0.3))*0.4; 
 vec3 mid = mix(vec3(0.25), high, kHighMix); 
 float highBoost = min(effectAmount, 30.0*blurLum2) * (1.0-params.y); 
 high = mix(high, mid, highBoost); 
 high = mix(pix.rgb, high, smoothstep(0.2, 0.8, blurLum)); 
 high = mix(pix.rgb, high, blurLum2); 
 vec4 result; 
 result.rgb = mix(shad, high, min(blurLum, 1.0)); 
 Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
 effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
 float midAmt = abs(shadAmt)*0.1*(1.0-params.z); 
 mid = mix(vec3(0.5), result.rgb, 1.0 + midAmt); 
 result.rgb = mix(result.rgb, mid, min(effectAmount, 30.0*blurLum2)); 
 result.rgb = max(result.rgb, 0.0)+neg; 
 result.a = pix.a; 
 return result; 
kernel vec4 _highlightsAndShadows_noblur2(__sample pix, vec4 params) 
 vec4 blur = pix; 
 float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max( 0.001, pix.r + pix.g + pix.b); 
 float shadAmt = params.x * pow(min(rgbFactor, 1.0), 1.0-params.x); 
 vec3 shadExp = mix(pow(vec3(2.0), (-shadAmt - blur.rgb)), vec3(1.0), params.z); 
 float blurLum2 = max(0.0, max(max(blur.r, blur.g), blur.b)); 
 float blurLum = sqrt(blurLum2); 
 float kGain = 0.5 + 0.5*smoothstep(0.5, 1.0, params.x); 
 float newGain = shadAmt; 
 vec3 neg = min(pix.rgb, 0.0); 
 vec3 shad = (1.0+newGain)*pow(max(pix.rgb, 0.0)*kGain, shadExp)*2.0; 
 vec3 ycc = pix.r * vec3(0.299, 0.596, 0.212) + 
 pix.g * vec3(0.587, -0.2755, -0.523) + 
 pix.b * vec3(0.114, -0.321, 0.311); 
 float Y = sign(ycc.r)*pow(abs(ycc.r)*kGain, shadExp.r)*2.0; 
 vec3 shad2 = Y * vec3(1.00048, 0.999864, 0.999446) + 
 ycc.g * vec3(0.955558, -0.271545, -1.10803) + 
 ycc.b * vec3(0.619549, -0.646786, 1.70542); 
 shad = mix(shad, shad2, 0.35); 
 shad = mix(pix.rgb, shad, (smoothstep(0.0, 0.1+shadAmt, sqrt(blurLum)))); 
 shad = mix(shad, pix.rgb, blurLum); 
 vec3 high = sign(pix.rgb)*pow(abs(pix.rgb)*params.w, vec3((2.0 - params.y))); 
 Y = dot(high, vec3(0.299, 0.587, 0.114)); 
 float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
 float kHighMix = 1.0 + (1.0-min(1.0, params.y+0.3))*0.4; 
 vec3 mid = mix(vec3(0.25), high, kHighMix); 
 float highBoost = min(effectAmount, 30.0*blurLum2) * (1.0-params.y); 
 high = mix(high, mid, highBoost); 
 high = mix(pix.rgb, high, smoothstep(0.2, 0.8, blurLum)); 
 high = mix(pix.rgb, high, blurLum2); 
 vec4 result; 
 result.rgb = mix(shad, high, min(blurLum, 1.0)); 
 Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
 effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
 float midAmt = abs(shadAmt)*0.1*(1.0-params.z); 
 mid = mix(vec3(0.5), result.rgb, 1.0 + midAmt); 
 result.rgb = mix(result.rgb, mid, min(effectAmount, 30.0*blurLum2)); 
 result.rgb = max(result.rgb, 0.0)+neg; 
 result.a = pix.a; 
 return result; 
kernel vec4 _highlightsAndShadows1(__sample pix, __sample blur, vec4 params)
 float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max( 0.001, pix.r + pix.g + pix.b); 
 float shadAmt = params.x * pow(min(rgbFactor, 1.0), 1.0-params.x); 
 vec3 shadExp = mix(pow(vec3(2.0), (-shadAmt - blur.rgb)), vec3(1.0), params.z); 
 float blurLum2 = max(0.0, max(max(blur.r, blur.g), blur.b)); 
 float blurLum = sqrt(blurLum2); 
 float kGain = 0.5 + 0.5*smoothstep(0.5, 1.0, params.x); 
 vec3 shad = sign(pix.rgb)*pow(abs(pix.rgb)*kGain, shadExp)*2.0; 
 vec3 ycc = pix.r * vec3(0.299, 0.596, 0.212) + 
 pix.g * vec3(0.587, -0.2755, -0.523) + 
 pix.b * vec3(0.114, -0.321, 0.311); 
 float Y = sign(ycc.r)*pow(abs(ycc.r)*kGain, shadExp.r)*2.0; 
 vec3 shad2 = Y * vec3(1.00048, 0.999864, 0.999446) + 
 ycc.g * vec3(0.955558, -0.271545, -1.10803) + 
 ycc.b * vec3(0.619549, -0.646786, 1.70542); 
 shad = mix(shad, shad2, 0.35); 
 shad = mix(pix.rgb, shad, sqrt(smoothstep(0.0, 0.1+shadAmt, sqrt(blurLum)))); 
 shad = mix(shad, pix.rgb, blurLum); 
 vec3 high = sign(pix.rgb)*pow(abs(pix.rgb)*params.w, vec3((2.0 - params.y))); 
 Y = dot(high, vec3(0.299, 0.587, 0.114)); 
 float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
 float kHighMix = 1.0 + (1.0-min(1.0, params.y+0.3))*0.4; 
 vec3 mid = mix(vec3(0.25), high, kHighMix); 
 float highBoost = min(effectAmount, 30.0*blurLum2) * (1.0-params.y); 
 high = mix(high, mid, highBoost); 
 high = mix(pix.rgb, high, smoothstep(0.2, 0.8, blurLum)); 
 high = mix(pix.rgb, high, blurLum2); 
 vec4 result; 
 result.rgb = mix(shad, high, min(blurLum, 1.0)); 
 Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
 effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
 float midAmt = abs(shadAmt)*0.1*(1.0-params.z); 
 mid = mix(vec3(0.5), result.rgb, 1.0 + midAmt); 
 result.rgb = mix(result.rgb, mid, min(effectAmount, 30.0*blurLum2)); 
 result.a = pix.a; 
 return result; 
kernel vec4 _highlightsAndShadows_noblur1(__sample pix, vec4 params) 
 vec4 blur = pix; 
 float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max( 0.001, pix.r + pix.g + pix.b); 
 float shadAmt = params.x * pow(min(rgbFactor, 1.0), 1.0-params.x); 
 vec3 shadExp = mix(pow(vec3(2.0), (-shadAmt - blur.rgb)), vec3(1.0), params.z); 
 float blurLum2 = max(0.0, max(max(blur.r, blur.g), blur.b)); 
 float blurLum = sqrt(blurLum2); 
 float kGain = 0.5 + 0.5*smoothstep(0.5, 1.0, params.x); 
 vec3 shad = sign(pix.rgb)*pow(abs(pix.rgb)*kGain, shadExp)*2.0; 
 vec3 ycc = pix.r * vec3(0.299, 0.596, 0.212) + 
 pix.g * vec3(0.587, -0.2755, -0.523) + 
 pix.b * vec3(0.114, -0.321, 0.311); 
 float Y = sign(ycc.r)*pow(abs(ycc.r)*kGain, shadExp.r)*2.0; 
 vec3 shad2 = Y * vec3(1.00048, 0.999864, 0.999446) + 
 ycc.g * vec3(0.955558, -0.271545, -1.10803) + 
 ycc.b * vec3(0.619549, -0.646786, 1.70542); 
 shad = mix(shad, shad2, 0.35); 
 shad = mix(pix.rgb, shad, sqrt(smoothstep(0.0, 0.1+shadAmt, sqrt(blurLum)))); 
 shad = mix(shad, pix.rgb, blurLum); 
 vec3 high = sign(pix.rgb)*pow(abs(pix.rgb)*params.w, vec3((2.0 - params.y))); 
 Y = dot(high, vec3(0.299, 0.587, 0.114)); 
 float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
 float kHighMix = 1.0 + (1.0-min(1.0, params.y+0.3))*0.4; 
 vec3 mid = mix(vec3(0.25), high, kHighMix); 
 float highBoost = min(effectAmount, 30.0*blurLum2) * (1.0-params.y); 
 high = mix(high, mid, highBoost); 
 high = mix(pix.rgb, high, smoothstep(0.2, 0.8, blurLum)); 
 high = mix(pix.rgb, high, blurLum2); 
 vec4 result; 
 result.rgb = mix(shad, high, min(blurLum, 1.0)); 
 Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
 effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
 float midAmt = abs(shadAmt)*0.1*(1.0-params.z); 
 mid = mix(vec3(0.5), result.rgb, 1.0 + midAmt); 
 result.rgb = mix(result.rgb, mid, min(effectAmount, 30.0*blurLum2)); 
 result.a = pix.a; 
 return result; 
kernel vec4 _highlightsAndShadows0(__sample pix, __sample blur, vec4 params) 
 float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max(0.001, pix.r + pix.g + pix.b); 
 rgbFactor = clamp(rgbFactor, 0.0, 1.0); 
 float shadAmt = params.x * pow(rgbFactor, max(0.0,(1.0-params.x))); 
 vec3 clamped = clamp(pix.rgb, 0.00001, 0.99999); 
 float gray = (clamped.r + clamped.g + clamped.b) * 0.33333; 
 float gi = 1.0 / gray; 
 float gii = 1.0 / (1.0 - gray); 
 float rgbsat = max((clamped.r - gray) * gii, (gray - clamped.r) * gi); 
 float skin = min(1.0, max(0.0, min(clamped.r - clamped.g, clamped.g * 2.0 - clamped.b)) * 4.0 * (1.0 - rgbsat) * gi); 
 skin = 0.15 + skin * 0.7; 
 vec3 rgbExp = pow(vec3(2.0), (-shadAmt - blur.rgb)); 
 float uniformExp = min(rgbExp.r, min(rgbExp.g, rgbExp.b)); 
 vec3 shadExp = mix(rgbExp, vec3(uniformExp), skin); 
 float nopMix = params.z; 
 shadExp = mix(shadExp, vec3(1.0, 1.0, 1.0), nopMix); 
 vec3 shad = sign(pix.rgb)*pow(abs(pix.rgb)*0.5, shadExp)*2.0; 
 float maxChan = max(0.0, max(max(blur.r, blur.g), blur.b)); 
 float blurLum = sqrt(maxChan); 
 float origPercent = sqrt( smoothstep(0.0, 0.1 + 0.5*shadAmt*shadAmt, blurLum) ); 
 origPercent *= (1.0-origPercent); 
 shad = mix(shad, pix.rgb, origPercent); 
 vec3 high = sign(pix.rgb)*pow(abs(pix.rgb)*params.w, vec3((2.0 - params.y))); 
 origPercent = 1.0 - smoothstep(0.2, 0.8, blurLum); 
 high = mix(high, pix.rgb, origPercent); 
 vec4 result; 
 result.rgb = mix(shad, high, blurLum); 
 float Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
 float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
 vec3 mid = mix(vec3(0.5), result.rgb, 1.0 + abs(shadAmt)*0.05); 
 result.rgb = mix(result.rgb, mid.rgb, min(effectAmount, 30.0*blurLum*blurLum)); 
 result.a = pix.a; 
 return result; 
kernel vec4 _highlightsAndShadows_noblur0(__sample pix, vec4 params) 
 vec4 blur = pix; 
 float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max(0.001, pix.r + pix.g + pix.b); 
 rgbFactor = clamp(rgbFactor, 0.0, 1.0); 
 float shadAmt = params.x * pow(rgbFactor, max(0.0,(1.0-params.x))); 
 vec3 clamped = clamp(pix.rgb, 0.00001, 0.99999); 
 float gray = (clamped.r + clamped.g + clamped.b) * 0.33333; 
 float gi = 1.0 / gray;
 float gii = 1.0 / (1.0 - gray);
 float rgbsat = max((clamped.r - gray) * gii, (gray - clamped.r) * gi); 
 float skin = min(1.0, max(0.0, min(clamped.r - clamped.g, clamped.g * 2.0 - clamped.b)) * 4.0 * (1.0 - rgbsat) * gi); 
 skin = 0.15 + skin * 0.7; 
 vec3 rgbExp = pow(vec3(2.0), (-shadAmt - blur.rgb)); 
 float uniformExp = min(rgbExp.r, min(rgbExp.g, rgbExp.b)); 
 vec3 shadExp = mix(rgbExp, vec3(uniformExp), skin); 
 float nopMix = params.z; 
 shadExp = mix(shadExp, vec3(1.0, 1.0, 1.0), nopMix); 
 vec3 shad = sign(pix.rgb)*pow(abs(pix.rgb)*0.5, shadExp)*2.0; 
 float maxChan = max(0.0, max(max(blur.r, blur.g), blur.b)); 
 float blurLum = sqrt(maxChan); 
 float origPercent = sqrt( smoothstep(0.0, 0.1 + 0.5*shadAmt*shadAmt, blurLum) ); 
 origPercent *= (1.0-origPercent); 
 shad = mix(shad, pix.rgb, origPercent); 
 vec3 high = sign(pix.rgb)*pow(abs(pix.rgb)*params.w, vec3((2.0 - params.y))); 
 origPercent = 1.0 - smoothstep(0.2, 0.8, blurLum); 
 high = mix(high, pix.rgb, origPercent); 
 vec4 result; 
 result.rgb = mix(shad, high, blurLum); 
 float Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
 float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
 vec3 mid = mix(vec3(0.5), result.rgb, 1.0 + abs(shadAmt)*0.05); 
 result.rgb = mix(result.rgb, mid.rgb, min(effectAmount, 30.0*blurLum*blurLum)); 
 result.a = pix.a; 
 return result; 
kernel vec4 _shadows_noblur(__sample pix, vec4 params) 
 vec4 blur = pix; 
 float rgbFactor = dot(vec3(1.0, 0.8, 1.1), max(pix.rgb, 0.0)) / max(0.001, pix.r + pix.g + pix.b); 
 rgbFactor = clamp(rgbFactor, 0.0, 1.0); 
 float shadAmt = params.x * pow(rgbFactor, max(0.0,(1.0-params.x))); 
 vec3 clamped = clamp(pix.rgb, 0.00001, 0.99999); 
 float gray = (clamped.r + clamped.g + clamped.b) * 0.33333; 
 float gi = 1.0 / gray; 
 float gii = 1.0 / (1.0 - gray); 
 float rgbsat = max((clamped.r - gray) * gii, (gray - clamped.r) * gi); 
 float skin = min(1.0, max(0.0, min(clamped.r - clamped.g, clamped.g * 2.0 - clamped.b)) * 4.0 * (1.0 - rgbsat) * gi); 
 skin = 0.15 + skin * 0.7; 
 vec3 rgbExp = pow(vec3(2.0), (-shadAmt - blur.rgb)); 
 float uniformExp = min(rgbExp.r, min(rgbExp.g, rgbExp.b)); 
 vec3 shadExp = mix(rgbExp, vec3(uniformExp), skin); 
 float nopMix = params.z; 
 shadExp = mix(shadExp, vec3(1.0, 1.0, 1.0), nopMix); 
 vec3 shad = sign(pix.rgb)*pow(abs(pix.rgb)*0.5, shadExp)*2.0; 
 float maxChan = max(0.0, max(max(blur.r, blur.g), blur.b)); 
 float blurLum = sqrt(maxChan); 
 float origPercent = sqrt( smoothstep(0.0, 0.1 + 0.5*shadAmt*shadAmt, blurLum) ); 
 origPercent *= (1.0-origPercent); 
 shad = mix(shad, pix.rgb, origPercent); 
 vec4 result; 
 result.rgb = mix(shad, pix.rgb, blurLum); 
 float Y = dot(result.rgb, vec3(0.299, 0.587, 0.114)); 
 float effectAmount = max(max(-2.6*Y*Y - 2.6*Y + 0.98, -6.25*Y*Y - 6.25*Y + 0.5965), 1.0); 
 vec3 mid = mix(vec3(0.5), result.rgb, 1.0 + abs(shadAmt)*0.05); 
 result.rgb = mix(result.rgb, mid.rgb, min(effectAmount, 30.0*blurLum*blurLum)); 
 result.a = pix.a; 
 return result; 
Highlights
FillLight
10.?
inputLowLimit
inputHighLimit
kernel vec4 _histogram_display (sampler image, float height, vec2 hilo) 
 vec2 d = destCoord(); 
 vec2 histcoord = vec2(floor(d.x)+0.5, 0.5); 
 vec4 v = sample(image, samplerTransform(image, histcoord)); 
 v = step(vec4(d.y), height*v); 
 float vi = v.r*4.0 + v.g*2.0 + v.b; 
 vec4 p = vec4(.25,.25,.25,1.0); 
 p = (vi==4.0) ? vec4(.50,.05,.05,1.0) : p; 
 p = (vi==6.0) ? vec4(.20,.40,.05,1.0) : p; 
 p = (vi==2.0) ? vec4(.05,.50,.05,1.0) : p; 
 p = (vi==3.0) ? vec4(.05,.20,.40,1.0) : p; 
 p = (vi==1.0) ? vec4(.05,.05,.50,1.0) : p; 
 p = (vi==5.0) ? vec4(.20,.05,.40,1.0) : p; 
 p = (vi==7.0) ? vec4(.05,.10,.30,1.0) : p; 
 p.rgb = (d.x<hilo.x+0.5) ? p.rgb*vec3(0.4) : p.rgb; 
 p.rgb = (d.x>=hilo.y+0.5) ? p.rgb*vec3(0.6) + vec3(0.4) : p.rgb; 
 return p; 
kernel vec2 _holeDistortion (vec2 center, float radius2) 
 vec2 delta = destCoord() - center; 
 float dist2 = dot(delta,delta); 
 return (dist2 <= radius2) ? center : (destCoord() - delta * radius2 / dist2); 
kernel vec4 _holeAntialias(__sample src, vec2 center, float radius) 
 return src * clamp(length(destCoord() - center) - radius, 0.0, 1.0); 
CIImageFlipped
CIImagePremultiplied
opaque
CIImageColorSpace
kCIImageToneMapHDRtoSDR
CIImageEdgesAreClear
CIImageProperties
kCIImageApplyOrientationProperty
CIImageClampToEdge
CIImageNearestSampling
CIImageEdgeRepeat
kCIImageAlphaOne
kCIImageCacheHint
kCIImageCacheImmediately
kCIImageYCCMatrix
kCIImageTextureTarget
kCIImageTextureFormat
ignorePixelFormatFor601Fixup
kCIImageAuxiliaryDepth
kCIImageAuxiliaryDisparity
kCIImageAVDepthData
kCIImageAVPortraitEffectsMatte
kCIImageAuxiliaryPortraitEffectsMatte
kCIImageAuxiliarySemanticSegmentationSkinMatte
kCIImageAuxiliarySemanticSegmentationHairMatte
kCIImageAuxiliarySemanticSegmentationTeethMatte
kCIImageAuxiliarySemanticSegmentationGlassesMatte
kCIImageAuxiliarySemanticSegmentationSkyMatte
kCIImageAuxiliaryHDRGainMap
kCIImageAVSemanticSegmentationMatte
CIImageSurfaceFormat
-[CIImage initWithCGImage:options:]
CIImage
ABGR8
mask
decode array
pixel format that is unsupported
kCIImageRequestSurfaceFormat
v48@?0^v8Q16Q24Q32Q40
{JPEG}.ChromaSubsamplingX
{JPEG}.ChromaSubsamplingY
-[CIImage initWithBitmapData:bytesPerRow:size:format:options:]
v24@?0^v8Q16
-[CIImage initWithTexture:size:options:]
-[CIImage initWithMTLTexture:options:]
initWithCVImage
v64@?0^v8Q16Q24Q32Q40Q48Q56
-[CIImage initWithCVPixelBuffer:options:]
-[CIImage initWithCVImageBuffer:options:]
-[CIImage imageByColorMatchingWorkingSpaceToColorSpace:]
-[CIImage imageByColorMatchingWorkingSpaceToRGBorGrayColorSpace:]
-[CIImage imageByColorMatchingColorSpaceToWorkingSpace:]
-[CIImage imageByToneMappingColorSpaceToWorkingSpace:]
-[CIImage imageByTaggingWithColorSpace:]
-[CIImage imageBySettingProperties:]
-[CIImage imageBySettingPropertiesNoCopy:]
kContextInfoIsMetal
kContextInfoSupportsMPS
-[CIImage initWithArrayOfImages:selector:]
<CIImage: %p extent [infinite]>
<CIImage: %p extent [empty]>
<CIImage: %p extent [%g %g %g %g]>
<CIImage: %p extent [infinite]>
<CIImage: %p extent [empty]>
<CIImage: %p extent [%g %g %g %g]>
CoreImage doesn't support old-style archiving
CIImageEncoder
CoreImage doesn't support archiving infinite images.
-[CIImage encodeWithCoder:]_block_invoke
-[CIImage initWithCoder:]_block_invoke
<CIImage: %p> printTree:
-[CIImage setValue:forKeyPath:]
kCIImageTextScaleFactor
-[CIImage(TextImage) initWithAttributedString:format:options:]
CIImage <%p>
tagcolorspace 
tagcolorspace%c
CICGImageData
CICGImageWidth
CICGImageHeight
CICGImageBPC
CICGImageBPP
CICGImageBPR
CICGImageAlphaInfo
CICGImageInterp
CICGImageRI
abortable
blend_kernel
kernel vec4 _clearer() { return vec4(0.0); }
CIImageAccumulator
-[CIImageAccumulator init]
-[CIImageAccumulator initWithExtent:format:options:]
<CIImageAccumulator: %p extent [%g %g %g %g] format %s>
kCIImageAutoAdjustEnhance
kCIImageAutoAdjustRedEye
kCIImageAutoAdjustFeatures
kCIImageAutoAdjustCrop
kCIImageAutoAdjustLevel
kCIImageAutoAdjustLevel_MinAngle
kCIImageAutoAdjustLevel_MaxAngle
kCIImageAutoAdjustLevel_UseVerticalDetector
kCIImageAutoAdjustLevel_VerticalAngleThreshold
kCIImageAutoAdjustLevel_DominantAngleDiffThreshold
CIImageAutoAdjust
   adding crop rect: x=%.3f,y=%.3f,w=%.3f,h=%.3f
inputPoint2
inputPoint3
inputPoint4
iPhone
iPad
DUMP_AUTO_ENHANCE_ARRAY
filters = %@
inputMesh
leftPupil
rightPupil
innerLips
noseCrest
leftEye
rightEye
leftEyeX
leftEyeY
rightEyeX
rightEyeY
mouthCenterX
mouthCenterY
noseBridgeX
noseBridgeY
noseTipX
noseTipY
leftEyeLeftX
leftEyeLeftY
leftEyelidNWX
leftEyelidNWY
leftEyelidUpperX
leftEyelidUpperY
leftEyelidNEX
leftEyelidNEY
leftEyeRightX
leftEyeRightY
leftEyelidSEX
leftEyelidSEY
leftEyelidLowerX
leftEyelidLowerY
leftEyelidSWX
leftEyelidSWY
rightEyeLeftX
rightEyeLeftY
rightEyelidNWX
rightEyelidNWY
rightEyelidUpperX
rightEyelidUpperY
rightEyelidNEX
rightEyelidNEY
rightEyeRightX
rightEyeRightY
rightEyelidSEX
rightEyelidSEY
rightEyelidLowerX
rightEyelidLowerY
rightEyelidSWX
rightEyelidSWY
leftEyePosition
rightEyePosition
leftEyeTouchSize
leftEyeSize
rightEyeTouchSize
rightEyeSize
mouthPosition
mouthCenter
fullSizeImage
imageExtent
orientation
inputCameraModel
inputCorrectionInfo
autoRotateFilterFFT: props exist
Orientation = %d
  Found makerNotes
    Found vector: %.3f,%.3f,%.3f
acc = (%.5f, %.5f, %.5f)
accelTilt = %.3f deg, accelPitch = %.3f deg, accMagnitudeDev %.3f
accelPitch = %.3f deg, accelMagnitudeDev = %.3f
MaxAccelPitch
MaxPixelTilt
MinPixelTilt
MaxAccelMagDev
MaxAccelFFTDiff
MaxPitch = %.3f, MaxPixelTilt = %.3f, MinPixelTilt = %.3f, MaxAccelMagDev = %.3f, MaxAccelFFTDifff = %.3f
FFT detected angle = %.3f deg
Crop: Based on %d features
  feature%d has left eye at (%.3f,%.3f), right eye at (%.3f,%.3f)
  clip overall %% = %.3f
    too much clipping - reverting back to rotated crop only
    too little clipping - reverting back
int soft_horizonDetectionFFTAngles(uint8_t *, int, int, int, _Bool, float, int, _CIHorizonDetectedAngle *)
horizonDetectionFFTAngles
void *VisionLibrary(void)
_Bool soft_horizonDetectionFFT(uint8_t *, int, int, int, float *, int)
horizonDetectionFFT
kCIImageProcessorSynchronizeInputs
kCIImageProcessorAllowPartialOutputRegion
-[CIImageProcessorInOut initWithSurface:texture:allowSRGB:bounds:context:]
<%@: %p %s extent [infinite]>
<%@: %p %s extent [empty]>
<%@: %p %s extent [%g %g %g %g]>
-[CIImageProcessorOutput initWithSurface:texture:allowSRGB:bounds:context:]
-[CIImageProcessorOutput baseAddress]
-[CIImageProcessorOutput metalCommandBuffer]
-[CIImageProcessorInput baseAddress]
-[CIImage(CIImageProcessor) imageWithExtent:processorDescription:argumentDigest:inputFormat:outputFormat:options:roiCallback:processor:]
Image Processor
v108@?0^^{__IOSurface}8^{Texture=(?=Q{?=II}{?=^v^v})}16^{CGRect={CGPoint=dd}{CGSize=dd}}24^B32^{__IOSurface=}40{Texture=(?=Q{?=II}{?=^v^v})}48{CGRect={CGPoint=dd}{CGSize=dd}}64B96^v100
%s must be overridden in %@ class
+[CIImageProcessorKernel processWithInputs:arguments:output:error:]
processWithInputs:arguments:output:error:
+[CIImageProcessorKernel applyWithExtent:inputs:arguments:error:]
CIImageProcessorKernel
outputFormat must be 0, %s.
inputFormat for image %d must be 0, %s.
CIGenericMetalProcessor
CIMetalProcessor
filterName
R8, Rh, Rf, BGRA8, RGBAh, RGBAf
null
emptyCIVector
emptyCIImage
emptyNSData
emptyNSString
emptyNSArray
emptyNSDictionary
CIImageProcessorDigestObject
tile_size
kCIImageProviderContentDigest
kCIImageProviderName
provideImageData:bytesPerRow:origin::size::userInfo:
-[CIImage(CIImageProvider) initWithImageProvider:size::format:colorSpace:options:]
provideImageTexture:bounds:userInfo:
-[CIImage(CIImageProvider) initWithImageProvider:width:height:format:colorSpace:options:]
-[CIImage(CIImageProvider) _initWithImageProvider:width:height:format:colorSpace:surfaceCache:options:]
CIImage kCIImageEdgeRepeat not supported.
bytes
width
height
filename
%@.bmtl
dumping surface for filename %s
inputFilename
inputShouldDumpInputValues
.txt
kernel vec4 _yccCombiner (__sample imY, __sample imCC) 
 return vec4(imY.r, imCC.rg, imY.a); 
integral_image_manual
CIIntegralImage.mm
input.region.size.width == output.region.size.width
input.region.size.height == output.region.size.height
compute_integral_image
kernel vec2 _kaleida (vec4 parms, vec4 rota, vec4 rotb) 
 vec2 ctr = parms.xy; 
 float TwoPiDivCount = parms.z; 
 float CountDivTwoPi = parms.w; 
 vec2 v = destCoord() - ctr; 
 v = vec2(dot(v, rota.xy), dot(v, rota.zw)); 
 const float pi = 3.141592653589793; 
 const float halfpi = 1.570796326794897; 
 v.y = abs(v.y); 
 float a = atan(v.y,v.x); 
 a = - TwoPiDivCount * floor(a*CountDivTwoPi+0.5); 
 float x = (a>halfpi) ? pi-a : a; 
 x = (x<-halfpi) ? -pi-x : x; 
 float sn = x - (x*x*x/6.0) + (x*x*x*x*x/120.0) - (x*x*x*x*x*x*x/5040.0) + (x*x*x*x*x*x*x*x*x/362880.0); 
 x = abs(a); 
 float k = (x>halfpi) ? -1.0 : 1.0; 
 x = (x>halfpi) ? pi-x : x; 
 x = x*x; 
 x = (((0.000024801587302*x - 0.001388888888889)*x + 0.041666666666667)*x - 0.5)*x + 1.0; 
 float cs = x*k; 
 v = vec2(v.x*cs - v.y*sn, v.x*sn + v.y*cs); 
 v.y = abs(v.y); 
 v = vec2(dot(v, rotb.xy),dot(v, rotb.zw)); 
 return v + ctr; 
CIKernelMessageType
CIKernelMessageTypeNote
CIKernelMessageTypeRemark
CIKernelMessageTypeWarning
CIKernelMessageTypeError
CIKernelMessageTypeFatal
CIKernelMessageFilename
CIKernelMessageLineNumber
kCIKernelMessageOffset
kCIKernelMessageDescription
kCIKernelMessageTypeSyntaxError
kCIKernelMessageTypeInternalError
kCIKernelMessageTypeFunctionName
kCIKernelOutputFormat
kCIKernelThreadsPerThreadgroup
kCIKernelThreadgroupsPerGrid
No valid kernels were in the string
Printed AST of kernel %s:
Kernel %s has an unsupported type for the parameter %s
outputFormat
kCIFormat
Function does not exist in library data. %s
Check if Metal library is linked with -cikernel option.
reflect
Function does not return a supported type, which must be float2 (for CIWarpKernels)or float4 or half4 (for all other kernels).
coreimage::priv::Destination
coreimage::priv::Destination_h
.coerce
Unsupported type for parameter '%@'.
.coerce3
Function has too many destination parameters.
If specified, destination must be the last parameter of a CIKernel function.
ciKernelMain
reflectConstants
<%@: %s>
vec4  compare (vec4 x, vec4 y, vec4 z)    { return mix(y, z, step(0.0,x)); }
vec3  compare (vec3 x, vec3 y, vec3 z)    { return mix(y, z, step(0.0,x)); }
vec2  compare (vec2 x, vec2 y, vec2 z)    { return mix(y, z, step(0.0,x)); }
float compare (float x, float y, float z) { return x < 0.0 ? y : z; }
vec4  cos_ (vec4 x)  { return cos(x); }
vec3  cos_ (vec3 x)  { return cos(x); }
vec2  cos_ (vec2 x)  { return cos(x); }
float cos_ (float x) { return cos(x); }
vec4  sin_ (vec4 x)  { return sin(x); }
vec3  sin_ (vec3 x)  { return sin(x); }
vec2  sin_ (vec2 x)  { return sin(x); }
float sin_ (float x) { return sin(x); }
vec4  tan_ (vec4 x)  { return tan(x); }
vec3  tan_ (vec3 x)  { return tan(x); }
vec2  tan_ (vec2 x)  { return tan(x); }
float tan_ (float x) { return tan(x); }
vec2 cossin (float x)
    return vec2(cos(x), sin(x));
vec2 cossin_ (float x)
    return vec2(cos_(x), sin_(x));
vec2 sincos (float x)
    return vec2(sin(x), cos(x));
vec2 sincos_ (float x)
    return vec2(sin_(x), cos_(x));
vec4 premultiply (vec4 s)
    return vec4(s.rgb*s.a, s.a);
hvec4 premultiply (hvec4 s)
    return hvec4(s.rgb*s.a, s.a);
vec4 unpremultiply (vec4 s)
    return vec4(s.rgb/max(s.a,0.00001), s.a);
hvec4 unpremultiply (hvec4 s)
    return hvec4(s.rgb/max(s.a,0.0001h), s.a);
vec3 srgb_to_linear (vec3 s)
    return sign(s)*mix(abs(s)*0.077399380804954, pow(abs(s)*0.947867298578199 + 0.052132701421801, vec3(2.4)), step(0.04045, abs(s)));
hvec3 srgb_to_linear (hvec3 s)
    return sign(s)*mix(abs(s)*0.077399380804954h, pow(abs(s)*0.947867298578199h + 0.052132701421801h, hvec3(2.4h)), step(0.04045h, abs(s)));
vec4 srgb_to_linear (vec4 s)
    s = unpremultiply(s);
    s.rgb = sign(s.rgb)*mix(abs(s.rgb)*0.077399380804954, pow(abs(s.rgb)*0.947867298578199 + 0.052132701421801, vec3(2.4)), step(0.04045, abs(s.rgb)));
    return premultiply(s);
hvec4 srgb_to_linear (hvec4 s)
    s = unpremultiply(s);
    s.rgb = sign(s.rgb)*mix(abs(s.rgb)*0.077399380804954h, pow(abs(s.rgb)*0.947867298578199h + 0.052132701421801h, hvec3(2.4h)), step(0.04045h, abs(s.rgb)));
    return premultiply(s);
vec4 _srgb_to_linear (vec4 s)
    s.rgb = sign(s.rgb)*mix(abs(s.rgb)*0.077399380804954, pow(abs(s.rgb)*0.947867298578199 + 0.052132701421801, vec3(2.4)), step(0.04045, abs(s.rgb)));
    return s;
vec3 linear_to_srgb (vec3 s)
    return sign(s)*mix(abs(s)*12.92, pow(abs(s), vec3(0.4166667)) * 1.055 - 0.055, step(0.0031308, abs(s)));
hvec3 linear_to_srgb (hvec3 s)
    return sign(s)*mix(abs(s)*12.92h, pow(abs(s), hvec3(0.4166667h)) * 1.055h - 0.055h, step(0.0031308h, abs(s)));
vec4 linear_to_srgb (vec4 s)
    s = unpremultiply(s);
    s.rgb = sign(s.rgb)*mix(abs(s.rgb)*12.92, pow(abs(s.rgb), vec3(0.4166667)) * 1.055 - 0.055, step(0.0031308, abs(s.rgb)));
    return premultiply(s);
hvec4 linear_to_srgb (hvec4 s)
    s = unpremultiply(s);
    s.rgb = sign(s.rgb)*mix(abs(s.rgb)*12.92h, pow(abs(s.rgb), hvec3(0.4166667h)) * 1.055h - 0.055h, step(0.0031308h, abs(s.rgb)));
    return premultiply(s);
vec4 _linear_to_srgb (vec4 s)
    s.rgb = sign(s.rgb)*mix(abs(s.rgb)*12.92, pow(abs(s.rgb), vec3(0.4166667)) * 1.055 - 0.055, step(0.0031308, abs(s.rgb)));
    return s;
vec2 destCoord ()
    return _dc;
#define _samplerOffset(src, offset) (samplerTransform(src,offset) - samplerTransform(src,vec2(0.0)))
#define gatherX(src, point) vec4 \
    sample(src, point+_samplerOffset(src,vec2(-0.5,-0.5))).x, \
    sample(src, point+_samplerOffset(src,vec2( 0.5,-0.5))).x, \
    sample(src, point+_samplerOffset(src,vec2( 0.5, 0.5))).x, \
    sample(src, point+_samplerOffset(src,vec2(-0.5, 0.5))).x  \
#define gatherY(src, point) vec4 \
    sample(src, point+_samplerOffset(src,vec2(-0.5,-0.5))).y, \
    sample(src, point+_samplerOffset(src,vec2( 0.5,-0.5))).y, \
    sample(src, point+_samplerOffset(src,vec2( 0.5, 0.5))).y, \
    sample(src, point+_samplerOffset(src,vec2(-0.5, 0.5))).y  \
#define gatherZ(src, point) vec4 \
    sample(src, point+_samplerOffset(src,vec2(-0.5,-0.5))).z, \
    sample(src, point+_samplerOffset(src,vec2( 0.5,-0.5))).z, \
    sample(src, point+_samplerOffset(src,vec2( 0.5, 0.5))).z, \
    sample(src, point+_samplerOffset(src,vec2(-0.5, 0.5))).z  \
#define gatherW(src, point) vec4 \
    sample(src, point+_samplerOffset(src,vec2(-0.5,-0.5))).w, \
    sample(src, point+_samplerOffset(src,vec2( 0.5,-0.5))).w, \
    sample(src, point+_samplerOffset(src,vec2( 0.5, 0.5))).w, \
    sample(src, point+_samplerOffset(src,vec2(-0.5, 0.5))).w  \
#define _unordered_gatherX(src, point) gatherX(src, point)
#define _unordered_gatherY(src, point) gatherY(src, point)
#define _unordered_gatherZ(src, point) gatherZ(src, point)
#define _unordered_gatherW(src, point) gatherW(src, point)
#define samplerOrigin(src) samplerExtent(src).xy
#define samplerSize(src) samplerExtent(src).zw
void writeImage (vec4 color, vec2 point) {}
void writeImagePlane (vec4 color, vec2 point) {}
void writePixel (int r, int g, int b, int a, vec2 point) {}
vec2 writeCoord () { return vec2(0.0); }
#define new _new
#define delete _delete
#define and _and
#define not _not
#define or _or
#define xor _xor
__sampler
sampler
-[CIKernel _initWithString:andMetalLibrary:usingCruftCompatibility:]
+[CIKernel kernelWithFunctionName:fromMetalLibraryData:outputPixelFormat:error:]
+[CIKernel kernelWithFunctionName:fromMetalLibraryData:outputGroupSize:error:]
kCIKernelFunctionConstants
Cannot initialize kernel with given library data.
+[CIKernel kernelWithFunctionName:fromMetalLibraryData:options:error:]
Cannot initialize kernel with Metal DAG compiler disabled.
+[CIKernel kernelNamesFromMetalLibraryData:]
 = %@
, kCIFormat
-[CIKernel applyWithExtent:roiCallback:arguments:options:]
_arg%d
CISampler
Sampler2D
CIVector
CIVectorSize
NSData
    preservesRange
    preservesAlpha
    canReduceOutputChannels
    arguments: (
%s%s len%d %s
unknown
%s%s %s
    output: %s
-[CIColorKernel applyWithExtent:roiCallback:arguments:options:]
-[CIColorKernel applyWithExtent:roiCallback:arguments:]
-[CIColorKernel applyWithExtent:arguments:options:]
-[CIWarpKernel applyWithExtent:roiCallback:arguments:options:]
-[CIWarpKernel applyWithExtent:roiCallback:arguments:]
-[CIWarpKernel applyWithExtent:roiCallback:inputImage:arguments:options:]
{%g,%g %g x %g}
CIKernel
0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ_abcdefghijklmnopqrstuvwxyz
[CIKernelPool] 
note: 
remark: 
WARNING: 
ERROR: 
FATAL ERROR: 
v24@?0@"NSString"8^B16
 errors 
 error 
generated.
Expected a CIImage or a CISampler. 
Expected a leaf CIImage.
Expected an NSNumber.
Expected an NSArray of count 2 of NSNumbers
Expected an NSArray of count 3 of NSNumbers
Expected an NSArray of count 4 of NSNumbers
Expected an NSNumber or a CIVector of count 1. 
Expected a CIVector of count 2 or more. 
Expected a CIVector of count 3 or more. 
Expected a CIVector of count 4 or more. 
Expected a CIVector of count 4.
Expected a CIVector of count 6 or 9. 
Expected a CIVector of count 16. 
Expected a CIColor or CIVector. 
Expected an NSData. 
vec3 _toLab (vec3 rgb) 
 vec3 XYZ = vec3(dot(rgb, vec3(0.452350,0.399530,0.148409)), 
 dot(rgb, vec3(0.222488,0.716873,0.060608)), 
 dot(rgb, vec3(0.016868,0.117668,0.865571))); 
 XYZ = max(XYZ, vec3(0.0)); 
 XYZ = compare(XYZ - 0.008856, 7.787 * XYZ + 16.0 / 116.0, pow(XYZ,vec3(0.33333333))); 
 return vec3(116.0 * XYZ.y - 16.0, 500.0 * (XYZ.x - XYZ.y), 200.0 * (XYZ.y - XYZ.z)); 
 float _deltaE (vec3 lab1, vec3 lab2) 
 vec3 d = lab1 - lab2; 
 float dL = d.x; 
 float da = d.y; 
 float db = d.z; 
 float C1 = length(lab1.yz); 
 float C2 = length(lab2.yz); 
 float Cgmean = sqrt(C1*C2); 
 float dC = C1 - C2; 
 float dH2 = max(da*da + db*db - dC*dC, 0.0); 
 float K1 = 0.045; 
 float K2 = 0.015; 
 float Sc = 1.0 + K1*Cgmean; 
 float Sh = 1.0 + K2*Cgmean; 
 float Lv = dL; 
 float Cv = dC / Sc; 
 float Hv2 = dH2 / (Sh * Sh); 
 return sqrt(Lv*Lv + Cv*Cv + Hv2); 
 kernel vec4 _LabDeltaE (__sample c1, __sample c2) 
 vec4 c1overwhite = c1 + (1.0 - c1.a); 
 vec3 lab1w = _toLab(c1overwhite.rgb); 
 vec3 lab1b = _toLab(c1.rgb); 
 vec4 c2overwhite = c2 + (1.0 - c2.a); 
 vec3 lab2w = _toLab(c2overwhite.rgb); 
 vec3 lab2b = _toLab(c2.rgb); 
 float dE = max(_deltaE(lab1w, lab2w), _deltaE(lab1b, lab2b)); 
 return vec4(dE); 
kernel vec4 _lanczosDown2(sampler src, vec4 scale) 
 vec2 d = destCoord() * scale.xy; 
 vec2 o0 = scale.zw * 0.732871; 
 vec2 o1 = scale.zw * 2.83784; 
 vec2 o2 = scale.zw * 4.6968; 
 vec4 q0 = sample(src, samplerTransform(src, d - o2)); 
 vec4 q1 = sample(src, samplerTransform(src, d - o1)); 
 vec4 q2 = sample(src, samplerTransform(src, d - o0)); 
 vec4 q3 = sample(src, samplerTransform(src, d + o0)); 
 vec4 q4 = sample(src, samplerTransform(src, d + o1)); 
 vec4 q5 = sample(src, samplerTransform(src, d + o2)); 
 return (0.581891)*(q2+q3) + (-0.100636)*(q1+q4) + (0.0187453)*(q0+q5); 
float _lanc3h (float x) 
 x = abs(x); 
 if (x >= 3.0) return 0.0; 
 if (x < 1e-3) return 1.0; 
 x *= 3.141592653589793; 
 return 3.0*sin(x)*sin(x/3.0) / (x*x); 
 kernel vec4 _lanczosDownH(sampler src, vec4 scale) 
 vec2 c = destCoord() * scale.xy; 
 vec2 pm1 = vec2(floor(c.x-0.5)+0.5, c.y); 
 vec2 pm6 = pm1 - scale.zw * 5.0; 
 vec2 pm5 = pm1 - scale.zw * 4.0; 
 vec2 pm4 = pm1 - scale.zw * 3.0; 
 vec2 pm3 = pm1 - scale.zw * 2.0; 
 vec2 pm2 = pm1 - scale.zw * 1.0; 
 vec2 pp1 = pm1 + scale.zw * 1.0; 
 vec2 pp2 = pm1 + scale.zw * 2.0; 
 vec2 pp3 = pm1 + scale.zw * 3.0; 
 vec2 pp4 = pm1 + scale.zw * 4.0; 
 vec2 pp5 = pm1 + scale.zw * 5.0; 
 vec2 pp6 = pm1 + scale.zw * 6.0; 
 vec4 vm6 = sample(src, samplerTransform(src, pm6)); 
 vec4 vm5 = sample(src, samplerTransform(src, pm5)); 
 vec4 vm4 = sample(src, samplerTransform(src, pm4)); 
 vec4 vm3 = sample(src, samplerTransform(src, pm3)); 
 vec4 vm2 = sample(src, samplerTransform(src, pm2)); 
 vec4 vm1 = sample(src, samplerTransform(src, pm1)); 
 vec4 vp1 = sample(src, samplerTransform(src, pp1)); 
 vec4 vp2 = sample(src, samplerTransform(src, pp2)); 
 vec4 vp3 = sample(src, samplerTransform(src, pp3)); 
 vec4 vp4 = sample(src, samplerTransform(src, pp4)); 
 vec4 vp5 = sample(src, samplerTransform(src, pp5)); 
 vec4 vp6 = sample(src, samplerTransform(src, pp6)); 
 float wm6 = _lanc3h((pm6.x-c.x)/scale.x); 
 float wm5 = _lanc3h((pm5.x-c.x)/scale.x); 
 float wm4 = _lanc3h((pm4.x-c.x)/scale.x); 
 float wm3 = _lanc3h((pm3.x-c.x)/scale.x); 
 float wm2 = _lanc3h((pm2.x-c.x)/scale.x); 
 float wm1 = _lanc3h((pm1.x-c.x)/scale.x); 
 float wp1 = _lanc3h((pp1.x-c.x)/scale.x); 
 float wp2 = _lanc3h((pp2.x-c.x)/scale.x); 
 float wp3 = _lanc3h((pp3.x-c.x)/scale.x); 
 float wp4 = _lanc3h((pp4.x-c.x)/scale.x); 
 float wp5 = _lanc3h((pp5.x-c.x)/scale.x); 
 float wp6 = _lanc3h((pp6.x-c.x)/scale.x); 
 float wsum = wm6+wm5+wm4+wm3+wm2+wm1+wp1+wp2+wp3+wp4+wp5+wp6; 
 return (wm6*vm6 + wm5*vm5 + wm4*vm4 + wm3*vm3 + wm2*vm2 + wm1*vm1 + 
 wp6*vp6 + wp5*vp5 + wp4*vp4 + wp3*vp3 + wp2*vp2 + wp1*vp1)/wsum; 
float _lanc3v (float x) 
 x = abs(x); 
 if (x >= 3.0) return 0.0; 
 if (x < 1e-3) return 1.0; 
 x *= 3.141592653589793; 
 return 3.0*sin(x)*sin(x/3.0) / (x*x); 
 kernel vec4 _lanczosDownV(sampler src, vec4 scale) 
 vec2 c = destCoord() * scale.xy; 
 vec2 pm1 = vec2(c.x, floor(c.y-0.5)+0.5); 
 vec2 pm6 = pm1 - scale.zw * 5.0; 
 vec2 pm5 = pm1 - scale.zw * 4.0; 
 vec2 pm4 = pm1 - scale.zw * 3.0; 
 vec2 pm3 = pm1 - scale.zw * 2.0; 
 vec2 pm2 = pm1 - scale.zw * 1.0; 
 vec2 pp1 = pm1 + scale.zw * 1.0; 
 vec2 pp2 = pm1 + scale.zw * 2.0; 
 vec2 pp3 = pm1 + scale.zw * 3.0; 
 vec2 pp4 = pm1 + scale.zw * 4.0; 
 vec2 pp5 = pm1 + scale.zw * 5.0; 
 vec2 pp6 = pm1 + scale.zw * 6.0; 
 vec4 vm6 = sample(src, samplerTransform(src, pm6)); 
 vec4 vm5 = sample(src, samplerTransform(src, pm5)); 
 vec4 vm4 = sample(src, samplerTransform(src, pm4)); 
 vec4 vm3 = sample(src, samplerTransform(src, pm3)); 
 vec4 vm2 = sample(src, samplerTransform(src, pm2)); 
 vec4 vm1 = sample(src, samplerTransform(src, pm1)); 
 vec4 vp1 = sample(src, samplerTransform(src, pp1)); 
 vec4 vp2 = sample(src, samplerTransform(src, pp2)); 
 vec4 vp3 = sample(src, samplerTransform(src, pp3)); 
 vec4 vp4 = sample(src, samplerTransform(src, pp4)); 
 vec4 vp5 = sample(src, samplerTransform(src, pp5)); 
 vec4 vp6 = sample(src, samplerTransform(src, pp6)); 
 float wm6 = _lanc3v((pm6.y-c.y)/scale.y); 
 float wm5 = _lanc3v((pm5.y-c.y)/scale.y); 
 float wm4 = _lanc3v((pm4.y-c.y)/scale.y); 
 float wm3 = _lanc3v((pm3.y-c.y)/scale.y); 
 float wm2 = _lanc3v((pm2.y-c.y)/scale.y); 
 float wm1 = _lanc3v((pm1.y-c.y)/scale.y); 
 float wp1 = _lanc3v((pp1.y-c.y)/scale.y); 
 float wp2 = _lanc3v((pp2.y-c.y)/scale.y); 
 float wp3 = _lanc3v((pp3.y-c.y)/scale.y); 
 float wp4 = _lanc3v((pp4.y-c.y)/scale.y); 
 float wp5 = _lanc3v((pp5.y-c.y)/scale.y); 
 float wp6 = _lanc3v((pp6.y-c.y)/scale.y); 
 float wsum = wm6+wm5+wm4+wm3+wm2+wm1+wp1+wp2+wp3+wp4+wp5+wp6; 
 return (wm6*vm6 + wm5*vm5 + wm4*vm4 + wm3*vm3 + wm2*vm2 + wm1*vm1 + 
 wp6*vp6 + wp5*vp5 + wp4*vp4 + wp3*vp3 + wp2*vp2 + wp1*vp1)/wsum; 
kernel vec4 _lanczosUpH(sampler src, float scale) 
 vec4 w; 
 vec2 c = destCoord(); 
 c.x = scale*c.x - 0.5; 
 vec2 d = c; 
 c.x = floor(c.x); 
 float x = (c.x - d.x + 1.0); 
 w.z = x*x*(x*(x*(x*-0.41086841 + 0.78286595) + 1.04059357) - 2.41189213) + 1.0; 
 w.x = x*x*(x*(x*(x*-0.29216512 + 1.02524562) - 0.52422910) - 0.20885140); 
 x = 1.0-x; 
 w.y = x*x*(x*(x*(x*-0.41086841 + 0.78286595) + 1.04059357) - 2.41189213) + 1.0; 
 w.w = 1.0 - w.x - w.y - w.z; 
 vec4 p0 = sample(src, samplerTransform(src, c + vec2(-0.5,0.0))); 
 vec4 p1 = sample(src, samplerTransform(src, c + vec2(+0.5,0.0))); 
 vec4 p2 = sample(src, samplerTransform(src, c + vec2(+1.5,0.0))); 
 vec4 p3 = sample(src, samplerTransform(src, c + vec2(+2.5,0.0))); 
 return w.x*p0 + w.y*p1 + w.z*p2 + w.w*p3; 
kernel vec4 _lanczosUpV(sampler src, float scale) 
 vec4 w; 
 vec2 c = destCoord(); 
 c.y = scale*c.y - 0.5; 
 vec2 d = c; 
 c.y = floor(c.y); 
 float x = (c.y - d.y + 1.0); 
 w.z = x*x*(x*(x*(x*-0.41086841 + 0.78286595) + 1.04059357) - 2.41189213) + 1.0; 
 w.x = x*x*(x*(x*(x*-0.29216512 + 1.02524562) - 0.52422910) - 0.20885140); 
 x = 1.0-x; 
 w.y = x*x*(x*(x*(x*-0.41086841 + 0.78286595) + 1.04059357) - 2.41189213) + 1.0; 
 w.w = 1.0 - w.x - w.y - w.z; 
 vec4 p0 = sample(src, samplerTransform(src, c + vec2(0.0,-0.5))); 
 vec4 p1 = sample(src, samplerTransform(src, c + vec2(0.0,+0.5))); 
 vec4 p2 = sample(src, samplerTransform(src, c + vec2(0.0,+1.5))); 
 vec4 p3 = sample(src, samplerTransform(src, c + vec2(0.0,+2.5))); 
 return w.y*p1 + w.z*p2 + w.x*p0 + w.w*p3; 
kernel vec4 _lozengeRefraction(sampler src, vec2 p0, vec2 p1, float radius, vec2 v01, vec2 x01, float indexOfRefraction, float levitation) 
 vec2 v0 = destCoord() - p0; 
 vec3 c0 = cross(vec3(v0, 0.0), vec3(v01, 0.0)); 
 vec2 unitvec = (c0.z < 0.0) ? x01 : -x01; 
 float dist = abs(c0.z); 
 float dist2 = length(v0); 
 vec2 unitvec2 = normalize(v0); 
 float d0 = dot(v01, v0); 
 dist = (d0 < 0.0) ? dist : dist2; 
 unitvec = (d0 < 0.0) ? unitvec : unitvec2; 
 v0 = destCoord() - p1; 
 dist2 = length(v0); 
 unitvec2 = normalize(v0); 
 d0 = dot(v01, v0); 
 dist = (d0 < 0.0) ? dist2 : dist; 
 unitvec = (d0 < 0.0) ? unitvec2 : unitvec; 
 d0 = dist / radius; 
 vec3 surfaceNormal = vec3(unitvec * d0, sqrt(1.0 - d0 * d0)); 
 float surfaceHeight = surfaceNormal.z * radius + levitation; 
 float eta = 1.0 / indexOfRefraction; 
 float c1 = surfaceNormal.z; 
 float cs2 = 1.0 - eta * eta * (1.0 - c1 * c1); 
 vec3 rayDirection = eta * vec3(0.0, 0.0, -1.0); 
 c1 = eta * c1 - sqrt(abs(cs2)); 
 rayDirection += c1 * surfaceNormal; 
 float t = - surfaceHeight / rayDirection.z; 
 vec2 travel = t * rayDirection.xy; 
 travel = max(min(travel, vec2(radius*2.0)), vec2(-radius*2.0)); 
 vec4 color = sample(src, samplerTransform(src, destCoord() + travel)); 
 color = (cs2 < 0.0) ? vec4(0.0, 0.0, 0.0, 0.0) : color; 
 float alpha = clamp(radius - dist, 0.0, 1.0); 
 vec4 unrefracted = sample(src, samplerCoord(src)); 
 return mix(unrefracted, color, alpha); 
kernel vec4 _torusRefraction(sampler src, vec2 center, float a, float b, float c, float indexOfRefraction, float levitation) 
 vec2 v0 = destCoord() - center; 
 float dist = length(v0); 
 vec2 unitvec = normalize(v0); 
 float fdom = a * dist + b; 
 float alpha = clamp((1.0 - abs(fdom)) * c, 0.0, 1.0); 
 vec3 surfaceNormal = vec3(unitvec * fdom, sqrt(1.0 - fdom * fdom)); 
 float surfaceHeight = surfaceNormal.z * c + levitation; 
 vec3 rayOrigin = vec3(destCoord(), surfaceHeight); 
 float eta = 1.0 / indexOfRefraction; 
 float c1 = surfaceNormal.z; 
 float cs2 = 1.0 - eta * eta * (1.0 - c1 * c1); 
 vec3 rayDirection = eta * vec3(0.0, 0.0, -1.0); 
 c1 = eta * c1 - sqrt(abs(cs2)); 
 rayDirection += c1 * surfaceNormal; 
 float t = - surfaceHeight / rayDirection.z; 
 vec3 hitPoint = rayOrigin + t * rayDirection; 
 if (alpha<0.001) hitPoint.xy = vec2(50.0); 
 vec4 color = sample(src, samplerTransform(src, hitPoint.xy)); 
 color = (cs2 < 0.0) ? vec4(0.0, 0.0, 0.0, 0.0) : color; 
 vec4 unrefracted = sample(src, samplerCoord(src)); 
 return mix(unrefracted, color, alpha); 
inputTuningParameters
%d, 
focus = 
zeroShiftPercentile
slm_calcV2
float __dummyDoNothing() { return 10.0; }
int __myMAX(int a,int b) { return a > b ? a : b; }
int __myMIN(int a,int b) { return a < b ? a : b; }
vec2 __calcPosition(vec2 index,vec4 rect) {
  vec2 step = rect.zw / 64.0;
  vec2 pos  = rect.xy + step * index + step / 2.0;
  return pos;
kernel vec4 _ciLensModelCalculator(sampler image, vec4 focusRect, sampler minMaxImage, float4 cpuParams)
    float zeroShiftPercentile = cpuParams.x;
    int histBuf[256];
    for(int i = 0 ; i < 256; i++) {
    
  histBuf[i] = 0;
    }
   vec2 minMax = sample(minMaxImage, samplerTransform(minMaxImage, vec2(0.5))).rg;
   float shiftMin = floor(65536.0 * minMax.x) / 65536.0;
   float shiftMax = ceil(65536.0 * minMax.y) / 65536.0;
   float shiftRange = shiftMax - shiftMin;
   float shiftRecipRange = 1.0 / shiftRange; 
   for(int j = 0; j < 64; j++) {
       for ( int i = 0; i <  64; i++ ) {
            vec2 location = vec2(float(i),float(j));
            vec2 focusLocation  = __calcPosition(location,focusRect);
            float shiftVal = sample(image, samplerTransform(image, focusLocation)).r;
            int index = int( min( 256.0f * shiftRecipRange * ( shiftVal - shiftMin ), 255.0f ) );
            index = __myMIN(__myMAX(index,0),255);
            histBuf[index]++;
        }
    }
    int binCountThreshold = int(floor( zeroShiftPercentile * 64.0 * 64.0 ));
    int binCount = 0;
    int oldBinCount = 0;
    int zeroShiftBinIndex = 0;
    for ( zeroShiftBinIndex = 0; (zeroShiftBinIndex < 256) && (binCount < binCountThreshold); zeroShiftBinIndex++ )
    {
    
binCount += histBuf[zeroShiftBinIndex];
    }
    float zeroShiftFractionalBinPos = min(1.0, max( 0.0, float( binCountThreshold - oldBinCount ) / max( float( binCount - oldBinCount ), 1.0f ))); 
    float interpolateZeroShiftBinIndex = max( 0.0f, zeroShiftBinIndex - 1.0 ) + zeroShiftFractionalBinPos; 
    float zeroShift = (shiftRange * float(interpolateZeroShiftBinIndex + 0.5 ) / 256.0) + shiftMin;
    float radiusScale   = cpuParams.y;
    float maxFGBlur     = cpuParams.z;
    float shiftDeadZone = cpuParams.w;
    return vec4(zeroShift, radiusScale, maxFGBlur, shiftDeadZone);
disparityScalingFactor
maxBlur
maxFGBlur
shiftDeadZone
-[CILensModelCalculator outputImage]
CILensModel.m
calc
Version
minimumSimulatedAperture
maximumSimulatedAperture
kernel vec4 _CILensModelApply(__sample shiftMap, __sample p) {
  float radiusOffset  = p.x;
  float radiusScale   = p.y;
  float maxFGBlur     = p.z;
  float shiftDeadZone = p.w;
  float shiftVal = shiftMap.x; 
  float relShift = abs( min( shiftVal - radiusOffset, maxFGBlur ) );
  float dzRelShift = mix( 0.0, relShift, clamp(relShift * shiftDeadZone, 0.0, 1.0));
  float blurVal = clamp( radiusScale * dzRelShift , 0.0, 1.0);
  float  resultBlurVal = clamp(sqrt(blurVal), 0.0, 1.0);
  return vec4(resultBlurVal,0.0,0.0,1.0);
-[CILensModelApply outputImage]
applyKernel
slm_calc
slm_apply
slm_shiftmap_calcminmax0
slm_shiftmap_calcminmax1
slm_shiftmap_calcminmax2
roi_left
fallbackFocusROI_left
roi_top
fallbackFocusROI_top
roi_width
fallbackFocusROI_width
roi_height
fallbackFocusROI_height
simulatedFocalLength
aperture
focusRect
kernel vec4 _lenticularHalo(sampler noise, vec2 center, vec2 sourcecenter, float noiseRadius, float haloThicknessRecip, float a, float b, vec3 rgbdist, __color color) 
 vec2 v = destCoord() - center; 
 vec3 rgbfunc = clamp((length(v) - rgbdist) * haloThicknessRecip, 0.0, 1.0); 
 rgbfunc = 2.0 * min(rgbfunc, 1.0 - rgbfunc); 
 rgbfunc = (3.0 - 2.0 * rgbfunc) * rgbfunc * rgbfunc; 
 vec2 noiseloc = normalize(v) * noiseRadius + sourcecenter; 
 vec4 npix = sample(noise, samplerTransform(noise, noiseloc)); 
 vec3 color3 = (npix.r * a + b) * rgbfunc * color.rgb; 
 return vec4(color3, max(max(color3.r, color3.g), color3.b)); 
inputHaloRadius
inputHaloWidth
inputHaloOverlap
CILenticularHaloGenerator only has one input
kernel vec2 _lighttunnel (vec4 param) 
 vec2 p = destCoord() - param.xy; 
 float rlen = param.z * inversesqrt(dot(p,p)); 
 float angle = log(rlen) * param.w; 
 vec2 cs = vec2(cos(angle), sin(angle)); 
 p = vec2(dot(p, cs), dot(p, vec2(-cs.y, cs.x))); 
 p = p * rlen + param.xy; 
 p = mix(destCoord(), p, step(rlen, 1.0)); 
 return p; 
kernel vec4 _localContrast(__sample im, __sample shc, float amt) 
 float midAmt = amt; 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 float y = dot(im.rgb, vec3(0.3333)); 
 y = sqrt(y); 
 y = y*(1.0-y); 
 im.rgb = sqrt(im.rgb); 
 float pivot = sqrt(shc.g); 
 float a = midAmt*y; 
 float b = -pivot*a; 
 vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt); 
 im.rgb = mix(im.rgb, pix, 0.8); 
 im.rgb = max(im.rgb, 0.0); 
 im.rgb *= im.rgb; 
 im.rgb = im.rgb + neg + pos; 
 return im; 
inputSmallImage
CILocalLight-stats
lightMap
lightMapWidth
lightMapHeight
lightMapAvg
localAutoValue
proxyLightMap
proxyLightMapWidth
proxyLightMapHeight
inputLightMapWidth
inputLightMapHeight
inputLocalLight
inputSmartShadows
kernel vec4 _shadowKernel(__sample im, __sample adj, float str) 
 adj.r = 3.4*adj.r-1.2; 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 vec4 orig = im; 
 float y = sqrt(dot(im.rgb, vec3(.33333))); 
 float s = mix(0.0, adj.r, str); 
 vec3 gain = s > 0.0 ? vec3(0.0*s) : vec3(-2.75*s*s, -2.75*s*s, -2.5*s*s); 
 im.rgb = im.rgb*im.rgb*gain + im.rgb*(1.0-gain); 
 float m = 1.0 + 1.85*s*(max(0.1-y, 0.0)) ;
 im.rgb = (clamp(m*im.rgb, 0.0, 1.0)); 
 float midAmt = s < 0.0 ? min(s*s,1.0) : 0.0; 
 y = y*(1.0-y); 
 im.rgb = sqrt(im.rgb); 
 float pivot = .4; 
 float a = midAmt*y; 
 float b = -pivot*a; 
 vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt); 
 im.rgb = mix(im.rgb, pix, 0.8); 
 im.rgb = max(im.rgb, 0.0); 
 im.rgb *= im.rgb; 
 im.rgb = clamp(im.rgb, 0.0,1.0)+pos+neg; 
 return im; 
kernel vec4 _polyKernel(__sample im, __sample adj, float str) 
 adj.r = 3.4*adj.r-1.2; 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 vec4 orig = im; 
 float y = sqrt(dot(im.rgb, vec3(.33333))); 
 float s = mix(0.0, adj.r, str); 
 vec3 gain = s > 0.0 ? vec3(1.5*s) : vec3(1.75*s, 1.75*s, 1.55*s); 
 im.rgb = im.rgb*im.rgb*gain + im.rgb*(1.0-gain); 
 im.rgb = (clamp(im.rgb, 0.0, 1.0)); 
 float midAmt = min(str, .5); 
 y = y*(1.0-y); 
 im.rgb = sqrt(im.rgb); 
 float pivot = max(adj.g, 0.5); 
 float a = midAmt*y; 
 float b = -pivot*a; 
 vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(pivot), -y*midAmt); 
 im.rgb = mix(im.rgb, pix, 0.8); 
 im.rgb = max(im.rgb, 0.0); 
 im.rgb *= im.rgb; 
 im.rgb = clamp(im.rgb, 0.0,1.0)+pos+neg; 
 return im; 
-[CILocalLightFilter outputImage]
CILocalLight.mm
CGRectEqualToRect([guideImage extent], [inputImage extent])
inputImage != nil
guideImage != nil
inputLocalLight != nil
CGRectEqualToRect([lightMapImage extent], [inputImage extent])
CILocalLight
_lightMapImageFromData_block_invoke
x == 0
y == 0
width == lmWidth
height == lmHeight
CIEdgePreserveUpsampleRGFilter
kernel vec4 _lumaMap (__sample pixel, sampler2D table,vec2 normalizer) 
 float luma = dot(pixel, vec4(0.299, 0.587, 0.114, 0.0)); 
 vec4 result = texture2D(table, vec2(normalizer.x * luma + normalizer.y, 0.5)); 
 result.a = pixel.a; 
 return result; 
10.11
kernel vec4 _maskToAlpha (__sample src) { return src.yyyy; }
kernel vec4 _betterDown2 (sampler image) 
 vec4 U = sample(image, samplerTransform(image, destCoord()*2.0 + vec2(0.0, 1.0))); 
 vec4 D = sample(image, samplerTransform(image, destCoord()*2.0 + vec2(0.0,-1.0))); 
 vec4 R = sample(image, samplerTransform(image, destCoord()*2.0 + vec2( 1.0,0.0))); 
 vec4 L = sample(image, samplerTransform(image, destCoord()*2.0 + vec2(-1.0,0.0))); 
 return (U+D+L+R)*0.25; 
vec4 _mvbUp (sampler src, vec2 dc, vec2 scale) 
 vec2 d = scale * dc - 0.5; 
 vec2 c = floor(d); 
 vec2 x = (c - d + 1.0); 
 vec2 X = (d - c); 
 vec2 w1 = (-1.0/3.0)*x*x*x + 0.5*x*x + 0.5*x + 1.0/6.0; 
 vec2 w2 = 1.0 - w1; 
 vec2 o1 = (-0.5*x*x*x + 0.5*x*x + 0.5*x + 1.0/6.0) / w1 + c - 0.5; 
 vec2 o2 = (X*X*X/6.0) / w2 + c + 1.5; 
 vec4 r; 
 r = w1.x * w1.y * sample(src, samplerTransform(src, vec2(o1.x,o1.y))); 
 r += w2.x * w1.y * sample(src, samplerTransform(src, vec2(o2.x,o1.y))); 
 r += w1.x * w2.y * sample(src, samplerTransform(src, vec2(o1.x,o2.y))); 
 r += w2.x * w2.y * sample(src, samplerTransform(src, vec2(o2.x,o2.y))); 
 return r; 
 kernel vec4 _maskedVariableBlur (sampler sM, 
 sampler s0, sampler s1, sampler s2, sampler s3, sampler s4, sampler s5, sampler s6, 
 float maxBlur) 
 vec2 dc = destCoord(); vec4 mask = sample(sM, samplerTransform(sM, dc)); 
 float k = mask.y; 
 k = clamp(k, 0.0, 1.0); 
 float m = k*maxBlur; 
 m = log2(m*4.0/3.0); 
 m = max(m,0.0); 
 float mLo = floor(m); 
 vec4 c0 = sample(s0, samplerTransform(s0, dc)); 
 vec4 c1 = _mvbUp(s1, dc, vec2(0.5)); vec4 c2 = _mvbUp(s2, dc, vec2(0.25)); vec4 c3 = _mvbUp(s3, dc, vec2(0.125)); vec4 c4 = _mvbUp(s4, dc, vec2(0.0625)); vec4 c5 = _mvbUp(s5, dc, vec2(1./32.)); vec4 c6 = _mvbUp(s6, dc, vec2(1./64.)); vec4 cLo = c0; 
 vec4 cHi = c1; 
 cLo = (mLo > 0.5) ? c1 : cLo; 
 cHi = (mLo > 0.5) ? c2 : cHi; 
 cLo = (mLo > 1.5) ? c2 : cLo; 
 cHi = (mLo > 1.5) ? c3 : cHi; 
 cLo = (mLo > 2.5) ? c3 : cLo; 
 cHi = (mLo > 2.5) ? c4 : cHi; 
 cLo = (mLo > 3.5) ? c4 : cLo; 
 cHi = (mLo > 3.5) ? c5 : cHi; 
 cLo = (mLo > 4.5) ? c5 : cLo; 
 cHi = (mLo > 4.5) ? c6 : cHi; 
 cLo = (mLo > 5.5) ? c6 : cLo; 
 return mix(cLo,cHi,m-mLo); 
inputSubsampling
inputEPS
inputFGThresholdValue
inputBGThresholdValue
inputErosionKernelSize
inputUseDepthFilter
kernel vec4 _median3x3(sampler src) 
 vec2 d; 
 vec4 p1,p2,p3,p4,p5,p6,p7,p8,p9; 
 vec4 e1, e2, e3, e4, e5, e6, e7, e8, e9, e10; 
 vec4 e11, e12, e13, e14, e15, e16, e17, e18, e19, e20; 
 vec4 e21, e22, e23, e24, e25, e26, e27, e28, e29; 
 d = destCoord(); 
 p1 = sample(src, samplerTransform(src, d + vec2(+1.0, 0.0))); 
 p2 = sample(src, samplerTransform(src, d + vec2(+1.0,+1.0))); 
 p3 = sample(src, samplerTransform(src, d + vec2( 0.0,+1.0))); 
 p4 = sample(src, samplerTransform(src, d + vec2(-1.0,+1.0))); 
 p5 = sample(src, samplerTransform(src, d + vec2(-1.0, 0.0))); 
 p6 = sample(src, samplerTransform(src, d + vec2(-1.0,-1.0))); 
 p7 = sample(src, samplerTransform(src, d + vec2( 0.0,-1.0))); 
 p8 = sample(src, samplerTransform(src, d + vec2(+1.0,-1.0))); 
 p9 = sample(src, samplerTransform(src, d)); 
 e1 = min(p2 , p3 ); e2 = max(p2 , p3 ); 
 e3 = min(p5 , p6 ); e4 = max(p5 , p6 ); 
 e5 = min(p8 , p9 ); e6 = max(p8 , p9 ); 
 e7 = min(p1 , e1 ); e8 = max(p1 , e1 ); 
 e9 = min(p4 , e3 ); e10 = max(p4 , e3 ); 
 e11 = min(p7 , e5 ); e12 = max(p7 , e5 ); 
 e13 = min(e8 , e2 ); e14 = max(e8 , e2 ); 
 e15 = min(e10, e4 ); e16 = max(e10, e4 ); 
 e17 = min(e12, e6 ); e18 = max(e12, e6 ); 
 e19 = max(e7 , e9 ); 
 e20 = min(e16, e18); 
 e21 = max(e19, e11); 
 e22 = min(e14, e20); 
 e23 = min(e15, e17); e24 = max(e15, e17); 
 e25 = max(e13, e23); 
 e26 = min(e24, e25); 
 e27 = min(e26, e22); e28 = max(e26, e22); 
 e29 = max(e21, e27); 
 return min(e29, e28); 
kernel vec4 _mesh1(vec4 pt1, float width, __color color, float opacity) 
 float hw, dist, interpolant; 
 vec2 p1, p2, p, v, w, s; 
 hw = width*0.5; 
 p = destCoord(); 
 p1 = pt1.rg; p2 = pt1.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist = compare(v.x*s.x + v.y*s.y, length(v), dist); 
 w = p - p2; 
 dist = compare(w.x*s.x + w.y*s.y, dist, length(w)); 
 interpolant = clamp(hw - dist, 0.0, 1.0); 
 interpolant = (3.0 - 2.0*interpolant)*interpolant*interpolant; 
 return compare(vec4(dist - (hw - 1.0)), color, compare(vec4(dist - hw), color * interpolant, vec4(0.0))) * opacity; 
kernel vec4 _mesh2(vec4 pt1, vec4 pt2, float width, __color color, float opacity) 
 float hw, dist1, dist2, interpolant; 
 vec2 p1, p2, p, v, w, s; 
 hw = width*0.5; 
 p = destCoord(); 
 p1 = pt1.rg; p2 = pt1.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist1 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist1 = compare(v.x*s.x + v.y*s.y, length(v), dist1); 
 w = p - p2; 
 dist1 = compare(w.x*s.x + w.y*s.y, dist1, length(w)); 
 p1 = pt2.rg; p2 = pt2.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 interpolant = clamp(hw - dist1, 0.0, 1.0); 
 interpolant = (3.0 - 2.0*interpolant)*interpolant*interpolant; 
 return compare(vec4(dist1 - (hw - 1.0)), color, compare(vec4(dist1 - hw), color * interpolant, vec4(0.0))) * opacity; 
kernel vec4 _mesh4(vec4 pt1, vec4 pt2, vec4 pt3, vec4 pt4, float width, __color color, float opacity) 
 float hw, dist1, dist2, interpolant; 
 vec2 p1, p2, p, v, w, s; 
 hw = width*0.5; 
 p = destCoord(); 
 p1 = pt1.rg; p2 = pt1.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist1 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist1 = compare(v.x*s.x + v.y*s.y, length(v), dist1); 
 w = p - p2; 
 dist1 = compare(w.x*s.x + w.y*s.y, dist1, length(w)); 
 p1 = pt2.rg; p2 = pt2.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt3.rg; p2 = pt3.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt4.rg; p2 = pt4.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 interpolant = clamp(hw - dist1, 0.0, 1.0); 
 interpolant = (3.0 - 2.0*interpolant)*interpolant*interpolant; 
 return compare(vec4(dist1 - (hw - 1.0)), color, compare(vec4(dist1 - hw), color * interpolant, vec4(0.0))) * opacity; 
kernel vec4 _mesh8(vec4 pt1, vec4 pt2, vec4 pt3, vec4 pt4, vec4 pt5, vec4 pt6, vec4 pt7, vec4 pt8, float width, __color color, float opacity) 
 float hw, dist1, dist2, interpolant; 
 vec2 p1, p2, p, v, w, s; 
 hw = width*0.5; 
 p = destCoord(); 
 p1 = pt1.rg; p2 = pt1.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist1 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist1 = compare(v.x*s.x + v.y*s.y, length(v), dist1); 
 w = p - p2; 
 dist1 = compare(w.x*s.x + w.y*s.y, dist1, length(w)); 
 p1 = pt2.rg; p2 = pt2.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt3.rg; p2 = pt3.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt4.rg; p2 = pt4.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt5.rg; p2 = pt5.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt6.rg; p2 = pt6.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt7.rg; p2 = pt7.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt8.rg; p2 = pt8.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 interpolant = clamp(hw - dist1, 0.0, 1.0); 
 interpolant = (3.0 - 2.0*interpolant)*interpolant*interpolant; 
 return compare(vec4(dist1 - (hw - 1.0)), color, compare(vec4(dist1 - hw), color * interpolant, vec4(0.0))) * opacity; 
kernel vec4 _mesh16(vec4 pt1, vec4 pt2, vec4 pt3, vec4 pt4, vec4 pt5, vec4 pt6, vec4 pt7, vec4 pt8, vec4 pt9, vec4 pt10, vec4 pt11, vec4 pt12, vec4 pt13, vec4 pt14, vec4 pt15, vec4 pt16, float width, __color color, float opacity) 
 float hw, dist1, dist2, interpolant; 
 vec2 p1, p2, p, v, w, s; 
 hw = width*0.5; 
 p = destCoord(); 
 p1 = pt1.rg; p2 = pt1.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist1 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist1 = compare(v.x*s.x + v.y*s.y, length(v), dist1); 
 w = p - p2; 
 dist1 = compare(w.x*s.x + w.y*s.y, dist1, length(w)); 
 p1 = pt2.rg; p2 = pt2.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt3.rg; p2 = pt3.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt4.rg; p2 = pt4.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt5.rg; p2 = pt5.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt6.rg; p2 = pt6.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt7.rg; p2 = pt7.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt8.rg; p2 = pt8.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt9.rg; p2 = pt9.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt10.rg; p2 = pt10.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt11.rg; p2 = pt11.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt12.rg; p2 = pt12.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt13.rg; p2 = pt13.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt14.rg; p2 = pt14.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt15.rg; p2 = pt15.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt16.rg; p2 = pt16.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 interpolant = clamp(hw - dist1, 0.0, 1.0); 
 interpolant = (3.0 - 2.0*interpolant)*interpolant*interpolant; 
 return compare(vec4(dist1 - (hw - 1.0)), color, compare(vec4(dist1 - hw), color * interpolant, vec4(0.0))) * opacity; 
kernel vec4 _mesh32(vec4 pt1, vec4 pt2, vec4 pt3, vec4 pt4, vec4 pt5, vec4 pt6, vec4 pt7, vec4 pt8, vec4 pt9, vec4 pt10, vec4 pt11, vec4 pt12, vec4 pt13, vec4 pt14, vec4 pt15, vec4 pt16, vec4 pt17, vec4 pt18, vec4 pt19, vec4 pt20, vec4 pt21, vec4 pt22, vec4 pt23, vec4 pt24, vec4 pt25, vec4 pt26, vec4 pt27, vec4 pt28, vec4 pt29, vec4 pt30, vec4 pt31, vec4 pt32, float width, __color color, float opacity) 
 float hw, dist1, dist2, interpolant; 
 vec2 p1, p2, p, v, w, s; 
 hw = width*0.5; 
 p = destCoord(); 
 p1 = pt1.rg; p2 = pt1.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist1 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist1 = compare(v.x*s.x + v.y*s.y, length(v), dist1); 
 w = p - p2; 
 dist1 = compare(w.x*s.x + w.y*s.y, dist1, length(w)); 
 p1 = pt2.rg; p2 = pt2.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt3.rg; p2 = pt3.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt4.rg; p2 = pt4.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt5.rg; p2 = pt5.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt6.rg; p2 = pt6.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt7.rg; p2 = pt7.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt8.rg; p2 = pt8.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt9.rg; p2 = pt9.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt10.rg; p2 = pt10.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt11.rg; p2 = pt11.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt12.rg; p2 = pt12.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt13.rg; p2 = pt13.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt14.rg; p2 = pt14.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt15.rg; p2 = pt15.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt16.rg; p2 = pt16.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt17.rg; p2 = pt17.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt18.rg; p2 = pt18.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt19.rg; p2 = pt19.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt20.rg; p2 = pt20.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt21.rg; p2 = pt21.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt22.rg; p2 = pt22.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt23.rg; p2 = pt23.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt24.rg; p2 = pt24.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt25.rg; p2 = pt25.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt26.rg; p2 = pt26.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt27.rg; p2 = pt27.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt28.rg; p2 = pt28.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt29.rg; p2 = pt29.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt30.rg; p2 = pt30.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt31.rg; p2 = pt31.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 p1 = pt32.rg; p2 = pt32.ba; 
 v = p - p1; 
 s = p2 - p1; 
 dist2 = abs((v.x*s.y - v.y*s.x) / max(length(s), 0.01)); 
 dist2 = compare(v.x*s.x + v.y*s.y, length(v), dist2); 
 w = p - p2; 
 dist2 = compare(w.x*s.x + w.y*s.y, dist2, length(w)); 
 dist1 = min(dist1, dist2); 
 interpolant = clamp(hw - dist1, 0.0, 1.0); 
 interpolant = (3.0 - 2.0*interpolant)*interpolant*interpolant; 
 return compare(vec4(dist1 - (hw - 1.0)), color, compare(vec4(dist1 - hw), color * interpolant, vec4(0.0))) * opacity; 
_wrapper
originalObject
@"CIFilter"
@"CIImage"
metaFilterForFilter
CIMetaFilter.mm
s0 && s1 && s2 && s3 && s4
ivar is nil for key %@
Not adding new key to class because types are inconsistent (%s & %s)
addKeyForToFilter
success
setValueForObject
value == object_getIvar(object, var)
com.apple.photos.ImageConversionService
Metal compute pipeline state creation failed: %@
Metal render pipeline state creation failed: %@
Failed to create device for prewarming using %@
Failed to create library from %@ for prewarming
Failed to create %@ MTLFunction for prewarming
Failed to create MTLComputePipelineState from %@ for prewarming
%@.%s
Metal command buffer was not committed due to some compile/render failure.
Error executing command buffer = %s (%s)
Aborting ICS due to command buffer error
Metal library creation failed: %@
Cannot get function '%s' from source:
/tmp/%llX.metallib
serializeToURL:error:
Overriding function '%s' with precompiled one in default metallib (from %@).
Metal function creation/specialization failed: %@
AMDStat_GPU_Engine_Ticks
Intel
GPU_CoreClocks
NVIDIA
MTLStatHostElapsedCycles
v32@?0@"<MTLCommandBuffer>"8@"NSData"16Q24
Error requesting counters
MTLStatTotalGPUCycles
MTLStat_nSec
RendererStatsPerfCallback
com.apple.coreimage.perDispatchCommandBuffer
com.apple.coreimage.perDispatchCommandBuffer: %s
_texture
_buffer
Unknown
filterParameters
inputImages
inputImageKeys
+[CIMetalProcessor processWithInputs:arguments:output:error:]
CIMetalWrapper.m
filter
+[CIMetalProcessor roiForInput:arguments:outputRect:]
inputFilterName
kernel vec4 _minimumComponent (__sample s) { return vec4(vec3(min(min(s.r,s.g),s.b)), s.a); }
kernel vec4 _maximumComponent (__sample s) { return vec4(vec3(max(max(s.r,s.g),s.b)), s.a); }
inputPoint
kernel vec2 _mirror (vec2 center, vec3 tst, vec4 off, vec4 mtx) 
 float test = dot(tst.xy, destCoord()) + tst.z; 
 vec2 p = destCoord() - center; 
 p = (test < 0.0) ? p + off.xy : vec2(dot(p, mtx.xy), dot(p, mtx.zw)) + off.zw; 
 return p + center; 
inputCompression
kernel vec4 _modTransition (__sample src0, __sample src1, vec2 center, vec4 parms, vec4 xform, vec4 botparms, vec4 topparms) 
 vec2 offset = destCoord() - center, vv; 
 float r = offset.x * parms.z; 
 float a = botparms.z / (r * botparms.x + botparms.y) + botparms.w; 
 float b = topparms.z / (r * topparms.x + topparms.y) + topparms.w; 
 float v = (r<0.5) ? a : b; 
 vv = vec2(v * parms.w, offset.y); 
 vv = vec2(dot(vv, xform.xy), dot(vv, xform.zw)); 
 vv = fract(vv + center); 
 vv = 2.0 * min(vv, vec2(1.0) - vv); 
 float len = clamp(length(vv)* parms.x + parms.y, 0.0, 1.0); 
 return mix(src1, src0, len); 
kernel vec4 _maxDisk (sampler i, float r) 
 vec2 dc = destCoord(); 
 vec4 v = sample(i, samplerCoord(i)); 
 float rr = ceil(r); 
 float r2 = r*r; 
 float x,y; 
 for (x = -rr; x<=rr; x+=1.0) 
 for (y = -rr; y<=rr; y+=1.0) 
 vec2 p = vec2(x,y); 
 if (dot(p,p)<=r2) 
 v = max(v, sample(i, samplerTransform(i,dc+p))); 
 return v; 
kernel vec4 _minDisk (sampler i, float r) 
 vec2 dc = destCoord(); 
 vec4 v = sample(i, samplerCoord(i)); 
 float rr = ceil(r); 
 float r2 = r*r; 
 float x,y; 
 for (x = -rr; x<=rr; x+=1.0) 
 for (y = -rr; y<=rr; y+=1.0) 
 vec2 p = vec2(x,y); 
 if (dot(p,p)<=r2) 
 v = min(v, sample(i, samplerTransform(i,dc+p))); 
 return v; 
kernel vec4 _max3x3 (sampler s, vec4 d) 
 vec2 p = destCoord (); 
 vec4 c = sample(s, samplerTransform(s, p - d.yy)); 
 c = max(c, sample(s, samplerTransform(s, p - d.wx))); 
 c = max(c, sample(s, samplerTransform(s, p + d.yz))); 
 c = max(c, sample(s, samplerTransform(s, p - d.xw))); 
 c = max(c, sample(s, samplerTransform(s, p ))); 
 c = max(c, sample(s, samplerTransform(s, p + d.xw))); 
 c = max(c, sample(s, samplerTransform(s, p - d.yz))); 
 c = max(c, sample(s, samplerTransform(s, p + d.wx))); 
 c = max(c, sample(s, samplerTransform(s, p + d.yy))); 
 return c; 
kernel vec4 _min3x3 (sampler s, vec4 d) 
 vec2 p = destCoord (); 
 vec4 c = sample(s, samplerTransform(s, p - d.yy)); 
 c = min(c, sample(s, samplerTransform(s, p - d.wx))); 
 c = min(c, sample(s, samplerTransform(s, p + d.yz))); 
 c = min(c, sample(s, samplerTransform(s, p - d.xw))); 
 c = min(c, sample(s, samplerTransform(s, p ))); 
 c = min(c, sample(s, samplerTransform(s, p + d.xw))); 
 c = min(c, sample(s, samplerTransform(s, p - d.yz))); 
 c = min(c, sample(s, samplerTransform(s, p + d.wx))); 
 c = min(c, sample(s, samplerTransform(s, p + d.yy))); 
 return c; 
kernel vec4 _gradient (__sample sMax, __sample sMin) 
 return vec4( (sMax.rgb - sMin.rgb) * .5, sMax.a); 
kernel vec4 _laplacian (__sample s, __sample sMax, __sample sMin) 
 return vec4( (sMax.rgb + sMin.rgb - 2.0 * s.rgb) * .5, s.a); 
kernel vec4 _average (__sample s0, __sample s1, float w) 
 return mix(s0, s1, w); 
kernel vec4 _morphmin (sampler i, float n, vec2 d) 
 vec2 dc = destCoord(); 
 vec4 s = sample(i, samplerTransform(i, dc)); 
 for (float x = -n; x <= n; x++) 
 s = min(s, sample(i, samplerTransform(i, dc + d*x))); 
 return s; 
kernel vec4 _morphmax (sampler i, float n, vec2 d) 
 vec2 dc = destCoord(); 
 vec4 s = sample(i, samplerTransform(i, dc)); 
 for (float x = -n; x <= n; x++) 
 s = max(s, sample(i, samplerTransform(i, dc + d*x))); 
 return s; 
kernel vec4 _motionBlur (sampler src, vec4 parms) 
 vec2 dc = destCoord(); 
 vec4 s0 = sample (src, samplerTransform(src, dc - parms.xy * 2.0)); 
 vec4 s1 = sample (src, samplerTransform(src, dc - parms.xy)); 
 vec4 s2 = sample (src, samplerTransform(src, dc)); 
 vec4 s3 = sample (src, samplerTransform(src, dc + parms.xy)); 
 vec4 s4 = sample (src, samplerTransform(src, dc + parms.xy * 2.0)); 
 vec2 w = parms.zw; 
 return w.x * s2 + w.y * (s3 + s1 + (w.y * (s4 + s0))); 
kernel vec4 _zoomBlur (sampler src, vec2 center, vec4 parms, vec4 w0, float w1) 
 vec2 v = destCoord() - center; 
 vec4 s0 = sample (src, samplerCoord (src)); 
 vec4 s1 = sample (src, samplerTransform (src, v * parms.x + center)); 
 vec4 s2 = sample (src, samplerTransform (src, v * parms.y + center)); 
 vec4 s3 = sample (src, samplerTransform (src, v * parms.z + center)); 
 vec4 s4 = sample (src, samplerTransform (src, v * parms.w + center)); 
 return s4*w0.x + s3*w0.y + s2*w0.z + s1*w0.w + s0*w1; 
kernel vec4 _zoom (sampler src, vec2 center, float k) 
 vec2 dist = destCoord() - center; 
 vec4 result = vec4(0.0); 
 for (int n=0; n<100; n++) 
 float f = float(n) / 99.0; 
 f -= 0.5; 
 f = (f + f*f*f)*0.8 + 0.5; 
 vec2 p = dist * mix(k, 1.0, f); 
 result += sample(src, samplerTransform(src, center + p)) * 0.01; 
 return result; 
kernel vec4 _opTile (sampler src, vec2 center, vec2 params, vec4 trans) 
 vec2 t3; 
 vec2 t1 = destCoord() - center; 
 vec2 t2 = floor (t1 * params.x) * params.y; 
 t1 = t1 - t2; 
 t3.x = dot (t2, trans.xy); 
 t3.y = dot (t2, trans.zw); 
 t1 = t3 + t1 + center; 
 return sample (src, samplerTransform (src, t1)); 
kernel vec4 _pageCurlTransition(sampler front, sampler back, sampler emap, vec4 cyl, vec2 cyloff, vec4 fbrot, vec2 fboff, vec4 hi, vec2 hioff, float radius, vec4 emapExtent) 
 vec2 backPt; 
 vec2 d = destCoord(); 
 vec2 frontPt = backPt = vec2(dot(d,cyl.xy),dot(d,cyl.zw)) + cyloff; 
 float f = frontPt.x; 
 float asn = sqrt(1.0-pow(frontPt.x,1.5)) - 1.0; 
 float v = frontPt.x + asn*asn*0.5625; 
 frontPt.x = v; 
 backPt.x = (3.141592653589793 - v); 
 frontPt = vec2(dot(frontPt,fbrot.xy),dot(frontPt,fbrot.zw)) + fboff; 
 backPt = vec2(dot(backPt,fbrot.xy),dot(backPt,fbrot.zw)) + fboff; 
 frontPt = (f <= 0.0) ? d : frontPt; 
 vec2 highPt = vec2(dot(d,hi.xy),dot(d,hi.zw)) + hioff; 
 backPt = (f <= 0.0) ? highPt : backPt; 
 vec4 fs = sample(front, samplerTransform(front, frontPt)); 
 vec4 bs = sample(back, samplerTransform(back, backPt)); 
 vec2 n = clamp(f * radius * cyl.xy, -1.0, 1.0); 
 vec2 bn0 = ((f < 0.0) ? vec2(0.0) : n); 
 bn0 = bn0 * 0.5 + 0.5; 
 bn0 = bn0 * emapExtent.zw + emapExtent.xy; 
 vec4 es = sample(emap, samplerTransform(emap, bn0)); 
 es *= bs.a; 
 bs = es + (1.0 - es.a) * bs; 
 vec4 pix = bs + (1.0 - bs.a) * fs; 
 pix *= clamp((1.0 - f) * radius, 0.0, 1.0); 
 return pix; 
kernel vec4 _pageCurlTransNoEmap(sampler front, sampler back, vec4 cyl, vec2 cyloff, vec4 fbrot, vec2 fboff, vec4 hi, vec2 hioff, float radius) 
 vec2 backPt; 
 vec2 d = destCoord(); 
 vec2 frontPt = backPt = vec2(dot(d,cyl.xy),dot(d,cyl.zw)) + cyloff; 
 float f = frontPt.x; 
 float asn = sqrt(1.0-pow(frontPt.x,1.5)) - 1.0; 
 float v = frontPt.x + asn*asn*0.5625; 
 frontPt.x = v; 
 backPt.x = (3.141592653589793 - v); 
 frontPt = vec2(dot(frontPt,fbrot.xy),dot(frontPt,fbrot.zw)) + fboff; 
 backPt = vec2(dot(backPt,fbrot.xy),dot(backPt,fbrot.zw)) + fboff; 
 frontPt = (f <= 0.0) ? d : frontPt; 
 vec2 highPt = vec2(dot(d,hi.xy),dot(d,hi.zw)) + hioff; 
 backPt = (f <= 0.0) ? highPt : backPt; 
 vec4 fs = sample(front, samplerTransform(front, frontPt)); 
 vec4 bs = sample(back, samplerTransform(back, backPt)); 
 vec4 pix = bs + (1.0 - bs.a) * fs; 
 pix *= clamp((1.0 - f) * radius, 0.0, 1.0); 
 return pix; 
kernel vec4 _pageCurlWithShadowTransition (sampler front, sampler back, vec4 cyl, vec2 cyloff, vec4 fbrot, vec2 fboff, vec4 hi, vec2 hioff, float radius, vec4 shadowDims, float shadowSize, float shadowAmount, vec4 sheenBright, vec4 sheenDark) 
 float shadowSizeBack = 2.5; 
 float pi = 3.141592653589793; 
 vec2 frontPt, frontPtAlt, backPt, backPtAlt, highPt; 
 vec2 d = destCoord(); 
 vec2 dcyl = vec2(dot(d,cyl.xy),dot(d,cyl.zw)) + cyloff; 
 frontPt = frontPtAlt = dcyl; 
 backPt = backPtAlt = dcyl; 
 float f = frontPt.x; 
 float asn = sqrt(1.0-pow(f,1.5)) - 1.0; 
 frontPt.x = (f <= 0.0) ? f : ((f >= 1.0) ? 9999.0*f : f + asn*asn*0.5625); 
 float ss = f + 0.570796326794897 * smoothstep(0.607,1.3,f); 
 asn = sqrt(1.0-pow(f,1.5)) - 1.0; 
 frontPtAlt.x = (f <= 0.0) ? f : ((f >= 0.9) ? ss : f + asn*asn*0.5625); 
 backPt.x = pi - frontPt.x; 
 backPtAlt.x = pi - frontPtAlt.x; 
 frontPt = vec2(dot(frontPt,fbrot.xy),dot(frontPt,fbrot.zw)) + fboff; 
 frontPtAlt = vec2(dot(frontPtAlt,fbrot.xy),dot(frontPtAlt,fbrot.zw)) + fboff; 
 backPt = vec2(dot(backPt,fbrot.xy),dot(backPt,fbrot.zw)) + fboff; 
 backPtAlt = vec2(dot(backPtAlt,fbrot.xy),dot(backPtAlt,fbrot.zw)) + fboff; 
 frontPtAlt = mix(frontPtAlt, d, 2.0*shadowSize); 
 frontPt = (f < 0.0) ? d : frontPt; 
 highPt = vec2(dot(d,hi.xy),dot(d,hi.zw)) + hioff; 
 backPt = (f < 0.0) ? highPt : backPt; 
 backPtAlt = mix(backPtAlt, highPt, 2.0*shadowSize); 
 vec4 fs = sample(front, samplerTransform(front, frontPt)); 
 fs *= clamp((1.0 - f) * radius, 0.0, 1.0); 
 vec4 bs = sample(back, samplerTransform(back, backPt)); 
 bs *= clamp((1.0 - f) * radius, 0.0, 1.0); 
 float sl = (f<0.0) ? 0.0 : f; 
 sl = clamp(2.5 * (sl - 0.6), 0.0, 1.0); 
 sl = (sl > 0.75) ? (0.4 + 15.0 * (sl - 0.82) * (sl - 0.82)) : (0.35 * sl + 0.375 * sl * sl); 
 vec4 shading = mix(sheenBright, sheenDark, sl); 
 shading *= bs.a; 
 bs = shading + (1.0-shading.a)*bs; 
 vec4 one = vec4(1.0); 
 vec4 zero = vec4(0.0); 
 float light = 0.0; 
 float netH, rr; 
 netH = mix(2.0, 0.5*shadowSizeBack, smoothstep(0.5,1.0,f)); 
 netH = mix(2.3, netH, fs.a); 
 rr = netH * shadowSize * radius; 
 vec4 pp1 = vec4(backPtAlt.xy-shadowDims.xy, shadowDims.zw-backPtAlt.xy)/rr; 
 vec4 v4 = 0.5 + 0.64*pp1 - 0.14*pp1*pp1*pp1; 
 v4 = compare(pp1+one, zero, v4); 
 vec4 ss1 = compare(pp1-one, v4, one); 
 float xx = (1.0-f)/(netH * shadowSize); 
 float fv = 0.5 + 0.64*xx - 0.14*xx*xx*xx; 
 fv = (xx<=-1.0) ? 0.0 : fv; 
 fv = (xx>=1.0) ? 1.0 : fv; 
 light = ss1.x * ss1.y * ss1.z * ss1.w * fv; 
 light = clamp(light, 0.0, 1.0); 
 } float light2; 
 float netH, rr; 
 netH = clamp(f*f,0.0,1.5)*0.65; 
 netH = (f<0.0) ? 0.0 : netH; 
 rr = netH * shadowSize * shadowSizeBack * radius; 
 vec4 pp2 = vec4(frontPtAlt.xy-shadowDims.xy, shadowDims.zw-frontPtAlt.xy)/rr; 
 vec4 v4 = 0.5 + 0.64*pp2 - 0.14*pp2*pp2*pp2; 
 v4 = compare(pp2+one, zero, v4); 
 vec4 ss2 = compare(pp2-one, v4, one); 
 float xx = (1.0-f)/(shadowSize * shadowSizeBack); 
 float fv = 0.5 + 0.64*xx - 0.14*xx*xx*xx; 
 fv = (xx<=-1.0) ? 0.0 : fv; 
 fv = (xx>=1.0) ? 1.0 : fv; 
 light2 = ss2.x * ss2.y * ss2.z * ss2.w * fv; 
 light2 *= 1.0 - fs.a; 
 light2 *= clamp(f*1.0, 0.0, 1.0); 
 light2 = clamp(light2, 0.0, 1.0); 
 if (f<0.0) light2 = 0.0; } light = max(light, light2); 
 light = min(light, 0.5); 
 vec4 shadow = vec4(0.0, 0.0,0.0, light*shadowAmount); 
 vec4 pix = fs; 
 pix = shadow + (1.0-shadow.a)*pix; 
 pix = bs + (1.0-bs.a)*pix; 
 return pix; 
kernel vec4 _pageCurlNoShadowTransition (sampler front, sampler back, vec4 cyl, vec2 cyloff, vec4 fbrot, vec2 fboff, vec4 hi, vec2 hioff, float radius, vec4 sheenBright, vec4 sheenDark) 
 float pi = 3.141592653589793; 
 vec2 d = destCoord(); 
 vec2 dcyl = vec2(dot(d,cyl.xy),dot(d,cyl.zw)) + cyloff; 
 vec2 frontPt = dcyl; 
 vec2 backPt = dcyl; 
 float f = frontPt.x; 
 float asn = sqrt(1.0-pow(f,1.5)) - 1.0; 
 frontPt.x = (f <= 0.0) ? f : ((f >= 1.0) ? 9999.0*f : f + asn*asn*0.5625); 
 backPt.x = pi - frontPt.x; 
 frontPt = vec2(dot(frontPt,fbrot.xy),dot(frontPt,fbrot.zw)) + fboff; 
 backPt = vec2(dot(backPt,fbrot.xy),dot(backPt,fbrot.zw)) + fboff; 
 frontPt = (f < 0.0) ? d : frontPt; 
 vec2 highPt = vec2(dot(d,hi.xy),dot(d,hi.zw)) + hioff; 
 backPt = (f < 0.0) ? highPt : backPt; 
 vec4 fs = sample(front, samplerTransform(front, frontPt)); 
 fs *= clamp((1.0 - f) * radius, 0.0, 1.0); 
 vec4 bs = sample(back, samplerTransform(back, backPt)); 
 bs *= clamp((1.0 - f) * radius, 0.0, 1.0); 
 float sl = (f<0.0) ? 0.0 : f; 
 sl = clamp(2.5 * (sl - 0.6), 0.0, 1.0); 
 sl = (sl > 0.75) ? (0.4 + 15.0 * (sl - 0.82) * (sl - 0.82)) : (0.35 * sl + 0.375 * sl * sl); 
 vec4 shading = mix(sheenBright, sheenDark, sl); 
 shading *= bs.a; 
 bs = shading + (1.0-shading.a)*bs; 
 return bs + (1.0-bs.a)*fs; 
inputShadowSize
inputShadowExtent
inputAcuteAngle
kernel vec2 _parallelogramTile (vec2 center, vec4 ftrans, vec4 btrans) 
 vec2 t2; 
 vec2 t1 = destCoord() - center; 
 t2.x = dot(t1, ftrans.xy); 
 t2.y = dot(t1, ftrans.zw); 
 t2 = fract(t2); 
 t2 = min(t2, vec2(1.0) - t2); 
 t2 = t2 + t2; 
 t1.x = dot(t2, btrans.xy); 
 t1.y = dot(t2, btrans.zw); 
 return t1 + center; 
inputBottomLeft
inputBottomRight
inputTopRight
inputTopLeft
kernel vec2 _perspectiveTransform(vec3 A1, vec3 A2, vec3 A3, vec2 origin) 
 vec3 h = vec3(destCoord(), 1.0); 
 vec2 p = vec2(dot(h, A1), dot(h, A2)); 
 float w = 1.0 / max(dot(h, A3), 0.000001); 
 return p * w + origin; 
kernel vec4 _perspectiveMask(__sample p, vec3 A3) { return p * ((dot(vec3(destCoord(), 1.0), A3)<0.000001) ? 0.0 : 1.0); } 
inputCrop
kernel vec2 _perspectiveCorrection(vec3 A1, vec3 A2, vec3 A3) 
 vec3 h = vec3(destCoord(), 1.0); 
 vec2 p = vec2(dot(h, A1), dot(h, A2)); 
 return p / max(dot(h, A3), 0.000001); 
%@.%d
scube
com.apple.coreimage.photoEffectsIsolation
inputGrainAmount
kernel vec4 _photoEffectDepthBlend (__sample fg, __sample bg, __sample depthMap, const float thresh) 
 float d = min(2.0*depthMap.r, 1.0); 
 vec3 blended = mix(fg.rgb, bg.rgb, d); 
 float g = smoothstep(thresh, thresh+.15, d); 
 blended = mix(fg.rgb, blended, g); 
 return vec4(blended, fg.a); 
%@BG
com.apple.coreimage.photoEffects3DIsolation
inputISO
kernel vec4 _blendGrains(__sample isoImages, float log10iso) 
 vec4 c = isoImages; 
 float mix10_50 = mix(c.r, c.g, log10iso*1.43067655809 
 - 1.43067655809); 
 float mix50_400 = mix(c.g, c.b, log10iso*1.10730936496 
 - 1.88128539659); 
 float mix400_3200 = mix(c.b, c.a, log10iso*1.10730936496 
 - 2.88128539659); 
 float v = compare(log10iso - 1.69897000434, mix10_50, compare(log10iso - 2.60205999133, mix50_400, mix400_3200)); 
 return vec4(v,v,v,1.0); 
kernel vec4 _grainBlendAndMix(__sample img, __sample grainImage, float contrast, float mixAmount) 
 vec3 rgb = img.rgb; 
 float luminance = clamp(dot(rgb, vec3(.333333)), 0.0, 1.0); 
 float gamma = 4.01 - 2.0*luminance; 
 rgb = sign(rgb) * pow(abs(rgb), vec3(1.0/gamma)); 
 float grain = grainImage.r - 0.5; 
 float mult = contrast * grain; 
 rgb += (max(luminance, 0.5) * mult * (1.0-luminance)); 
 rgb = sign(rgb) * pow(abs(rgb), vec3(gamma)); 
 rgb = min(rgb, 1.0); 
 return mix(img, vec4(rgb,img.a), mixAmount); 
kernel vec2 _paddedTile2(vec4 k) { return fract(destCoord() * k.zw) * k.xy + vec2(1.0); }
inputSeed
noiseImage
rgba
kernel vec2 _pinchDistortionScaleLT1(vec2 c, vec4 param) 
 vec2 p = destCoord() - c; 
 float r = length(p) * param.y + .000001; 
 p = p * inversesqrt(r) + c; 
 return mix(destCoord(), p, param.z); 
kernel vec2 _pinchDistortionScaleGE1(vec2 c, vec4 param) 
 vec2 p = destCoord() - c; 
 float r = length(p) * param.y + .000001; 
 vec2 pRGT = pow(r, param.w) * p + c; 
 p = p * inversesqrt(r) + c; 
 p = mix(destCoord(), p, param.z); 
 return (r <= 1.0) ? p : pRGT; 
Invalid scale %g in CIPinchDistortion, must be less than 2
map_point_inv
CIPinchDistortion.m
scale < 2.0
kernel vec2 _pixellate (vec2 c, vec2 params) { return (floor((destCoord() - c) * params.x) + 0.5) * params.y + c; }
kernel vec4 _hexagonalPixellate(sampler src, vec2 center, vec2 skew_to_unit, vec2 unit_to_skew, float sqrt3inv) 
 vec2 t0 = destCoord() - center; 
 vec2 t0_skewed = t0; 
 t0_skewed.x -= t0_skewed.y * sqrt3inv; 
 vec2 t0_unit = t0_skewed * skew_to_unit; 
 vec2 t0_slot = floor(t0_unit); 
 vec2 t0_offset = t0_unit - t0_slot; 
 vec2 t0_base = t0_slot * unit_to_skew; 
 vec2 p0 = t0_base; 
 vec2 p1 = t0_base; 
 p1.y = p1.y + unit_to_skew.y; 
 vec2 p2 = t0_base; 
 p2.x = p2.x + unit_to_skew.x; 
 vec2 p3 = t0_base + unit_to_skew; 
 p0 = compare(vec2(t0_offset.x + t0_offset.y - 1.0), p0, p3); 
 p0.x += p0.y * sqrt3inv; 
 p1.x += p1.y * sqrt3inv; 
 p2.x += p2.y * sqrt3inv; 
 vec2 d0 = t0 - p0; 
 d0 = d0 * d0; 
 float d1 = d0.x + d0.y; 
 vec3 s0 = vec3(p0, d1 * inversesqrt(d1)); 
 d0 = t0 - p1; 
 d0 = d0 * d0; 
 d1 = d0.x + d0.y; 
 vec3 s1 = vec3(p1, d1 * inversesqrt(d1)); 
 d0 = t0 - p2; 
 d0 = d0 * d0; 
 d1 = d0.x + d0.y; 
 vec3 s2 = vec3(p2, d1 * inversesqrt(d1)); 
 vec3 desc = vec3(s0.z - s1.z); 
 vec3 s3 = compare(desc, s0, s1); 
 vec3 s4 = compare(desc, s1, s0); 
 desc = vec3(s3.z - s4.z); 
 vec3 s5 = compare(desc, s3, s2); 
 vec3 s6 = compare(desc, s2, s3); 
 desc = vec3(s4.z - s6.z); 
 vec3 s7 = compare(desc, s4, s6); 
 vec4 c0 = sample(src, samplerTransform(src, s5.xy + center)); 
 vec4 c1 = sample(src, samplerTransform(src, s7.xy + center)); 
 return mix(c0, c1, clamp((s5.z - s7.z) * 0.5 + 0.5, 0.0, 1.0)); 
vec4 _pointillizeStep( sampler src, vec4 background, sampler noise, vec2 cellSize, vec2 noiseOffset, vec2 cellOffset, vec2 dc) 
 float o; 
 float tSize = 256.0; 
 float _randomFactor = 0.65; 
 float _radiusFactor = 0.71; 
 float _colorRandom = 0.1; 
 vec2 noiseLoc = floor(dc*cellSize.y + .5) + noiseOffset; 
 vec4 np = sample(noise, samplerTransform(noise, mod(noiseLoc, tSize))); 
 vec2 cellLoc = (floor(dc*cellSize.y - 0.5) + 0.5) * cellSize.x + 0.5 + cellOffset; 
 cellLoc += (np.xy - 0.5) * cellSize.x * _randomFactor; 
 o = distance(dc, cellLoc); 
 o = clamp((1.0 - o * cellSize.y / _radiusFactor) * 3.0, 0.0, 1.0); 
 o = (3.0 - 2.0 * o) * o * o; 
 vec4 p1 = sample(src, samplerTransform(src, cellLoc)); 
 p1.rgb += vec3(np.b - 0.5) * _colorRandom * p1.a; 
 return mix(background, p1, o); 
 kernel vec4 _pointillize(sampler src, sampler noise, vec4 parms) 
 vec4 background = sample(src, samplerCoord(src)).aaaa; 
 background = _pointillizeStep(src, background, noise, parms.zw, parms.xy + vec2(0.5,0.5), vec2(parms.z,parms.z), destCoord()); 
 background = _pointillizeStep(src, background, noise, parms.zw, parms.xy + vec2(-0.5,0.5), vec2(0,parms.z), destCoord()); 
 background = _pointillizeStep(src, background, noise, parms.zw, parms.xy + vec2(0.5,-0.5), vec2(parms.z,0), destCoord()); 
 background = _pointillizeStep(src, background, noise, parms.zw, parms.xy + vec2(-0.5,-0.5), vec2(0,0), destCoord()); 
 return background; 
inputDraftMode
kernel vec4 _xSmooth(sampler image)
    float v;
    float sum = 0.0;
    float minv = 100.0;
    vec2  dc = destCoord();
    for(int i = -4; i < 5; i++) {
        v = sample(image, samplerTransform(image, dc + vec2(float(i),0.0))).r;
        sum += (v*v) * 0.1111111111;
        minv = min(minv,v);
    }
    return vec4(sqrt(sum),minv,0.0,1.0);
kernel vec4 _ySmooth(sampler image,sampler reference,vec4 blurValues)
    vec2 v;
    float sum = 0.0;
    float minv = 100.0;
    vec2  dc = destCoord();
    for(int i = -4; i < 5; i++) {
        v = sample(image, samplerTransform(image, dc + vec2(0.0,float(i)))).rg;
        sum += (v.r*v.r) * 0.1111111111;
        minv = min(minv,v.g);
    }
    sum = sqrt(sum);
    float refT0 = blurValues.x;
    float refT1 = blurValues.y;
    float minT0 = blurValues.z;
    float minT1 = blurValues.w;
    float ref = sample(reference, samplerCoord(reference)).x;
    float mixWeight = smoothstep(refT0, refT1, ref) * smoothstep(minT0, minT1, minv);
    float result = mix(ref, sum, mixWeight);
    return vec4(result,0.0,0.0,1.0);
nIterations
originalBlurValueT0
originalBlurValueT1
localMinimumBlurValueT0
localMinimumBlurValueT1
vec2 __pseudo_randKY( vec2 pos )
float rand1 = mod(12.63 * pos.x - 57.3 * pos.y * pos.y, 0.01369) 
+ mod(75.833 * pos.y - 37.135 * pos.x * pos.x, 0.014) 
+ mod(39.7 * pos.x * pos.y + 21.7 * pos.x * pos.y * pos.y, 0.0879);
vec2 rand2 = fract(3576.7453 * vec2( rand1, 2.0 * rand1 ));
vec2 rand3 = fract(vec2(7.7387 * (rand2.x + rand2.y), 33.707 * (rand2.x - rand2.y)));
return rand3;
kernel vec4 _CIPortraitBlurNoise(__sample pixBlurred, vec4 params)
    float lumaNoiseAmpl = params.x;
    float lumaNoiseModelCoeff = params.y;
    vec2 randVal = __pseudo_randKY( destCoord() / params.zw );
    float noiseLuma = clamp( sqrt( -2.0 * log(randVal.x) ) * cos( 6.2832 * randVal.y ), -5.0, 5.0 );
    vec4 kRGB_to_Y = vec4( 0.299 , 0.587, 0.114, 0.0);
    float outLuma = dot( pixBlurred, kRGB_to_Y );
    float addLumaNoiseLevel = lumaNoiseAmpl * mix( 1.0, outLuma, lumaNoiseModelCoeff );
    vec4 pixOut = clamp( pixBlurred + (noiseLuma * addLumaNoiseLevel) , 0.0, 1.0);
    pixOut.w = pixBlurred.w;
 return pixOut;
_CIPortraitBlurNoiseM
kernel vec4 _CIPortraitBlurDir(sampler image,vec3 params)
    vec2 dir = params.yz;
    vec2 dc = destCoord(); 
    vec4 pix0 = sample( image, samplerTransform(image, dc -3.0 * dir));
    vec4 pix1 = sample( image, samplerTransform(image, dc -2.0 * dir));
    vec4 pix2 = sample( image, samplerTransform(image, dc - dir));
    vec4 pix3 = sample( image, samplerTransform(image, dc));
    vec4 pix4 = sample( image, samplerTransform(image, dc + dir));
    vec4 pix5 = sample( image, samplerTransform(image, dc + 2.0 * dir));
    vec4 pix6 = sample( image, samplerTransform(image, dc + 3.0 * dir));
    float outW = pix3.w;
    pix0.w = pix0.w * pix0.w;
    pix1.w = pix1.w * pix1.w;
    pix2.w = pix2.w * pix2.w;
    pix3.w = pix3.w * pix3.w;
    pix4.w = pix4.w * pix4.w;
    pix5.w = pix5.w * pix5.w;
    pix6.w = pix6.w * pix6.w;
    float radius = max(params.x * pix3.w, 1e-2);
    float radius2 = 1.0 / (2.0 * radius * radius);
    float weight0 = 1.0;
    float weight1 = exp(-1.0 * radius2);
    float weight2 = weight1 * weight1 * weight1 * weight1;
    float weight3 = weight2 * weight2 * weight1;
    float invWeightSum = 1.0 / (pix0.w * weight3 + pix1.w * weight2 + pix2.w * weight1 + pix3.w * weight0 + pix4.w * weight1 + pix5.w * weight2 + pix6.w * weight3 );
    weight0 *= invWeightSum;
    weight1 *= invWeightSum;
    weight2 *= invWeightSum;
    weight3 *= invWeightSum;
   vec4 pixOut;
   pixOut.xyz = weight3 * pix0.w * pix0.xyz + weight2 * pix1.w * pix1.xyz + weight1 * pix2.w * pix2.xyz 
              + weight0 * pix3.w * pix3.xyz + weight1 * pix4.w * pix4.xyz + weight2 * pix5.w * pix5.xyz 
              + weight3 * pix6.w * pix6.xyz;
   pixOut.w = outW;
    
return pixOut;
_CIPortraitBlurDirM
inputShape
NSString
vec2 _pseudo_randPBN( vec2 pos )
    float rand1 = mod(12.63 * pos.x - 57.3 * pos.y * pos.y, 0.01369) + mod(75.833 * pos.y - 37.135 * pos.x * pos.x, 0.014) + mod(39.7 * pos.x * pos.y + 21.7 * pos.x * pos.y * pos.y, 0.0879);
    vec2 rand2 = fract(3576.7453 * vec2( rand1, 2.0 * rand1 ));
    return fract(vec2(7.7387 * (rand2.x + rand2.y), 33.707 * (rand2.x - rand2.y)));
vec4 _pixWeight( vec4 sampledPix,vec2 offset,float basePixRawR,float distWeight,vec2 spatialWeightSoftMinMax ,float highlightBoostGain,vec2 relativeWeightThreshold) {
    float sampleR = 1.0 / sqrt(offset.x*offset.x + offset.y*offset.y);
    float spatialWeight = clamp(spatialWeightSoftMinMax.x * sampledPix.w * sampleR + spatialWeightSoftMinMax.y, 0.0, 1.0);
    float colorWeight = highlightBoostGain * (sampledPix.x + sampledPix.y + sampledPix.z) + 1.0; 
    float backgroundWeight = (3.0 - 2.0 * sampledPix.w);
    float rwT = clamp(relativeWeightThreshold.x * (sampledPix.w - basePixRawR) + relativeWeightThreshold.y, 0.0, 1.0);
    float relativeWeight = rwT * rwT * (3.0 - 2.0 * rwT); 
    float totalWeight = distWeight * spatialWeight * colorWeight * backgroundWeight * relativeWeight;
    return vec4( totalWeight * sampledPix.xyz, totalWeight );
float _ushortMultiply(float a,float multiplier) {
   int q = int(a) * int(multiplier);
   int r = q/65536;
   int m = q - r * 65536;
   float mf = float(m);
   return mf + compare(mf, 65535.0, 0.0);
kernel vec4 _CIPortraitBlur(sampler image,vec4 sizeAndScale,vec3 p0,vec4 p1,vec2 relativeWeightThreshold) 
   float maxBlurInPixels         = p0.x;
   float sharpRadius             = p0.y;
   float highlightBoostGain      = p0.z;
   vec2 spatialWeightSoftMinMax  = p1.xy;
   float basePixelWeight         = p1.z;
   int numSamples                = int(p1.w);
    vec2 dc = destCoord();
    vec4 basePix = sample(image, samplerCoord(image));
    float rawBlurRadius = basePix.w * basePix.w;
    float blurRadius = rawBlurRadius * maxBlurInPixels;
    vec4 outRGB;
    if ( blurRadius >= sharpRadius )
    {
      vec4 pixSum = vec4(basePix.xyz * basePixelWeight, basePixelWeight);
   vec2 randXY = _pseudo_randPBN(dc/sizeAndScale.xy) * sizeAndScale.zw * 65536.0;
      for ( int i = 0; i < numSamples; i++ )
      {
           vec2 randXY2 = (1./32767.5) * randXY - 1.0; 
           float randDist = randXY2.x*randXY2.x + randXY2.y*randXY2.y;
           float randNorm0 = max(abs(randXY2.x),abs(randXY2.y));
           float randShape = randNorm0 / sqrt(randDist);
           vec2  samplePos = randShape * rawBlurRadius * randXY2;
           float randW = randShape * randShape;
           samplePos.y = -samplePos.y;
           randXY.x = _ushortMultiply(randXY.x, 28563.0);
           randXY.y = _ushortMultiply(randXY.y, 44519.0);
        vec4 pix = sample( image, samplerTransform(image, dc + maxBlurInPixels * samplePos));
           pix.w = pix.w * pix.w;
           pixSum += _pixWeight(pix, samplePos, rawBlurRadius, randW, spatialWeightSoftMinMax, highlightBoostGain, relativeWeightThreshold);
        }
        outRGB.xyz = pixSum.w > 0.0 ?  vec3(pixSum.xyz / pixSum.w) : basePix.xyz;
        outRGB.w = basePix.w;
    }
    else
    {
        outRGB = basePix;
    }
return outRGB;
_CIPortraitBlurM
_CIPortraitBlurShapeM
vec2 _pseudo_randPBNS( vec2 pos )
    float rand1 = mod(12.63 * pos.x - 57.3 * pos.y * pos.y, 0.01369) + mod(75.833 * pos.y - 37.135 * pos.x * pos.x, 0.014) + mod(39.7 * pos.x * pos.y + 21.7 * pos.x * pos.y * pos.y, 0.0879);
    vec2 rand2 = fract(3576.7453 * vec2( rand1, 2.0 * rand1 ));
    return fract(vec2(7.7387 * (rand2.x + rand2.y), 33.707 * (rand2.x - rand2.y)));
float _spatialWeightHearts(vec4 sampledPix,vec2 offset,vec4 shapeOrientation) {
   offset = offset.x * shapeOrientation.xy + offset.y * shapeOrientation.zw;
   vec2 sampleR = vec2(abs(offset.x), -offset.y) / sampledPix.w;
   vec2 v = sampleR - vec2(0.45, -0.217945);
   float lenSquared = v.x * v.x + v.y * v.y;
   bool circleT = lenSquared <= 0.25;
   bool innerT = dot(sampleR, vec2( -0.593342, 0.780268 ))  +0.340111 > 0.0;
   bool tailT  = dot(vec2(sampleR), vec2( -0.842548, -0.780268 )) +0.780268 > 0.0;
   return circleT || (innerT && tailT) ? 1.0 : 0.0;
float _spatialWeightPentagon(vec4 sampledPix,vec2 offset,vec4 shapeOrientation) {
   offset = offset.x * shapeOrientation.xy + offset.y * shapeOrientation.zw;
   vec2 sampleR = vec2(abs(offset.x), -offset.y) / sampledPix.w;
   float v1 =  dot( sampleR, vec2(-0.690758, 0.950983) ) + 0.950983;
   float v2 =  dot( sampleR, vec2(-1.117980, -0.3628144) ) + 0.950984;
   float v3 =  sampleR.y;
   return v1 > 0.0 && v2 > 0.0 && v3 < 0.808738 ? 1.0 : 0.0;
float _spatialWeightRings(vec4 sampledPix,vec2 offset) {
   vec2 sampleR = offset / sampledPix.w;
   float sampleD = length(sampleR);
   return sampleD > 0.3 && sampleD <= 1.0 ? 1.0 : 0.0;
float _spatialWeightStars(vec4 sampledPix,vec2 offset,vec4 shapeOrientation) {
   offset = offset.x * shapeOrientation.xy + offset.y * shapeOrientation.zw;
   vec2 sampleR = vec2(abs(offset.x), -offset.y) / sampledPix.w;
   float t1a = dot( sampleR, vec2(-1.11798, 1.53915) ) - 0.587209;
   float t1b = dot( sampleR, vec2(1.80874, -0.58816) ) - 0.588168;
   float t2a = sampleR.y + 0.30924;
   float t2b = dot( sampleR, vec2( 1.11798, 1.53915 ) ) - 0.587209;
   return ((t1a < 0.0) && (t1b < 0.0)) || ((t2a > 0.0) && (t2b < 0.0)) ? 1.0 : 0.0;
float _spatialWeightSwirl(vec4 sampledPix,vec2 offset,vec4 rotVec) {
    vec2 sampleR = offset / sampledPix.w; 
    float sampleD = length(sampleR.x * rotVec.xy + sampleR.y * rotVec.zw);
    return sampleD <= 1.0 ? 1.0 : 0.0;
float _spatialWeightSwirl2(vec4 sampledPix, vec2 offset, vec2 offsetUV, vec4 rotVec) { 
vec2 sampleR = offset / sampledPix.w; 
vec2 iRotVec = vec2(-rotVec.y, rotVec.x); 
vec2 uv = sampleR.x * rotVec.xy + sampleR.y * iRotVec + offsetUV; 
uv.y = abs(uv.y) +  rotVec.z; 
float sampleD = length(uv); 
float w = sampleD >= 0.8 ? 1.0 : 0.5; 
return sampleD <= 1.0 ? w : 0.0; 
float _spatialWeightSwirl3(vec4 sampledPix, vec2 offset, float radiusScale, vec4 rotVec) { 
vec2 sampleR = offset / sampledPix.w; 
vec2 iRotVec = vec2(-rotVec.y, rotVec.x); 
vec2 uv = sampleR.x * rotVec.xy + sampleR.y * iRotVec; 
uv.y = uv.y > 0.0 ? uv.y : uv.y - rotVec.z; 
float sampleD = length(uv) * radiusScale; 
float w = sampleD >= 0.8 ? 1.0 : 0.5; 
return sampleD <= 1.0 ? w : 0.0; 
vec3 _pixWeightShape( vec4 sampledPix,vec2 offset,float basePixRawR,float distWeight,vec2 spatialWeightSoftMinMax ,float highlightBoostGain,vec2 relativeWeightThreshold,vec4 shapeOrientation,float shape) {
   vec3 spatialWeight = vec3( 0.0, 0.0, 0.0 );
   int shapeN = int(shape);
   if (shapeN == 0) spatialWeight = vec3( _spatialWeightHearts(sampledPix, offset, shapeOrientation) );
   else if ( shapeN == 1 ) spatialWeight = vec3( _spatialWeightPentagon(sampledPix, offset, shapeOrientation) );
   else if ( shapeN == 2 ) spatialWeight = vec3( _spatialWeightRings(sampledPix, offset) );
   else if ( shapeN == 3 ) spatialWeight = vec3( _spatialWeightStars(sampledPix, offset, shapeOrientation) );
   else if ( shapeN == 4 || shapeN == 5 ) spatialWeight = vec3( _spatialWeightSwirl(sampledPix, offset, shapeOrientation) );
   else if ( shapeN == 6 ) {
       spatialWeight.x = _spatialWeightSwirl2(sampledPix, offset, vec2(0,0.1), shapeOrientation);
       spatialWeight.y = _spatialWeightSwirl2(sampledPix, offset, vec2(0,0), shapeOrientation);
       spatialWeight.z = _spatialWeightSwirl2(sampledPix, offset, vec2(0,-0.1), shapeOrientation);
   } else if ( shapeN == 7 ) {
       spatialWeight.x = _spatialWeightSwirl3(sampledPix, offset, 1.1, shapeOrientation);
       spatialWeight.y = _spatialWeightSwirl3(sampledPix, offset, 1.0, shapeOrientation);
       spatialWeight.z = _spatialWeightSwirl3(sampledPix, offset, 1.05, shapeOrientation);
   } else {
      float sampleR = 1.0 / sqrt(offset.x*offset.x + offset.y*offset.y);
      spatialWeight = vec3( clamp(spatialWeightSoftMinMax.x * sampledPix.w * sampleR + spatialWeightSoftMinMax.y, 0.0, 1.0) );
   }
    float colorWeight = highlightBoostGain * (sampledPix.x + sampledPix.y + sampledPix.z) + 1.0; 
    float backgroundWeight = (3.0 - 2.0 * sampledPix.w);
    float rwT = clamp(relativeWeightThreshold.x * (sampledPix.w - basePixRawR) + relativeWeightThreshold.y, 0.0, 1.0);
    float relativeWeight = rwT * rwT * (3.0 - 2.0 * rwT); 
    vec3 totalWeight = distWeight * spatialWeight * colorWeight * backgroundWeight * relativeWeight;
    return totalWeight;
float _ushortMultiply2(float a,float multiplier) {
   int q = int(a) * int(multiplier);
   int r = q/65536;
   int m = q - r * 65536;
   return float(m) + ( m < 0  ? 65536.0 : 0.0);
kernel vec4 _CIPortraitBlurShape( sampler image,vec4 sizeAndScale,vec3 p0,vec4 p1,vec2 relativeWeightThreshold,vec4 shapeV,float shapeN) 
   float maxBlurInPixels         = p0.x;
   float sharpRadius             = p0.y;
   float highlightBoostGain      = p0.z;
   vec2 spatialWeightSoftMinMax  = p1.xy;
   float basePixelWeight         = p1.z;
   int numSamples                = int(p1.w);
    vec2 dc = destCoord();
    vec4 basePix = sample(image, samplerCoord(image));
    float rawBlurRadius = basePix.w * basePix.w;
    float blurRadius = rawBlurRadius * maxBlurInPixels;
  vec2 halfDims = 0.5 * sizeAndScale.xy;
  vec4 rotVec =  (halfDims.yxxy - dc.yxxy);
  float rotLen = length(rotVec.xy);
  float rotLenNorm = 2.0 * rotLen / max(halfDims.x, halfDims.y);
  rotVec *= 1.0 / rotLen;
  if ( int(shapeN) == 5 ) {
    rotVec *= vec4( -1.0 - rotLenNorm, -1.0, 1.0 + rotLenNorm, -1.0 );
    shapeV = rotVec;
  } else if ( int(shapeN) == 4 ) {
    rotVec *= vec4(-1.0, -1.0 - rotLenNorm, 1.0, -1.0 - rotLenNorm);
    shapeV = rotVec;
  } else if ( int(shapeN) == 6 ) {
    shapeV = vec4(rotVec.x, rotVec.y, rotLenNorm/8.0, 0.0);
  } else if ( int(shapeN) == 7 ) {
    shapeV = vec4(rotVec.x, rotVec.y, rotLenNorm/8.0, 0.0);
    vec4 outRGB;
    if ( blurRadius >= sharpRadius )
    {
      vec3 pixSum = basePix.xyz * basePixelWeight;
      vec3 pixWeightSum = vec3( basePixelWeight );
       vec2 randXY = _pseudo_randPBNS(dc/sizeAndScale.xy) * sizeAndScale.zw * 65536.0;
      for ( int i = 0; i < numSamples; i++ )
      {
           vec2 randXY2 = (1./32767.5) * randXY - 1.0; 
           float randDist = randXY2.x*randXY2.x + randXY2.y*randXY2.y;
           float randNorm0 = max(abs(randXY2.x),abs(randXY2.y));
           float randShape = randNorm0 / sqrt(randDist);
           vec2  samplePos = randShape * rawBlurRadius * randXY2;
           float randW = randShape * randShape;
           samplePos.y = -samplePos.y;
           randXY.x = ceil(_ushortMultiply2(randXY.x, 28563.0));
           randXY.y = ceil(_ushortMultiply2(randXY.y, 44519.0));
            vec4 pix = sample( image, samplerTransform(image, dc + maxBlurInPixels * samplePos));
           pix.w = pix.w * pix.w;
           vec3 pixWeight = _pixWeightShape(pix, samplePos, rawBlurRadius, randW, spatialWeightSoftMinMax, highlightBoostGain, relativeWeightThreshold, shapeV, shapeN);
           pixSum += pix.xyz * pixWeight;
           pixWeightSum += pixWeight;
        }
        outRGB.xyz = pixSum / pixWeightSum;
        outRGB.w = basePix.w;
    }
    else
    {
        outRGB = basePix;
    }
    return outRGB;
kernel vec4 _CIPortraitBlurBlendWithMaskFromAlpha(__sample sharp,__sample blurry,vec4 radii ) {
  float maxBlur = radii.x;
  float sharpRadius = radii.y;
  float softRadius = radii.z;
  float width = radii.w;
  float blurRadius = maxBlur * width * blurry.w * blurry.w;
  blurry.w = clamp( (blurRadius - sharpRadius) / softRadius, 0.0, 1.0);
  vec4 c = mix(sharp, blurry, blurry.w);
  c.w = sharp.w;
  return c;
_CIPortraitBlurBlendWithMaskFromAlphaM
CIPortraitBlurPreProcess
inputBlurmapImage
inputUseMetal
/tmp/preprocessed-CI.tiff
sharpRadius
highlightBoostGain
nSamples
spatialWeightSoftMin
spatialWeightSoftMax
relativeWeightThreshold
basePixelWeight
/tmp/blur-CI.tiff
antiAliasBlurStrength
CIPortraitBlurDirectionalBlur
inputHorizontalBlur
inputAntiAliasBlurStrength
/tmp/blur-X-CI.tiff
/tmp/blur-Y-CI.tiff
CIPortraitBlurNoise
inputLumaNoiseAmpl
inputLumaNoiseModelCoeff
lumaNoiseModelCoeff
/tmp/blur-NoiseAddedHalfRes-CI.tiff
/tmp/upsampledBlurredImage.tiff
/tmp/blur-NoiseAddedFullRes-CI.tiff
softRadius
/tmp/finalBlend.tiff
CI_DISABLE_PORTRAIT_METAL
CIPortraitBlurV2
CI_ENABLE_NEW_PORTRAIT
-[CIPortraitBlur outputImage]
CIPortraitBlur.m
kernel vec4 _CIBlurPreProcess(__sample downsampledImage,__sample refinedBlurmap)
{ return vec4(downsampledImage.xyz, refinedBlurmap.x); }
_CIBlurPreProcessM
hearts
pentagons
rings
stars
swirl
warp
lens1
lens2
+[CIHighlightRecoveryProcessor compilePipelineForDevice:functionName:constantValues:]
CIPortraitBlurV2.m
!error
library
function
pipelineState
maxIntensityT0
maxIntensityT1
minIntensityT0
minIntensityT1
V3HLR::kXhlrbTileSize
V3HLR::kXhlrbMaxIntensityThresholdM
V3HLR::kXhlrbMaxIntensityThresholdC
V3HLR::kXhlrbMinIntensityThresholdM
V3HLR::kXhlrbMinIntensityThresholdC
blurRadiusT0
blurRadiusT1
apertureScaling
sparserendering_xhlrb_scan
sparserendering_xhlrb_diffuse
sparserendering_xhlrb_copy_back
+[CIHighlightRecoveryProcessor processWithInputs:arguments:output:error:]
inputW%RENDERING_XHLRB_TILE_SIZE ==0
inputH%RENDERING_XHLRB_TILE_SIZE == 0
XHLRBComputeBlit
XHLRBComputeCompute
iterations
CGRectContainsRect(input.region, output.region)
inputApertureScale
inputBlurRadius
inputMaxIntensity
inputMinIntensity
scale
HighlightRecovery
Required parameter %@ is not specified.
CISDOFHighlightRecovery
_sparserendering_antialias_x
_sparserendering_antialias_y
_sparserendering_antialias_y_no_noise
_noiseGenerator
kernel vec4 _sparserendering_add_noise(__sample inputTex,__sample noiseLumaTex,vec2 params) { float lumaNoiseModelCoeff = params.x; float lumaNoiseAmpl = params.y; vec4 pixBlurred = inputTex; float noiseLuma = noiseLumaTex.x * 10.0 - 5.0; vec3 kRGB_to_Y = vec3( 0.299 , 0.587, 0.114 ); float outLuma = dot( pixBlurred.xyz, kRGB_to_Y ); float addLumaNoiseLevel = lumaNoiseAmpl * mix( 1.0, outLuma, lumaNoiseModelCoeff ); vec4 pixOut; pixOut.xyz = clamp( pixBlurred.xyz + noiseLuma * addLumaNoiseLevel, vec3(0.0), vec3(1.0) ); pixOut.w = pixBlurred.w; return clamp(pixOut, vec4(0.0), vec4(1.0)); }
-[CIPortraitAntialias outputImage:horizontal:]
_sparserendering_prefilter_x
_sparserendering_prefilter_y
preFilterRadius
preFilterBlurStrength
preFilterGain
CIPortraitBlurVr-dumpImage
%@/%@%gx%g.f16
filename = %@
ringAmplitude
ringSharpness
shapeObstructionCoeff
alphaEpsilon
alphaGain
mode
weightGain
intensityGain
_sparserendering_stepLUT
_sparserendering_baseVecLUT
_sparserendering_opt2x_sample_noAlphaLUT
_sparserendering_opt2x_sample_withAlphaLUT
_sparserendering_sample_noAlphaLUT
_sparserendering_sample_withAlphaLUT
_sparserendering_opt2x_sample
_sparserendering_opt2x_sampleWithAlpha
_sparserendering_opt_sample_h
_sparserendering_sample_h
CI_SDOF_LUT
SensorWidth
SensorHeight
defaultSimulatedAperture
CIHighlightRecovery
CISparseRendererPreFiltering
CISparseRenderer
CIPortraitAntialias
inputMaxBlurInPixels
inputAntiAliasRadius
antiAliasRadius
inputRect
inputSensorSize
CIPortraitBlurCombiner
inputBlurImage
_CIPortraitBlurBlendWithMaskFromAlphaWithMatte
kernel vec4 _CIPortraitBlurBlendWithMaskMatteFromAlpha(__sample sharp,__sample blurry,__sample matte,vec4 radii ) {
  float maxBlurWidth = radii.x;
  float sharpRadius = radii.y;
  float softRadius = radii.z;
  float blendingAlphaGain = radii.w;
  float blurRadius = maxBlurWidth * blurry.w * blurry.w;
  blurry.w = clamp( (blurRadius - sharpRadius) / softRadius, 0.0, 1.0);
  blurry.w = min(blurry.w, 1.0 - clamp(blendingAlphaGain * matte.x, 0.0, 1.0)); 
  vec4 c = mix(sharp, blurry, blurry.w);
  c.w = sharp.w;
  return c;
kernel vec4 _CIPortraitBlurBlendWithMaskMatteFromAlphaYCC(__sample sharp,__sample blurry,__sample matte,vec4 radii,float blendingAlphaGainChroma) {
  float maxBlurWidth = radii.x;
  float sharpRadius = radii.y;
  float softRadius = radii.z;
  float blendingAlphaGainLuma = radii.w;
  float blurRadius = maxBlurWidth * blurry.w * blurry.w;
  float blurMapBackgroundAlpha = clamp( (blurRadius - sharpRadius) / softRadius, 0.0, 1.0); 
  float chromaBackgroundAlpha = min( blurMapBackgroundAlpha, 1.0 - clamp( blendingAlphaGainChroma * matte.x, 0.0, 1.0) ); 
  float lumaBackgroundAlpha = min( blurMapBackgroundAlpha, 1.0 - clamp( blendingAlphaGainLuma * matte.x, 0.0, 1.0) ); 
  vec4 c = vec4(mix(sharp, blurry, blurry.w).xyz, sharp.w); 
  if ( chromaBackgroundAlpha < 1.0 ) { 
     vec3 mixV = vec3(lumaBackgroundAlpha, chromaBackgroundAlpha, chromaBackgroundAlpha); 
     c.xyz = mix(mixV, c.xyz, chromaBackgroundAlpha); 
  return c; 
blendingQuarterResAlphaGain
blendingFullResAlphaGain
nRings
None
8.dng
7.dng
6.dng
+[CIFilter(CIRAWFilter) filterWithImageURL:options:]
inputEnableNoiseTracking
inputNoiseReductionAmount
inputEnableSharpening
inputEnableVendorLensCorrection
inputDisableGamutMap
inputLuminanceNoiseReductionAmount
inputColorNoiseReductionAmount
inputNoiseReductionSharpnessAmount
inputNoiseReductionContrastAmount
inputNoiseReductionDetailAmount
inputMoireAmount
inputBaselineExposure
inputBoost
inputBoostShadowAmount
inputNeutralChromaticityX
inputNeutralChromaticityY
inputNeutralTemperature
inputNeutralTint
inputNeutralLocation
inputScaleFactor
inputIgnoreOrientation
inputImageOrientation
inputLinearSpaceFilter
inputDecoderVersion
supportedDecoderVersions
outputNativeSize
inputEnableEDRMode
inputLocalToneMapAmount
activeKeys
properties
CoreImage
__TEXT
__inpbpm
+[InpaintingTilingFilter initializeBoundaryPreservingTile]_block_invoke
inputReturnDemosaiced
CreateListOfSupportedCamerasAndVersions
CIFilter
inputHueMagMR
inputHueMagRY
inputHueMagYG
inputHueMagGC
inputHueMagCB
inputHueMagBM
inputRequestedSushiMode
RCCreateCIImageFromBufferAndProperties
raw-image
kCGImageSourceShouldUseRawDataForFulleSize
kCGImageSourceShouldUseRawDataForFullSize
kCGImageSourceSupportedSushiLevels
{Raw}
version
filters
RAWDemosaicFilter
RAWGamutMap
inputGamutMapMax
RAWReduceNoise
inputLNRAmount
inputCNRAmount
inputSharpenAmount
inputContrastAmount
inputDetailAmount
RAWRadialLensCorrection
inputLDCExecuteFlags
RAWConvert
inputNeutral
RAWAdjustTempTint
inputWhitePoint
RAWAdjustExposureAndBias
inputExposure
RAWHueMagnet
RAWAdjustColorTRC
inputBoostAmount
inputReferencePoints
inputBoostHDRAmount
inputTRCy3
inputTRCs3
inputTRCy4
inputTRCs4
RAWAdjustColors
RAWTemperatureAdjust
RAWLinearSpacePlaceholder
RAWProfileGainTableMap
kCGImageSourceNoiseReductionAmount
kCGImageSourceLuminanceNoiseReductionAmount
kCGImageSourceColorNoiseReductionAmount
kCGImageSourceNoiseReductionSharpnessAmount
kCGImageSourceNoiseReductionContrastAmount
kCGImageSourceNoiseReductionDetailAmount
kCGImageSourceChromaBlurMoireAmount
kCGImageSourceDisableVendorLensDistortionCorrection
kCGImageSourceUseEDRMode
inputNeutralXY
PixelWidth
PixelHeight
{Raw}.filters
inputCropRect
{Exif}.PixelXDimension
{Exif}.PixelYDimension
RAWCropFilter
-[CIRAWFilterImpl(CustomAccessors) inputImage]
CIRAWFilterImpl.m
_inputImage != nil
-[CIRAWFilterImpl(CustomAccessors) setInputDecoderVersion:]
kCGImageSourceReturnDemosaiced
RAWProfileGainTableMap.inputStrength
kCGImageSourceVendorLensCorrectionFeatures
RAWAdjustExposureAndBias.inputBias
RAWAdjustExposureAndBias.inputBaselineExposure
RAWHueMagnet.inputHueMagMR
RAWHueMagnet.inputHueMagRY
RAWHueMagnet.inputHueMagYG
RAWHueMagnet.inputHueMagGC
RAWHueMagnet.inputHueMagCB
RAWHueMagnet.inputHueMagBM
bsamt
RAWLensCorrectionDNG
RAWRadialLensCorrectionRB
Invalid parameter not satisfying: %@
(rVector != nil) && (gVector != nil) && (bVector != nil)
Kernel %@ should be of class CIColorKernel
mc00
mc01
mc02
mc10
mc11
mc12
mc20
mc21
mc22
bknd
btpnt
btwid
blamt
bamt
otrcS0
otrcS1
otrcS2
otrcS3
otrcS4
otrcY1
otrcY2
otrcY3
kernel vec4 _convertUsingColorMatrix(__sample pix, vec4 rv, vec4 gv, vec4 bv) { 
 vec4 color = pix.r * rv + pix.g * gv + pix.b * bv; 
 color.a = pix.a; 
 return color; 
CIRAWGamutMapping: key %@ was not found in the RAW dictionary
kernel vec4 _localBoost(__sample color, vec4 breaks, vec4 coeffs1, vec4 coeffs2, vec4 coeffs3, vec4 coeffs4, float scaleAboveOne) { 
 float x; 
 vec4 powers, interval1, interval2, interval3, interval4, answer; 
 x = color.r; 
 powers.rgb = vec3(x); 
 powers.rg = powers.rg * vec2(x); 
 powers.r = powers.r * x; 
 powers.a = 1.0; 
 interval1.r = dot(powers, coeffs1); 
 interval2.r = dot(powers, coeffs2); 
 interval3.r = dot(powers, coeffs3); 
 interval4.r = dot(powers, coeffs4); 
 answer.r = (x - 1.0) * scaleAboveOne + 1.0; 
 x = color.g; 
 powers.rgb = vec3(x); 
 powers.rg = powers.rg * vec2(x); 
 powers.r = powers.r * x; 
 powers.a = 1.0; 
 interval1.g = dot(powers, coeffs1); 
 interval2.g = dot(powers, coeffs2); 
 interval3.g = dot(powers, coeffs3); 
 interval4.g = dot(powers, coeffs4); 
 answer.g = (x - 1.0) * scaleAboveOne + 1.0; 
 x = color.b; 
 powers.rgb = vec3(x); 
 powers.rg = powers.rg * vec2(x); 
 powers.r = powers.r * x; 
 powers.a = 1.0; 
 interval1.b = dot(powers, coeffs1); 
 interval2.b = dot(powers, coeffs2); 
 interval3.b = dot(powers, coeffs3); 
 interval4.b = dot(powers, coeffs4); 
 answer.b = (x - 1.0) * scaleAboveOne + 1.0; 
 answer = compare(color - breaks.w, interval4, answer); 
 answer = compare(color - breaks.z, interval3, answer); 
 answer = compare(color - breaks.y, interval2, answer); 
 answer = compare(color - breaks.x, interval1, answer); 
 answer = compare(color, vec4(0.0), answer); 
 answer.a = color.a; 
 return answer; 
kernel vec4 _boostRGB(__sample color, vec4 breaks, vec4 coeffs1, vec4 coeffs2, vec4 coeffs3, vec4 coeffs4, float scaleAboveOne) { 
 float x; 
 vec4 powers, interval1, interval2, interval3, interval4, answer; 
 x = color.r; 
 powers.rgb = vec3(x); 
 powers.rg = powers.rg * vec2(x); 
 powers.r = powers.r * x; 
 powers.a = 1.0; 
 interval1.r = dot(powers, coeffs1); 
 interval2.r = dot(powers, coeffs2); 
 interval3.r = dot(powers, coeffs3); 
 interval4.r = dot(powers, coeffs4); 
 answer.r = (x - 1.0) * scaleAboveOne + 1.0; 
 x = color.g; 
 powers.rgb = vec3(x); 
 powers.rg = powers.rg * vec2(x); 
 powers.r = powers.r * x; 
 powers.a = 1.0; 
 interval1.g = dot(powers, coeffs1); 
 interval2.g = dot(powers, coeffs2); 
 interval3.g = dot(powers, coeffs3); 
 interval4.g = dot(powers, coeffs4); 
 answer.g = (x - 1.0) * scaleAboveOne + 1.0; 
 x = color.b; 
 powers.rgb = vec3(x); 
 powers.rg = powers.rg * vec2(x); 
 powers.r = powers.r * x; 
 powers.a = 1.0; 
 interval1.b = dot(powers, coeffs1); 
 interval2.b = dot(powers, coeffs2); 
 interval3.b = dot(powers, coeffs3); 
 interval4.b = dot(powers, coeffs4); 
 answer.b = (x - 1.0) * scaleAboveOne + 1.0; 
 answer = compare(color - breaks.w, interval4, answer); 
 answer = compare(color - breaks.z, interval3, answer); 
 answer = compare(color - breaks.y, interval2, answer); 
 answer = compare(color - breaks.x, interval1, answer); 
 answer = compare(color, vec4(0.0), answer); 
 answer = compare(answer, vec4(0.0), answer); 
 answer.a = color.a; 
 return answer; 
kernel vec4 _boostRGBLNoGamma(__sample color, vec4 breaks, vec4 coeffs1, vec4 coeffs2, vec4 coeffs3, vec4 coeffs4, float scaleAboveOne) { 
 float x, luminance; 
 vec4 powers, interval1, interval2, interval3, interval4, answer, xcolor; 
 x = color.r; 
 powers.rgb = vec3(x); 
 powers.rg = powers.rg * vec2(x); 
 powers.r = powers.r * x; 
 powers.a = 1.0; 
 interval1.r = dot(powers, coeffs1); 
 interval2.r = dot(powers, coeffs2); 
 interval3.r = dot(powers, coeffs3); 
 interval4.r = dot(powers, coeffs4); 
 x = color.g; 
 powers.rgb = vec3(x); 
 powers.rg = powers.rg * vec2(x); 
 powers.r = powers.r * x; 
 powers.a = 1.0; 
 interval1.g = dot(powers, coeffs1); 
 interval2.g = dot(powers, coeffs2); 
 interval3.g = dot(powers, coeffs3); 
 interval4.g = dot(powers, coeffs4); 
 x = color.b; 
 powers.rgb = vec3(x); 
 powers.rg = powers.rg * vec2(x); 
 powers.r = powers.r * x; 
 powers.a = 1.0; 
 interval1.b = dot(powers, coeffs1); 
 interval2.b = dot(powers, coeffs2); 
 interval3.b = dot(powers, coeffs3); 
 interval4.b = dot(powers, coeffs4); 
 luminance = dot(color.rgb, vec3(0.299, 0.587, 0.114)); 
 x = luminance; 
 powers.rgb = vec3(x); 
 powers.rg = powers.rg * vec2(x); 
 powers.r = powers.r * x; 
 powers.a = 1.0; 
 interval1.a = dot(powers, coeffs1); 
 interval2.a = dot(powers, coeffs2); 
 interval3.a = dot(powers, coeffs3); 
 interval4.a = dot(powers, coeffs4); 
 xcolor = color; 
 xcolor.a = luminance; 
 answer = xcolor*scaleAboveOne + vec4(1.0-scaleAboveOne); 
 answer = compare(xcolor - breaks.w, interval4, answer); 
 answer = compare(xcolor - breaks.z, interval3, answer); 
 answer = compare(xcolor - breaks.y, interval2, answer); 
 answer = compare(xcolor - breaks.x, interval1, answer); 
 return answer; 
kernel vec4 _boostHybrid(__sample color, sampler rgblboostnogamma, float transitionBreakpoint, float transitionWidth, float luminanceAmount) { 
 float luminance, factor, interpolant; 
 vec4 xcolor, answer; 
 luminance = dot(color.rgb, vec3(0.299, 0.587, 0.114)); 
 answer = sample(rgblboostnogamma, samplerCoord(rgblboostnogamma)); 
 xcolor = color; 
 xcolor.a = luminance; 
 answer = compare(xcolor, vec4(0.0), answer); 
 answer = max(answer, vec4(0.0)); 
 factor = answer.a / max(luminance, 0.000001); 
 color.rgb = color.rgb * vec3(factor); 
 color.rgb = max(color.rgb, vec3(0.0)); 
 interpolant = clamp((luminance - (transitionBreakpoint - transitionWidth * 0.5)) / transitionWidth, 0.0, 1.0); 
 interpolant = 1.0 - ((3.0 - 2.0 * interpolant) * interpolant * interpolant); 
 interpolant = interpolant * luminanceAmount; 
 color.rgb = mix(answer.rgb, color.rgb, interpolant); 
 return color; 
com.apple.coreimage
signpost_perspectiveAC
CIPerspectiveAutoCalc
saliencyHeatMap
focalLength
lineSearchRangeV
lineSearchRangeH
pitchLimit
yawLimit
rollLimit
generateDebugImage
minimumPitchCorrectionArea
minimumYawCorrectionArea
inputFocalLength
inputPitch
inputYaw
inputRoll
confidence
debugImage
pitchFailureReason
yawFailureReason
pitchCorrectionAreaCoverage
yawCorrectionAreaCoverage
unlimitedPitch
unlimitedYaw
unlimitedRoll
CIPerspectiveAutoCalcDefaultImpl
CIPerspectiveAutoCalc.mm
com.apple.CoreImage.PerspectiveACVersion
kernel vec2 _paddedTile(vec4 k) { return fract(destCoord() * k.zw) * k.xy + vec2(1.0); }
Invalid CIDetectorMinFeatureSize specified. Ignoring.
Invalid optionMaxCount specified. Ignoring.
Cannot find features in an infinite image.
Unable to create a VNDetectRectanglesRequest.
VNRequestOptionDetectionLevel_Fast
VNRequestOptionDetectionLevel
VNDetectRectanglesRequest
Class getVNDetectRectanglesRequestClass()_block_invoke
NSString *getVNImageOptionCIContext()
VNImageOptionCIContext
kernel vec4 _rectangle (vec4 parms1, vec4 parms2, __color color) 
 vec4 d0 = destCoord().xxyy; 
 d0 = d0 * parms1 + parms2; 
 d0 = clamp(max(d0, d0.yxwz), 0.0, 1.0); 
 d0 = 1.0 - smoothstep(0.0, 1.0, d0); 
 return d0.x * d0.z * color; 
kernel vec4 _roundedrect(vec4 bounds, float radius, __color color) 
 vec2 p = destCoord(); 
 vec2 lo = bounds.xy; 
 vec2 hi = bounds.zw; 
 p = max(min(p-(lo+radius),0.0),p-(hi-radius)); 
 return color * clamp((radius - length(p) + 0.5)*1.5, 0.0, 1.0); 
convexHull
pointX
undefined
CIRedEyeCorrections %lu
CIRedEyeCorrection
x = %.5f, y = %.5f, width = %.5f, height = %.5f, alpha = 0.0244, density = 0.86, strength = 0.0757, redBias = 0.253, pupilSize = 0.50, pupilDarkenAmount = 0.75
pointY
size
%@ %@ %@
%@ %@ %@ %@
pupilShadeLow
pupilShadeMedium
pupilShadeHigh
pupilShadeAverage
interocularDistance
%@ %@
snappedX
snappedY
bitmaskX
bitmaskY
bitmaskThreshold
cornealReflectionX
cornealReflectionY
cornealReflectionThreshold
existingPupilLow
existingPupilMedium
existingPupilHigh
existingPupilAverage
averageSkinLuminance
searchRectangleMinimumY
searchRectangleMaximumY
searchRectangleMinimumX
searchRectangleMaximumX
repairRectangleMinimumY
repairRectangleMaximumY
repairRectangleMinimumX
repairRectangleMaximumX
forceCase
pupilShadeAlignment
finalEyeCase
RedEyeW
fullImageWidth
RedEyeH
fullImageHeight
RedEyeISV
imageSpecialValue
RedEyeOrt
imageOrientation
RedEyeSNR
imageSignalToNoiseRatio
RedEyeModel
x = %.5f, y = %.5f, width = 10.0, height = 10.0, alpha = 0.0244, density = 0.86, strength = 0.0757, redBias = 0.253, pupilSize = 0.50, pupilDarkenAmount = 0.75
faceRect
leftPoly0
leftPoly1
leftPoly2
leftPoly3
leftPoly4
leftPoly5
leftPoly6
leftPoly7
%@ %@ %@ %@ %@ %@ %@ %@ %@ %@ %@ %@ %@ %@ %@ %@
leftRect
leftDistMatrix
rightPoly0
rightPoly1
rightPoly2
rightPoly3
rightPoly4
rightPoly5
rightPoly6
rightPoly7
rightRect
rightDistMatrix
counterClockwise
maxPoints
nPoints
hullBody
%@ %@ %@ %@ %@ %@
%@ %@ %@ %@ %@ %@ %@ %@
ioffx
ioffy
xPosition
saturation
luminance
skinval
avgLuminance
minLuminance
maxLuminance
darkPercent
clipPercent
variance
nNonZero
settings
%@ %@ %@ %@ %@
faceIndex
side
%@ %@ %@ %@ %@ %@ %@ %@ %@ %@
alignmentTolerance
capture
connectThreshold
downsampleOversizeX
downsampleOversizeY
downsampleType
gradientChannel
edgeFindingChannel
minMagnitude
regressionRadius
transform
http://ns.apple.com/adjustment-settings/1.0/sType/redeye
RedEyeCorrections
RedEyeInfo
http://ns.apple.com/adjustment-settings/1.0/sType/red-eye
CIRedEyeCorrection_processor
vImageConvert_Planar16FtoPlanar8 error %zi in CIRedEyeCorrection
Unknown input pixel format in CIRedEyeCorrection %i
cameraModel
vImageConvert_Planar8toPlanar16F error %zi in CIRedEyeCorrection
Unknown output pixel format in CIRedEyeCorrection %i
CI_PRINT_TIME%.*s %s(c:%llu, n:%llu) = %.3gms
CI_PRINT_TIME%.*s %s(c:%llu) = %.3gms
CI_PRINT_TIME%.*s %s = %.3gms
red-eye repair dictionary is of unknown type
processingResolution
executionContext
espressoResources
+[InpaintingSinglePassFilter processWithInputs:arguments:output:error:]
+[InpaintingSinglePassFilter performInpaintingAndBlendingOnSRGBImage:usingThresholdedMask:blendingRadius:inpaintingResourceDescriptor:espressoResources:executionContext:]
forceFail
iPhone X
iPhone 4
KODAK
inspector
centerX
centerY
face %d   left (%.1f, %.1f) right (%.1f, %.1f) IOD %.1f
face %d   mouth (%.1f, %.1f) center (%.1f, %.1f)
face %d   nose bridge (%.1f, %.1f) tip (%.1f, %.1f)
face %d   left eye l (%.1f, %.1f) u (%.1f, %.1f) r (%.1f, %.1f) d (%.1f, %.1f)
face %d   right eye l (%.1f, %.1f) u (%.1f, %.1f) r (%.1f, %.1f) d (%.1f, %.1f)
red-eye correction was prevented: no face detected
red-eye correction was prevented: (face %d) features too small to resolve properly
L[xp %.3f hue %.3f sat %.3f lum %.1f] 
R[xp %.3f hue %.3f sat %.3f lum %.1f] 
%s (L) prevent sclera repair
%s (L) prevent shine repair
%s (R) prevent sclera repair
%s (R) prevent shine repair
mutableCopyOfArray: %s
bad repair dictionary
could not allocate repair product
zero length convex hull
could not allocate convex hull radial stuff
degenerate convex hull
could not allocate alpha mask
could not allocate widened convex hull
could not allocate repair dictionary
could not allocate resampled original bitmap
could not allocate color space
could not allocate 4 channel difference map
could not allocate difference map
could not allocate gradient map
could not allocate 4 channel glint map
could not allocate glint map
empty eye rectangle
illegal downsample type
could not initialize grid
could not increase grid oint allocation
could not allocate points for thread closure
attempting closure of invalid thread
could not allocate convex hull
could not measure shape of thread
could not allocate points when improving shape
could not add more points when improving shape
could not allocate shape points
nor enough points allocated to shape
could not allocate shape points on copy
too many threads
net numbers change within a thread!
could not increase shape allocation
attempt to gather info on invalid thread
could not increase thread allocation
degenerate line equation
number preceeding greater than zero, yet threadPrev is -1
could not allocate space to copy grid
convex hull failed convexity test
attempt to compute convex hull of invalid thread
could not allocate bitmap context
zero length segment
segments are collinear
could not allocate convex hull mask
could not allocate line equations
thread number of points mismatch
thread is degenerate
attempt to connect to invalid thread
could not increase convex hull point allocation
could not allocate convex hull bitmap
too many points in grid
illegal eye index
illegal gradient channel
could not allocate face bitmap
no repair
could not allocate max buffer
could not find gradient edge
could not allocate eye polygon map
disqualified sclera repair
disqualified shine repair
unknown error code
RedEye.ci
%@_%d
kernel vec4 _drr_puncturec2(__sample center, float r, float hardness, vec2 s) __attribute__((outputFormat(kCIFormatRh))) { vec2 p = destCoord(); float d = (p.x-center.x)*(p.x-center.x)*s.x + (p.y-center.y)*(p.y-center.y)*s.y; d = 1.0 - smoothstep(hardness*r*r, r*r, d); return vec4(d, 0.0, 0.0, 1.0); }
kernel vec4 _drr_puncturec2_hard(__sample center, float r, float hardness, vec2 s) __attribute__((outputFormat(kCIFormatRh))) { vec2 p = destCoord(); float d = (p.x-center.x)*(p.x-center.x)*s.x + (p.y-center.y)*(p.y-center.y)*s.y; return vec4(d <= r*r ? 1.0 : 0.0); }
kernel vec4 _drr_maximumRh(__sample a, __sample b) __attribute__((outputFormat(kCIFormatRh))) { return max(a, b); }
kernel vec4 _drr_combine_rgba(__sample r, __sample g, __sample b, __sample a) { return vec4(r.x, g.x, b.x, a.x); }
kernel vec4 _drr_r(__sample c) __attribute__((outputFormat(kCIFormatR8))) { return vec4(c.r, 0.0, 0.0, 1.0); }
kernel vec4 _drr_g(__sample c) __attribute__((outputFormat(kCIFormatR8))) { return vec4(c.g, 0.0, 0.0, 1.0); }
kernel vec4 _drr_b(__sample c) __attribute__((outputFormat(kCIFormatR8))) { return vec4(c.b, 0.0, 0.0, 1.0); }
kernel vec4 _drr_a(__sample c) __attribute__((outputFormat(kCIFormatR8))) { return vec4(c.a, 0.0, 0.0, 1.0); }
kernel vec4 _drr_smoothstepRh(__sample m, float cutoff) __attribute__((outputFormat(kCIFormatRh))) { return vec4(smoothstep(0.0, cutoff, m.r), 0.0, 0.0, 1.0); }
kernel vec4 _drr_maxmask(__sample a, __sample b) __attribute__((outputFormat(kCIFormatRh))) { return a.r > 0.0 ? max(a,b) : a; }
kernel vec4 _drr_maxScalarRh(__sample a, float v) __attribute__((outputFormat(kCIFormatRh))) { a.r = max(a.r, v); return a; }
kernel vec4 _drr_minimumRh(__sample a, __sample b) __attribute__((outputFormat(kCIFormatRh))) { return min(a,b); }
kernel vec4 _drr_multiply(__sample a, __sample b) __attribute__((outputFormat(kCIFormatRh))) { return a*b; }
kernel vec4 _drr_refilter_chan(__sample img) { return vec4(img.r, img.r, img.r, img.a); }
kernel vec4 _drr_binarize(__sample m) __attribute__((outputFormat(kCIFormatRh))) { m.r = m.r > 0.00001 ? 1.0 : 0.0; return m; }
kernel vec4 _drr_binarize_inv(__sample m) __attribute__((outputFormat(kCIFormatRh))) { m.r = m.r > 0.00001 ? 0.0 : 1.0; return m; }
kernel vec4 _drr_binarize_alpha(__sample c, __sample m, float t) __attribute__((outputFormat(kCIFormatRGBAh))) { c *= m.r > 0.001 ? 1.0 : 0.0; c *= min(1.0-c.r, c.r) > t ? 1.0 : 0.0; return c; }
kernel vec4 _drr_binarize_alpha_inv(__sample c, __sample m, float t) __attribute__((outputFormat(kCIFormatRGBAh))) { c *= m.r > 0.001 ? 0.0 : 1.0; c *= min(1.0-c.r, c.r) > t ? 1.0 : 0.0; return c; }
kernel vec4 _drr_conditionalZeroRh(__sample img, __sample mask, float threshold) __attribute__((outputFormat(kCIFormatRh))) { return img * (mask.r > threshold ? 1.0 : 0.0); }
kernel vec4 _drr_chromaexc(__sample outside, __sample inside, float t2, float thresholdSclera, float thresholdScleraBrightness) __attribute__((outputFormat(kCIFormatRh))) { vec3 diff = inside.rgb-outside.rgb; float n = min(inside.r, outside.r); float exc = dot(diff, diff) < t2*n ? 0.0 : 1.0; float redness = max(inside.r-min(inside.g, inside.b), 0.0) / max(0.00001, inside.r); exc *= (inside.r > thresholdScleraBrightness && redness < thresholdSclera) ? 0.0 : 1.0; return vec4(exc, 0.0, 0.0, 1.0) ; }
kernel vec4 _drr_detect_specs(__sample primary, __sample secondary, float tuning, float cutoff) __attribute__((outputFormat(kCIFormatRh))) { float spec2 = min(secondary.r, secondary.b) * max(0.0, sign(secondary.b-tuning*secondary.g)); float s = spec2 * max(0.0, sign(spec2-cutoff)); return vec4(1.0-s, 0.0, 0.0, 1.0); }
kernel vec4 _drr_mmv(vec2 center, vec2 u, vec2 v, float c, float s, float normu, float normv, float plateau) __attribute__((outputFormat(kCIFormatRh))) { vec2 p = destCoord(); vec2 w = p-center; vec2 qu = w - dot(w,u) * u; vec2 qv = w - dot(w,v) * v; float du = sqrt(dot(qu,qu)) * normu; float dv = sqrt(dot(qv,qv)) * normv; float mu = 1.0-smoothstep(s*c, c, du); float mv = 1.0-smoothstep(s*c, c, dv); float m = mu*mv; m = m > plateau ? 1.0 : m; return vec4(m, 0.0, 0.0, 1.0); }
kernel vec4 _drr_mmi(__sample center, float2 u, float2 v, float c, float s, float normu, float normv, float plateau) __attribute__((outputFormat(kCIFormatRh))) { vec2 p = destCoord(); vec2 w = p-center.xy; vec2 qu = w - dot(w,u) * u; vec2 qv = w - dot(w,v) * v; float du = sqrt(dot(qu,qu)) * normu; float dv = sqrt(dot(qv,qv)) * normv; float mu = 1.0-smoothstep(s*c, c, du); float mv = 1.0-smoothstep(s*c, c, dv); float m = mu*mv; m = m > plateau ? 1.0 : m; return vec4(m, 0.0, 0.0, 1.0); }
RRradialEllipticalMask
CIRedEyeUtils.mm
kernel vec4 _drr_puncture2(vec2 center, float r, float hardness, vec2 s) __attribute__((outputFormat(kCIFormatRh))) { vec2 p = destCoord(); float d = (p.x-center.x)*(p.x-center.x)*s.x + (p.y-center.y)*(p.y-center.y)*s.y; d = 1.0-smoothstep(hardness*r*r, r*r, d); return vec4(d, 0.0, 0.0, 1.0); }
kernel vec4 _drr_puncture2_hard(vec2 center, float r, float hardness, vec2 s) __attribute__((outputFormat(kCIFormatRh))) { vec2 p = destCoord(); float d = (p.x-center.x)*(p.x-center.x)*s.x + (p.y-center.y)*(p.y-center.y)*s.y; return vec4(d <= r*r ? 1.0 : 0.0); }
kernel vec4 _drr_rcsoft(__sample center, float scale2, float hardness, float norm) __attribute__((outputFormat(kCIFormatRh))) { vec2 p = destCoord(); float d = (p.x-center.x)*(p.x-center.x)*norm + (p.y-center.y)*(p.y-center.y)*norm; d = 1.0-smoothstep(hardness*scale2, scale2, d); return vec4(d, 0.0, 0.0, 1.0); }
kernel vec4 _drr_pclip(__sample c, float t) { c.r = c.r < t ? 0.0 : c.r; c.g = c.g < t ? 0.0 : c.g; c.b = c.b < t ? 0.0 : c.b; return c; }
kernel vec4 _drr_specular(__sample c) __attribute__((outputFormat(kCIFormatRh))) { return float4(0.5*(c.r+c.g+c.b-min(min(c.r,c.g),c.b))); }
_drr_rawred_sm
_drr_rawred_large
convexFillHorizontal
Unknown CIDetectorTracking specified. Ignoring.
Unknown CIDetectorMinFeatureSize specified. Ignoring.
Unknown CIDetectorNumberOfAngles specified. Ignoring.
Face detection finding face error: %@
Face detection finding facial expression error: %@
kernel vec4 _reduceCrop (sampler image) 
 vec4 p = sample(image, samplerTransform(image, vec2(0.5, 0.5))); 
 vec2 d = abs(destCoord() - 0.5); 
 return max(d.x, d.y) < 0.5 ? p : vec4(0.0); 
kernel vec4 _areaMax4(sampler image, vec2 bound) 
 vec2 d = 2.0*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2(-0.5,-0.5))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2(+0.5,-0.5))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2(-0.5,+0.5))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2(+0.5,+0.5))); 
 p0 = (d.x+0.5 < bound.x) ? max(p0, p1) : p0; 
 p2 = (d.x+0.5 < bound.x) ? max(p2, p3) : p2; 
 p0 = (d.y+0.5 < bound.y) ? max(p0, p2) : p0; 
 return p0; 
kernel vec4 _horizMax4(sampler image, float bound) 
 vec2 d = vec2(4.0,1.0)*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2(-1.5, 0.0))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2(-0.5, 0.0))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2(+0.5, 0.0))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2(+1.5, 0.0))); 
 p0 = (d.x-0.5 < bound) ? max(p0, p1) : p0; 
 p0 = (d.x+0.5 < bound) ? max(p0, p2) : p0; 
 p0 = (d.x+1.5 < bound) ? max(p0, p3) : p0; 
 return p0; 
kernel vec4 _vertMax4(sampler image, float bound) 
 vec2 d = vec2(1.0,4.0)*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2( 0.0,-1.5))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2( 0.0,-0.5))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2( 0.0,+0.5))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2( 0.0,+1.5))); 
 p0 = (d.y-0.5 < bound) ? max(p0, p1) : p0; 
 p0 = (d.y+0.5 < bound) ? max(p0, p2) : p0; 
 p0 = (d.y+1.5 < bound) ? max(p0, p3) : p0; 
 return p0; 
kernel vec4 _areaMin4(sampler image, vec2 bound) 
 vec2 d = 2.0*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2(-0.5,-0.5))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2(+0.5,-0.5))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2(-0.5,+0.5))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2(+0.5,+0.5))); 
 p0 = (d.x+0.5 < bound.x) ? min(p0, p1) : p0; 
 p2 = (d.x+0.5 < bound.x) ? min(p2, p3) : p2; 
 p0 = (d.y+0.5 < bound.y) ? min(p0, p2) : p0; 
 return p0; 
kernel vec4 _horizMin4(sampler image, float bound) 
 vec2 d = vec2(4.0,1.0)*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2(-1.5, 0.0))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2(-0.5, 0.0))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2(+0.5, 0.0))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2(+1.5, 0.0))); 
 p0 = (d.x-0.5 < bound) ? min(p0, p1) : p0; 
 p0 = (d.x+0.5 < bound) ? min(p0, p2) : p0; 
 p0 = (d.x+1.5 < bound) ? min(p0, p3) : p0; 
 return p0; 
kernel vec4 _vertMin4(sampler image, float bound) 
 vec2 d = vec2(1.0,4.0)*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2( 0.0,-1.5))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2( 0.0,-0.5))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2( 0.0,+0.5))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2( 0.0,+1.5))); 
 p0 = (d.y-0.5 < bound) ? min(p0, p1) : p0; 
 p0 = (d.y+0.5 < bound) ? min(p0, p2) : p0; 
 p0 = (d.y+1.5 < bound) ? min(p0, p3) : p0; 
 return p0; 
kernel vec4 _areaMaxAlphaS4(sampler image, vec2 bound) 
 vec2 d = 2.0*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2(-0.5,-0.5))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2(+0.5,-0.5))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2(-0.5,+0.5))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2(+0.5,+0.5))); 
 p0 = (d.x+0.5 < bound.x) ? (p0.a>=p1.a ? p0 : p1) : p0; 
 p2 = (d.x+0.5 < bound.x) ? (p2.a>=p3.a ? p2 : p3) : p2; 
 p0 = (d.y+0.5 < bound.y) ? (p0.a>=p2.a ? p0 : p2) : p0; 
 return p0; 
kernel vec4 _areaMaxAlphaH4(sampler image, float bound) 
 vec2 d = vec2(4.0,1.0)*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2(-1.5, 0.0))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2(-0.5, 0.0))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2(+0.5, 0.0))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2(+1.5, 0.0))); 
 p0 = (d.x-0.5 < bound) ? (p0.a>=p1.a ? p0 : p1) : p0; 
 p0 = (d.x+0.5 < bound) ? (p0.a>=p2.a ? p0 : p2) : p0; 
 p0 = (d.x+1.5 < bound) ? (p0.a>=p3.a ? p0 : p3) : p0; 
 return p0; 
kernel vec4 _areaMaxAlphaV4(sampler image, float bound) 
 vec2 d = vec2(1.0,4.0)*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2( 0.0,-1.5))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2( 0.0,-0.5))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2( 0.0,+0.5))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2( 0.0,+1.5))); 
 p0 = (d.y-0.5 < bound) ? (p0.a>=p1.a ? p0 : p1) : p0; 
 p0 = (d.y+0.5 < bound) ? (p0.a>=p2.a ? p0 : p2) : p0; 
 p0 = (d.y+1.5 < bound) ? (p0.a>=p3.a ? p0 : p3) : p0; 
 return p0; 
kernel vec4 _areaMinAlphaS4(sampler image, vec2 bound) 
 vec2 d = 2.0*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2(-0.5,-0.5))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2(+0.5,-0.5))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2(-0.5,+0.5))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2(+0.5,+0.5))); 
 p0 = (d.x+0.5 < bound.x) ? (p0.a<=p1.a ? p0 : p1) : p0; 
 p2 = (d.x+0.5 < bound.x) ? (p2.a<=p3.a ? p2 : p3) : p2; 
 p0 = (d.y+0.5 < bound.y) ? (p0.a<=p2.a ? p0 : p2) : p0; 
 return p0; 
kernel vec4 _areaMinAlphaH4(sampler image, float bound) 
 vec2 d = vec2(4.0,1.0)*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2(-1.5, 0.0))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2(-0.5, 0.0))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2(+0.5, 0.0))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2(+1.5, 0.0))); 
 p0 = (d.x-0.5 < bound) ? (p0.a<=p1.a ? p0 : p1) : p0; 
 p0 = (d.x+0.5 < bound) ? (p0.a<=p2.a ? p0 : p2) : p0; 
 p0 = (d.x+1.5 < bound) ? (p0.a<=p3.a ? p0 : p3) : p0; 
 return p0; 
kernel vec4 _areaMinAlphaV4(sampler image, float bound) 
 vec2 d = vec2(1.0,4.0)*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2( 0.0,-1.5))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2( 0.0,-0.5))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2( 0.0,+0.5))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2( 0.0,+1.5))); 
 p0 = (d.y-0.5 < bound) ? (p0.a<=p1.a ? p0 : p1) : p0; 
 p0 = (d.y+0.5 < bound) ? (p0.a<=p2.a ? p0 : p2) : p0; 
 p0 = (d.y+1.5 < bound) ? (p0.a<=p3.a ? p0 : p3) : p0; 
 return p0; 
kernel vec4 _reduceCropMinMaxRed (sampler image) __attribute__((outputFormat(kCIFormatRGh))) 
 vec4 p = sample(image, samplerTransform(image, vec2(0.5, 0.5))); 
 vec2 d = abs(destCoord() - 0.5); 
 return max(d.x, d.y) < 0.5 ? p : vec4(0.0); 
kernel vec4 _areaMinMaxRed16 (sampler image, vec2 bound,float first) __attribute__((outputFormat(kCIFormatRGh))) 
 vec2 d = 4.0*destCoord(); 
 vec2 mm = vec2(1.0e20, -1.0e20); 
 for (float j = -1.5; j < 2.0; j+=1.0) { 
 for (float i = -1.5; i < 2.0; i+=1.0) { 
 vec2 location = d + vec2(i,j); 
 vec4 p = sample(image, samplerTransform(image, location)); 
 vec2 v = first > 0.1 ? p.rr : p.rg; 
 if (location.x < bound.x && location.y < bound.y) 
 mm = vec2(min(v.r, mm.r), max(v.g, mm.g)); 
 return vec4(mm, 0.0, 1.0); 
kernel vec4 _areaMinMaxRed4 (sampler image, vec2 bound,float first) __attribute__((outputFormat(kCIFormatRGh))) 
 vec2 d = 2.0*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2(-0.5,-0.5))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2(+0.5,-0.5))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2(-0.5,+0.5))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2(+0.5,+0.5))); 
 vec2 mm0 = ( first > 0.1 ) ? p0.rr : p0.rg; 
 vec2 mm1 = ( first > 0.1 ) ? p1.rr : p1.rg; 
 vec2 mm2 = ( first > 0.1 ) ? p2.rr : p2.rg; 
 vec2 mm3 = ( first > 0.1 ) ? p3.rr : p3.rg; 
 mm0.r = (d.x+0.5 < bound.x) ? min(mm0.r, mm1.r) : mm0.r; 
 mm2.r = (d.x+0.5 < bound.x) ? min(mm2.r, mm3.r) : mm2.r; 
 mm0.r = (d.y+0.5 < bound.y) ? min(mm0.r, mm2.r) : mm0.r; 
 mm0.g = (d.x+0.5 < bound.x) ? max(mm0.g, mm1.g) : mm0.g; 
 mm2.g = (d.x+0.5 < bound.x) ? max(mm2.g, mm3.g) : mm2.g; 
 mm0.g = (d.y+0.5 < bound.y) ? max(mm0.g, mm2.g) : mm0.g; 
 return vec4(mm0.rg, 0.0, 1.0); 
kernel vec4 _horizMinMaxRed4(sampler image, float bound,float first) __attribute__((outputFormat(kCIFormatRGh))) 
 vec2 d = vec2(4.0,1.0)*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2(-1.5, 0.0))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2(-0.5, 0.0))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2(+0.5, 0.0))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2(+1.5, 0.0))); 
 vec2 mm0 = ( first > 0.1 ) ? p0.rr : p0.rg; 
 vec2 mm1 = ( first > 0.1 ) ? p1.rr : p1.rg; 
 vec2 mm2 = ( first > 0.1 ) ? p2.rr : p2.rg; 
 vec2 mm3 = ( first > 0.1 ) ? p3.rr : p3.rg; 
 mm0.r = (d.x-0.5 < bound) ? min(mm0.r, mm1.r) : mm0.r; 
 mm0.r = (d.x+0.5 < bound) ? min(mm0.r, mm2.r) : mm0.r; 
 mm0.r = (d.x+1.5 < bound) ? min(mm0.r, mm3.r) : mm0.r; 
 mm0.g = (d.x-0.5 < bound) ? max(mm0.g, mm1.g) : mm0.g; 
 mm0.g = (d.x+0.5 < bound) ? max(mm0.g, mm2.g) : mm0.g; 
 mm0.g = (d.x+1.5 < bound) ? max(mm0.g, mm3.g) : mm0.g; 
 return vec4(mm0.rg, 0.0, 1.0); 
kernel vec4 _vertMinMaxRed4(sampler image, float bound,float first) __attribute__((outputFormat(kCIFormatRGh))) 
 vec2 d = vec2(1.0,4.0)*destCoord(); 
 vec4 p0 = sample(image, samplerTransform(image, d + vec2( 0.0,-1.5))); 
 vec4 p1 = sample(image, samplerTransform(image, d + vec2( 0.0,-0.5))); 
 vec4 p2 = sample(image, samplerTransform(image, d + vec2( 0.0,+0.5))); 
 vec4 p3 = sample(image, samplerTransform(image, d + vec2( 0.0,+1.5))); 
 vec2 mm0 = ( first > 0.1 ) ? p0.rr : p0.rg; 
 vec2 mm1 = ( first > 0.1 ) ? p1.rr : p1.rg; 
 vec2 mm2 = ( first > 0.1 ) ? p2.rr : p2.rg; 
 vec2 mm3 = ( first > 0.1 ) ? p3.rr : p3.rg; 
 mm0.r = (d.y-0.5 < bound) ? min(mm0.r, mm1.r) : mm0.r; 
 mm0.r = (d.y+0.5 < bound) ? min(mm0.r, mm2.r) : mm0.r; 
 mm0.r = (d.y+1.5 < bound) ? min(mm0.r, mm3.r) : mm0.r; 
 mm0.g = (d.y-0.5 < bound) ? max(mm0.g, mm1.g) : mm0.g; 
 mm0.g = (d.y+0.5 < bound) ? max(mm0.g, mm2.g) : mm0.g; 
 mm0.g = (d.y+1.5 < bound) ? max(mm0.g, mm3.g) : mm0.g; 
 return vec4(mm0.rg, 0.0, 1.0); 
kernel vec4 _minMaxNormalize(__sample c, __sample minc, __sample maxc) 
 c.rgb = (c.rgb - minc.rgb) / max(maxc.rgb - minc.rgb, 0.00001); 
 return c; 
kernel vec4 _minMaxRedNormalize(__sample c, __sample minmaxc) __attribute__((outputFormat(kCIFormatRh))) 
 c.r = (c.r - minmaxc.r) / max(minmaxc.g - minmaxc.r, 0.00001); 
 return c; 
-[CIKMeans _combine:]
CIReduction.mm
typeMeans < 0 || typeMeans == 0
typeMeans < 0 || typeMeans == 1
v.count == 3 || v.count == 4
typeMeans < 0 || typeMeans == 2
float _KM_distance2(vec4 c) { return dot(c.rgb,c.rgb); } 
 kernel vec4 _KM_select(sampler image, sampler means, float K, float k) { 
 vec4 img = sample(image, samplerTransform(image, destCoord())); 
 vec4 clusterk = sample(means, samplerTransform(means, vec2(0.5 + k, 0.5))); 
 float distk = _KM_distance2(img-clusterk); 
 int KK = int(K); 
 int kk = int(k); 
 for (int i = 0; i < KK; i++) { 
 if (i != kk) { 
 vec4 ki = sample(means, samplerTransform(means, vec2(0.5) + vec2(i, 0))); 
 if (_KM_distance2(img-ki) < distk) 
 return vec4(0.0); 
 return img; 
kernel vec4 _KM_defuse(sampler means, sampler randk, float K, float eps) { 
 vec2 p = destCoord(); 
 vec4 ki = sample(means, samplerTransform(means, p)); 
 vec4 ri = sample(randk, samplerTransform(randk, p)); 
 int kk = int(p.x-0.5); 
 int KK = int(K); 
 for (int j = kk+1; j < KK; j++) { 
 vec4 kj = sample(means, samplerTransform(means, vec2(0.5) + vec2(j, 0))); 
 if (dot(ki.rgb-kj.rgb,ki.rgb-kj.rgb) < eps) 
 return vec4(ri.rgb, 1.0); 
 return ki; 
-[CIKMeans outputImage]
Either inputMeans or inputCount should be specified.
infinite
%.1f x %.1f
Mean seeds should be passed as a K x 1 image but received %@]
kernel vec4 _ACWeightedCoordinatesR(__sample weight, vec4 originInvExtent) __attribute__((outputFormat(kCIFormatRGBAh))) { 
 return weight.r * vec4((destCoord()-originInvExtent.xy)*originInvExtent.zw, 1.0, 1.0); 
kernel vec4 _ACCentroid(__sample c, vec4 extent) __attribute__((outputFormat(kCIFormatRGh))) { 
 return vec4(extent.xy + c.xy / max(c.z, 0.0001) * vec2(extent.zw), 0.0, 1.0);
kernel vec4 _RCFalloffGaussian(__sample img, __sample center, float invSigma2) __attribute__((outputFormat(kCIFormatRh))) { 
 vec2 d = destCoord(); 
 vec2 c = center.xy; 
 return img * exp(-dot(d-c,d-c)*invSigma2); 
kernel vec4 _RCFalloffDisk(__sample img, __sample center, float r2) __attribute__((outputFormat(kCIFormatRh))) { 
 vec2 d = destCoord(); 
 vec2 c = center.xy; 
 return img * (dot(d-c,d-c) < r2 ? 1.0 : 0.0); 
kernel vec4 _RCCenter(vec2 c) __attribute__((outputFormat(kCIFormatRGh))) { 
 return vec4(c.x, c.y, 0., 1.); 
kernel vec4 _PSDrawSpread(__sample coordinate, float r2) __attribute__((outputFormat(kCIFormatRGBAh))) 
 vec2 v = destCoord() - coordinate.xy; 
 return dot(v,v) <= r2 ? vec4(1.0) : vec4(0.0); 
float _PC_distance2(vec4 c) { return dot(c.rgb,c.rgb); 
 kernel vec4 _PC_coord(sampler image, sampler means, float K, float k) __attribute__((outputFormat(kCIFormatRh))) { 
 vec4 img = sample(image, samplerTransform(image, destCoord())); 
 vec4 clusterk = sample(means, samplerTransform(means, vec2(0.5 + k, 0.5))); 
 float distk = _PC_distance2(img-clusterk); 
 int KK = int(K); 
 int kk = int(k); 
 for (int i = 0; i < KK; i++) { 
 if (i != kk) { 
 vec4 ki = sample(means, samplerTransform(means, vec2(0.5) + vec2(i, 0))); 
 if (_PC_distance2(img-ki) < distk) 
 return vec4(0.0, 0.0, 0.0, 1.0); 
 return vec4(1.0, 0.0, 0.0, 1.0); 
-[CIPaletteCentroid outputImage]
kernel vec4 _areaAvg8(sampler image) 
 vec2 d = 8.0*destCoord(); 
 vec4 p = sample(image, samplerTransform(image, d + vec2(-3.0,-3.0))) 
 + sample(image, samplerTransform(image, d + vec2(-1.0,-3.0))) 
 + sample(image, samplerTransform(image, d + vec2( 1.0,-3.0))) 
 + sample(image, samplerTransform(image, d + vec2( 3.0,-3.0))) 
 + sample(image, samplerTransform(image, d + vec2(-3.0,-1.0))) 
 + sample(image, samplerTransform(image, d + vec2(-1.0,-1.0))) 
 + sample(image, samplerTransform(image, d + vec2( 1.0,-1.0))) 
 + sample(image, samplerTransform(image, d + vec2( 3.0,-1.0))) 
 + sample(image, samplerTransform(image, d + vec2(-3.0, 1.0))) 
 + sample(image, samplerTransform(image, d + vec2(-1.0, 1.0))) 
 + sample(image, samplerTransform(image, d + vec2( 1.0, 1.0))) 
 + sample(image, samplerTransform(image, d + vec2( 3.0, 1.0))) 
 + sample(image, samplerTransform(image, d + vec2(-3.0, 3.0))) 
 + sample(image, samplerTransform(image, d + vec2(-1.0, 3.0))) 
 + sample(image, samplerTransform(image, d + vec2( 1.0, 3.0))) 
 + sample(image, samplerTransform(image, d + vec2( 3.0, 3.0))); 
 return 0.0625*p; 
kernel vec4 _areaAvg4(sampler image) 
 vec2 d = 4.0*destCoord(); 
 vec4 p = sample(image, samplerTransform(image, d + vec2(-1.0,-1.0))) 
 + sample(image, samplerTransform(image, d + vec2(+1.0,-1.0))) 
 + sample(image, samplerTransform(image, d + vec2(-1.0,+1.0))) 
 + sample(image, samplerTransform(image, d + vec2(+1.0,+1.0))); 
 return 0.25*p; 
kernel vec4 _areaAvg2(sampler image) 
 vec2 d = 2.0*destCoord(); 
 return sample(image, samplerTransform(image, d)); 
kernel vec4 _vertAvg16(sampler image) 
 vec2 d = vec2(1.0, 16.0) * destCoord(); 
 vec4 p = sample(image, samplerTransform(image, d + vec2(0.0,-7.0))) 
 + sample(image, samplerTransform(image, d + vec2(0.0,-5.0))) 
 + sample(image, samplerTransform(image, d + vec2(0.0,-3.0))) 
 + sample(image, samplerTransform(image, d + vec2(0.0,-1.0))) 
 + sample(image, samplerTransform(image, d + vec2(0.0,+1.0))) 
 + sample(image, samplerTransform(image, d + vec2(0.0,+3.0))) 
 + sample(image, samplerTransform(image, d + vec2(0.0,+5.0))) 
 + sample(image, samplerTransform(image, d + vec2(0.0,+7.0))); 
 return p * 0.125; 
kernel vec4 _vertAvg8(sampler image) 
 vec2 d = vec2(1.0, 8.0) * destCoord(); 
 vec4 p = sample(image, samplerTransform(image, d + vec2(0.0,-3.0))) 
 + sample(image, samplerTransform(image, d + vec2(0.0,-1.0))) 
 + sample(image, samplerTransform(image, d + vec2(0.0,+1.0))) 
 + sample(image, samplerTransform(image, d + vec2(0.0,+3.0))); 
 return p * 0.25; 
kernel vec4 _vertAvg4(sampler image) 
 vec2 d = vec2(1.0, 4.0) * destCoord(); 
 vec4 p = sample(image, samplerTransform(image, d + vec2(0.0,-1.0))) 
 + sample(image, samplerTransform(image, d + vec2(0.0,+1.0))); 
 return p * 0.5; 
kernel vec4 _vertAvg2(sampler image) 
 vec2 d = vec2(1.0,2.0)*destCoord(); 
 return sample(image, samplerTransform(image, d)); 
kernel vec4 _horizAvg16(sampler image) 
 vec2 d = vec2(16.0, 1.0) * destCoord(); 
 vec4 p = sample(image, samplerTransform(image, d + vec2(-7.0, 0.0))) 
 + sample(image, samplerTransform(image, d + vec2(-5.0, 0.0))) 
 + sample(image, samplerTransform(image, d + vec2(-3.0, 0.0))) 
 + sample(image, samplerTransform(image, d + vec2(-1.0, 0.0))) 
 + sample(image, samplerTransform(image, d + vec2(+1.0, 0.0))) 
 + sample(image, samplerTransform(image, d + vec2(+3.0, 0.0))) 
 + sample(image, samplerTransform(image, d + vec2(+5.0, 0.0))) 
 + sample(image, samplerTransform(image, d + vec2(+7.0, 0.0))); 
 return p * 0.125; 
kernel vec4 _horizAvg8(sampler image) 
 vec2 d = vec2(8.0, 1.0) * destCoord(); 
 vec4 p = sample(image, samplerTransform(image, d + vec2(-3.0, 0.0))) 
 + sample(image, samplerTransform(image, d + vec2(-1.0, 0.0))) 
 + sample(image, samplerTransform(image, d + vec2(+1.0, 0.0))) 
 + sample(image, samplerTransform(image, d + vec2(+3.0, 0.0))); 
 return p * 0.25; 
kernel vec4 _horizAvg4(sampler image) 
 vec2 d = vec2(4.0, 1.0) * destCoord(); 
 vec4 p = sample(image, samplerTransform(image, d + vec2(-1.0, 0.0))) 
 + sample(image, samplerTransform(image, d + vec2(+1.0, 0.0))); 
 return p * 0.5; 
kernel vec4 _horizAvg2(sampler image) 
 vec2 d = vec2(2.0,1.0)*destCoord(); 
 return sample(image, samplerTransform(image, d)); 
kernel vec4 _RCSelectGreaterThan(__sample c, __sample d, __sample minimax, float threshold) { return minimax.g > threshold ? c : d; 
kernel vec2 _fourfoldRotatedTile(vec2 center, vec4 ftrans, vec4 btrans) 
 vec2 t1, t2, t3, t4, t5, ci; 
 t1 = destCoord() - center; 
 t2.x = dot(t1, ftrans.xy); 
 t2.y = dot(t1, ftrans.zw); 
 ci = fract(floor(t2) * 0.5) * 2.0; 
 t2 = fract(t2); 
 t4 = 1.0 - t2; 
 t3 = vec2(t4.y, t2.x); 
 t5 = vec2(t2.y, t4.x); 
 t2 = mix(t2, t5, ci.x); 
 t3 = mix(t3, t4, ci.x); 
 t2 = mix(t2, t3, ci.y); 
 t1.x = dot(t2, btrans.xy); 
 t1.y = dot(t2, btrans.zw); 
 return t1 + center; 
kernel vec2 _sixfoldRotatedTile(vec2 center, vec4 ftrans, vec4 btrans) 
 vec2 t1, t2; 
 t1 = destCoord() - center; 
 t2.x = dot(t1, ftrans.xy); 
 t2.y = dot(t1, ftrans.zw); 
 t2 = fract(t2); 
 t1.x = 1.0 - t2.y; 
 t1.y = t2.x + t2.y - 1.0; 
 t2 = (t1.y < 0.0) ? t2 : t1; 
 t1.x = t2.y; 
 t1.y = 1.0 - t2.x - t2.y; 
 t2 = (1.0 - 2.0 * t2.x - t2.y < 0.0) ? t1 : t2; 
 t1.x = 1.0 - t2.x - t2.y; 
 t1.y = t2.x; 
 t2 = (1.0 - 2.0 * t2.y - t2.x < 0.0) ? t1 : t2; 
 t1.x = t2.y; 
 t1.y = 1.0 - t2.x - t2.y; 
 t2 = (1.0 - 2.0 * t2.x - t2.y < 0.0) ? t1 : t2; 
 t1.x = dot(t2, btrans.xy); 
 t1.y = dot(t2, btrans.zw); 
 return t1 + center; 
kernel vec2 _twelvefoldReflectedTile(vec2 center, vec4 ftrans, vec4 btrans) 
 vec2 t1, t2; 
 float d0, d1; 
 t1 = destCoord() - center; 
 t2.x = dot(t1.xy, ftrans.xy); 
 t2.y = dot(t1.xy, ftrans.zw); 
 t2 = fract(t2).xy; 
 d0 = t2.x - t2.y; 
 vec2 lt = vec2(lessThan(vec2(d0), vec2(0.0))); 
 t2 = mix(t2.yx, t2.xy, lt); 
 d0 = 1.0 - t2.x - t2.y; 
 t1 = 1.0 - t2.yx; 
 lt = vec2(lessThan(vec2(d0), vec2(0.0))); 
 t2 = mix(t2, t1, lt); 
 d1 = 1.0 - 2.0 * t2.x - t2.y; 
 d0 = 1.0 - t2.x - t2.y; 
 t2.x = (d1 < 0.0) ? d0 : t2.x; 
 d1 = 0.5 - 0.5 * t2.x - t2.y; 
 d0 = 1.0 - t2.x - t2.y; 
 t2.y = (d1 < 0.0) ? d0 : t2.y; 
 t1.x = dot(t2.xy, btrans.xy); 
 t1.y = dot(t2.xy, btrans.zw); 
 return t1 + center; 
kernel vec2 _fourfoldTranslatedTile(vec2 center, vec4 ftrans, vec4 btrans) 
 vec2 t1, t2; 
 t1 = destCoord() - center; 
 t2.x = dot(t1, ftrans.xy); 
 t2.y = dot(t1, ftrans.zw); 
 t2 = fract(t2); 
 t1.x = dot(t2, btrans.xy); 
 t1.y = dot(t2, btrans.zw); 
 return t1 + center; 
kernel vec2 _glideReflectedTile(vec2 center, vec4 ftrans, vec4 btrans) 
 vec2 t1, t2, t3, t4, t5, ci; 
 t1 = destCoord() - center; 
 t2.x = dot(t1, ftrans.xy); 
 t2.y = dot(t1, ftrans.zw); 
 ci = fract(floor(t2) * 0.5) * 2.0; 
 t2 = fract(t2); 
 t3 = vec2(t2.x, t2.y + 1.0); 
 t4 = vec2(1.0 - t2.x, t2.y); 
 t5 = vec2(t4.x, t4.y + 1.0); 
 t2 = mix(t2, t5, ci.x); 
 t3 = mix(t3, t4, ci.x); 
 t2 = mix(t2, t3, ci.y); 
 t1.x = dot(t2, btrans.xy); 
 t1.y = dot(t2, btrans.zw); 
 return t1 + center; 
kernel vec2 _eightfoldReflectedTile(vec2 center, vec4 ftrans, vec4 btrans) 
 vec2 t1, t2; 
 float d0; 
 t1 = destCoord() - center; 
 t2.x = dot(t1, ftrans.xy); 
 t2.y = dot(t1, ftrans.zw); 
 t2 = fract(t2); 
 t2 = min(t2, 1.0 - t2); 
 d0 = t2.y - t2.x; 
 vec2 lt = vec2(lessThan(vec2(d0), vec2(0.0))); 
 t2 = mix(t2.yx, t2.xy, lt); 
 t1.x = dot(t2, btrans.xy); 
 t1.y = dot(t2, btrans.zw); 
 return t1 + center; 
kernel vec2 _fourfoldReflectedTile(vec2 center, vec4 ftrans, vec4 btrans) 
 vec2 t1, t2; 
 t1 = destCoord() - center; 
 t2.x = dot(t1, ftrans.xy); 
 t2.y = dot(t1, ftrans.zw); 
 t2 = fract(t2); 
 t2 = min (t2, 1.0 - t2); 
 t2 = t2 + t2; 
 t1.x = dot(t2, btrans.xy); 
 t1.y = dot(t2, btrans.zw); 
 return t1 + center; 
kernel vec2 _sixfoldReflectedTile(vec2 center, vec4 ftrans, vec4 btrans) 
 vec2 t1, t2; 
 float d0, d1, d2; 
 t1 = destCoord() - center; 
 t2.x = dot(t1, ftrans.xy); 
 t2.y = dot(t1, ftrans.zw); 
 t2 = fract(t2); 
 d0 = t2.x - t2.y; 
 vec2 lt = vec2(lessThan(vec2(d0), vec2(0.0))); 
 t2 = mix(t2.yx, t2.xy, lt); 
 d2 = t2.x + t2.y; 
 d0 = 2.0 - d2; 
 d1 = d0 - t2.y; 
 t2.y = (d1 < 0.0) ? d0 : t2.y; 
 d0 = 1.0 - d2; 
 d1 = d0 * -1.0 + t2.x; 
 t2.x = (d1 < 0.0) ? d0 : t2.x; 
 d0 = t2.x - t2.y; 
 lt = vec2(lessThan(vec2(d0), vec2(0.0))); 
 t2 = mix(t2.yx, t2.xy, lt); 
 t1.x = dot(t2, btrans.xy); 
 t1.y = dot(t2, btrans.zw); 
 return t1 + center; 
singular matrix cannot be inverted
-[CIRenderDestination init]
-[CIRenderDestination _initWithInternalRenderDestination:width:height:format:colorspace:]
internal CI render destination is invalid.
internal CI image is invalid.
internal CI context is invalid.
-[CIRenderDestination initWithPixelBuffer:]
-[CIRenderDestination initWithWidth:height:pixelFormat:colorSpace:pixelBufferProvider:]
-[CIRenderDestination initWithIOSurface:]
-[CIRenderDestination initWithWidth:height:pixelFormat:colorSpace:surfaceProvider:]
-[CIRenderDestination initWithMTLTexture:commandBuffer:]
-[CIRenderDestination initWithWidth:height:pixelFormat:commandBuffer:mtlTextureProvider:]
-[CIRenderDestination initWithGLTexture:target:width:height:]
-[CIRenderDestination initWithBitmapData:width:height:bytesPerRow:format:]
-[CIRenderDestination setAlphaMode:]
-[CIRenderDestination setColorSpace:]
-[CIRenderDestination setBlendKernel:]
 because the MTLTexture usage does not inlude MTLTextureUsageShaderRead
 (%@)
<%@: %p%@ format: %s size: %ux%u
    colorspace: 
    alphaMode: None
    alphaMode: Premultiplied
    alphaMode: Unpremultiplied
    blendKernel: %s
    blendsInDestinationColorSpace: %d
    flipped: %d
    dithered: %d
    clamped: %d
-[CIRenderInfo init]
<%@: %p> {
  passCount: %ld 
  pixelsProcessed: %ld 
  kernelExecutionTime: %.5f ms 
-[CIRenderTask init]
CIRenderTaskWaitUntilCompleted
Unexpected error in the backing renderer.
-[CIRenderTask waitUntilCompletedAndReturnError:]
CIContextStartTask
The CIContext is invalid.
-[CIContext(CIRenderDestination) _startTaskToRender:toDestination:forPrepareRender:forClear:error:]
The destination is nil.
The destination is invalid.
The image extent and destination extent do not intersect.
The destination format is not support om GLES.
CIContextRenderDestination
kernel vec4 _destDither (__sample c, __sample n, float amount) 
 float nn = (n.r + n.g + n.b + n.a)*0.25 - 0.5; 
 c.rgb = clamp(c.rgb + amount*nn, vec3(0.0), vec3(1.0)); 
 return c; 
kernel vec4 _rippleTransition (sampler src1, sampler src2, sampler emap, vec2 center, vec4 parms, vec2 emapscaling) 
 vec2 dest = destCoord(); 
 vec2 delta = dest - center; 
 float delta_length = length(delta); 
 vec2 unit = delta / delta_length; 
 float scaled = (delta_length - parms.x) * parms.y; 
 vec4 normalized_radius = vec4(scaled * parms.z) + vec4(-0.0, -1.0, -2.0, -3.0); 
 vec4 smoothed = smoothstep(0.0, 1.0, clamp(normalized_radius.xyzy, 0.0, 1.0)); 
 vec4 cubic = smoothed * vec4(1.0, -2.0, 1.0, 1.0) + vec4(0.0, 1.0, -1.0, 0.0); 
 smoothed = compare(vec4(normalized_radius.x), vec4(0.0), vec4(cubic.x)); 
 smoothed = compare(vec4(normalized_radius.y), smoothed, vec4(cubic.y)); 
 smoothed = compare(vec4(normalized_radius.z), smoothed, vec4(cubic.z)); 
 normalized_radius = compare(vec4(normalized_radius.w), vec4(smoothed), vec4(0.0)); 
 vec2 displacement = normalized_radius.xy * unit; 
 vec2 location = displacement * parms.w + dest; 
 vec2 emap_location = (displacement * 0.5 + 0.5) * emapscaling; 
 vec4 pix1 = sample(src1, samplerTransform(src1, location)); 
 vec4 pix2 = sample(src2, samplerTransform(src2, location)); 
 vec4 emap_pix = sample(emap, samplerTransform(emap, emap_location)); 
 vec4 tmp = mix(pix2, pix1, cubic.w); 
 emap_pix *= tmp.a; 
 tmp = tmp * (1.0 - emap_pix.a) + emap_pix; 
 return tmp; 
Couldn't get the pixel buffer from input image
Couldn't get the outputBuffer from saliency map
VNGenerateImageSaliencyRequest
Class getVNGenerateImageSaliencyRequestClass()_block_invoke
affine_matrix
wrap_mode
filter_mode
black
clamp
periodic
nearest
linear
point
blur
blur_format
-[CISampler initWithImage:options:]
<CISampler: %p extent [infinite]>
<CISampler: %p extent [empty]>
<CISampler: %p extent [%g %g %g %g]>
<CISampler: %p>
kernel vec4 _sepia (__sample s, float amount) 
 vec4 color = vec4(1.0, 0.99, 0.92, 1.0); 
 vec4 c0 = vec4(0.895663e-3, -0.1104567e-2, -0.60827e-3, 0.32774281e-1); 
 vec4 c1 = vec4(3.1166719, 0.79263718, 0.32196859e-1, 1.4118470); 
 vec4 c2 = vec4(-50.933413, 0.46548312, 1.0275550, -.90690876); 
 vec4 c3 = vec4(708.79386, -0.39031064, -0.58540133e-1, 0.66210230); 
 vec4 c4 = vec4(-3605.9836, 0.13231560, 0.0, -0.19916155); 
 float l = dot(s.rgb, vec3(.2125, .7154, .0721)); 
 float la = l / max(0.0001, s.a); 
 vec4 t = c0*s.a + (c1 + (c2 + (c3 + c4*la)*la)*la)*l; 
 t.r = (l < 0.085*s.a) ? t.r : t.a; 
 vec3 r = (l*l-l < 0.0) ? t.rgb : vec3(l,l,l); 
 return mix(s,vec4(r, s.a)*color, amount); 
suffix
{CGPoint=dd}
kernel vec4 _shadedmaterial(sampler heightfield, sampler envmap, float surfaceScale, vec2 envscaling) 
 vec2 d = destCoord(); 
 vec4 sup = sample(heightfield, samplerTransform(heightfield, d+vec2( 0.0,+1.0))); 
 vec4 sdown = sample(heightfield, samplerTransform(heightfield, d+vec2( 0.0,-1.0))); 
 vec4 sleft = sample(heightfield, samplerTransform(heightfield, d+vec2(-1.0, 0.0))); 
 vec4 sright = sample(heightfield, samplerTransform(heightfield, d+vec2(+1.0, 0.0))); 
 vec4 scenter = sample(heightfield, samplerCoord(heightfield)); 
 vec3 normal = normalize(vec3(sleft.r - sright.r, sdown.r - sup.r, surfaceScale)); 
 vec2 eloc = (normal.xy * 0.495 + 0.5) * envscaling; 
 vec4 pix = sample(envmap, samplerTransform(envmap, eloc)); 
 return pix * scenter.a; 
kernel vec4 _shadedmaterial_0(sampler heightfield, sampler envmap, vec2 envscaling) 
 vec4 scenter = sample(heightfield, samplerCoord(heightfield)); 
 vec3 normal = vec3(0.0, 0.0, 1.0); 
 vec2 eloc = (normal.xy * 0.495 + 0.5) * envscaling; 
 vec4 pix = sample(envmap, samplerTransform(envmap, eloc)); 
 return pix * scenter.a; 
0_standardized
kernel vec4 _lumaRange(__sample image, float e0, float e1) __attribute__((outputFormat(kCIFormatRh))) { float y = dot(image.rgb, vec3(0.2126, 0.7152, 0.0722)); float i = smoothstep(e0, e1, y); return vec4(vec3(i), 1.0); }
0_Enhanced
1_Preprocessed
2_GradMap_dir
2_GradMap_mag
kernel vec4 _gradientNormalizeV2(__sample grad, vec4 gMinMax) __attribute__((outputFormat(kCIFormatRGh))) { float norm = 1.0 / (gMinMax.y - gMinMax.x); return (grad - gMinMax.x) * norm; }
3_GradMapNormalized_dir
3_GradMapNormalized_mag
kernel vec4 _gradientThresholdV2(__sample grad, float e0, float e1) __attribute__((outputFormat(kCIFormatRGh))) { float2 G = grad.xy; float mG = length(G); G *= smoothstep(e0, e1, mG); return float4(G, 0, 1); }
4_GradMapThresholded_dir
4_GradMapThresholded_mag
6_LineSegments
/tmp/vLines_vpCluster_%lu_%lu_%s.png
isect
parallel
/tmp/vLines_vpCluster_final.png
/tmp/hLines_vpCluster_%lu_%lu_%s.png
/tmp/hLines_vpCluster_final.png
f16@?0r^8
-[CIPerspectiveAutoCalcV2 computeConfidence]
CIPerspectiveAutoCalcV2.mm
CI_AUTOPERSPECTIVE_DEBUG
/tmp/PerspectiveV2_%@.png
kernel vec4 _noiseReduction(sampler src, vec2 offset, vec3 weight, vec3 intensity) 
 vec2 c = destCoord(); 
 vec4 cn = sample(src, samplerTransform(src, c)); 
 vec4 t0 = sample(src, samplerTransform(src, c + vec2(0.0,-offset.x))); 
 vec4 t1 = sample(src, samplerTransform(src, c + vec2(0.0, offset.x))); 
 vec4 t2 = sample(src, samplerTransform(src, c + vec2(-offset.x,0.0))); 
 vec4 t3 = sample(src, samplerTransform(src, c + vec2( offset.x,0.0))); 
 vec4 t4 = sample(src, samplerTransform(src, c + vec2( offset.y, offset.y))); 
 vec4 t5 = sample(src, samplerTransform(src, c + vec2( offset.y,-offset.y))); 
 vec4 t6 = sample(src, samplerTransform(src, c + vec2(-offset.y,-offset.y))); 
 vec4 t7 = sample(src, samplerTransform(src, c + vec2(-offset.y, offset.y))); 
 t0 = (t0+t1+t2+t3)*weight.x + (t4+t5+t6+t7)*weight.y + cn*weight.z; 
 vec4 d = abs(t0 - cn); 
 float s = intensity.x + intensity.y * (d.r + d.g + d.b); 
 s = clamp(s, intensity.z, 1.0); 
 return mix(cn, t0, s); 
inputNoiseLevel
kernel vec4 _convertRGBtoY (__sample c) 
 c = vec4(c.rgb/max(c.a,0.00001), c.a); 
 float Y = sqrt(max(dot(c.rgb, vec3(0.299,0.587,0.114)), 0.0)); 
 c.rgb = vec3(Y); 
 return c; 
kernel vec4 _blur1(sampler src) 
 vec2 p = destCoord(); 
 vec4 pixB = sample(src, samplerTransform(src, p + vec2(-1.0, 1.0))); 
 vec4 pixA = sample(src, samplerTransform(src, p + vec2( 0.0, 1.0))); 
 pixB += sample(src, samplerTransform(src, p + vec2( 1.0, 1.0))); 
 pixA += sample(src, samplerTransform(src, p + vec2(-1.0, 0.0))); 
 vec4 pix = sample(src, samplerTransform(src, p)); 
 pixA += sample(src, samplerTransform(src, p + vec2( 1.0, 0.0))); 
 pixB += sample(src, samplerTransform(src, p + vec2(-1.0,-1.0))); 
 pixA += sample(src, samplerTransform(src, p + vec2( 0.0,-1.0))); 
 pixB += sample(src, samplerTransform(src, p + vec2( 1.0,-1.0))); 
 pix.g = pix.r * 0.25 + pixA.r * 0.125 + pixB.r * 0.0625; 
 return pix; 
kernel vec4 _blur2(sampler src) 
 vec2 p = destCoord(); 
 vec4 pixB = sample(src, samplerTransform(src, p + vec2(-2.0, 2.0))); 
 vec4 pixA = sample(src, samplerTransform(src, p + vec2( 0.0, 2.0))); 
 pixB += sample(src, samplerTransform(src, p + vec2( 2.0, 2.0))); 
 pixA += sample(src, samplerTransform(src, p + vec2(-2.0, 0.0))); 
 vec4 pix = sample(src, samplerTransform(src, p)); 
 pixA += sample(src, samplerTransform(src, p + vec2( 2.0, 0.0))); 
 pixB += sample(src, samplerTransform(src, p + vec2(-2.0,-2.0))); 
 pixA += sample(src, samplerTransform(src, p + vec2( 0.0,-2.0))); 
 pixB += sample(src, samplerTransform(src, p + vec2( 2.0,-2.0))); 
 pix.b = pix.g * 0.25 + pixA.g * 0.125 + pixB.g * 0.0625; 
 return pix; 
kernel vec4 _blur4(sampler src) 
 vec2 p = destCoord(); 
 vec4 pixB = sample(src, samplerTransform(src, p + vec2(-4.0, 4.0))); 
 vec4 pixA = sample(src, samplerTransform(src, p + vec2( 0.0, 4.0))); 
 pixB += sample(src, samplerTransform(src, p + vec2( 4.0, 4.0))); 
 pixA += sample(src, samplerTransform(src, p + vec2(-4.0, 0.0))); 
 vec4 pix = sample(src, samplerTransform(src, p)); 
 pixA += sample(src, samplerTransform(src, p + vec2( 4.0, 0.0))); 
 pixB += sample(src, samplerTransform(src, p + vec2(-4.0,-4.0))); 
 pixA += sample(src, samplerTransform(src, p + vec2( 0.0,-4.0))); 
 pixB += sample(src, samplerTransform(src, p + vec2( 4.0,-4.0))); 
 pix.a = pix.b * 0.25 + pixA.b * 0.125 + pixB.b * 0.0625; 
 return pix; 
kernel vec4 _edgesPrep(__sample s) 
 s = vec4(s.rgb/max(s.a,0.00001), s.a); 
 s.rgb = sqrt(max(s.rgb, vec3(0.0))); 
 return s; 
kernel vec4 _findEdges(sampler src, float scale) 
 vec2 p = destCoord(); 
 vec4 rA = sample(src, samplerTransform(src, p)) - 
 sample(src, samplerTransform(src, p + vec2(1.0, 1.0))); 
 vec4 rB = sample(src, samplerTransform(src, p + vec2(0.0, 1.0))) - 
 sample(src, samplerTransform(src, p + vec2(1.0, 0.0))); 
 vec4 r = (rA*rA + rB*rB) * scale; 
 float R = min(max(max(r.r, r.g), r.b),1.0); 
 return vec4(vec3(R), 1.0); 
kernel vec4 _sharpenCombineEdges(__sample orig, __sample blurs, vec3 sharps, __sample edges) 
 vec4 so = vec4(orig.rgb/max(orig.a,0.00001), orig.a); 
 float Y = blurs.r + dot(blurs.r - blurs.gba, sharps); 
 so.rgb = vec3(Y*Y) + 
 so.r * vec3( 0.701428, -0.299276, -0.297756) + 
 so.g * vec3(-0.5881610, 0.4133170, -0.5857185) + 
 so.b * vec3(-0.113745, -0.113905, 0.884027); 
 float alpha = edges.x; 
 so = vec4(so.rgb*so.a, so.a); 
 return mix(orig, so, alpha); 
inputEdgeScale
kernel vec4 _sharpenLuminance(__sample ip, __sample bl, float s) 
 vec3 luminance = vec3(0.299, 0.587, 0.114); 
 vec3 invLuminance = vec3(1.0, -0.5093696763, -0.1942078365); 
 float intensity = 1.0 + s; 
 vec3 s0,s1; 
 s0.x = dot(luminance, bl.rgb); 
 s0.yz = bl.rb - s0.x; 
 s1.x = dot(luminance, ip.rgb); 
 s1.yz = ip.rb - s1.x; 
 s0 = mix(s0,s1, intensity); 
 ip.g = dot(invLuminance, s0); 
 ip.rb = s0.yz + s0.x; 
 return ip; 
inputSkyAmount
inputGrassAmount
kernel vec4 _grassAndSkyAdjust (__sample im, vec2 params) 
 float enhanceGrass = params.x; 
 float enhanceSky = params.y; 
 vec3 ipt, ipt2; 
 float range; 
 vec3 lms = im.r * vec3(0.3347, 0.1747, 0.0187) + 
 im.g * vec3(0.5984, 0.7151, 0.1018) + 
 im.b * vec3(0.0671, 0.1106, 0.8794); 
 lms = sign(lms)*pow(abs(lms), vec3(0.43)); 
 ipt = lms.r * vec3(0.4, 4.455, 0.8056) + 
 lms.g * vec3(0.4, -4.851, 0.3572) + 
 lms.b * vec3(0.2, 0.396,-1.1628); 
 float hue = atan((sqrt(ipt.b*ipt.b+ipt.g*ipt.g)-ipt.g),ipt.b)/3.1416+0.5; 
 range = hue - 0.88; 
 float maskGrass = exp((-1.0*range*range)/(2.0*.088*.088)); 
 range = 1.0 - smoothstep(0.4, 0.5, ipt.r); 
 maskGrass *= range; 
 vec2 idealGrass = vec2(-0.03, 0.1); 
 vec2 toIdeal = idealGrass - ipt.gb; 
 float dist = sqrt(toIdeal.r*toIdeal.r+toIdeal.g*toIdeal.g); 
 float chroma2 = 4.0*(ipt.g*ipt.g + ipt.b*ipt.b); 
 float str = enhanceGrass*pow(chroma2, .2); 
 str = str*min(1.0, 1.0-chroma2*chroma2); 
 str = min(str, 1.5); 
 float scale = min(1.0, 0.1/(dist+0.05)); 
 ipt2.gb = ipt.gb + str*toIdeal*scale; 
 ipt2.gb *= enhanceGrass; 
 ipt2.r = ipt.r; 
 ipt = mix(ipt, ipt2.rgb, maskGrass); 
 float maskSky = smoothstep(0.2, 0.5, ipt.r); 
 range = ipt.g + .04; 
 maskSky *= exp((-1.0*range*range)/(2.0*0.15*0.15)); 
 range = ipt.b + 0.1; 
 maskSky *= exp((-1.0*range*range)/(2.0*0.2*0.2)); 
 vec3 lms = ipt.r * vec3(1.0000, 1.0000, 1.0000) + 
 ipt.g * vec3(0.0976,-0.1139, 0.0326) + 
 ipt.b * vec3(0.2052, 0.1332,-0.6769); 
 lms = sign(lms)*pow(abs(lms), vec3(1.0/.43)); 
 im.rgb = lms.r * vec3( 5.3089, -1.3026, 0.0381) + 
 lms.g * vec3(-4.4648, 2.5193, -0.1968) + 
 lms.b * vec3( 0.1564, -0.2175, 1.1590); 
 im.rgb = max(im.rgb, 0.0); 
 float gain = max(1.0, 1.0 + enhanceSky); 
 float gamma = 1.0 + abs(enhanceSky); 
 vec4 result = pow(gain*im, vec4(gamma)); 
 float gray = (result.r + result.b + result.g)/3.0; 
 result.rgb += (result.rgb-gray) * abs(enhanceSky) * 0.5; 
 result = mix(im, result, maskSky); 
 result.a = im.a; 
 return result; 
inputNeutralGamma
inputTone
inputHue
inputGrain
kernel vec4 _smartBlackAndWhite(__sample image, sampler2D hueImage, vec4 rgbWeights, vec4 normalizer) 
 float scaleFactor = rgbWeights.w; 
 float neutralGamma = normalizer.z; 
 float phototone = normalizer.w; 
 image = clamp(image, 0.0, 1.0); 
 vec3 lms; 
 lms.x = dot(image.rgb, vec3(0.3139902162, 0.6395129383, 0.0464975462)); 
 lms.y = dot(image.rgb, vec3(0.155372406, 0.7578944616, 0.0867014186)); 
 lms.z = dot(image.rgb, vec3(0.017752387, 0.109442094, 0.8725692246)); 
 lms = pow(lms, vec3(0.43)); 
 float i = dot(lms, vec3(0.4,0.4,0.2)); 
 float p = dot(lms, vec3(4.4550,-4.8510,0.3960)); 
 float t = dot(lms, vec3(0.8056,0.3572,-1.1628)); 
 float chroma = sqrt(p*p+t*t); 
 float hue = 0.5 + (atan(t, p) / 6.28318530718); 
 vec2 huePt = vec2(hue * normalizer.x + normalizer.y, 0.5); 
 float exponent = scaleFactor * texture2D(hueImage, huePt).a; 
 float cd = 0.06 + 0.53*abs(i-0.5); 
 float lumDamp = smoothstep(0.0, 1.0, 25.0*i); 
 float x = smoothstep(0.0, 1.0, chroma/cd); 
 exponent = x*(1.0-i)*lumDamp*(exponent - 1.0) + 1.0; 
 float bw = dot(image.rgb, rgbWeights.rgb); 
 bw = pow(bw, exponent); 
 x = 1.0 - smoothstep(0.0, 1.0, chroma * 10.0); 
 float lumAdjust = bw*(1.0 - bw)*x*(neutralGamma - 1.0) + 1.0;
 lumAdjust = 5.0 - 4.0 * lumAdjust; 
 bw = pow(bw, lumAdjust); 
 float result = 1.8031*bw*bw*bw - 2.1972*bw*bw + 1.3823*bw; 
 bw = mix(bw, result, -phototone); 
 return vec4(bw,bw,bw,image.a); 
There is no need to call smartBlackAndWhiteStatistics.
Just use [CIFilter filterWithName:@"CISmartBlackAndWhite"] instead.
There is no need to call smartBlackAndWhiteAdjustmentsForValue:andStatistics:.
Warning smartToneStatistics will soon need [receiver properties] be non-nil so flash-fired state can be determined.
tonalRange
highKey
autoValue
blackPoint
whitePoint
satPercentile75
satPercentile98
satPercentileG98
satAutoValue
inputShadows
inputHighlights
inputBlack
inputRawHighlights
inputVibrancy
inputCast
inputUseCube
inputUseCubeColorSpace
kernel vec4 _smarttone_brightness_neg (__sample c, float gamma) 
 vec3 neg = min(c.rgb, 0.0); 
 c.rgb = max(c.rgb, 0.0); 
 vec3 pix = pow(c.rgb, vec3(gamma)); 
 float lum = dot(c.rgb, vec3(0.39, .5, .11)); 
 vec3 pix2 = lum>0.0 ? c.rgb*pow(lum, gamma)/lum : vec3(0.0); 
 pix = mix(pix, pix2, 0.8) + neg; 
 return vec4(pix, c.a); 
kernel vec4 _smarttone_brightness_pos (__sample c, float gamma) 
 vec3 neg = min(c.rgb, 0.0); 
 vec3 pos = max(c.rgb, 1.0)-1.0; 
 c.rgb = clamp(c.rgb, 0.0, 1.0); 
 vec3 m = 1.0-c.rgb; 
 float a = 0.6; 
 vec4 result = c; 
 result.rgb = 1.0 - (pow(m, vec3(gamma))+a*( ((gamma-1.0)*m*(1.0-m*m))/(gamma*gamma))); 
 c.rgb = pow(c.rgb, vec3(1.0-((min(gamma, 2.95)-1.0)/2.6))); 
 result.rgb = mix(c.rgb, result.rgb, .85); 
 result.rgb = result.rgb+neg+pos; 
 return result; 
kernel vec4 _smarttone_contrast (__sample im, float midAmt) 
 vec3 neg = min(im.rgb, 0.0); 
 vec3 pos = max(im.rgb, 1.0)-1.0; 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 float y = dot(im.rgb, vec3(0.3333)); 
 y = sqrt(y); 
 float sat = (im.r-y)*(im.r-y)+(im.g-y)*(im.g-y)+(im.b-y)*(im.b-y); 
 y = y*(1.0-y); 
 im.rgb = sqrt(im.rgb); 
 float a = midAmt*y; 
 float b = -0.5*a; 
 vec3 pix = im.r * vec3(0.299*a) + 
 im.g * vec3(0.587*a) + 
 im.b * vec3(0.114*a) + 
 im.rgb + vec3(b); 
 im.rgb = mix(im.rgb, vec3(0.5), -y*midAmt); 
 im.rgb = mix(im.rgb, pix, 0.8+sat); 
 im.rgb = max(im.rgb, 0.0); 
 im.rgb *= im.rgb; 
 im.rgb = im.rgb + neg + pos; 
 return im; 
kernel vec4 _smarttone_highlightcontrast (__sample pix, float highAmt, float sat) 
 float lum = clamp(dot(pix.rgb, vec3(.3333)),0.0,1.0); 
 vec3 high = pow(max(pix.rgb, 0.0), vec3(3.0 - 2.0*highAmt)) + min(pix.rgb, 0.0); 
 float pivot = 0.8; 
 vec3 pix1 = (high - pivot)*(4.0 - 3.0*highAmt) + pivot; 
 float h = highAmt*highAmt*highAmt*highAmt; 
 float a = (4.0 - 3.0*h); 
 vec3 pix2 = (lum-pivot)*a+pivot + high.rgb -lum; 
 high = mix(pix2, pix1, sat); 
 pix.rgb = mix(pix.rgb, high, lum*lum); 
 return pix; 
kernel vec4 _rawHighlights(__sample pix, float gain) 
 vec3 high = gain*pix.rgb; 
 float lum = clamp(dot(pix.rgb, vec3(.3333)), 0.0, 1.0); 
 vec3 neg = min(high, 0.0); 
 high.rgb = mix(max(pix.rgb, 0.0), high.rgb, lum*lum) + neg; 
 return vec4(high, pix.a); 
CISmartToneFilter-cubeContext
kernel vec4 _smartcolor_contrast (__sample im, float amt) 
 vec3 diff = im.rgb-dot(im.rgb, vec3(.0, .3, .5)); 
 float dist = distance(diff, vec3(0.0)); 
 dist = smoothstep(0.0, 1.0, dist); 
 float strength = 5.0*dist*amt; 
 vec3 pos = max(im.rgb, 1.0)-1.0 + min(im.rgb, 0.0); 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 strength *= (im.b-im.g); 
 strength = max(strength, -0.35); 
 vec4 result; 
 result.rgb = im.rgb/(strength + 1.0 - (im.rgb*strength)) + pos; 
 result.a = im.a; 
 return result; 
kernel vec4 _smartcolor_contrast_darken (__sample im, float amt) 
 vec3 diff = im.rgb-dot(im.rgb, vec3(.0, .3, .5)); 
 float dist = distance(diff, vec3(0.0)); 
 dist = smoothstep(0.0, 1.0, dist); 
 float strength = 5.0*dist*amt; 
 vec3 pos = max(im.rgb, 1.0)-1.0 + min(im.rgb, 0.0); 
 im.rgb = clamp(im.rgb, 0.0, 1.0); 
 strength *= (im.b-im.g); 
 float gray = 1.0-min(dot(im.rgb, vec3(0.5, 0.7, -0.20)), 1.0); 
 vec4 result; 
 result.rgb = strength < 0.0 ? pow(im.rgb, vec3(1.0-strength*gray)) : im.rgb/(strength+1.0-(im.rgb*strength)); 
 result.rgb += pos; result.a = im.a; 
 return result; 
kernel vec4 _smartcolor_vibrancy_gt1 (__sample im, float amt) 
 float gray = dot(clamp(im.rgb, 0.0, 1.0), vec3(.3, .5, .2)); 
 float y = dot(clamp(im.rgb, 0.0, 1.0), vec3(.4, .2, .1)); 
 float damp = 1.0-4.0*y*(1.0-y); 
 float s = 1.0/(im.r+im.g+im.b); 
 float r = im.r*s; 
 float b = im.b*s; 
 float d = 1.0-.8*smoothstep(0.2, 0.4, r-b); 
 damp *= d; 
 damp = amt > 2.5 ? min(damp+(amt-2.5)/5.0, 1.0) : damp; 
 float sat = min(amt, 3.0); 
 vec4 result; 
 result.rgb = (im.rgb - gray)*sat + gray; 
 result.rgb = mix(im.rgb, result.rgb, damp); 
 result.a = im.a; 
 return result; 
kernel vec4 _smartcolor_vibrancy_lt1 (__sample im, float amt) 
 float gray = dot(im.rgb, vec3(0.333333)); 
 im.rgb = mix(vec3(gray), im.rgb, amt); 
 return im; 
kernel vec4 _smartcolor_cast (__sample im, float lum, float grayI, float grayQ, float strength) 
 vec4 pix = clamp(im, 0.0, 1.0); 
 pix.rgb = pow(pix.rgb, vec3(.25)); 
 pix.rgb = pix.r * vec3(0.299, 0.595716, 0.211456) + 
 pix.g * vec3(0.587, -0.274453, -0.522591) + 
 pix.b * vec3(0.114, -0.321263, 0.311135); 
 vec2 grayOffset = vec2(grayI, grayQ) ; 
 vec3 result = pix.rgb; 
 float newStrength = 1.0 + (strength-1.0)*(1.0-pix.r) ; 
 result.gb = pix.gb + newStrength*grayOffset ; 
 float damp = max(min(1.0, pix.r/(lum+0.00001)),0.0) ; 
 result.rgb = mix(pix.rgb, result.rgb, damp) ; 
 pix.rgb = result.r * vec3(1.0) + 
 result.g * vec3(0.956296, -0.272122, -1.10699) + 
 result.b * vec3(0.621024, -0.647381, 1.70461); 
 pix.rgb = clamp(pix.rgb, 0.0, 1.0); 
 pix.rgb *= pix.rgb*pix.rgb*pix.rgb; 
 pix.rgb += min(im.rgb, 0.0) + max(im.rgb,1.0) -1.0; 
 return pix; 
CISmartColorFilter-cubeContext
CISmartTone-histogram
CISmartColor-histogram
CI_SMART_TONE_USE_CUBE
CI_SMART_COLOR_USE_CUBE
inputImage2
kernel vec4 _maskMultiplicationKernel(__sample i, __sample m) { vec4 res = vec4(1.0); res.rgb = i.rgb * m.rgb; return res; }
kernel vec4 _maskThresholdingKernel(__sample c, float t) { bvec3 compRes = lessThan(c.rgb - t, vec3(0.0)); c.rgb = any(compRes) ? vec3(0.0) : vec3(1.0); return c; }
CIInpaintingImageHelpers-BGRAVImageWrapper
CIInpaintingSingletonContext
inputB
inputC
kernel vec4 _cubicDownsample2 (sampler src, vec4 parms) 
 vec2 p = destCoord() * 2.0; 
 vec4 r = vec4(0.0); 
 float w1 = parms.x; 
 float w2 = parms.y; 
 vec4 off = vec4(-parms.wz,parms.zw); 
 r += sample(src, samplerTransform(src, p + off.xx)) * w2 * w2; 
 r += sample(src, samplerTransform(src, p + off.yx)) * w1 * w2; 
 r += sample(src, samplerTransform(src, p + off.zx)) * w1 * w2; 
 r += sample(src, samplerTransform(src, p + off.wx)) * w2 * w2; 
 r += sample(src, samplerTransform(src, p + off.xy)) * w2 * w1; 
 r += sample(src, samplerTransform(src, p + off.yy)) * w1 * w1; 
 r += sample(src, samplerTransform(src, p + off.zy)) * w1 * w1; 
 r += sample(src, samplerTransform(src, p + off.wy)) * w2 * w1; 
 r += sample(src, samplerTransform(src, p + off.xz)) * w2 * w1; 
 r += sample(src, samplerTransform(src, p + off.yz)) * w1 * w1; 
 r += sample(src, samplerTransform(src, p + off.zz)) * w1 * w1; 
 r += sample(src, samplerTransform(src, p + off.wz)) * w2 * w1; 
 r += sample(src, samplerTransform(src, p + off.xw)) * w2 * w2; 
 r += sample(src, samplerTransform(src, p + off.yw)) * w1 * w2; 
 r += sample(src, samplerTransform(src, p + off.zw)) * w1 * w2; 
 r += sample(src, samplerTransform(src, p + off.ww)) * w2 * w2; 
 return r; 
kernel vec4 _cubicDownsample2h (sampler src, vec4 parms) 
 vec2 dir = vec2(1.0,0.0); 
 vec2 p = destCoord() * vec2(2.0,1.0); 
 vec4 r = vec4(0.0); 
 vec4 off = vec4(-parms.wz,parms.zw); 
 r += sample(src, samplerTransform(src, p + dir * off.xx)) * parms.y; 
 r += sample(src, samplerTransform(src, p + dir * off.yy)) * parms.x; 
 r += sample(src, samplerTransform(src, p + dir * off.zz)) * parms.x; 
 r += sample(src, samplerTransform(src, p + dir * off.ww)) * parms.y; 
 return r; 
kernel vec4 _cubicDownsample2v (sampler src, vec4 parms) 
 vec2 dir = vec2(0.0,1.0); 
 vec2 p = destCoord() * vec2(1.0,2.0); 
 vec4 r = vec4(0.0); 
 vec4 off = vec4(-parms.wz,parms.zw); 
 r += sample(src, samplerTransform(src, p + dir * off.xx)) * parms.y; 
 r += sample(src, samplerTransform(src, p + dir * off.yy)) * parms.x; 
 r += sample(src, samplerTransform(src, p + dir * off.zz)) * parms.x; 
 r += sample(src, samplerTransform(src, p + dir * off.ww)) * parms.y; 
 return r; 
kernel vec4 _cubicDownsampleH (sampler src, vec4 scale, vec4 coefsLT1, vec4 coefsLT2) 
 vec2 dc = destCoord(); 
 vec2 dcMappedToSrc = scale.xy * dc; 
 vec2 dcMinus2MappedToSrc = scale.xy * (dc - 2.0); 
 vec2 dcPlus2MappedToSrc = scale.xy * (dc + 2.0); 
 float firstSrc = floor(dcMinus2MappedToSrc.x+0.5) + 0.5; 
 float lastSrc = floor(dcPlus2MappedToSrc.x-0.5) + 0.5; 
 vec4 r = vec4(0.0); 
 float sum = 0.0; 
 vec2 p = dcMappedToSrc; 
 float invScale = scale.z; 
 float delta = (firstSrc - dcMappedToSrc.x) * invScale; 
 for (p.x = firstSrc; p.x <= lastSrc; p.x += 1.0) 
 float x = abs(delta); 
 vec4 xvec = vec4(x*x*x, x*x, x, 1.0); 
 float weight = (x<1.0) ? dot(xvec,coefsLT1) : dot(xvec,coefsLT2); 
 r += sample(src, samplerTransform(src, p)) * weight; 
 sum += weight; 
 delta += invScale; 
 return r / sum; 
kernel vec4 _cubicDownsampleV (sampler src, vec4 scale, vec4 coefsLT1, vec4 coefsLT2) 
 vec2 dc = destCoord(); 
 vec2 dcMappedToSrc = scale.xy * dc; 
 vec2 dcMinus2MappedToSrc = scale.xy * (dc - 2.0); 
 vec2 dcPlus2MappedToSrc = scale.xy * (dc + 2.0); 
 float firstSrc = floor(dcMinus2MappedToSrc.y+0.5) + 0.5; 
 float lastSrc = floor(dcPlus2MappedToSrc.y-0.5) + 0.5; 
 vec4 r = vec4(0.0); 
 float sum = 0.0; 
 vec2 p = dcMappedToSrc; 
 float invScale = scale.w; 
 float delta = (firstSrc - dcMappedToSrc.y) * invScale; 
 for (p.y = firstSrc; p.y <= lastSrc; p.y += 1.0) 
 float x = abs(delta); 
 vec4 xvec = vec4(x*x*x, x*x, x, 1.0); 
 float weight = (x<1.0) ? dot(xvec,coefsLT1) : dot(xvec,coefsLT2); 
 r += sample(src, samplerTransform(src, p)) * weight; 
 sum += weight; 
 delta += invScale; 
 return r / sum; 
kernel vec4 _cubicUpsample10 (sampler src, vec2 scale) 
 vec2 d = scale * destCoord() - 0.5; 
 vec2 c = floor(d); 
 vec2 x = (c - d + 1.0); 
 vec2 X = (d - c); 
 vec2 w1 = (-1.0/3.0)*x*x*x + 0.5*x*x + 0.5*x + 1.0/6.0; 
 vec2 w2 = 1.0 - w1; 
 vec2 o1 = (-0.5*x*x*x + 0.5*x*x + 0.5*x + 1.0/6.0) / w1 + c - 0.5; 
 vec2 o2 = (X*X*X/6.0) / w2 + c + 1.5; 
 vec4 r; 
 r = w1.x * w1.y * sample(src, samplerTransform(src, vec2(o1.x,o1.y))); 
 r += w2.x * w1.y * sample(src, samplerTransform(src, vec2(o2.x,o1.y))); 
 r += w1.x * w2.y * sample(src, samplerTransform(src, vec2(o1.x,o2.y))); 
 r += w2.x * w2.y * sample(src, samplerTransform(src, vec2(o2.x,o2.y))); 
 return r; 
vec2 _cubic_coefs_ (vec2 x, vec4 c) 
 x = abs(x); 
 return c.x * x*x*x + c.y * x*x + c.z * x + c.w; 
 kernel vec4 _cubicUpsampleX0 (sampler src, vec2 scale, vec4 coefsLT1, vec4 coefsLT2) 
 vec2 dcMappedToSrc = scale * destCoord(); 
 vec2 srcCenterBefore = floor(dcMappedToSrc-0.5) + 0.5; 
 vec2 delta = srcCenterBefore - dcMappedToSrc; 
 vec2 weight0 = _cubic_coefs_(delta - 1.0, coefsLT2); 
 vec2 weight1 = _cubic_coefs_(delta , coefsLT1); 
 vec2 weight3 = _cubic_coefs_(delta + 2.0, coefsLT2); 
 vec2 w1 = weight0 + weight1; 
 vec2 w2 = vec2(1.0) - w1; 
 vec2 o1 = compare(w1 - 0.0001, vec2(0.0), weight1 / w1) + (srcCenterBefore - 1.0); 
 vec2 o2 = compare(w2 - 0.0001, vec2(0.0), weight3 / w2) + (srcCenterBefore + 1.0); 
 vec4 r; 
 r = w1.x * w1.y * sample(src, samplerTransform(src, vec2(o1.x,o1.y))); 
 r += w2.x * w1.y * sample(src, samplerTransform(src, vec2(o2.x,o1.y))); 
 r += w1.x * w2.y * sample(src, samplerTransform(src, vec2(o1.x,o2.y))); 
 r += w2.x * w2.y * sample(src, samplerTransform(src, vec2(o2.x,o2.y))); 
 return r; 
vec2 _cubic_coefs (vec2 x, vec4 c) 
 x = abs(x); 
 return c.x * x*x*x + c.y * x*x + c.z * x + c.w; 
 kernel vec4 _cubicUpsample (sampler src, vec2 scale, vec4 coefsLT1, vec4 coefsLT2) 
 vec2 dcMappedToSrc = scale * destCoord(); 
 vec2 srcCenterBefore = floor(dcMappedToSrc-0.5) + 0.5; 
 vec2 delta = srcCenterBefore - dcMappedToSrc; 
 vec4 r = vec4(0.0); 
 vec2 p; 
 vec2 w0 = _cubic_coefs(delta - 1.0, coefsLT2); 
 vec2 w1 = _cubic_coefs(delta , coefsLT1); 
 vec2 w2 = _cubic_coefs(delta + 1.0, coefsLT1); 
 vec2 w3 = 1.0 - (w0 + w1 + w2); 
 p.y = -1.0; 
 p.x = -1.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w0.x * w0.y; 
 p.x = 0.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w1.x * w0.y; 
 p.x = 1.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w2.x * w0.y; 
 p.x = 2.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w3.x * w0.y; 
 p.y = 0.0; 
 p.x = -1.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w0.x * w1.y; 
 p.x = 0.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w1.x * w1.y; 
 p.x = 1.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w2.x * w1.y; 
 p.x = 2.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w3.x * w1.y; 
 p.y = 1.0; 
 p.x = -1.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w0.x * w2.y; 
 p.x = 0.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w1.x * w2.y; 
 p.x = 1.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w2.x * w2.y; 
 p.x = 2.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w3.x * w2.y; 
 p.y = 2.0; 
 p.x = -1.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w0.x * w3.y; 
 p.x = 0.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w1.x * w3.y; 
 p.x = 1.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w2.x * w3.y; 
 p.x = 2.0; r += sample(src, samplerTransform(src, srcCenterBefore + p)) * w3.x * w3.y; 
 return r; 
kernel vec4 _cubicUpsample10v (sampler src, float scale) 
 vec2 dc = destCoord(); 
 float d = scale * dc.y - 0.5; 
 float c = floor(d); 
 float x = (c - d + 1.0); 
 float X = (d - c); 
 float w1 = (-1.0/3.0)*x*x*x + 0.5*x*x + 0.5*x + 1.0/6.0; 
 float w2 = 1.0 - w1; 
 float o1 = (-0.5*x*x*x + 0.5*x*x + 0.5*x + 1.0/6.0) / w1 + c - 0.5; 
 float o2 = (X*X*X/6.0) / w2 + c + 1.5; 
 vec4 r; 
 r = w1 * sample(src, samplerTransform(src, vec2(dc.x,o1))); 
 r += w2 * sample(src, samplerTransform(src, vec2(dc.x,o2))); 
 return r; 
kernel vec4 _cubicUpsample10h (sampler src, float scale) 
 vec2 dc = destCoord(); 
 float d = scale * dc.x - 0.5; 
 float c = floor(d); 
 float x = (c - d + 1.0); 
 float X = (d - c); 
 float w1 = (-1.0/3.0)*x*x*x + 0.5*x*x + 0.5*x + 1.0/6.0; 
 float w2 = 1.0 - w1; 
 float o1 = (-0.5*x*x*x + 0.5*x*x + 0.5*x + 1.0/6.0) / w1 + c - 0.5; 
 float o2 = (X*X*X/6.0) / w2 + c + 1.5; 
 vec4 r; 
 r = w1 * sample(src, samplerTransform(src, vec2(o1,dc.y))); 
 r += w2 * sample(src, samplerTransform(src, vec2(o2,dc.y))); 
 return r; 
kernel vec4 _spotLight (__sample src, vec3 lightpos, vec3 lightpointsat, vec4 lightcolor, vec2 parms) 
 vec4 t0 = vec4(0.0); 
 t0.xy = destCoord(); 
 vec4 r0; 
 r0.xyz = lightpos - t0.xyz; 
 r0.w = 0.0; 
 r0 = normalize(r0); 
 float k0 = dot(r0.xyz, lightpointsat); 
 k0 = clamp(k0, 0.0, 1.0); 
 k0 = pow(k0, parms.x); 
 vec4 r3 = k0 * lightcolor; 
 r0 = r0.z * r3; 
 vec4 dest = r0 * src; 
 return dest; 
inputConcentration
inputLightPosition
inputLightPointsAt
inputCrossScale
inputCrossAngle
inputCrossOpacity
inputCrossWidth
kernel vec4 _starshine(vec2 center, vec4 xyvec, vec4 parms, float widthrecip, __color color) 
 vec2 offset = destCoord() - center; 
 vec2 loc = vec2(dot(offset, xyvec.xy), dot(offset, xyvec.zw)); 
 float l = length(offset); 
 float rlen = parms.x / l; 
 loc = max(abs(loc) * widthrecip + parms.w, vec2(0.0000001)); 
 loc = abs(parms.x / loc); 
 loc = loc * loc * loc; 
 float f = loc.x * loc.y * parms.z; 
 float g = clamp(1.0 - l * parms.y, 0.0, 1.0); 
 return min(rlen * rlen * color + g * g * f, vec4(1.0)); 
kernel vec2 _stretch (vec2 center, vec3 param) 
 vec2 g = vec2(1.0) - clamp(abs(destCoord() - center) * param.x, 0.0, 1.0); 
 g = (g * -2.0 + vec2(3.0)) * g * g; 
 g *= param.y * sin((destCoord() - center.yy) * param.z); 
 return destCoord() - g; 
kernel vec2 _stretchcrop (vec2 sizeIn, vec2 center, vec4 p) 
 vec2 a = p.xy, b = p.zw; 
 vec2 c = destCoord(); 
 c = (c-center)/sizeIn; 
 c = c / (a + b*abs(c)); 
 c = (c + 0.5)*sizeIn; 
 return c; 
inputCropAmount
inputCenterStretchAmount
kernel vec2 _ninePartStretched (vec2 bpmin, vec2 growth, vec2 slope) 
 vec2 dc = destCoord(); 
 vec2 c1 = slope * (dc - bpmin) + bpmin; 
 vec2 c2 = dc - growth; 
 return max(min(dc,c1),c2); 
inputBreakpoint0
inputBreakpoint1
inputGrowAmount
kernel vec2 _ninePartTiledAlt (vec4 bp01, vec2 growth, vec2 shift) 
 vec2 dc = destCoord(); 
 vec2 bp0 = bp01.xy; 
 vec2 bp1 = bp01.zw; 
 vec2 myMod; { 
 vec2 a = dc - shift; 
 vec2 b = bp1-bp0; 
 myMod = a - b*floor(a/b); 
 vec2 c1 = bp0 + myMod; 
 vec2 p = compare(dc - bp0, dc, c1); 
 p = compare(dc - (bp1+growth), p, dc - growth); 
 return p; 
inputFlipYTiles
kernel vec4 _stripes (vec2 center, __color c0, __color c1, vec3 params) 
 float d0; 
 d0 = (destCoord() - center).x; 
 d0 = fract(d0 * params.x - .25); 
 d0 = min (1.0 - d0, d0); 
 d0 = clamp (d0 * params.y + params.z, 0.0, 1.0); 
 float d1 = (d0 * -2.0 + 3.0) * d0 * d0; 
 return mix(c1, c0, d1); 
kernel vec4 _sunbeams(sampler noise, vec4 centers, vec4 params, __color color) 
 float sunRadius2 = params.x; 
 float striationFactor = params.y; 
 float a = params.z; 
 float b = params.w; 
 vec2 v = destCoord() - centers.xy; 
 float len = length(v); 
 float len2 = dot(v,v); 
 vec2 noiseCtr = centers.zw; 
 vec2 noiseLoc = normalize(v) * 50.0 + noiseCtr; 
 vec4 npix = sample(noise, samplerTransform(noise, noiseLoc)); 
 float noiseAmount = npix.r * a + b; 
 float f2 = sunRadius2 / (len2+0.0001); 
 vec4 pix = f2 * color + noiseAmount; 
 return pix * clamp(1.0 - len * striationFactor, 0.0, 1.0); 
inputSunRadius
kernel vec4 _swipeTransition(__sample src0, __sample src1, __color color, vec4 parms) 
 float k1 = clamp(dot(vec4(destCoord(), 1.0, 0.0), parms), 0.0, 1.0); 
 float k0 = min(1.0-k1, k1) * 2.0 * parms.w; 
 return mix(mix(src1, src0, k1), color, k0); 
inputTargetNeutral
kernel vec4 _whitepointadjust (__sample img, __color color) { return img * color; }
kernel vec4 _falseColor (__sample img, __color c0, __color c1) 
 return img.a * mix (c0, c1, dot(img.rgb, vec3(.2125, .7154, .0721))); 
/System/Library/PrivateFrameworks/Futhark.framework
%s%@
SIMULATOR_ROOT
FKTextDetector
FKTextDetector not loaded
Text detection failed with error: %@
ASCII
%@;%@
inputFontName
HelveticaNeue
inputFontSize
-[CITextImageGenerator outputImage]
-[CIAttributedTextImageGenerator outputImage]
kernel vec4 _curve16 (__sample s, sampler2D curveImage, vec2 normalizer) 
 s.rgb = normalizer.x * s.rgb + normalizer.y; 
 vec2 v = texture2D(curveImage, vec2(s.r , 0.5)).rg; 
 s.r = 0.9961089494 * v.r + 0.0038910506 * v.g; 
 v = texture2D(curveImage, vec2(s.g, 0.5)).rg; 
 s.g = 0.9961089494 * v.r + 0.0038910506 * v.g; 
 v = texture2D(curveImage, vec2(s.b, 0.5)).rg; 
 s.b = 0.9961089494 * v.r + 0.0038910506 * v.g; 
 return s; 
%d, %d
Curve0x
Curve0y
Curve1x
Curve1y
Curve2x
Curve2y
Curve3x
Curve3y
Curve4x
Curve4y
ToneCurve
ToneCurveName
Custom
kernel vec4 _triangleKaleidoscopeColor (__sample c, vec2 center, vec4 ftrans, float decay) 
 vec2 p = destCoord() - center; 
 p = vec2(dot(p, ftrans.xy), dot(p, ftrans.zw)); 
 highp vec3 z = vec3(1.0 + p.x - p.y, 2.0 - p.x - 2.0 * p.y, 2.0 - 2.0 * p.x - p.y); 
 z = abs(floor(z)); 
 float K = pow(decay, dot(z, vec3(1.0))); 
 c.rgb *= K; 
 return c; 
kernel vec2 _triangleKaleidoscopeGeom (vec2 center, vec4 ftrans, vec4 btrans) 
 vec2 p = destCoord() - center; 
 p = vec2(dot(p, ftrans.xy), dot(p, ftrans.zw)); 
 p = fract(p); 
 p = (p.x > p.y) ? p.yx : p; 
 p.y = (p.y > 2.0 - p.x - p.y) ? (2.0 - p.x - p.y) : p.y; 
 p.x = (p.x < 1.0 - p.x - p.y) ? (1.0 - p.x - p.y) : p.x; 
 p = (p.x > p.y) ? p.yx : p; 
 p = vec2(dot(p, btrans.xy), dot(p, btrans.zw)); 
 p += center; 
 return p; 
kernel vec4 _triangleTile (sampler src, vec2 center, vec4 ftrans, vec4 btrans) 
 vec2 t = destCoord() - center; 
 t = vec2(dot(t, ftrans.xy), dot(t, ftrans.zw)); 
 t = fract(t); 
 t = (t.x > t.y) ? t.yx : t; 
 t.y = (t.y > 2.0 - t.x - t.y) ? (2.0 - t.x - t.y) : t.y; 
 t.x = (t.x < 1.0 - t.x - t.y) ? (1.0 - t.x - t.y) : t.x; 
 t = (t.x > t.y) ? t.yx : t; 
 t = vec2(dot(t, btrans.xy), dot(t, btrans.zw)); 
 t += center; 
 return sample(src, samplerTransform(src, t)); 
kernel vec2 _twirl(vec4 param) 
 vec2 d = destCoord() - param.xy; 
 float r = min(length(d) * param.z, 1.0); 
 float _1mr = 1.0 - r; 
 float ss = (_1mr * -2.0 + 3.0) * _1mr * _1mr; 
 float angle = param.w * ss; 
 vec2 cs = vec2(cos(angle), sin(angle)); 
 vec2 p = vec2(dot(d, cs), dot(d, vec2(-cs.y, cs.x))); 
 return (r >= 1.0) ? destCoord() : p + param.xy; 
kernel vec4 _unsharpmask (__sample s, __sample b, float k) { s.rgb += (s.rgb - b.rgb * (s.a/max(b.a, 0.0001))) * k; return s; }
NSString *getVNImageOptionImageOrientation(void)
Class getVNFaceObservationClass(void)_block_invoke
NSString *getVNFaceAttributeSmiling(void)
VNFaceAttributeSmiling
NSString *getVNFaceAttributeEyesClosed(void)
VNFaceAttributeEyesClosed
vec2 __clampToRect(vec2 point,vec4 rect) {
  return clamp(point,rect.xy,rect.xy + rect.zw);
vec4 sampleBilinear(sampler image,vec2 p) {
    vec2 xy0 = p - vec2(0.5);
    vec2  p0 = floor(xy0);
    vec2  p1 = p0 + vec2(1.0);
    vec2 amount = p1 - xy0;
    vec4 ll = sample(image, samplerTransform(image, p0 + vec2(0.5)));
    vec4 ur = sample(image, samplerTransform(image, p1 + vec2(0.5)));
    vec4 lr = sample(image, samplerTransform(image, vec2(p1.x, p0.y) + vec2(0.5)));
    vec4 ul = sample(image, samplerTransform(image, vec2(p0.x, p1.y) + vec2(0.5)));
    vec4 bottom = mix(lr, ll, amount.x);
    vec4 top = mix(ur, ul, amount.x);
    return mix(top, bottom, amount.y);
kernel vec4 _variableBoxBlur(sampler integralImage,sampler radiusImage,float scale,vec4 e) {
  vec4 v = unpremultiply(sample(radiusImage, samplerCoord(radiusImage)));
  float radius = scale * dot(v.rgb,vec3(0.2126, 0.7152, 0.0722));
 radius = max(radius, 0.5);
  vec2 c = destCoord();
  vec2 lowerLeft = __clampToRect(c + vec2(-radius-1.0, -radius), e);
  vec2 upperRight = __clampToRect(c + vec2(radius, radius+1.0), e);
  vec4 ul = sampleBilinear(integralImage, vec2(lowerLeft.x, upperRight.y));
  vec4 ur = sampleBilinear(integralImage, upperRight);
  vec4 ll = sampleBilinear(integralImage, lowerLeft);
  vec4 lr = sampleBilinear(integralImage, vec2(upperRight.x, lowerLeft.y));
  vec4 rc = ul + lr - ur - ll;
  vec2 diagonal = upperRight - lowerLeft;
  float usedArea = abs(diagonal.x * diagonal.y);
  float originalArea = (2.0*radius+1.0) * (2.0*radius+1.0);
 rc /= rc.a;
 rc.a = 1.0;
  return premultiply(rc);
Invalid resource descriptor
Model resource descriptor: %@, network: %p, plan: %p: context: %p, configurationName: %@
PATH:
Model initialized using "PATH:"-prefixed descriptor from: %@
unable to create image/mask vImage wrapper objects
no_alpha_premultiply
Error setting no_alpha_premultiply parameter inside Espresso, espresso status: %d
Error binding image inside Espresso, espresso status: %d
Error converting planarF image into RGBA8/BGRA8
%dpx
Error executing espresso plan: %@
target
source
mask_outline
InpaintingSkipANEPath
Invalid state: espresso model already initialized.
Could not create Espresso context
Could not create Espresso plan
Could not create/add network to Espresso plan
Could not reset espresso plan phase.
Could not select espresso configuration
Could not declare Espresso network input buffer: %@
Could not declare Espresso network output buffer: %@
Could not build Espresso plan
espresso_return_status_t soft_espresso_plan_destroy(espresso_plan_ref_t)
CIEspresso.h
espresso_plan_destroy
void *EspressoLibrary()
/System/Library/PrivateFrameworks/Espresso.framework/Espresso
/System/Library/PrivateFrameworks/Espresso.framework/Contents/MacOS/Espresso
espresso_return_status_t soft_espresso_context_destroy(espresso_context_ref_t)
espresso_context_destroy
espresso_return_status_t soft_espresso_blob_set_int_option(espresso_network_t, const char *, const char *, int)
espresso_blob_set_int_option
espresso_return_status_t soft_espresso_network_bind_input_vimagebuffer_bgra8(espresso_network_t, const char *, int, vImage_Buffer, espresso_simple_image_preprocessing_params_t *)
espresso_network_bind_input_vimagebuffer_bgra8
espresso_return_status_t soft_espresso_network_bind_buffer(espresso_network_t, const char *, espresso_buffer_t *, espresso_bind_mode_flags, espresso_bind_ptr_flags, espresso_bind_format_flags)
espresso_network_bind_buffer
espresso_return_status_t soft_espresso_plan_execute_sync(espresso_plan_ref_t)
espresso_plan_execute_sync
espresso_error_info_t soft_espresso_plan_get_error_info(espresso_plan_ref_t)
espresso_plan_get_error_info
espresso_context_ref_t soft_espresso_create_context(espresso_engine_t, int)
espresso_create_context
espresso_plan_ref_t soft_espresso_create_plan(espresso_context_ref_t, int)
espresso_create_plan
espresso_return_status_t soft_espresso_plan_add_network(espresso_plan_ref_t, const char *, espresso_storage_type_t, espresso_network_t *)
espresso_plan_add_network
espresso_plan_phase_t soft_espresso_plan_get_phase(espresso_plan_ref_t)
espresso_plan_get_phase
espresso_return_status_t soft_espresso_plan_build_clean(espresso_plan_ref_t)
espresso_plan_build_clean
espresso_return_status_t soft_espresso_network_select_configuration(espresso_network_t, const char *)
espresso_network_select_configuration
espresso_return_status_t soft_espresso_network_declare_input(espresso_network_t, const char *)
espresso_network_declare_input
espresso_return_status_t soft_espresso_network_declare_output(espresso_network_t, const char *)
espresso_network_declare_output
espresso_return_status_t soft_espresso_plan_build(espresso_plan_ref_t)
espresso_plan_build
[%g]
[%g %g]
[%g %g %g]
[%g %g %g %g]
[%g %g %g %g
CICount
CI_%zu
kernel vec4 _vibrance_neg(__sample pixel0, float vibrance) 
 vec4 pixel = clamp(pixel0, 0.0001, 0.9999); 
 vec4 pdelta = pixel0 - pixel; 
 float gray = (pixel.r + pixel.g + pixel.b) * 0.33333; 
 float gi = 1.0 / gray; 
 float gii = 1.0 / (1.0 - gray); 
 vec3 rgbsat = max((pixel.rgb - gray) * gii, (gray - pixel.rgb) * gi); 
 float sat = max(max(rgbsat.r, rgbsat.g), rgbsat.b); 
 float skin = min(pixel.r - pixel.g, pixel.g * 2.0 - pixel.b) * 4.0 * (1.0 - rgbsat.r) * gi; 
 skin = 0.15 + clamp(skin, 0.0, 1.0) * 0.7; 
 float boost = ((sat * (sat - 1.0) + 1.0) * vibrance) * (1.0-skin); 
 pixel = clamp(pixel + (pixel - gray) * boost, 0.0, 1.0); 
 pixel.a = pixel0.a; 
 pixel.rgb += pdelta.rgb; 
 return pixel; 
kernel vec4 _vibrance_pos(__sample pixel0, vec4 vvec) 
 vec4 pixel = clamp(pixel0, 0.0001, 0.9999); 
 vec4 pdelta = pixel0 - pixel; 
 float gray = (pixel.r + pixel.g + pixel.b) * 0.33333; 
 float gi = 1.0 / gray; 
 float gii = 1.0 / (1.0 - gray); 
 vec3 rgbsat = max((pixel.rgb - gray) * gii, (gray - pixel.rgb) * gi); 
 float sat = max(max(rgbsat.r, rgbsat.g), rgbsat.b); 
 float skin = min(pixel.r - pixel.g, pixel.g * 2.0 - pixel.b) * 4.0 * (1.0 - rgbsat.r) * gi; 
 skin = 0.15 + clamp(skin, 0.0, 1.0) * 0.7; 
 float boost = dot(vvec, vec4(1.0, sat, sat*sat, sat*sat*sat)) * (1.0 - skin); 
 pixel = clamp(pixel + (pixel - gray) * boost, 0.0, 1.0); 
 pixel.a = pixel0.a; 
 pixel.rgb += pdelta.rgb; 
 return pixel; 
Vibrance
kernel vec4 _vignette (__sample s, vec4 params) 
 vec2 point = destCoord() - params.xy; 
 float len2 = dot(point, point); 
 float v = pow(max(1.0 - len2 * params.w, 0.0), params.z); 
 s.rgb *= v; 
 return s; 
kernel vec4 _vignetteeffect (__sample s, vec2 center, vec4 params) 
 vec2 point = (destCoord() - center) * params.x; 
 float dist = sqrt(dot(point,point)); 
 float x = clamp((dist-params.y)*params.z,0.0,1.0); 
 x = x*x*x*((6.0*x - 15.0)*x + 10.0); 
 float v = 1.0 - x*params.w; 
 v = ((( -0.120638501063760*v + 0.543878646118680)*v + 0.538772615443760)*v + 0.037600999734998)*v; 
 s.rgb *= v; 
 return s; 
kernel vec4 _vignetteeffectneg (__sample s, vec2 center, vec4 params) 
 vec2 point = (destCoord() - center) * params.x; 
 float dist = sqrt(dot(point,point)); 
 float x = clamp((dist-params.y)*params.z,0.0,1.0); 
 x = x*x*x*((6.0*x - 15.0)*x + 10.0); 
 float v = 16.0*x*params.w + 1.0; 
 s.rgb *= v; 
 return s; 
face
allPoints
leftEyebrow
medianLine
outerLips
rightEyebrow
junkiness
kCIVNDetectOptionRequestLandmarks
kCIVNDetectOptionRequestAttributes
kCIVNDetectOptionRequestPose
kCIVNDetectOptionRequestFast
kCIVNDetectOptionRequestSegments
CIVNDetectFaces
NSString *getVNImageOptionCIContext(void)
Class getVNImageRequestHandlerClass(void)_block_invoke
VNDetectFaceRectanglesRequest
Class getVNDetectFaceRectanglesRequestClass(void)_block_invoke
VNClassifyFaceAttributesRequest
Class getVNClassifyFaceAttributesRequestClass(void)_block_invoke
VNDetectFaceLandmarksRequest
Class getVNDetectFaceLandmarksRequestClass(void)_block_invoke
VNDetectFacePoseRequest
Class getVNDetectFacePoseRequestClass(void)_block_invoke
Class getVNGenerateFaceSegmentsRequestClass(void)_block_invoke
maxGradientMagnitude: %f
kernel vec4 _gradientNormalizeV1(__sample grad, float norm) __attribute__((outputFormat(kCIFormatRGh))) { return grad * norm; }
kernel vec4 _gradientThresholdV1(__sample grad, float e0, float e1) __attribute__((outputFormat(kCIFormatRGh))) { float2 G = grad.xy; float mG = length(G); G *= smoothstep(e0, e1, mG); return float4(G, 0, 1); }
kernel vec4 _gradientRangeLimit(__sample grad, float gxgyE0, float gxgyE1, float gygxE0, float gygxE1) __attribute__((outputFormat(kCIFormatRGh))) { float2 G = grad.xy; float Gy = abs(G.y); float Gx = abs(G.x); if (Gy + Gx < 0.001) return vec4(0); if (Gx < Gy) { float gxgy = G.x / G.y; return grad * (1.0 - smoothstep(gxgyE0, gxgyE1, gxgy)); } else { float gygx = G.y / G.x; return grad * (1.0 - smoothstep(gygxE0, gygxE1, gygx)); } }
5_GradMapRangeLimited_dir
5_GradMapRangeLimited_mag
/tmp/guides.png
/tmp/PerspectiveV1_%@.png
CIAztecCodeGenerator
CIBarcodeGenerator
CICode128BarcodeGenerator
CIPDF417BarcodeGenerator
CIQRCodeGenerator
{CGPoint=dd}@:
v@:{CGPoint=dd}}
parameterB
parameterC
underColorRemoval
grayComponentReplacement
textureImage
setBackgroundImage:
setMaskImage:
setSmallImage:
setTargetImage:
setBacksideImage:
inputBacksideImage
setShadingImage:
setGradientImage:
setPaletteImage:
inputPaletteImage
setTextureImage:
setParameterB:
setParameterC:
setUnderColorRemoval:
setGrayComponentReplacement:
v@:@
v@:f
v@:B}
{CGRect={CGPoint=dd}{CGSize=dd}}@:
v@:{CGRect={CGPoint=dd}{CGSize=dd}}
{CGAffineTransform=dddddd}@:
v@:{CGAffineTransform=dddddd}
v@:q}
v@:Q}
kernel vec2 _vortexDistortion(vec2 center, vec2 params) 
 vec2 d = destCoord() - center; 
 float len = length(d); 
 float r = len * params.x - 1.0; 
 float a = r * r * params.y / len; 
 vec2 sc = vec2(cos(a), sin(a)); 
 vec2 p = vec2(dot(d, sc), dot(d, vec2(-sc.y, sc.x))); 
 return (r >= 0.0) ? destCoord() : p+center; 
,vec2 samplePoint
destCoord()
samplePoint
float
vec2
vec3
vec4
color
mat2
mat3
mat4
__table
kernel vec4 autoROI_%s(__sample s,vec4 e,
%s v%d%s
  vec2 pt = ( 
v%d%s
,s.xy) - e.xy) / e.zw; return pt.xyxy; }
kernel vec4 autoROI_%s(sampler s,vec4 e,
  vec2 pt = 
 return ((samplerTransform(s, pt).xyxy)- e.xyxy) / e.zwzw; }
CIWarpKernel-autoROI
kernel vec2 _wrapMirror (vec2 dim) { return mix(dim - abs(dim-destCoord()), abs(destCoord()), vec2(lessThan(destCoord(), 0.5 * dim))); }
general
render
performance
compile
signpost_render
signpost_compile
signpost_cache
signpost_detector
signpost_filter
signpost_dualredeye
 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
CIMetalWrapper
CIPortraitBlurStitchableV2
CIPortraitBlurV3
CIPortraitBlurStitchableV3
BlurMapSmoothing
DisparitySmoothing
DisparityRefinement
Rendering
RenderingV3
faces.%@
xhlrb
kernel vec4 _convertDepthOrDisparity(__sample s) 
  __attribute__((outputFormat(kCIFormatRh)))
{ return vec4(1.0/max(s.r,1e-6), s.gba); }
kernel vec4 _segmentationFusion(__sample blurmap,__sample alpha,vec3 addBlur,vec3 removeBlur) { float additiveTerm = clamp( addBlur.x * alpha.x + addBlur.y, 0.0, addBlur.z ); float subtractiveTerm = clamp( removeBlur.x * alpha.x + removeBlur.y, 0.0, removeBlur.z ); float outputBlurValue = sqrt ( clamp( ( blurmap.x * blurmap.x )+ additiveTerm - subtractiveTerm, 0.0, 1.0) ); return vec4(outputBlurValue, outputBlurValue, outputBlurValue, 1.0); }
additiveLowerAlpha
additiveUpperAlpha
additiveMaxBlur
subtractiveLowerAlpha
subtractiveUpperAlpha
subtractiveMaxBlur
disparity_refinement_slm_passthrough
disparity_refinement_calcweightsX
disparity_refinement_calcweightsY
radius
weightScaling
-[CIDisparityWeightsV3 outputImage]
CIsDOF.m
weightsXKernel
weightsYKernel
disparity_refinement_preproc
disparity_refinement_preproc_no_alpha
-[CIDisparityPreprocV3 outputImage]
preprocKernel
disparity_refinement_sample
maxReconstructionWeight
disparitySigma
lumaSigma
chromaSigma
segmentationSigma
accumulatedWeightT0
accumulatedWeightT1
innerSamplingRadius
outerSamplingRadius
-[CIDisparityRefinementSparseSamplerV3 outputImage]
sampleKernel
-[CIDisparityRefinementSparseSamplerV3 outputImage]_block_invoke
disparity_refinement_antialias
aaLumaSigma
aaChromaSigma
aaSegmentationSigma
aaSpatialSigma
-[CIDisparityRefinementAntialiasV3 outputImage]
antialiasKernel
-[CIDisparityRefinementAntialiasV3 outputImage]_block_invoke
CIDisparityPreprocV3
inputAlphaImage
CIDisparityWeightsV3
CIDisparityRefinementSparseSamplerV3
inputPreprocImage
CIDisparityRefinementAntialiasV3
inputDisparityWeightImage
inputLeftEyePosition
inputRightEyePosition
inputChinPosition
inputFaceMidPoint
CGImageMetadataRef
inputOriginalSize
CILensModelCalculator
inputMinMaxImage
inputSimulatedAperture
inputIntrinsicMatrixFocalLength
CILensModelApply
inputLensModelParams
inputFacesLeftEyeX
inputFacesLeftEyeY
inputFacesCenterX
inputFacesCenterY
inputFacesRightEyeX
inputFacesRightEyeY
inputFacesChinX
inputFacesChinY
inputFacesMaxBlurOnEyes
maxBlurOnEyes
inputFacesMaxBlurDistFromFocus
maxBlurDistFromFocus
inputFacesEyeToEyebrowRatio
eyeToEyebrowRatio
inputFacesLinearBlurGrowthM
linearBlurGrowthM
inputFacesLinearBlurGrowthC
linearBlurGrowthC
inputFacesDistToBlurScaling
distToBlurScaling
inputFacesCapMultip
capMultip
inputFacesGainMultip
gainMultip
CIFaceMaskCalculator
CIFaceMaskApply
inputParameterImage
inputImageSize
inputDistanceAdd
inputAdditiveMaxBlur
inputFaceMaskAdditiveMaxBlur
inputSubtractiveMaxBlur
inputFaceMaskSubtractiveMaxBlur
inputSubjectDistanceMinimumFocusDistance
inputSubjectDistanceMaximumFocusDistance
inputSubjectDistanceScalingFactor
inputSubjectDistanceOffset
CIFaceMaskDelta
-[CIDepthEffectMakeBlurMap faceMaskDelta:extent:parameters:distanceToAdd:]
[filter isKindOfClass:NSClassFromString(@"CIFaceMaskDelta")]
-[CIDepthEffectMakeBlurMap blurMapV2:]
shiftMap
slmParams
blurMap
faceMaskParams
CI_NATIVE_FOCAL_PLANE
CIFocalPlaneNative
inputLensModelCalculatorImage
inputMainImage
inputPredicateImage
CIDisparityRefinementV3
-[CIDepthEffectMakeBlurMap blurMapV3:shiftmap:alphaImage:]
lensModelParams
refinedShiftmap
CI_DISABLE_SEGMENTATION_FUSION
CISegmentationFusion
-[CIDepthEffectMakeBlurMap blurMapV4:shiftmap:alphaImage:hairImage:]
hairAdditiveLowerAlpha
hairAdditiveUpperAlpha
hairAdditiveMaxBlur
hairSubtractiveLowerAlpha
hairSubtractiveUpperAlpha
hairSubtractiveMaxBlur
faceMaskAdditiveMaxBlur
faceMaskSubtractiveMaxBlur
smoothstepMin
smoothstepMax
personDistance
personThreshold
personMaxBlur
hairDistance
hairThreshold
hairMaxBlur
minimumFocusDistance
maximumFocusDistance
protectBodyStrength
distanceAdd
relativeApertureScalingStrength
subjectDistanceScalingFactor
subjectDistanceOffset
eyeProtectionMaxFaces
eyeProtectionFaceWeightsSmoothStepMin
eyeProtectionFaceWeightsSmoothStepMax
eyeProtectionOvalDimsDistanceScale
eyeProtectionOvalDimsDistanceOffset
eyeProtectionOvalDimsRadiusHorizontal
eyeProtectionOvalDimsRadiusVertical
eyeProtectionOvalFallOffSmoothStepMin
eyeProtectionOvalFallOffSmoothStepMax
eyeProtectionPersonMaskSmoothStepMin
eyeProtectionPersonMaskSmoothStepMax
eyeProtectionPreventStrength
eyeProtectionSubtractiveMaxBlur
eyeProtectionSubtractiveApertureScaling
inputSmoothstepMin
inputSmoothstepMax
inputRelativeApertureScalingStrength
inputPersonDistance
inputPersonThreshold
inputPersonAdditive
inputPersonSubtractive
inputPersonMaxBlur
inputHairDistance
inputHairThreshold
inputHairAdditive
inputHairSubtractive
inputHairMaxBlur
inputProtectBodyStrength
faceDelta
inputFaceMaskDeltaImage
inputLeftEyeX
inputLeftEyeY
inputRightEyeX
inputRightEyeY
inputFaceMidPointX
inputFaceMidPointY
inputEyeProtectionMaxFaces
inputEyeProtectionFaceWeightsSmoothStepMin
inputEyeProtectionFaceWeightsSmoothStepMax
inputEyeProtectionOvalDimsDistanceScale
inputEyeProtectionOvalDimsDistanceOffset
inputEyeProtectionOvalDimsRadiusHorizontal
inputEyeProtectionOvalDimsRadiusVertical
inputEyeProtectionOvalFallOffSmoothStepMin
inputEyeProtectionOvalFallOffSmoothStepMax
inputEyeProtectionPersonMaskSmoothStepMin
inputEyeProtectionPersonMaskSmoothStepMax
inputEyeProtectionPreventStrength
inputEyeProtectionSubtractiveMaxBlur
inputEyeProtectionSubtractiveApertureScaling
inputPersonAlpha
inputHairAlpha
CIModifyBlurmap
-[CIDepthEffectMakeBlurMap outputImage]
CIBlurmapSmoothing
CIPortraitBlur
getRenderingParametersFromMetaData:
minSimulatedAperture:
maxSimulatedAperture:
inputShiftmapImage
inputShiftMin
inputShiftMax
inputUseMipmaps
inputUseNativeImage
inputUseNormalizedDisparity
lumaNoiseScale
inputBlurMap
depthBlurEffect
UnpackedRenderingParameters
http://ns.apple.com/depthBlurEffect/1.0/
depthBlurEffect:UnpackedRenderingParameters
<?xml version="1.0" encoding="UTF-8"?> <!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"> <plist version="1.0"> <dict> <key>DisparitySmoothing</key> <dict> <key>nIterations</key> <real>2</real> </dict> <key>NoiseEstimation</key> <dict> <key>HDR</key> <dict> <key>GainLevels</key> <array> <real>0.0</real> <real>1</real> <real>2</real> <real>4</real> <real>8</real> <real>16</real> <real>32</real> <real>64</real> </array> <key>NoiseLevels</key> <array> <real>0.0070000000000000001</real> <real>0.01</real> <real>0.014999999999999999</real> <real>0.017999999999999999</real> <real>0.02</real> <real>0.021999999999999999</real> <real>0.023</real> <real>0.025000000000000001</real> </array> </dict> <key>OIS</key> <dict> <key>GainLevels</key> <array> <real>0.0</real> <real>1</real> <real>2</real> <real>4</real> <real>8</real> <real>16</real> <real>32</real> <real>64</real> </array> <key>NoiseLevels</key> <array> <real>0.0070000000000000001</real> <real>0.01</real> <real>0.014999999999999999</real> <real>0.017999999999999999</real> <real>0.02</real> <real>0.021999999999999999</real> <real>0.023</real> <real>0.025000000000000001</real> </array> </dict> <key>SIS</key> <dict> <key>GainLevels</key> <array> <real>0.0</real> <real>1</real> <real>2</real> <real>4</real> <real>8</real> <real>16</real> <real>32</real> <real>64</real> </array> <key>NoiseLevels</key> <array> <real>0.0070000000000000001</real> <real>0.01</real> <real>0.014999999999999999</real> <real>0.017999999999999999</real> <real>0.02</real> <real>0.021999999999999999</real> <real>0.023</real> <real>0.025000000000000001</real> </array> </dict> <key>SingleImage</key> <dict> <key>GainLevels</key> <array> <real>0.0</real> <real>1</real> <real>2</real> <real>4</real> <real>8</real> <real>16</real> <real>32</real> <real>64</real> </array> <key>NoiseLevels</key> <array> <real>0.0050000000000000001</real> <real>0.0050000000000000001</real> <real>0.0070000000000000001</real> <real>0.01</real> <real>0.014999999999999999</real> <real>0.02</real> <real>0.028000000000000001</real> <real>0.033000000000000002</real> </array> </dict> </dict> <key>Rendering</key> <dict> <key>antiAliasBlurStrength</key> <real>0.15</real> <key>basePixelWeight</key> <real>9.9999999999999998e-13</real> <key>faces.capMultip</key> <real>1</real> <key>faces.chinThetaLimit</key> <real>1</real> <key>faces.chinThetaMultip</key> <real>1</real> <key>faces.chinVectorSnapping</key> <real>0.5</real> <key>faces.distToBlurScaling</key> <real>0.090999999999999998</real> <key>faces.eyeToEyebrowRatio</key> <real>1.3999999999999999</real> <key>faces.gainMultip</key> <real>1</real> <key>faces.linearBlurGrowthC</key> <real>0.00027901</real> <key>faces.linearBlurGrowthM</key> <real>0.01</real> <key>faces.maxBlurDistFromFocus</key> <real>0.00074405000000000001</real> <key>faces.maxBlurOnEyes</key> <real>0.0022000000000000001</real> <key>highlightBoostGain</key> <real>0.5</real> <key>lumaNoiseModelCoeff</key> <real>0.9</real> <key>lumaNoiseScale</key> <real>0.0025000000000000001</real> <key>maxBlur</key> <real>0.029999999999999999</real> <key>nSamples</key> <real>100</real> <key>relativeWeightThreshold</key> <real>0.0063120187260210497</real> <key>sharpRadius</key> <real>0.25</real> <key>softRadius</key> <real>1.5</real> <key>spatialWeightSoftMax</key> <real>1.05</real> <key>spatialWeightSoftMin</key> <real>0.94999999999999996</real> </dict> <key>RenderingV3</key> <dict> <key>preFilterRadius</key> <real>1</real> <key>preFilterBlurStrength</key> <real>0.05</real> <key>maxBlur</key> <real>0.03</real> <key>sharpRadius</key> <real>0.25</real> <key>softRadius</key> <real>1.5</real> <key>lumaNoiseModelCoeff</key> <real>0.9</real> <key>highlightBoostGain</key> <real>0.5</real> <key>nRings</key> <real>9</real> <key>basePixelWeight</key> <real>1E-12</real> <key>antiAliasBlurStrength</key> <real>0.6</real> <key>antiAliasRadius</key> <real>7</real> <key>relativeWeightThreshold</key> <real>0.00631201872602105</real> <key>alphaEpsilon</key> <real>0.05</real> <key>alphaGain</key> <real>2.0</real> <key>shapeObstructionCoeff</key> <real>0.7</real> <key>ringAmplitude</key> <real>2.0</real> <key>ringSharpness</key> <real>100.0</real> <key>xhlrbIterations</key> <real>50</real> <key>xhlrbBlurRadiusT0</key> <real>0.0025</real> <key>xhlrbBlurRadiusT1</key> <real>0.0075</real> <key>xhlrbMaxIntensityT0</key> <real>0.9</real> <key>xhlrbMaxIntensityT1</key> <real>1.0</real> <key>xhlrbMinIntensityT0</key> <real>0.0</real> <key>xhlrbMinIntensityT1</key> <real>0.2</real> <key>xhlrbExposureScoreT0</key> <real>1.0</real> <key>xhlrbExposureScoreT1</key> <real>5.0</real> <key>xhlrbClippedPixelsT0</key> <real>1.0</real> <key>xhlrbClippedPixelsT1</key> <real>5.0</real> <key>xhlrbRecoveryScoreT</key> <real>0.5</real> <key>xhlrbPreFilterGain</key> <real>25.0</real> <key>xhlrbWeightGain</key> <real>4.0</real> <key>xhlrbIntensityGain</key> <real>2.0</real> <key>faces.maxBlurOnEyes</key> <real>0.0022</real> <key>faces.maxBlurDistFromFocus</key> <real>7.4405e-04</real> <key>faces.eyeToEyebrowRatio</key> <real>1.4</real> <key>faces.linearBlurGrowthM</key> <real>0.01</real> <key>faces.linearBlurGrowthC</key> <real>2.7901e-4</real> <key>faces.distToBlurScaling</key> <real>0.091</real> <key>faces.capMultip</key> <real>1.0</real> <key>faces.gainMultip</key> <real>1.0</real> <key>faces.chinThetaLimit</key> <real>1.0</real> <key>faces.chinThetaMultip</key> <real>1.0</real> <key>faces.chinVectorSnapping</key> <real>0.5</real> </dict> <key>SLM</key> <dict> <key>fallbackFocusROI_height</key> <real>0.10000000000000001</real> <key>fallbackFocusROI_left</key> <real>0.45000000000000001</real> <key>fallbackFocusROI_top</key> <real>0.45000000000000001</real> <key>fallbackFocusROI_width</key> <real>0.10000000000000001</real> <key>maxFGBlur</key> <real>0.00020000000000000001</real> <key>shiftDeadZone</key> <real>0.29999999999999999</real> <key>simulatedAperture</key> <real>4.5</real> <key>zeroShiftPercentile</key> <real>0.75</real> </dict> <key>BlurMapSmoothing</key> <dict> <key>nIterations</key> <real>5</real> <key>originalBlurValueT0</key> <real>0.2</real> <key>originalBlurValueT1</key> <real>0.5</real> <key>localMinimumBlurValueT0</key> <real>0.05</real> <key>localMinimumBlurValueT1</key> <real>0.3</real> </dict> </dict> </plist>
SDOFParameterValue_block_invoke
sdofParameters
SDOFParameterValue
value
Fusion
BlurMapRefinement
depthBlurEffect:RenderingParameters
centerPos
leftEyeCenterPos
rightEyeCenterPos
chinCenterPos
CCFacePoints
Class getCCFacePointsClass(void)_block_invoke
void *CCPortraitLibrary(void)
/System/Library/VideoProcessors/CCPortrait.bundle/CCPortrait
/System/Library/VideoProcessors/CCPortrait.bundle/Contents/MacOS/CCPortrait
options
metadata
simulatedAperture
focalLengthInPixels
focusWindow
facePoints
inputImageLuma
inputImageChroma
inputShiftMap
inputSegmentation
inputHair
inputGlasses
CCMakeBlurMapArgs
Class getCCMakeBlurMapArgsClass(void)_block_invoke
CCMakeBlurMap
Class getCCMakeBlurMapClass(void)_block_invoke
faces.linearBlurGrowthC
faces.linearBlurGrowthM
faces.distToBlurScaling
faces.eyeToEyebrowRatio
faces.maxBlurOnEyes
faces.maxBlurDistFromFocus
faces.capMultip
faces.gainMultip
unified_rendering
UNIFIED_RENDERING
lumaNoiseAmplitude
inputAlpha
CCApplyBlurMapArgs
Class getCCApplyBlurMapArgsClass(void)_block_invoke
CCApplyBlurMap
Class getCCApplyBlurMapClass(void)_block_invoke
depthData:IntrinsicMatrixReferenceWidth
depthData:IntrinsicMatrixReferenceHeight
CCSDOFMetadata
Class getCCSDOFMetadataClass(void)_block_invoke
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
RenderingParameters
subjectDistanceMinimumFocusDistance
subjectDistanceMaximumFocusDistance
beyeProtectionOvalDimsDistanceOffset
kernel vec4 _scaleClamp(__sample p, float scale) 
 return clamp(p * scale, 0.0, 1.0); 
kernel vec4 _innerGorS (__sample b, __color color, float range) 
 return clamp((1.0 - b.a) / range, 0.0, 1.0) * color; 
inputOffset
inputRange
kernel vec4 _outerGorS (__sample b, __color color, float range) 
 return clamp(b.a / range, 0.0, 1.0) * color; 
inputSpread
inputGlowColorInner
inputGlowOuterOuter
inputShadowColorInner
inputShadowOuterOuter
inputShadowBlurInner
inputShadowBlurOuter
kernel vec4 _shapeEffectBlur_1 (__sample p0, __sample p1, __sample b0, __sample b1, __sample f0, 
 __color gcI, __color gcO, __color scI, __color scO, vec2 sparms) 
 gcI *= clamp( (1.0 - b0.a) * 2.0, 0.0, 1.0); 
 gcO *= clamp( b0.a * 2.0, 0.0, 1.0); 
 scI *= mix( (1.0 - p1.a), (1.0 - b1.a), sparms.x ); 
 scO *= mix( p1.a, b1.a, sparms.y ); 
 vec4 I,O; 
 I = (gcI + f0*(1.0 - gcI.a)); 
 I = (scI + I*(1.0 - scI.a)) * (p0.a); 
 O = (gcO + scO*(1.0 - gcO.a)) * (1.0 - p0.a); 
 return I + O*(1.0 - I.a); 
inputSoften
inputHighlightColor
inputShadowColor
kernel vec4 _outerBevelEmboss (sampler image, vec2 ss) 
 vec2 st = destCoord(); 
 float a = 0.0, mm_a, pm_a, mp_a, pp_a; 
 mm_a = sample(image, samplerTransform(image, st + ss.yy)).a; 
 pm_a = sample(image, samplerTransform(image, st + ss.xy)).a; 
 mp_a = sample(image, samplerTransform(image, st + ss.yx)).a; 
 pp_a = sample(image, samplerTransform(image, st + ss.xx)).a; 
 a = mm_a + pm_a - 1.3*(mp_a+pp_a); 
 a = clamp( a*0.5 + 0.5, 0.0, 1.0); 
 return vec4(a); 
kernel vec4 _outerBevelEmbossC (__sample v, __color hc, __color sc) 
 float a = v.a * 2.0 - 1.0; 
 vec4 result = hc*clamp(a, 0.0, 1.0) + sc*clamp(-a, 0.0, 1.0); 
 return result; 
kernel vec4 _invertedMask (__sample c) { return vec4(0.0, 0.0, 0.0, 1.0 - c.a); } 
kernel vec4 _multiplyByMask (__sample c, __sample m) { return c*m.a;} 
devicegray
devicergb
calRGB(
wp=d50 
wp=%.3f,%.3f,%.3f 
bp=%.3f,%.3f,%.3f 
gamma=1 
gamma=%.3f 
gamma=%.3f,%.3f,%.3f 
mtx=%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f,%.3f)
calGray(
gamma=1)
gamma=%.3f)
sRGB
"%s"
Lab Colorspace %p
Indexed Colorspace %p
DeviceN Colorspace %p
Pattern Colorspace %p
PlatformSets Colorspace %p
ConvertYCbCrtoREDEYEFORMAT: rowSamples is too small for CbCr bitmap
ConvertYCbCrtoREDEYEFORMAT: rowSamples is too small for Y bitmap
ConvertYCbCrtoREDEYEFORMAT: heights do not match
ConvertYCbCrtoREDEYEFORMAT: widths do not match
ConvertRedChannel5toY: rowSamples is too small for ARGB bitmap
ConvertRedChannel5toY: rowSamples is too small for CbCr bitmap
ConvertRedChannel5toY: rowSamples is too small for Y bitmap
ConvertRedChannel5toY: heights do not match
ConvertRedChannel5toY: widths do not match
ConvertRedChannel2toY: rowSamples is too small for ARGB bitmap
ConvertRedChannel2toY: rowSamples is too small for CbCr bitmap
ConvertRedChannel2toY: rowSamples is too small for Y bitmap
ConvertRedChannel2toY: heights do not match
ConvertRedChannel2toY: widths do not match
%.5f
%.6f
size = %d, center = %d, %d, I = %g, Q = %g
Projections error %d:%s in %s @ %s:%d
FastRegistration_status FastRegistration_computeSignatures(const vImage_Buffer *, _Bool, dispatch_queue_t, FastRegistration_Signatures *)
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-1200.29/Framework/api/Burst/Projections/FastRegistration_Core.c
FastRegistration error %d:%s in %s @ %s:%d
FastRegistration_status FastRegistration_register(const FastRegistration_Signatures *, const FastRegistration_Signatures *, float, dispatch_queue_t, float *, float *, float *, float *)
FastRegistration_status FastRegistration_processProjections(float *, vImagePixelCount)
!!! you should not read this !!!
error with the projections computation
vImage error
out of bounds error
memory allocation error
invalid parameter
invalid option
internal error
kernel vec4 _redEyeGlintfinder(__sample a, vec4 factors, vec4 offsets) { vec4 b = max(sqrt(a)*factors - offsets, vec4(0.0)); float y = b.r * b.g * b.b; return vec4(y, y, y, 1.0); }
kernel vec4 _redEyeHorizontalMinKernel(sampler im, float radius) { float offset; vec2 pt, sd; vec4 s, minsofar; pt = samplerCoord(im); sd = samplerTransform(im, destCoord() + vec2(1.0)) - pt; minsofar = sample(im, pt + vec2(0.0, 0.0)*sd); for (offset = 1.0; offset <= radius; offset += 1.0) { s = sample(im, pt + vec2(offset, 0.0)*sd); minsofar = min(minsofar, s); s = sample(im, pt + vec2(-offset, 0.0)*sd); minsofar = min(minsofar, s); } return minsofar; } kernel vec4 _redEyeVerticalMinKernel(sampler im, float radius) { float offset; vec2 pt, sd; vec4 s, minsofar; pt = samplerCoord(im); sd = samplerTransform(im, destCoord() + vec2(1.0)) - pt; minsofar = sample(im, pt + vec2(0.0, 0.0)*sd); for (offset = 1.0; offset <= radius; offset += 1.0) { s = sample(im, pt + vec2(0.0, offset)*sd); minsofar = min(minsofar, s); s = sample(im, pt + vec2(0.0, -offset)*sd); minsofar = min(minsofar, s); } return minsofar; }
kernel vec4 _redEyeHorizontalMaxKernel(sampler im, float radius) { float offset; vec2 pt, sd; vec4 s, maxsofar; pt = samplerCoord(im); sd = samplerTransform(im, destCoord() + vec2(1.0)) - pt; maxsofar = sample(im, pt + vec2(0.0, 0.0)*sd); for (offset = 1.0; offset <= radius; offset += 1.0) { s = sample(im, pt + vec2(offset, 0.0)*sd); maxsofar = max(maxsofar, s); s = sample(im, pt + vec2(-offset, 0.0)*sd); maxsofar = max(maxsofar, s); } return maxsofar; } kernel vec4 _redEyeVerticalMaxKernel(sampler im, float radius) { float offset; vec2 pt, sd; vec4 s, maxsofar; pt = samplerCoord(im); sd = samplerTransform(im, destCoord() + vec2(1.0)) - pt; maxsofar = sample(im, pt + vec2(0.0, 0.0)*sd); for (offset = 1.0; offset <= radius; offset += 1.0) { s = sample(im, pt + vec2(0.0, offset)*sd); maxsofar = max(maxsofar, s); s = sample(im, pt + vec2(0.0, -offset)*sd); maxsofar = max(maxsofar, s); } return maxsofar; }
kernel vec4 _redEyeDifference(sampler src1, sampler src2) { vec2 dc = destCoord(); vec4 s1, s2, diff; s1 = sample(src1, samplerTransform(src1, dc)); s2 = sample(src2, samplerTransform(src2, dc)); diff = max(s1 - s2, vec4(0.0)); return vec4(diff.rgb, 1.0); }
kernel vec4 _redEyeGaborToYAndVF(sampler src) { vec2 dc = destCoord(); vec2 pt, u, u2, v, v2; pt = samplerTransform(src, dc); u = samplerTransform(src, dc + vec2(1.0, 0.0)) - pt; v = samplerTransform(src, dc + vec2(0.0, 1.0)) - pt; u2 = u + u; v2 = v + v; float d2, d3, d4, d6, d7, d8, d9, d10, d11, d12; d2 = sample(src, pt - u + v2).r - sample(src, pt + u - v2).r; d3 = sample(src, pt + v2).r - sample(src, pt - v2).r; d4 = sample(src, pt + u + v2).r - sample(src, pt - u - v2).r; d6 = sample(src, pt - u2 + v ).r - sample(src, pt + u2 - v ).r; d7 = sample(src, pt - u + v ).r - sample(src, pt + u - v ).r; d8 = sample(src, pt + v ).r - sample(src, pt - v ).r; d9 = sample(src, pt + u + v ).r - sample(src, pt - u - v ).r; d10 = sample(src, pt + u2 + v ).r - sample(src, pt - u2 - v ).r; d11 = sample(src, pt - u2 ).r - sample(src, pt + u2 ).r; d12 = sample(src, pt - u ).r - sample(src, pt + u ).r; float fx = -0.54470*d12 - 0.17643*(d7 - d9) - 0.04445*d11 - 0.01801*(d6 - d10) - 0.00900*(d2 - d4); float fy = 0.54470*d8 + 0.17643*(d7 + d9) + 0.04445*d3 + 0.01801*(d2 + d4) + 0.00900*(d6 + d10); float mag = sqrt(fx*fx + fy*fy); float angle = atan(fy, fx) + 1.5707963; angle = compare(mag - 0.0001, 1.5707963, angle); angle = compare(angle, angle + 6.2831853, angle); float norm = compare(mag - 0.00001, 0.0, 1.0 / mag); fx *= norm; fy *= norm; return vec4(fx, fy, mag, angle); }
projectionRows_planar8UtoF
projectionCols_planar8UtoF
Projections_status Projections_projectionRowsCols_planar8UtoF(const uint8_t *, int, int, size_t, float *, float *)
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-1200.29/Framework/api/Burst/Projections/Projections_Core.c
Projections_status Projections_computeProjectionDerivative(const float *, int, float *)
function not implemented
out of boundaries
Projections_status Projections_computeShiftBruteForce(const float *, int, const Projections_meanStdTable *, const float *, int, const Projections_meanStdTable *, int, float, float *, float *, float *, float *)
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-1200.29/Framework/api/Burst/Projections/Projections_Optimizer.c
Projections_status Projections_computeCost(int, float, float, const float *, int, const Projections_meanStdTable *, const float *, int, const Projections_meanStdTable *, int, float *)
FILTERNAME
type
description
+[CIFilter(SDOFOnlyPrewarmingPrivate) prewarmedFilterFromString:]
CIFilter+Prewarming.m
[objectDescription[@"type"] isEqualToString:[[CIImage class] description]]
isEqualTo:
-[CIFilter(SDOFOnlyPrewarmingPrivate) verifyPrewarmedFilter:]
CGRectEqualToRect(goldImage.extent, fakeImage.extent)
[goldCCDDict isEqualToDictionary:fakeCCDDict]
B24@?0r^{__CFString=}8^{CGImageMetadataTag=}16
sector %d:
 -- max %d min %d grad %d
max average %.1f min average %.1f max gradient %.1f
sector %d 
factor %.3f offset %.3f max sample %d
%s -- hopper with %d elements total
  element %d i %3d/%d j %3d/%d score %5.3f
attempt to print invalid thread %d
closed 
thread %3d start %4d end %4d %3d points length %5.1f turn %6.1f
%s -- %d threads total
checkpoint %d bins (min %.2f max %.2f avg %.2f low avg %.2f high avg %.2f)
  %6.2f
mean = %.2f SD = %.2f
%s %3d with %d points
  %d
%s %3d with %d points and %d checkpoints
  %d (%.1f, %.1f)
%s after update %3d with %d points and %d checkpoints
edge width %.2f
%3d (%5.1f, %5.1f) %6.4f %6.1f
 del %6.1f
  0 %d (%.2f, %.2f)
  %d %d (%.2f, %.2f)
%s swapping
%3d (%5.1f, %5.1f) %6.4f %6.1f
 del %6.1f [%6.1f %6.1f %6.1f %6.1f]
1/%d scale: min %4.2f max %4.2f avg %4.2f # neg %d
%s-T.tiff
%s-C.tiff
%s-R.tiff
      %c %3d turn %d
%3.1f%% of IOD HSV (%5.3f, %5.3f, %5.1f) SAT (%2d %2d %2d) REC %5.1f
%s.tiff
1-ORIG
RedEyeChannel
inputChannel
2-REC
RedEyeMinMorphology
3-MIN
RedEyeMaxMorphology
4-MAX
RedEyeDifference
inputSubtractedImage
5-DIFF
RedEyeGradient
6-MAG
RedEyeGlintFinder
inputThresholds
7-SHIN
2-DIFF
A-OSHN
B-POLY
3-OPTI
4-DIST
%s glint neighborhood
intensity %5.1f diameter %4.1f falloff %.3f
5-PROD
6-SHIN
7-FINL
before
after
Original
Amber
Amber Specular
R + Y
Iris 1
RC7 New
Hue Red
Hue Orange
Hue Yellow
Red Finder 1
Red Finder 2
Glint Finder
Red Finder 1 + Glint
Sclera 1
Sclera 2
Hue Lim
Rng Amt
Y Thr
Red Prev
Thresh
kernel vec4 _redEyeChannelOriginal(__sample a, vec4 params) { return a; } kernel vec4 _redEyeChannelY(__sample a, vec4 params) { float y = dot(a, vec4(0.299, 0.587, 0.114, 0.0)); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRed(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float y = r; return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRC2(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = clamp(r - (g + b) * 0.5, 0.0, 1.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRC3(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = clamp(2.0*r - g - b - r*g, 0.0, 1.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRC4(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = clamp(3.0*r - 2.0*g - b - r*g, 0.0, 1.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRC5(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float y = max(r - g - r*g, 0.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRC6(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = clamp(0.5 - 1.7*(g + b) + 1.45*r, 0.0, 1.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRC7(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float y = clamp(2.0*r - 1.2*g - 0.2, 0.0, 1.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRC8(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = clamp(r*(r - max(g, b)), 0.0, 1.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelAmber(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = clamp(((r*(g+b))*(2.0*r - 2.0*g - b)) * 64.0, 0.0, 1.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelAmberSpecular(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = clamp((3.0*(g + b) - 4.0*r) * 0.5, 0.0, 1.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRPlusY(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = dot(a, vec4(0.299, 0.587, 0.114, 0.0)); y = (r + y) * 0.5; return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelIris1(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = max(r*g - b*0.2, 0.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRC7New(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = clamp(2.0*r - 1.2*g - 0.2 + r*g*b*0.4, 0.0, 1.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelHueRed(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float hi = max(r, max(g, b)); float lo = min(r, min(g, b)); float rng = hi - lo; float sum = hi + lo; float sat = min(rng / max(compare(sum - 1.0, sum, 2.0 - sum), 0.00001), 1.0); float lum = r*0.299 + g*0.587 + b*0.114; float hue = compare(r - (hi - 0.000001), 0.0, max(1.0 - abs(((g - b)*params.r) / rng), 0.0)); float y = compare(rng - 0.00001, 0.0, min(hue*rng*sat, 1.0))*params.g; return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelHueOrange(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float hi = max(r, max(g, b)); float lo = min(r, min(g, b)); float rng = hi - lo; float sum = hi + lo; float sat = min(rng / max(compare(sum - 1.0, sum, 2.0 - sum), 0.00001), 1.0); float lum = r*0.299 + g*0.587 + b*0.114; float hue = compare(r - (hi - 0.000001), 0.0, max(1.0 - abs(((g - b)*2.0) / rng - 1.0), 0.0)); float y = compare(rng - 0.00001, 0.0, min(hue*rng*sat, 1.0))*4.0; return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelHueYellow(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float hi = max(r, max(g, b)); float lo = min(r, min(g, b)); float rng = hi - lo; float sum = hi + lo; float sat = min(rng / max(compare(sum - 1.0, sum, 2.0 - sum), 0.00001), 1.0); float lum = r*0.299 + g*0.587 + b*0.114; float y = max(min(r*g*sat*lum*rng*4.0, 1.0), 0.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRC9(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float hi = max(r, max(g, b)); float lo = min(r, min(g, b)); float reddom = max(r - max(g, b), 0.0); float rng = hi - lo; float sum = hi + lo; float sat = min(rng / max(compare(sum - 1.0, sum, 2.0 - sum), 0.00001), 1.0); float y = min(r*reddom*rng*sat*3.0, 1.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRedfinder1(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = min(max(r - g, 0.0)*max(r - b, 0.0)*10.0*r, 1.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRedfinder2(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float hi = max(r, max(g, b)); float lo = min(r, min(g, b)); float y = r*(hi - lo); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelGlintfinder(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = max(r*params.r - (params.r - 1.0), 0.0)*max(g*params.g - (params.g - 1.0), 0.0)*max(b*params.b - (params.b - 1.0), 0.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelRedfinder1PlusGlint(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float y = max(r - g, 0.0)*max(r - b, 0.0)*10.0*r; y += r*g*b*0.4; y = max(min(y, 1.0), 0.0); return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelSclera1(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float lum = r*0.299 + g*0.587 + b*0.114; float hi = max(r, max(g, b)); float lo = min(r, min(g, b)); float rng = hi - lo; float y = max(1.0 - rng*params.r, 0.0)*max(lum - params.g, 0.0)*params.b; return vec4(y, y, y, 1.0); } kernel vec4 _redEyeChannelSclera2(__sample a, vec4 params) { float r = sqrt(max(a.r, 0.0)); float g = sqrt(max(a.g, 0.0)); float b = sqrt(max(a.b, 0.0)); float lum = r*0.299 + g*0.587 + b*0.114; float hi = max(r, max(g, b)); float lo = min(r, min(g, b)); float rng = hi - lo; float y = lum*(1.0 - rng)*(1.0 - (r - g)*(r - b)*params.r) - params.g; return vec4(y, y, y, 1.0); }
extractAlpha:alphaMap
extractAlpha:savedscans
computePupilAlphaMap:allPoints
computePupilAlphaMap:alphaMap
blurBitmapHorizontal:scan
blurBitmapVertical:scan
infill area boundary path
specular bitmask outside path
infill arcs surround arcs
specular bitmask path outside arc bodies
specular bitmask path outside arcs
arcCorrelation: improper crossing pairing at f1 %.2f
%d crossings:
  [%2d] f2 %.2f pix %.2f 
arcInfill: improper crossing pairing at f1 %.2f
extractFirstGradientMaximumFrom:scanline
computeOutlineByTracingSnake:snakeBodies
computeOutlineByTracingSnake:points
winning snake = connection of snakes %d and %d
computeBitmask: connected pieces search failed
computeBitmask: seedFill failed
computeBitmask: centroid closest bit search failed
computeBitmask: can not allocate bitmask bm2
computeBitmask: can not allocate bitmask bm
recomputeBitmask: seedFill failed
recomputeBitmask: can not allocate bitmask bm2
recomputeBitmask: can not allocate bitmask bm
closestConnectedComponent: seedFill failed
closestConnectedComponent: centroid closest bit search failed
closestConnectedComponent: can not allocate bitmask bm3
closestConnectedComponent: can not allocate bitmask bm2
closestConnectedComponent: can not allocate bitmask bm
cornealReflectionBitmask: can not allocate bitmask bm2 intended for spread
determineOutsidePath: nowhere to go
determineOutsidePath: border pixel expected
determineOutsidePath: overflow
determineOutsidePath: unable to allocate path body
determineOutsidePath: isolated point
determineOutsidePath: no bits set
determineOutsidePath: unable to allocate path
determineArcsAtAngleForOutsidePath: too many arc bodies
determineArcsAtAngleForOutsidePath: too many arcs
determineArcsAtAngleForOutsidePath: unable to allocate arc bodies
determineArcsAtAngleForOutsidePath: unable to allocate arcs
arcCorrelation: no crossings at f1
arcCorrelation: odd number of crossings
arcCorrelation: too many crossings
arcInfill: no crossings at f1
arcInfill: odd number of crossings
arcInfill: too many crossings
error - impossible connect arrangement
incorrect number of points
examineAlpha: bitmaps don't match
examineAlpha: bitmaps are the wrong number of samples per pixel
examineBitmask: bitmaps don't match
examineBitmask: bitmaps are the wrong number of samples per pixel
frame
initWithExternalBuffer:size:rowBytes:f
initWithExternalBuffer:subRectange:fullSize:rowBytes:f
redEyeRemovalWithPoint:recognitionChannels[0]
redEyeRemovalWithPoint:recognitionChannels[1]
redEyeRemovalWithPoint:recognitionChannels[i]
redEyeRemovalWithPoint:table16
extractAverageFaceY: bigyhisto
redEyeRemovalWithData:recognitionChannel
allocSpanStack:s
allocSpanStack:s->firstChunk
pushSpan:s->stackHeadChunk->next
allocSpanStack: span stack could not be allocated
spanSearch: empty span
freeSpanStack: span stack is null
seedFill: can not push span onto stack
seedFill: can not allocate span stack
Error: a compressed surface cannot be cleared using ClearSurface().
CI_TRASH_SURFACES_ON_SETVOLATILE
profileType
gammaR
gammaG
gammaB
phosphorRx
phosphorRy
phosphorGx
phosphorGy
phosphorBx
phosphorBy
whitePointx
whitePointy
copyright
displayRGB
HDTV
Composite NTSC
Composite PAL
HDTV Interim Color Implementation
Digital Cinema P3
D65 P3
QuickTime 'nclc' Video (%d,%d,%d)
Copyright 2007 Apple Inc.
rTRC
gTRC
bTRC
.png
.jpg
CI Internal Context
CI_PRINT_TIME new bitmap (%ldx%ld) = %.3f seconds
CIPersonSegmentationFilter
Couldn't get the output pixelBuffer from Vision request result
The output pixelBuffer from Vision is not the expected width.
The output pixelBuffer from Vision is not the expected height.
The output pixelBuffer from Vision is not the expected format.
CIPersonSegmentationKernel
-[CIPersonSegmentation outputImage]
VNGeneratePersonSegmentationRequest
Class getVNGeneratePersonSegmentationRequestClass(void)_block_invoke
<CI::Buffer %p>[%zu bytes]
[%zu bytes]
<CI::Color %p>[%g %g %g %g]
[%g %g %g %g 
kernel vec4 _colorAbsDiff(__sample c, __sample c2) { vec3 ad = abs(c.rgb - c2.rgb); return vec4(ad.rgb, c.a) * c2.a; }
v16@?0r^{__IOSurface=}8
%llX(%04x,%04x,%04x)
Cannot handle a (%lu x %lu) sized texture with the given GLES context!
CIEAGLContextTexImageIOSurface failed for %s!
GLTextureManager::attach_IOSurface unsupported format %s!
Program exceeds GLES%d uniform size limit. (%d > %zu)
position
texcoord
// Copyright 2015 Apple Inc.
attribute highp vec4 position;
attribute highp vec4 texcoord;
varying highp vec2 p0;
uniform highp mat3 vertexTransform;
void main()
  gl_Position = position;
  p0 = (vec3(texcoord.xy,1.0) * vertexTransform).xy;
opengl
opengles1
opengles2
opengles3
GL_APPLE_client_storage
GL_APPLE_texture_ycbcr_basic_formats
GL_APPLE_texture_ycbcr_extended_formats
GL_EXT_color_buffer_half_float
GL_EXT_shader_texture_lod
GL_OES_texture_half_float
GL_OES_texture_float
GL_APPLE_texture_xr
GLContext::set_surface_destination unsupported format %s!
Destination buffer size too large (%lu x %lu); cannot be larger than %d x %d.
attribute highp vec4 position;
attribute highp vec4 texcoord;
varying highp vec2 p0;
void main()
  gl_Position = position;
  p0 = texcoord.xy;
varying highp vec2 p0;
uniform sampler2D s0;
void main()
  gl_FragColor = texture2D(s0, p0);
Using low GPU priority for background rendering.
Unhandled type: %d
release_surface_block
compile_gl
finish_render
after_render
CI_SUBDIVIDE_QUADS
quad
readback_bitmap
bind_arguments
compile_shader
cikl
Unknown OpenGL Device
%llX(%04X)
Cannot handle a (%lu x %lu) sized texture with the given context!
Unexpected format requesting a texture for format %s
CI::KernelCompileQueue
metal
Unknown Metal Device
kContextInfoWorkingFormat
kContextInfoWorkingSpace
v24@?0Q8Q16
CI_PRINT_TIME [GPU] command buffer (%p) = %.1f ms
CI_PRINT_TIME [GPU] root program (%s) = %.1f ms
CI_PRINT_TIME [GPU] intermediate program (%s) = %.1f ms
compile_metal
compute_quad
cikl-from_archive
CI::RenderCompletionQueue
B12@?0i8
render_quad
wait_for_cache
create_intermediate
Core Image cannot allocate IOSurface with unspecified format.
Core Image cannot allocate surface of size %zu x %zu
%s/%d_intermediate_%d_%d_%d_%d_%d.png
Dumped intermediate to: %s
%s/%d_intermediate_%d_%d_%d_%d_%d.raw
Dumped raw intermediate to: %s
%s/%d_intermediate_%d_%d_%d_%d_%d.bmtl
Dumped bmtl intermediate to: %s
CI_ASSEMBLE_INPUT_TILES
CI::ObjectCacheQ
convert_identity
convert_rgb8_to_rgba8
convert_rgb16_to_rgba16
convert_rgbh_to_rgbah
convert_rgbf_to_rgbaf
convert_rgbah_to_rgba16
convert_rgba16_to_rgbah
convert_argb16_to_rgbah
convert_rgbah_to_rgbaf
convert_rgbaf_to_rgbah
convert_rgb16_to_rgbah
convert_rgbf_to_rgbah
convert_r8_to_rh
convert_rh_to_r8
convert_r8_to_rf
convert_rf_to_r8
convert_rh_to_rf
convert_rf_to_rh
convert_rgbah_to_rh
convert_rh_to_rgbah
convert_rgbaf_to_rf
convert_rf_to_rgbaf
unknown-conversion
v16@?0Q8
convert_cpu
LA16
R10p
RG10p
RG16
RGB8
RGB16
RGBh
RGBf
ARGB8
BGRX8
RGBX8
XRGB8
XBGR8
YCC420f
YCC420v
RGBA16
ARGB16
RGBX16
ARGBf
A2BGR10
A2RGB10
RGB10A2-WideGamut
ARGB10-WideGamut
RGB10A2-WideLinear
ARGB10-WideLinear
RGBA14
CbYCrY8
CbYCrY8f
YCbYCr8
YCbYCr8f
YCC420v10
YCC420f10
YCC420v10Packed
YCC420f10Packed
YCC420fh
unknown-format
420f
420v
RGB10WideGamut
CoreImage needs a %s swizzler so that %s can be read as %s.
kSwizzleBGRAtoRRGG1
kPixelFormatRG16
kPixelFormatBGRA8
kSwizzleBGRAtoLLAA
kPixelFormatLA16
kSwizzleAGBR
kPixelFormatABGR8
kPixelFormatRGBA8
kSwizzleGBA1
kPixelFormatXRGB8
kSwizzleAGB1
kPixelFormatXBGR8
kSwizzleARGB10
kPixelFormatARGB10WideGamut
kPixelFormatRGBA16
kPixelFormatARGB10WideLinear
kSwizzleRGB14
kPixelFormatRGBA14
need a swizzler so that %s can be read.
kSwizzleToARGB10
kSwizzleToRGB14
CoreImage needs a swizzler so that %s can be written.
_i%d
_u%d
_t%d
vec4 _ci_srgb_to_linear (vec4 s) { return _srgb_to_linear(s); }
_samplers[%d]
_transforms[%d]
_extents[%d]
_s%d
_s%d_transform0
_s%d_transform1
_s%d_extent
Cannot use sRGB texture binding with format %s for sampler %d in kernel '%s'.
Invalid DAG node type
vec4 _ci_linear_to_srgb (vec4 s) { return _linear_to_srgb(s); }
hvec4 _read_pixel(hsampler2D image, vec2 c, vec4 m0, vec4 m1) {
 float x = dot(vec4(c,1.0,0.0), m0);
 float y = dot(vec4(c,1.0,0.0), m1);
 return texture2D(image, vec2(x,y)); }
vec4 _read_pixel(sampler2D image, vec2 c, vec4 m0, vec4 m1) {
 float x = dot(vec4(c,1.0,0.0), m0);
 float y = dot(vec4(c,1.0,0.0), m1);
 return texture2D(image, vec2(x,y)); }
hvec4 _read_pixel(hsampler2D image, vec2 c, mat3 m){ return texture2D(image, (vec3(c, 1.0) * m).xy);}
vec4 _read_pixel(sampler2D image, vec2 c, mat3 m){ return texture2D(image, (vec3(c, 1.0) * m).xy);}
hvec4 _read_pixel_420(hsampler2D Y, hsampler2D cc, vec2 c, vec2 f, vec4 m0, vec4 m1){
 float x = dot(vec4(c,1.0,0.0), m0);
 float y = dot(vec4(c,1.0,0.0), m1);
 return hvec4(texture2D(Y, vec2(x,y)).r, texture2D(cc, 0.5*vec2(x,y)).rg, 1.0);}
vec4 _read_pixel_420(sampler2D Y, sampler2D cc, vec2 c, vec2 f, vec4 m0, vec4 m1){
 float x = dot(vec4(c,1.0,0.0), m0);
 float y = dot(vec4(c,1.0,0.0), m1);
 return vec4(texture2D(Y, vec2(x,y)).r, texture2D(cc, 0.5*vec2(x,y)).rg, 1.0);}
hvec4 _read_pixel_420_10p(hsampler2D Y, hsampler2D cc, vec2 c, vec2 f, vec4 m0, vec4 m1){ {
     int cInt = int(c.x-0.5);
     int lumaX = cInt/3;
     int chromaX = cInt/6;
     chromaX = 2*chromaX;
     highp vec3 pLuma = vec3(lumaX+0.5, c.y, 1.0);
     highp vec3 pChroma1 = vec3(2.0*(chromaX + 0.5), c.y, 1.0);
     highp vec3 pChroma2 = vec3(2.0*(chromaX + 1.5), c.y, 1.0);
     pLuma.x = dot(vec4(pLuma.x, pLuma.y, 1.0, 0.0) * m0);
     pChroma1.x = dot(vec4(pLuma.x, pLuma.y, 1.0, 0.0) * m0);
     pChroma2.x = dot(vec4(pLuma.x, pLuma.y, 1.0, 0.0) * m0);
     pChroma1.y = pChroma2.y = pLuma.y = dot(vec4(pLuma.y, pLuma.y, 1.0, 0.0) * m1);
     pLuma.x = dot(vec4(pLuma.y, pLuma.y, 1.0, 0.0) * m1);
     hvec3 lumaGroup = texture2D(Y, pLuma.xy).rgb;
     hvec3 chroma1 = texture2D(cc, pChroma1.xy).rgb;
     hvec3 chroma2 = texture2D(cc, pChroma2.xy).rgb;
     half luma = 0.0f;
     hvec2 chroma = vec2(0.0f);
     int lumaRemainder = cInt % 3;
     if (lumaRemainder == 0){ 
         luma = lumaGroup.z;
     } else if (lumaRemainder == 1) {
         luma = lumaGroup.y;
     } else {
         luma = lumaGroup.x;
     }
     int chromaRemainder = (cInt/2) % 3;
     if (chromaRemainder == 0){ 
         chroma = (0 == (cInt & 1)) ? chroma1.zy : vec2(0.5f)*(hvec2(chroma1.x, chroma2.z) + chroma1.zy);
     } else if (chromaRemainder == 1) {
         chroma = (0 == (cInt & 1)) ? hvec2(chroma1.x, chroma2.z) : hvec2(0.5f)*(chroma2.yx + hvec2(chroma1.x, chroma2.z));
     } else {
         chroma = chroma2.yx;
         chroma = (0 == (cInt & 1)) ? chroma2.yx : hvec2(0.5f)*(chroma2.yx + chroma1.zy);
         if (0 == (cInt & 1)) {
             chroma = chroma2.yx; 
         } else {             highp vec3 pChroma3 = vec3(2.0*(chromaX + 2.5), c.y, 1.0);
             pChroma3.x = dot(vec4(pChroma3.x, pChroma3.y, 1.0, 0.0) * m0);
             pChroma3.y = pLuma.y;
             hvec3 chroma3 = texture2D(cc, pChroma3.xy).rgb;
             chroma = hvec2(0.5f)*(chroma2.yx + chroma3.zy); 
         } 
     }
     return hvec4(luma, chroma.x, chroma.y, 1.0);
vec4 _read_pixel_420_10p(sampler2D Y, sampler2D cc, vec2 c, vec2 f, vec4 m0, vec4 m1)
     int cInt = int(c.x-0.5);
     int lumaX = cInt/3;
     int chromaX = cInt/6;
     chromaX = 2*chromaX;
     highp vec3 pLuma = vec3(lumaX+0.5, c.y, 1.0);
     highp vec3 pChroma1 = vec3(2.0*(chromaX + 0.5), c.y, 1.0);
     highp vec3 pChroma2 = vec3(2.0*(chromaX + 1.5), c.y, 1.0);
     pLuma.x = dot(vec4(pLuma.x, pLuma.y, 1.0, 0.0) * m0);
     pChroma1.x = dot(vec4(pLuma.x, pLuma.y, 1.0, 0.0) * m0);
     pChroma2.x = dot(vec4(pLuma.x, pLuma.y, 1.0, 0.0) * m0);
     pChroma1.y = pChroma2.y = pLuma.y = dot(vec4(pLuma.y, pLuma.y, 1.0, 0.0) * m1);
     pLuma.x = dot(vec4(pLuma.y, pLuma.y, 1.0, 0.0) * m1);
     vec3 lumaGroup = texture2D(Y, pLuma.xy).rgb;
     vec3 chroma1 = texture2D(cc, pChroma1.xy).rgb;
     vec3 chroma2 = texture2D(cc, pChroma2.xy).rgb;
     float luma = 0.0f;
     vec2 chroma = vec2(0.0f);
     int lumaRemainder = cInt % 3;
     if (lumaRemainder == 0){ 
         luma = lumaGroup.z;
     } else if (lumaRemainder == 1) {
         luma = lumaGroup.y;
     } else {
         luma = lumaGroup.x;
     }
     int chromaRemainder = (cInt/2) % 3;
     if (chromaRemainder == 0){ 
         chroma = (0 == (cInt & 1)) ? chroma1.zy : vec2(0.5f)*(vec2(chroma1.x, chroma2.z) + chroma1.zy);
     } else if (chromaRemainder == 1) {
         chroma = (0 == (cInt & 1)) ? vec2(chroma1.x, chroma2.z) : vec2(0.5f)*(chroma2.yx + vec2(chroma1.x, chroma2.z));
     } else {
         chroma = chroma2.yx;
         chroma = (0 == (cInt & 1)) ? chroma2.yx : vec2(0.5f)*(chroma2.yx + chroma1.zy);
         if (0 == (cInt & 1)) {
             chroma = chroma2.yx; 
         } else {             highp vec3 pChroma3 = vec3(2.0*(chromaX + 2.5), c.y, 1.0);
             pChroma3.x = dot(vec4(pChroma3.x, pChroma3.y, 1.0, 0.0) * m0);
             pChroma3.y = pLuma.y;
             vec3 chroma3 = texture2D(cc, pChroma3.xy).rgb;
             chroma = vec2(0.5f)*(chroma2.yx + chroma3.zy); 
         } 
     }
     return vec4(luma, chroma.x, chroma.y, 1.0);
hvec4 _read_pixel_420(hsampler2D Y, hsampler2D cc, vec2 c, vec2 f, mat3 m){
 highp vec3 p = vec3(c, 1.0) * m;
 return hvec4(texture2D(Y, p.xy).r, texture2D(cc, f*p.xy).rg, 1.0);}
vec4 _read_pixel_420(sampler2D Y, sampler2D cc, vec2 c, vec2 f, mat3 m){
 highp vec3 p = vec3(c, 1.0) * m;
 return vec4(texture2D(Y, p.xy).r, texture2D(cc, f*p.xy).rg, 1.0);}
hvec4 _read_pixel_420_10p(hsampler2D Y, hsampler2D cc, vec2 c, vec2 f, mat3 m)  {
     int cInt = int(c.x);
     int cInt2 = int(c.x*0.5);
     int lumaX = cInt/3;
     highp vec3 pLuma = vec3(lumaX+0.5, c.y, 1.0) * m;
     hvec3 lumaGroup = texture2D(Y, pLuma.xy).rgb;
     int lumaRem = cInt - lumaX*3;
     float luma = (lumaRem==0) ? lumaGroup.z : (lumaRem==1) ? lumaGroup.y : lumaGroup.x;
     int chromaX = (cInt2/3)*2;
     highp vec3 pChromaMinus1 = vec3(2.0*(chromaX - 0.5), c.y, 1.0) * m;
     highp vec3 pChroma1 = vec3(2.0*(chromaX + 0.5), c.y, 1.0) * m;
     highp vec3 pChroma2 = vec3(2.0*(chromaX + 1.5), c.y, 1.0) * m;
     highp vec3 pChroma3 = vec3(2.0*(chromaX + 2.5), c.y, 1.0) * m;
     hvec3 ccGroupMinus1 = texture2D(cc, pChromaMinus1.xy * f).rgb;
     hvec3 ccGroup1 = texture2D(cc, pChroma1.xy * f).rgb;
     hvec3 ccGroup2 = texture2D(cc, pChroma2.xy * f).rgb;
     hvec3 ccGroup3 = texture2D(cc, pChroma3.xy * f).rgb;
     hvec2 ccMinus1 = ccGroupMinus1.yx; 
     hvec2 cc1 = ccGroup1.zy; 
     hvec2 cc2 = hvec2(ccGroup1.x, ccGroup2.z); 
     hvec2 cc3 = ccGroup2.yx; 
     hvec2 cc4 = ccGroup3.zy; 
     float mixer = (cInt & 1)*0.5; 
     int chromaRem = cInt - (cInt/6)*6;
     hvec2 chroma = vec2(0);
     if (chromaRem == 0) {
         chroma = mix(ccMinus1, cc1, 0.75);
     } else if (chromaRem == 1) { 
         chroma = mix(cc1, cc2, 0.25);
     } else if (chromaRem == 2) { 
         chroma = mix(cc1, cc2, 0.75);
     } else if (chromaRem == 3) { 
         chroma = mix(cc2, cc3, 0.25);
     } else if (chromaRem == 4) { 
         chroma = mix(cc2, cc3, 0.75);
     } else if (chromaRem == 5) { 
         chroma = mix(cc3, cc4, 0.25);
     }
     return hvec4(luma, chroma.xy, 1.0); 
vec4 _read_pixel_420_10p(sampler2D Y, sampler2D cc, vec2 c, vec2 f, mat3 m)
     int cInt = int(c.x);
     int cInt2 = int(c.x*0.5);
     int lumaX = cInt/3;
     highp vec3 pLuma = vec3(lumaX+0.5, c.y, 1.0) * m;
     vec3 lumaGroup = texture2D(Y, pLuma.xy).rgb;
     int lumaRem = cInt - lumaX*3;
     float luma = (lumaRem==0) ? lumaGroup.z : (lumaRem==1) ? lumaGroup.y : lumaGroup.x;
     int chromaX = (cInt2/3)*2;
     highp vec3 pChromaMinus1 = vec3(2.0*(chromaX - 0.5), c.y, 1.0) * m;
     highp vec3 pChroma1 = vec3(2.0*(chromaX + 0.5), c.y, 1.0) * m;
     highp vec3 pChroma2 = vec3(2.0*(chromaX + 1.5), c.y, 1.0) * m;
     highp vec3 pChroma3 = vec3(2.0*(chromaX + 2.5), c.y, 1.0) * m;
     vec3 ccGroupMinus1 = texture2D(cc, pChromaMinus1.xy * f).rgb;
     vec3 ccGroup1 = texture2D(cc, pChroma1.xy * f).rgb;
     vec3 ccGroup2 = texture2D(cc, pChroma2.xy * f).rgb;
     vec3 ccGroup3 = texture2D(cc, pChroma3.xy * f).rgb;
     vec2 ccMinus1 = ccGroupMinus1.yx; 
     vec2 cc1 = ccGroup1.zy; 
     vec2 cc2 = vec2(ccGroup1.x, ccGroup2.z); 
     vec2 cc3 = ccGroup2.yx; 
     vec2 cc4 = ccGroup3.zy; 
     float mixer = (cInt & 1)*0.5; 
     int chromaRem = cInt - (cInt/6)*6;
     vec2 chroma = vec2(0);
     if (chromaRem == 0) {
         chroma = mix(ccMinus1, cc1, 0.75);
     } else if (chromaRem == 1) { 
         chroma = mix(cc1, cc2, 0.25);
     } else if (chromaRem == 2) { 
         chroma = mix(cc1, cc2, 0.75);
     } else if (chromaRem == 3) { 
         chroma = mix(cc2, cc3, 0.25);
     } else if (chromaRem == 4) { 
         chroma = mix(cc2, cc3, 0.75);
     } else if (chromaRem == 5) { 
         chroma = mix(cc3, cc4, 0.25);
     }
     return vec4(luma, chroma.xy, 1.0); 
hvec4 _cast_vec4_to_hvec4(vec4 v) { return hvec4(v); }
vec4 _cast_hvec4_to_vec4(hvec4 v) { return vec4(v); }
.bgra
.abgr
.argb
.gbra
.grab
.gbar
.aaaa
.rrrr
.rrrg
.rgba * _ci_constants.xxxy + _ci_constants.yyyx
.bgra * _ci_constants.xxxy + _ci_constants.yyyx
.argb * _ci_constants.xxxy + _ci_constants.yyyx
.grab * _ci_constants.xxxy + _ci_constants.yyyx
.abgr * _ci_constants.yxxx + _ci_constants.xyyy
.argb * _ci_constants.yxxx + _ci_constants.xyyy
.rrrr * _ci_constants.yyyx
.rrrr * _ci_constants.xxxy + _ci_constants.yyyx
.rrrr * _ci_constants.xyyy + _ci_constants.yyyx
.rggg * _ci_constants.xxyy + _ci_constants.yyyx
.aaaa * _ci_constants.xyyy + _ci_constants.yyyx
.raaa * _ci_constants.xxyy + _ci_constants.yyyx
.aaaa * _ci_constants.xxxy + _ci_constants.yyyx
dot(s.rg, _ci_constants.zw) * _ci_constants.xyyy + _ci_constants.yyyx
dot(s.rg, _ci_constants.zw) * _ci_constants.xxxy + _ci_constants.yyyx
dot(s.rg, _ci_constants.zw) * _ci_constants.yyyx
dot(s.rg, _ci_constants.zw) * _ci_constants.xxxx
dot(s.ra, _ci_constants.zw) * _ci_constants.xyyy + _ci_constants.yyyx
dot(s.ra, _ci_constants.zw) * _ci_constants.xxxy + _ci_constants.yyyx
dot(s.ra, _ci_constants.zw) * _ci_constants.yyyx
dot(s.ra, _ci_constants.zw) * _ci_constants.xxxx
dot(s.rg, _ci_constants.zw) * _ci_constants.xyyy + dot(s.ba, _ci_constants.zw) * _ci_constants.yxyy + _ci_constants.yyyx
dot(s.rg, _ci_constants.zw) * _ci_constants.xxxy + dot(s.ba, _ci_constants.zw) * _ci_constants.yyyx
fosl_filter_interface_version
fosl_filter_kernelpool_createPool
fosl_filter_kernelpool_hasError
fosl_filter_kernelpool_addLibrary
fosl_filter_kernelpool_addString
fosl_filter_kernelpool_destroyPool
fosl_filter_kernelpool_getNumKernels
fosl_filter_kernelpool_lookupKernel
fosl_filter_kernelpool_getKernelByIdx
fosl_filter_kernelpool_getNumDiagnostics
fosl_filter_kernelpool_getDiagnosticByIdx
fosl_filter_kernelpool_getKernelKind
fosl_filter_kernelpool_getKernelReturnType
fosl_filter_kernelpool_getKernelName
fosl_filter_kernelpool_getPrintedKernel
fosl_filter_kernelpool_getKernelDimensionality
fosl_filter_kernelpool_isPositionInvariant
fosl_filter_kernelpool_preservesAlpha
fosl_filter_kernelpool_getNumKernelParameters
fosl_filter_kernelpool_getParamName
fosl_filter_kernelpool_getParamType
fosl_filter_kernelpool_getNumKernelAttributes
fosl_filter_kernelpool_getAttributeKeyword
fosl_filter_kernelpool_getAttributeParameters
fosl_filter_kernelpool_hasAttributeParameters
fosl_filter_createGraph
fosl_filter_assignRoot
fosl_filter_destroyGraph
fosl_filter_createKernel
fosl_filter_addLibraryFunction
fosl_filter_addChild
fosl_filter_createSampler
fosl_filter_createImage
fosl_filter_createUniform
fosl_filter_createConstant
fosl_filter_createTransformMatrix
fosl_filter_createSampleTransform
fosl_filter_createUsePosition
fosl_filter_createPositionUpdate
fosl_filter_createCoordinateTransform
fosl_filter_setPositionUpdatePosition
fosl_filter_setPositionUpdateContinuation
fosl_filter_setSamplerNeedsSRGBToLinear
fosl_filter_setSamplerSwizzleMask
fosl_filter_setSamplerSwizzleMacro
fosl_filter_setMainEntryPointName
fosl_filter_parseNodesInGraph
fosl_filter_synthesizeMainInGraph
fosl_filter_synthesizeMainInGraphOfType
fosl_filter_synthesizeMainInGraphOfTypeWithOptions
fosl_filter_dumpGraph
fosl_filter_printGraph
fosl_filter_getStringForGraph
fosl_filter_getStringForGraphWithOptions
/usr/lib/libFosl_dynamic.dylib
IPHONE_SIMULATOR_ROOT
Core Image Fosl wrapper: Unable to determine iPhone simulator root SDK path.
%s%s
Unable to open Fosl library at path %s
foslFunctions
providerGetBytesAtPositionCallback_YCbYCr_surface
SurfaceToCG.c
info
buffer
providerGetBytesAtPositionCallback_CbYCrY_surface
providerGetBytesAtPositionCallback_YCbYCrFull_surface
providerGetBytesAtPositionCallback_CbYCrYFull_surface
providerGetBytesAtPositionCallback_2C08_surface
providerGetBytesAtPositionCallback_2C16_surface
providerGetBytesAtPositionCallback_2C0h_surface
providerGetBytesAtPositionCallback_2C0f_surface
providerGetBytesAtPositionCallback_1C08_surface
providerGetBytesAtPositionCallback_1C16_surface
providerGetBytesAtPositionCallback_1C0h_surface_lut
providerGetBytesAtPositionCallback_1C0h_surface
providerGetBytesAtPositionCallback_1C0f_surface
providerGetBytesAtPositionCallback_A008_surface
providerGetBytePointerCallback
providerReleaseBytePointerCallback
affine 
loQ 
hiQ 
%c%g  %g  %g
[%g %g %g %g %g %g]
affine %s
CI_CGNode_SurfaceCacheQueue
CGImageRef %p(%d) %s %ldx%ld 
 nearestsampling
 cache
CGImageRef %p(%d)%c
%s %ldx%ld%c
nearestsampling 
cache 
alpha_one
alpha_unpremul
alpha_premul-clear-edges
alpha_unpremul-clear-edges
alpha_unknown
edge_clamp
edge_unknown
clampRect 
clamp_to_alpha
color_matrix
bias
 %s=(%g %g %g %g)
%c%s=(%g %g %g %g)
colormatch
workingspace
_tonemapped
_to_
colormatch%c
B32@?0^v8^v16i24i28
CI_EXTENDED_PCS
kCGHLGInvOETFOpticalScale
kCGHLGOETFOpticalScale
kCGPQEETF3DLut
kCGHLGSceneMapping3DLut
B96@?0{CGColorConversionIteratorData=Iqqqqqq^^{CGColorTRCData}^^{CGColorMatrixData}^^{CGColorNxMTransformData}}8^{__CFDictionary=}88
B112@?0{CGColorConversionIteratorData=Iqqqqqq^^{CGColorTRCData}^^{CGColorMatrixData}^^{CGColorNxMTransformData}}8q88q96^q104
B104@?0{CGColorConversionIteratorData=Iqqqqqq^^{CGColorTRCData}^^{CGColorMatrixData}^^{CGColorNxMTransformData}}8q88q96
cmlut %llu
cm%zux%zulut %llu
kernel vec4 _cmlut (__sample im, sampler2D lut, vec2 dim)
  im.rgb = clamp(im.rgb, 0.0, 1.0); 
  im.rgb = im.rgb * dim.x + dim.y; 
  im.r = texture2D(lut, vec2(im.r, 0.5)).r; 
  im.g = texture2D(lut, vec2(im.g, 0.5)).r; 
  im.b = texture2D(lut, vec2(im.b, 0.5)).r; 
  return im;
cube
_cmlut
kernel vec4 _pq_eotf (__sample x, float scale)
  float a = 0.012683313515656; 
  float b = 6.277394636015326; 
  float c = 0.8359375; 
  float d = 18.8515625; 
  float e = 18.6875; 
  float f = scale; 
  vec4 Y; 
  Y = pow(abs(x), vec4(a)); 
  Y = max(Y - c, 0.0) / (d - e * Y); 
  Y = pow(Y, vec4(b)); 
  Y *= f * sign(x); 
  Y.a = x.a; 
  return Y; 
_pq_eotf
kernel vec4 _pq_inv_eotf (__sample x, float scale)
  float a = 0.1593017578125; 
  float b = 78.84375; 
  float c = 0.8359375; 
  float d = 18.8515625; 
  float e = 18.6875; 
  float f = scale; 
  vec4 Y; 
  Y = abs(x) * f; 
  Y = pow(Y, vec4(a)); 
  Y = (c + d * Y) / (1.0 + e * Y); 
  Y = pow(Y, vec4(b)); 
  Y *= sign(x); 
  Y.a = x.a; 
  return Y; 
_pq_inv_eotf
kernel vec4 _hlg_inv_oeotf (__sample x, float invScale)
  float a = 0.17883277; 
  float b = 0.284668922; 
  float c = 0.559910715; 
  float d = invScale; 
  float e = 4.0 * invScale; 
  float f = 0.0; 
  vec4 Y = abs(x); 
  Y = max(vec4(0.0), (1.0 - f) * Y + f);  Y = compare(Y-0.5, Y*Y*e, (exp((Y-c)/a)+b) * d); 
  Y = compare(x,-Y,Y); 
  Y.a = x.a; 
  return Y; 
invScale
_hlg_inv_oeotf
kernel vec4 _hlg_oetf (__sample x, float scale)
  float a = 0.17883277; 
  float b = 0.284668922; 
  float c = 0.559910715; 
  float d = 0.0833333358; 
  float e = scale; 
  vec4 Y = abs(x*e); 
  Y = compare(Y-d, sqrt(3.0 * Y), a * log(12.0 * max(Y,vec4(d)) - b) + c); 
  Y = compare(x,-Y,Y); 
  Y.a = x.a; 
  return Y; 
_hlg_oetf
kernel vec4 _hlg_lumscale (__sample im, vec4 lc, vec2 gg)
  float gamma = gg.x; 
  float gain = gg.y; 
  float rgbMax = max(max(im.r,im.g),im.b);  float Y = dot(vec4(im.rgb,rgbMax), lc); 
  Y = max(abs(Y), 0.0001); 
  im.rgb *= sign(Y) * gain * pow(Y, gamma); 
  return im; 
_hlg_lumscale
kernel vec4 _hlg_srmapping (__sample im, vec4 lc, vec2 gg)
  float gamma = gg.x; 
  float gain = gg.y; 
  vec4 rgbm_lg = im; 
  rgbm_lg.rgb *= gain; 
  rgbm_lg.a = max(max(rgbm_lg.r, rgbm_lg.g), rgbm_lg.b); 
  float Y_lg = dot(rgbm_lg, lc); 
  vec4 rgbm_sb = rgbm_lg; 
  rgbm_sb = pow(rgbm_lg, vec4(gamma)); 
  float Y_sb = dot(rgbm_sb, lc); 
  float tone_adjust = (Y_sb != 0.0) ? (Y_lg / Y_sb) : 1.0; 
  vec4 result = rgbm_sb * tone_adjust; 
  result.a = im.a; 
  return result; 
_hlg_srmapping
float __HermiteSpline(float X, float KneeStart, float maxLum) 
    return (2.0 * X * X * X - 3 * X * X + 1.0) * KneeStart + 
                 (X * X * X - 2 * X * X + X) * (1.0 - KneeStart) + 
          (-2.0 * X * X * X + 3 * X * X) * maxLum; 
float __PQ_InvEOTF(float N, vec2 m, vec3 c) 
    float X = pow(N, m.x); 
    return pow((c.x + c.y * X) / (1.0 + c.z* X), m.y); 
float __PQ_EOTF(float N, vec2 m, vec3 c) 
    float X = pow(N, 1.0/m.y); 
    return pow(max(X - c.x, 0.0) / (c.y - c.z * X), 1.0 / m.x); 
float __PQ_EETF(float Y_in, vec2 m, vec3 c, vec4 levels, vec2 minmaxLum, vec2 knee) 
    float masterPeakInv = levels.x; 
    float masterBlackInv = levels.y; 
    //float targetPeakInv = levels.z; 
    //float targetBlackInv = levels.w; 
    float minLum = minmaxLum.x; 
    float maxLum = minmaxLum.y; 
    float KneeStart = knee.x; 
    float KneeStartScale = knee.y; 
    float E  = __PQ_InvEOTF(Y_in/10000.0, m, c); 
    E = (E - masterBlackInv) / (masterPeakInv - masterBlackInv); 
    E = (E < KneeStart) ? E : __HermiteSpline((E - KneeStart) * KneeStartScale, KneeStart, maxLum); 
    E = (E < 0.0) ? minLum : (E < 1.0) ? (E + minLum * (1-E) * (1-E) * (1-E) * (1-E)) : E; 
    E = E * (masterPeakInv - masterBlackInv) + masterBlackInv; 
    return 10000.0 * __PQ_EOTF(E, m, c); 
kernel vec4 _pq_tonemapping(__sample im, vec2 m, vec3 c, vec4 levels, vec2 minmaxLum, vec2 knee, vec4 lc) 
    vec4 result = im; 
    float luminance = dot(im.rgb, lc.rgb); 
    if (luminance != 0) 
    { 
        float out_luminance = __PQ_EETF(luminance, m, c, levels, minmaxLum, knee); 
        result.rgb *= out_luminance / luminance; 
    } 
    return result; 
levels
minmaxLum
knee
_pq_tonemapping
kernel vec4 _cmcubeopaque (__sample im, sampler2D cube, vec4 dims)
  im.rgb = clamp(im.rgb, 0.0001, 0.9999);
  im.rgb *= dims.x;
  float flr = max(floor(im.b),0.0);
  float pageA = flr;
  float pageB = min(pageA+1.0, dims.x);
  vec2 xy = (0.5 + im.rg);
  vec2 pLo = xy + vec2(0.0, pageA * (dims.x + 1.0)); 
  vec2 pHi = xy + vec2(0.0, pageB * (dims.x + 1.0)); 
  vec3 sLo = texture2D(cube, pLo * dims.zw).rgb;
  vec3 sHi = texture2D(cube, pHi * dims.zw).rgb;
  im.rgb = mix(sLo, sHi, im.b - flr);
  return im;
dims
_cmcubeopaque
kernel vec4 _cm1x3lut (__sample im, sampler2D lut, vec2 dim)
  im.rgb = clamp(im.rgb, 0.0, 1.0); 
  im.rgb = im.rgb * dim.x + dim.y; 
  im.rgb = texture2D(lut, vec2(im.r, 0.5)).rgb; 
  return im;
_cm1x3lut
crop 
fill 
clear
gamma %g
colorkernel %s
=nil
 outputFormat=%s
%c%s
=(%d)
v24@?0^{__CFString=}8^v16
%coutputFormat=%s
%lld
kernel %s
%cthreadsPerGroup=(%d,%d,%d)
%cthreadgroupsPerGrid=(%d,%d,%d)
kernel float4 _gradientDirection(sample_f G) { return float4(G.xy, 0, 1); }
kernel float4 _gradientMagnitude(sample_f G) { return float4(float3(length(G.xy)), 1); }
pb%d.espresso
%@|SS*
Error while generating membrane: input image and input mask have to have the same size
warpkernel %s
intermediate-uncached
intermediate-cached
intermediate
%spremultiply
render_graph_core
processor 
:%llX
 noPartialOutput
 canReduceChannels
 supportsCompressed
%s(%d)
  digest=%llX
  outputFormat=%s
  inputFormat=%s
  noPartialOutput
  canReduceChannels
  supportsCompressed
ProviderImageSurfaceCacheQueue
provider
 %llX
 tile %zu,%zu
 tile %zu
Render failed because a pixel format %s is not supported.
 %ldx%ld
%ctile=%zux%zu
samplemode %s
setprops
srgb_to_linear
linear_to_srgb
srgb_noop
srgb_invalid
IOSurface %p
(%d)
 seed:%d
switch
swizzle_identity
swizzle_bgra
swizzle_abgr
swizzle_argb
swizzle_gbra
swizzle_grab
swizzle_gbar
swizzle_aaaa
swizzle_rrrr
swizzle_rrrg
swizzle_rgb1
swizzle_bgr1
swizzle_arg1
swizzle_gra1
swizzle_1bgr
swizzle_1rgb
swizzle_000r
swizzle_rrr1
swizzle_r001
swizzle_a001
swizzle_rg01
swizzle_ra01
swizzle_aaa1
swizzle_rg_to_rr1
swizzle_rg_to_ll1
swizzle_rg_to_a
swizzle_rg_to_i
swizzle_la_to_rr1
swizzle_la_to_ll1
swizzle_la_to_a
swizzle_la_to_i
swizzle_rgba_to_rrgg1
swizzle_rgba_to_llaa
swizzle_rg_to_cbycry
swizzle_rg_to_ycbycr
swizzle_to_r16_as_rg8
swizzle_to_l16_as_rg8
swizzle_to_a16_as_rg8
combine_r_as_rgba
combine_l_as_rgba
combine_a_as_rgba
swizzle_to_rg16_as_rgba8
swizzle_to_rg16_as_bgra8
swizzle_to_la16_as_rgba8
swizzle_to_la16_as_bgra8
swizzle_to_YCbYCr_as_rg8
swizzle_to_CbYCrY_as_rg8
swizzle_to_rgb_as_r
swizzle_to_a2bgr10_as_rgba8
swizzle_to_a2rgb10_as_rgba8
swizzle_to_rgb10_wide_as_rgba8
swizzle_to_rgb10_wide_linear_as_rgba8
combine_420
write_420
writeTG_420
swizzle_to_444_biplanar
swizzle_ycc_to_rgb
swizzle_to_laaa
swizzle_rgba8_to_a2rgb10
swizzle_rgba8_to_a2bgr10
swizzle_rgba8_to_rgb10_wide
swizzle_rgb10_wide
swizzle_bgr10_wide
swizzle_rgba8_to_rgb10_wide_linear
swizzle_rgb10_wide_linear
swizzle_bgr10_wide_linear
swizzle_to_rgb10_wide
swizzle_to_bgr10_wide
swizzle_to_rgb10_wide_linear
swizzle_to_bgr10_wide_linear
swizzle_to_rg_as_rgba
swizzle_to_r16_as_rgba
swizzle_to_a16_as_rgba
swizzle_to_l16_as_rgba
swizzle_to_la_as_rgba
unknown-swizzle
GLTexture %d
MTLTexture %p
Input Metal texture was created with a device that does not match the current context device.
Cannot render image (with an input %s texture) using a %s context.
 roi=
 extent=
 opaque
%croi=
%cextent=
%copaque
%cdigest=%llX
don't know how to create builtin kernel for type %d
_ci_affine
float2 _ci_affine(float4 vx, float4 vy)
  float4 d = float4(destCoord(), 1.0, 0.0);
  return float2(dot(d,vx),dot(d,vy));
_ci_crop
vec4 _ci_crop(vec4 p, float4 rect)
  highp float4 x = destCoord().xxyy * float4(1.0, -1.0, 1.0, -1.0) + rect;
  x = clamp(min(x, x.yzwx), float4(0.0), float4(1.0));
  return (x.x * x.z) * p;
_ci_clamp_rect
float2 _ci_clamp_rect(float4 r) { return min(max(destCoord(), r.xy), r.zw); }
_ci_srgb_to_lin
vec4 _ci_srgb_to_lin(vec4 s)
  s.rgb = srgb_to_linear(s.rgb);
  return s;
_ci_lin_to_srgb
vec4 _ci_lin_to_srgb(vec4 s)
  s.rgb = linear_to_srgb(s.rgb);
  return s;
_ci_premul
vec4 _ci_premul(vec4 s) { return premultiply(s); }
_ci_unpremul
vec4 _ci_unpremul(vec4 s) { return unpremultiply(s); }
_ci_clamp_to_alpha
vec4 _ci_clamp_to_alpha(vec4 s) { return clamp(s, 0.0, s.a); }
_ci_clamp_to_zero_to_one
vec4 _ci_clamp_to_zero_to_one(vec4 s) { return clamp(s, 0.0, 1.0); }
_ci_nearest
float2 _ci_nearest() { return (floor((destCoord())) + 0.5); }
_ci_pass_thru
vec4 _ci_pass_thru (vec4 s) { return s; }
_ci_fill
vec4 _ci_fill(vec4 c) {return c;}
_ci_gamma
vec4 _ci_gamma(vec4 s, float power)
  s.rgb = pow(max(vec3(0.0), s.rgb), vec3(power));
  return s;
power
_ci_sqr
vec4 _ci_sqr(vec4 s)
  s.rgb = max(vec3(0.0), s.rgb);
  s.rgb *= s.rgb;
  return s;
_ci_pow4
vec4 _ci_pow4(vec4 s)
  s.rgb = max(vec3(0.0), s.rgb);
  s.rgb = s.rgb * s.rgb * s.rgb * s.rgb;
  return s;
_ci_sqrt
vec4 _ci_sqrt(vec4 s)
  s.rgb = sqrt(max(vec3(0.0), s.rgb));
  return s;
_ci_curv
vec4 _ci_curv(vec4 s, vec4 p0, vec3 p1)
  float power = p0.x; 
  float a = p0.y, b = p0.z, c = p0.w; 
  float d = p1.x, e = p1.y, f = p1.z; 
  vec3 hi = pow(max(vec3(0.0), s.rgb * a + b), vec3(power)) + e; 
  vec3 lo = s.rgb * c + f; 
  s.rgb = mix(lo, hi, step(vec3(d), s.rgb));
  return s;}
_ci_colormatrix_canonical
vec4 _ci_colormatrix_canonical (vec4 s, vec4 r0, vec4 r1, vec4 r2) 
  s = unpremultiply(s);
  s.rgb = vec3(dot(s,r0), dot(s,r1), dot(s,r2)); 
  return premultiply(s);
_ci_colormatrix
vec4 _ci_colormatrix (vec4 s, vec4 c0, vec4 c1, vec4 c2, vec4 c3, vec4 bias) 
  s = unpremultiply(s);
  s = s.r*c0 + s.g*c1 + s.b*c2 + s.a*c3 + bias;
  return premultiply(s);
_ci_colormatrix3x4
vec4 _ci_colormatrix3x4 (vec4 s, vec4 c0, vec4 c1, vec4 c2) 
{ s.rgb = s.r*c0.rgb + s.g*c1.rgb + s.b*c2.rgb + s.a*vec3(c0.a,c1.a,c2.a); return s; }
_ci_colormatrix3x3
vec4 _ci_colormatrix3x3 (vec4 s, vec3 col0, vec3 col1, vec3 col2)
  s.rgb = s.r*col0 + s.g*col1 + s.b*col2;
  return s;
col0
col1
col2
_ci_colormatrix3x1
vec4 _ci_colormatrix3x1 (vec4 s, vec3 v) { return vec4(vec3(dot(s.rgb, v)), s.a); }
_ci_colormatrix_rrra
vec4 _ci_colormatrix_rrra(vec4 s) { return s.rrra; }
_ci_colormatrixdiag
vec4 _ci_colormatrixdiag (vec4 s, vec3 diag) 
  s.rgb *= diag;
  return s;
diag
_ci_colormatrixdiag4
vec4 _ci_colormatrixdiag4 (vec4 s, vec4 diag) 
  return s * diag;
_ci_aaaa
vec4 _ci_aaaa (vec4 s) { return s.aaaa; }
_ci_rrrr
vec4 _ci_rrrr (vec4 s) { return s.rrrr; }
_ci_000r
vec4 _ci_000r (vec4 s) { return vec4(0.,0.,0.,s.r); }
_ci_rrr1
vec4 _ci_rrr1 (vec4 s) { return vec4(s.rrr,1.); }
_ci_r001
vec4 _ci_r001 (vec4 s) { return vec4(s.r,0.,0.,1.); }
_ci_rg01
vec4 _ci_rg01 (vec4 s) { return vec4(s.rg,0.,1.); }
_ci_a001
vec4 _ci_a001 (vec4 s) { return vec4(s.a,0.,0.,1.); }
_ci_aaa1
vec4 _ci_aaa1 (vec4 s) { return vec4(s.www,1.); }
_ci_rrrg
vec4 _ci_rrrg (vec4 s) { return s.rrrg; }
_ci_bgra
vec4 _ci_bgra (vec4 s) { return s.bgra; }
_ci_abgr
vec4 _ci_abgr (vec4 s) { return s.abgr; }
_ci_gbra
vec4 _ci_gbra (vec4 s) { return s.gbra; }
_ci_grab
vec4 _ci_grab (vec4 s) { return s.grab; }
_ci_gbar
vec4 _ci_gbar (vec4 s) { return s.gbar; }
_ci_argb
vec4 _ci_argb (vec4 s) { return s.argb; }
_ci_gra1
vec4 _ci_gra1 (vec4 s) { s = s.grab; s.a = 1.0; return s; }
_ci_arg1
vec4 _ci_arg1 (vec4 s) { s = s.argb; s.a = 1.0; return s; }
_ci_rgb1
vec4 _ci_rgb1 (vec4 s) { return vec4(s.rgb, 1.0); }
_ci_bgr1
vec4 _ci_bgr1 (vec4 s) { return vec4(s.bgr, 1.0); }
_ci_1rgb
vec4 _ci_1rgb (vec4 s) { return vec4(1.0, s.rgb); }
_ci_1bgr
vec4 _ci_1bgr (vec4 s) { return vec4(1.0, s.bgr); }
_ci_rg_to_rr1
vec4 _ci_rg_to_rr1(vec4 s) { return vec4((s.g*256.0+s.r)/257.0, 0.0, 0.0, 1.0); }
_ci_rg_to_ll1
vec4 _ci_rg_to_ll1(vec4 s) { return vec4(vec3((s.g*256.0+s.r)/257.0), 1.0); }
_ci_rg_to_a
vec4 _ci_rg_to_a(vec4 s) { return vec4(0.0, 0.0, 0.0, (s.g*256.0+s.r)/257.0); }
_ci_rg_to_i
vec4 _ci_rg_to_i(vec4 s) { return vec4((s.g*256.0+s.r)/257.0); }
_ci_la_to_rr1
vec4 _ci_la_to_rr1(vec4 s) { return vec4((s.a*256.0+s.r)/257.0, 0.0, 0.0, 1.0); }
_ci_la_to_ll1
vec4 _ci_la_to_ll1(vec4 s) { return vec4(vec3((s.a*256.0+s.r)/257.0), 1.0); }
_ci_la_to_a
vec4 _ci_la_to_a(vec4 s) { return vec4(0.0, 0.0, 0.0, (s.a*256.0+s.r)/257.0); }
_ci_la_to_i
vec4 _ci_la_to_i(vec4 s) { return vec4((s.a*256.0+s.r)/257.0); }
_ci_rgba_to_rrgg1
vec4 _ci_rgba_to_rrgg1(vec4 s) { return vec4((s.g*256.0+s.r)/257.0, (s.a*256.0+s.b)/257.0, 0.0, 1.0); }
_ci_rgba_to_llaa
vec4 _ci_rgba_to_llaa(vec4 s) { return vec4(vec3((s.g*256.0+s.r)/257.0), (s.a*256.0+s.b)/257.0); }
_ci_to_r16_as_rg8
vec4 _ci_to_r16_as_rg8(vec4 s) 
  float r = s.r*65535.0; 
  float rL = mod(r,256.0); 
  float rH = (r-rL)/256.0; 
  return vec4(rL,rH,0.0,1.0)/255.0; 
_ci_to_l16_as_rg8
vec4 _ci_to_l16_as_rg8(vec4 s) 
  const vec4 gray = vec4(0.299, 0.587, 0.114, 0.0); 
  float l = dot(s,gray)*65535.0; 
  float lL = mod(l,256.0); 
  float lH = (l-lL)/256.0; 
  return vec4(lL,lH,0.0,1.0)/255.0; 
_ci_to_a16_as_rg8
vec4 _ci_to_a16_as_rg8(vec4 s) 
  float a = s.a*65535.0; 
  float aL = mod(a,256.0); 
  float aH = (a-aL)/256.0; 
  return vec4(aL,aH,0.0,1.0)/255.0; 
_ci_to_rg16_as_rgba8
vec4 _ci_to_rg16_as_rgba8(vec4 s) 
  float r = s.r*65535.0; 
  float rL = mod(r,256.0); 
  float rH = (r-rL)/256.0; 
  float g = s.g*65535.0; 
  float gL = mod(g,256.0); 
  float gH = (g-gL)/256.0; 
  return vec4(rL,rH,gL,gH)/255.0; 
_ci_to_rg16_as_bgra8
vec4 _ci_to_rg16_as_bgra8(vec4 s) 
  float r = s.r*65535.0; 
  float rL = mod(r,256.0); 
  float rH = (r-rL)/256.0; 
  float g = s.g*65535.0; 
  float gL = mod(g,256.0); 
  float gH = (g-gL)/256.0; 
  return vec4(gL,rH,rL,gH)/255.0; 
_ci_to_la16_as_rgba8
vec4 _ci_to_la16_as_rgba8(vec4 s) 
  const vec4 gray = vec4(0.299, 0.587, 0.114, 0.0); 
  float l = dot(s,gray)*65535.0; 
  float lL = mod(l,256.0); 
  float lH = (l-lL)/256.0; 
  float a = s.a*65535.0; 
  float aL = mod(a,256.0); 
  float aH = (a-aL)/256.0; 
  return vec4(lL,lH,aL,aH)/255.0; 
_ci_to_la16_as_bgra8
vec4 _ci_to_la16_as_bgra8(vec4 s) 
  const vec4 gray = vec4(0.299, 0.587, 0.114, 0.0); 
  float l = dot(s,gray)*65535.0; 
  float lL = mod(l,256.0); 
  float lH = (l-lL)/256.0; 
  float a = s.a*65535.0; 
  float aL = mod(a,256.0); 
  float aH = (a-aL)/256.0; 
  return vec4(aL,lH,lL,aH)/255.0; 
_ci_rg_to_cbycry
vec4 _ci_rg_to_cbycry(sampler s) 
  vec4 c = sample(s,samplerCoord(s)); 
  float col = step(0.5, fract(destCoord().x * 0.5)); 
  float cOther = sample(s,samplerCoord(s) + float2(1.0-2.0*col,0.0)).r; 
  vec4 r0 = vec4(c.g, c.r, cOther, 1.0); 
  vec4 r1 = vec4(c.g, cOther, c.r, 1.0); 
  return mix(r0,r1,vec4(col)); 
_ci_rg_to_ycbycr
vec4 _ci_rg_to_ycbycr(sampler s) 
  vec4 c = sample(s,samplerCoord(s)); 
  float col = step(0.5, fract(destCoord().x * 0.5)); 
  float cOther = sample(s,samplerCoord(s) + float2(1.0-2.0*col,0.0)).g; 
  vec4 r0 = vec4(c.r, c.g, cOther, 1.0); 
  vec4 r1 = vec4(c.r, cOther, c.g, 1.0); 
  return mix(r0,r1,vec4(col)); 
_ci_to_YCbYCr_as_rg8
vec4 _ci_to_YCbYCr_as_rg8(vec4 s) 
  vec2 YCb = s.rg, YCr = s.rb; 
  float m = step(0.5, fract(destCoord().x * 0.5)); 
  return vec4(mix(YCb,YCr,vec2(m)),0.0,1.0); 
_ci_to_CbYCrY_as_rg8
vec4 _ci_to_CbYCrY_as_rg8(vec4 s) 
  vec2 CbY = s.gr, CrY = s.br; 
  float m = step(0.5, fract(destCoord().x * 0.5)); 
  return vec4(mix(CbY,CrY,vec2(m)),0.0,1.0); 
_ci_to_rgb_as_r
vec4 _ci_to_rgb_as_r (vec4 s)
  float2 rCoord = writeCoord() * float2(3,1);
  writeImage(s.rrrr, rCoord);
  float2 gCoord = rCoord + float2(1,0);
  writeImage(s.gggg, gCoord);
  float2 bCoord = rCoord + float2(2,0);
  writeImage(s.bbbb, bCoord);
  return s; 
_ci_to_a2bgr10_as_rgba8
vec4 _ci_to_a2bgr10_as_rgba8 (vec4 s)
  vec4 denorm = clamp(s,vec4(0.0),vec4(1.0)) * vec4(vec3(1023.0), 3.0) + 0.5;
  int pixel  = int(denorm.r);
      pixel |= int(denorm.g) << 10;
      pixel |= int(denorm.b) << 20;
      pixel |= int(denorm.a) << 30;
  writePixel((pixel) & 0xFF, (pixel >> 8) & 0xFF, (pixel >> 16) & 0xFF, (pixel >> 24) & 0xFF, writeCoord());
  return s; 
_ci_to_a2rgb10_as_rgba8
vec4 _ci_to_a2rgb10_as_rgba8 (vec4 s)
  vec4 denorm = clamp(s,vec4(0.0),vec4(1.0)) * vec4(vec3(1023.0), 3.0) + 0.5;
  int pixel  = int(denorm.b);
      pixel |= int(denorm.g) << 10;
      pixel |= int(denorm.r) << 20;
      pixel |= int(denorm.a) << 30;
  writePixel((pixel) & 0xFF, (pixel >> 8) & 0xFF, (pixel >> 16) & 0xFF, (pixel >> 24) & 0xFF, writeCoord());
  return s; 
_ci_to_rgb10wide_as_rgba8
vec4 _ci_to_rgb10wide_as_rgba8 (vec4 s)
  s = vec4(linear_to_srgb(s.rgb) * (511.0/1023.0) + (384.0/1023.0), 1.0);
  vec4 denorm = clamp(s,vec4(0.0),vec4(1.0)) * vec4(vec3(1023.0), 3.0) + 0.5;
  int pixel  = int(denorm.b);
      pixel |= int(denorm.g) << 10;
      pixel |= int(denorm.r) << 20;
      pixel |= int(denorm.a) << 30;
  writePixel((pixel) & 0xFF, (pixel >> 8) & 0xFF, (pixel >> 16) & 0xFF, (pixel >> 24) & 0xFF, writeCoord());
  return s; 
_ci_to_rgb10widelinear_as_rgba8
vec4 _ci_to_rgb10widelinear_as_rgba8 (vec4 s)
  s = vec4((s.rgb) * (511.0/1023.0) + (384.0/1023.0), 1.0);
  vec4 denorm = clamp(s,vec4(0.0),vec4(1.0)) * vec4(vec3(1023.0), 3.0) + 0.5;
  int pixel  = int(denorm.b);
      pixel |= int(denorm.g) << 10;
      pixel |= int(denorm.r) << 20;
      pixel |= int(denorm.a) << 30;
  writePixel((pixel) & 0xFF, (pixel >> 8) & 0xFF, (pixel >> 16) & 0xFF, (pixel >> 24) & 0xFF, writeCoord());
  return s; 
_ci_writeTG_420
vec4 _ci_writeTG_420(vec4 color)
   const int grid = 16;
#if  __METAL_IOS__ || __METAL_MACOS__
   threadgroup vec2 tgcc[grid*grid];
#else
   vec2 tgcc[grid*grid];
#endif
  float2 py = writeCoord();
  float2 pc = writeCoord()/2.;
  writeImage(color.rrrr, py);
   int x = int(py.x);
   int y = int(py.y);
   int index = ((y%grid) *grid) + (x%grid);
   tgcc[index] = color.gb;
if (x%2==0 && y%2==0)
 vec2 cc = color.gb;
y++;
index = ((y%grid) *grid) + (x%grid);
cc += tgcc[index];
x++;y--;
index = ((y%grid) *grid) + (x%grid);
cc += tgcc[index];
y++;
index = ((y%grid) *grid) + (x%grid);
cc += tgcc[index];
writeImagePlane(vec4(cc/4.,0.,0.), pc);
return color; 
_ci_write_420
vec2 _ci_simd_shuffle_down(vec2 gb, int offset)
#if  __METAL_IOS__
   return simd_shuffle_down(gb, offset);
#endif 
   return vec2(0.,0.);
vec4 _ci_write_420(vec4 color)
  float2 py = writeCoord();
  float2 pc = writeCoord()/2.;
  writeImage(color.rrrr, py);
  const int x = int(py.x);
  const int y = int(py.y);
  vec2 cc = vec2(0.,0.);
  cc += _ci_simd_shuffle_down(color.gb, 0);
  cc += _ci_simd_shuffle_down(color.gb, 1);
  cc += _ci_simd_shuffle_down(color.gb, 16);
  cc += _ci_simd_shuffle_down(color.gb, 17);
if (x%2==0 && y%2==0)
writeImagePlane(vec4(cc.r/4,cc.g/4,0.,0.), pc);
  return color; 
_ci_combine_420
vec4 _ci_combine_420(vec4 s00, vec4 s10, vec4 s01, vec4 s11)
  float2 pc = writeCoord();
  float2 py = pc * 2.0;
  writeImage(s00.rrrr, py);
  writeImage(s10.rrrr, py + float2(1,0));
  writeImage(s01.rrrr, py + float2(0,1));
  writeImage(s11.rrrr, py + float2(1,1));
  vec4 cc = (s00 + s10 + s01 + s11) * 0.25;
  writeImagePlane(vec4(cc.gb,0.0,0.0), pc);
  return s00; 
_ci_swizzle_to_444
vec4 _ci_swizzle_to_444(vec4 s)
  float2 pc = writeCoord();
  writeImage(vec4(s.r,0.0,0.0,1.0), pc);
  writeImagePlane(vec4(s.gb,0.0,1.0), pc);
  return s; 
_ci_swizzle_rgba8_to_a2rgb10
vec4 _ci_swizzle_rgba8_to_a2rgb10(vec4 s) 
  s = floor(s * 255.0 + 0.5); 
  vec4 r; 
  r.b = (mod(s.g,  4.0) * 256.0 + s.r)              / 1023.0; 
  r.g = (mod(s.b, 16.0) *  64.0 + floor(s.g/ 4.0))  / 1023.0; 
  r.r = (mod(s.a, 64.0) *  16.0 + floor(s.b/16.0))  / 1023.0; 
  r.a = floor(s.a/63.99999) / 3.0; 
  return r; 
_ci_swizzle_rgba8_to_rgb10_wide
vec4 _ci_swizzle_rgba8_to_rgb10_wide(vec4 s) 
  s = floor(s * 255.0 + 0.5); 
  vec4 r; 
  r.b = (mod(s.g,  4.0) * 256.0 + s.r)              / 1023.0; 
  r.g = (mod(s.b, 16.0) *  64.0 + floor(s.g/ 4.0))  / 1023.0; 
  r.r = (mod(s.a, 64.0) *  16.0 + floor(s.b/16.0))  / 1023.0; 
  r.a = 1.0; 
  r.rgb = srgb_to_linear((r.rgb - 384.0/1023.0) * (1023.0/511.0)); 
  return r; 
_ci_swizzle_rgba8_to_rgb10widelinear
vec4 _ci_swizzle_rgba8_to_rgb10widelinear(vec4 s) 
  s = floor(s * 255.0 + 0.5); 
  vec4 r; 
  r.b = (mod(s.g,  4.0) * 256.0 + s.r)              / 1023.0; 
  r.g = (mod(s.b, 16.0) *  64.0 + floor(s.g/ 4.0))  / 1023.0; 
  r.r = (mod(s.a, 64.0) *  16.0 + floor(s.b/16.0))  / 1023.0; 
  r.a = 1.0; 
  r.rgb = ((r.rgb - 384.0/1023.0) * (1023.0/511.0)); 
  return r; 
_ci_swizzle_rgba8_to_a2bgr10
vec4 _ci_swizzle_rgba8_to_a2bgr10(vec4 s) 
  s = floor(s * 255.0 + 0.5); 
  vec4 r; 
  r.r = (mod(s.g,  4.0) * 256.0 + s.r)              / 1023.0; 
  r.g = (mod(s.b, 16.0) *  64.0 + floor(s.g/ 4.0))  / 1023.0; 
  r.b = (mod(s.a, 64.0) *  16.0 + floor(s.b/16.0))  / 1023.0; 
  r.a = floor(s.a/63.99999) / 3.0; 
  return r; 
_ci_rgb10wide
vec4 _ci_rgb10wide(vec4 s) { return vec4(srgb_to_linear((s.rgb - 384.0/1023.0) * (1023.0/511.0)), 1.0); }
_ci_rgb10widelinear
vec4 _ci_rgb10widelinear(vec4 s) { return vec4(((s.rgb - 384.0/1023.0) * (1023.0/511.0)), 1.0); }
_ci_bgr10wide
vec4 _ci_bgr10wide(vec4 s) { return vec4(srgb_to_linear((s.bgr - 384.0/1023.0) * (1023.0/511.0)), 1.0); }
_ci_bgr10widelinear
vec4 _ci_bgr10widelinear(vec4 s) { return vec4(((s.bgr - 384.0/1023.0) * (1023.0/511.0)), 1.0); }
_ci_to_rgb10wide
vec4 _ci_to_rgb10wide(vec4 s) { return vec4(linear_to_srgb(s.rgb) * (511.0/1023.0) + (384.0/1023.0), 1.0); }
_ci_to_rgb10widelinear
vec4 _ci_to_rgb10widelinear(vec4 s) { return vec4((s.rgb) * (511.0/1023.0) + (384.0/1023.0), 1.0); }
_ci_to_bgr10wide
vec4 _ci_to_bgr10wide(vec4 s) { return vec4(linear_to_srgb(s.bgr) * (511.0/1023.0) + (384.0/1023.0), 1.0); }
_ci_to_bgr10widelinear
vec4 _ci_to_bgr10widelinear(vec4 s) { return vec4((s.bgr) * (511.0/1023.0) + (384.0/1023.0), 1.0); }
_ci_ra01
vec4 _ci_ra01(vec4 s) { return vec4(s.ra, 0.0, 1.0); }
_ci_ycc_to_rgb
vec4 _ci_ycc_to_rgb(vec4 s) { return s.zxyw; }
_ci_swizzle_to_laaa
vec4 _ci_swizzle_to_laaa(vec4 s) 
  const vec4 g = vec4(0.299, 0.587, 0.114, 0.0); 
  return vec4(dot(s,g), s.aaa); 
_ci_combine_gray
vec4 _ci_combine_gray(vec4 s0, vec4 s1, vec4 s2, vec4 s3) 
  vec4 g = vec4(0.299, 0.587, 0.114, 0.0); 
  return vec4(dot(s0,g), dot(s1,g), dot(s2,g), dot(s3,g)); 
_ci_combine_r
vec4 _ci_combine_r(vec4 s0, vec4 s1, vec4 s2, vec4 s3) { return vec4(s0.r, s1.r, s2.r, s3.r); }
_ci_combine_a
vec4 _ci_combine_a(vec4 s0, vec4 s1, vec4 s2, vec4 s3) { return vec4(s0.a, s1.a, s2.a, s3.a); }
_ci_combine_rg
vec4 _ci_combine_rg(vec4 s0, vec4 s1) { return vec4(s0.rg, s1.rg); }
_ci_combine_r16
vec4 _ci_combine_r16(vec4 s0, vec4 s1) 
  float v0 = s0.r*65535.0; 
  float v0L = mod(v0,256.0); 
  float v0H = (v0-v0L)/256.0; 
  float v1 = s1.r*65535.0; 
  float v1L = mod(v1,256.0); 
  float v1H = (v1-v1L)/256.0; 
  return vec4(v0L,v0H,v1L,v1H)/255.0; 
_ci_combine_a16
vec4 _ci_combine_a16(vec4 s0, vec4 s1) 
  float v0 = s0.a*65535.0; 
  float v0L = mod(v0,256.0); 
  float v0H = (v0-v0L)/256.0; 
  float v1 = s1.a*65535.0; 
  float v1L = mod(v1,256.0); 
  float v1H = (v1-v1L)/256.0; 
  return vec4(v0L,v0H,v1L,v1H)/255.0; 
_ci_combine_l16
vec4 _ci_combine_l16(vec4 s0, vec4 s1) 
  vec4 g = vec4(0.299, 0.587, 0.114, 0.0); 
  float v0 = dot(s0,g)*65535.0; 
  float v0L = mod(v0,256.0); 
  float v0H = (v0-v0L)/256.0; 
  float v1 = dot(s1,g)*65535.0; 
  float v1L = mod(v1,256.0); 
  float v1H = (v1-v1L)/256.0; 
  return vec4(v0L,v0H,v1L,v1H)/255.0; 
_ci_combine_la
vec4 _ci_combine_la(vec4 s0, vec4 s1) 
  vec4 g = vec4(0.299, 0.587, 0.114, 0.0); 
  return vec4(dot(s0,g), s0.a, dot(s1,g), s1.a);
CIKernelLibrary
Cannot initialize kernel library on unsupported system.
Failed loading CoreImage.metallib from %@: %@
CINewMTLLibraryQueue
// Kernel Source
// Stitched DAG Functions
%zu: 
%s {
{Output of function #%zu}
{Buffer, index=%zu, offset=%zu}
{Texture, index=%zu}
{Sampler, index=%zu}
{%s}
newNamedConstantArray
// Function Constants
// DAG Functions
    arg%zu = 
type%lu 
_ci_half_to_float
_ci_float_to_half
_ci_group_output_00
_ci_group_output_00_h
_ci_group_output_10
_ci_group_output_10_h
_ci_group_output_01
_ci_group_output_01_h
_ci_group_output_11
_ci_group_output_11_h
v60@?0^v8^v16i24i28^v32Q40*48i56
B24@?0^v8^v16
_ci_read_pixel_420_r_rg
_ci_read_pixel_420_packed
_ci_read_pixel_420
_ci_read_pixel
_ci_read_pixel_420_r_rg_h
_ci_read_pixel_420_packed_h
_ci_read_pixel_420_h
_ci_read_pixel_h
_ci_srgb_to_linear
_ci_srgb_to_linear_h
Could not set the function constant '%@' because its type %s is unsupported.
Could not set the function constant '%@' because the client object is not a NSNumber.
Could not set the function constant '%@' because the client object is not a NSArray with %d items.
Could not set index %d for the function constant '%@' because the client object is not a NSNumber.
B36@?0^v8^v16i24i28i32
_ci_early_out_imageblock_nothing
_ci_early_out_nothing
_ci_early_out_imageblock
_ci_early_out
_ci_init_destcoord_imageblock
_ci_init_destcoord
_ci_group_write_00
_ci_group_write_00_h
_ci_group_write_10
_ci_group_write_10_h
_ci_group_write_01
_ci_group_write_01_h
_ci_group_write_11
_ci_group_write_11_h
_ci_linear_to_srgb
_ci_linear_to_srgb_h
_ci_write_block_h
_ci_write_pixel_h
_ci_write_pixel
ThreadPositionInGrid
Buffer
Texture2D
Sampler
ThreadPositionInThreadgroup
Imageblock
FunctionOutput
<Unknown>
(returns type%lu) 
(returns %s) 
Struct
Array
float2
float3
float4
float2x2
float2x3
float2x4
float3x2
float3x3
float3x4
float4x2
float4x3
float4x4
half
half2
half3
half4
half2x2
half2x3
half2x4
half3x2
half3x3
half3x4
half4x2
half4x3
half4x4
int2
int3
int4
uint
uint2
uint3
uint4
bool
bool2
bool3
bool4
Texture
Pointer
{%s, index=%zu}
Texture2DWrite
compile_metal_dag
build_dag
_ci_sampler_builder
_ci_dest_struct_builder
_ci_dest_struct_builder_h
ci_stdlib
Failed to load 'ci_stdlib' Metal library.
ci_filters
Failed to load 'ci_filters' Metal library.
ci_stdlib_h
Failed to load 'ci_stdlib_h' Metal library.
LoadCILibrariesQ
ci_stdlib_stitchable
Failed to load 'ci_stdlib_stitchable' Metal library.
ci_filters_stitchable
Failed to load 'ci_filters_stitchable' Metal library.
ci_stdlib_stitchable_h
Failed to load 'ci_stdlib_stitchable_h' Metal library.
CI::CoreImageDyLibCompilation
ci_%llX
metallibV1-from_archive
metallibV1
CoreImage.metallib
metallibV2-from_archive
metallibV2
set_roi_selector queue
memstream_write
memstream.c
ms->size < ms->capacity
ms->contents[ms->size] == 0
memstream_seek
ms->size < ms->capacity && ms->contents[ms->size] == 0
memstream_close
affine
CGImageRef
CGImageRef %p
CGImageRef %d
Destination surface is nil.
Source image provider is nil.
kCGImageBlockTileRequest
Source provider block set is nil.
Failed to access image block data.
surface_for_roi_from_cg
clampRect
clamp_to_zero_one
builtin_colormatrix_rrra
builtin_colormatrixdiag
builtin_colormatrixdiag4
builtin_colormatrix3x1
builtin_colormatrix3x3
builtin_colormatrix3x4
builtin_colormatrix
color_matrix_rrra
color_matrix_diag [%g, %g, %g]
color_matrix_diag4 [%g, %g, %g, %g]
color_matrix_3x1 [%g, %g, %g]
color_matrix_%s (
r=[%g %g %g],
g=[%g %g %g],
b=[%g %g %g])
b=[%g %g %g],
bias=[%g %g %g])
color_matrix_4x3 (
r=[%g %g %g %g],
g=[%g %g %g %g],
b=[%g %g %g %g],
color_matrix (
a=[%g %g %g %g],
bias=[%g %g %g %g])
color_matrix_diag
color_matrix_diag4
color_matrix_3x1
color_matrix_%s
color_matrix_4x3
color_matrix_diag%c[%g, %g, %g]
color_matrix_diag4%c[%g, %g, %g, %g]
color_matrix_3x1%c[%g, %g, %g]
color_matrix_%s%c
r=[%g %g %g]%c
g=[%g %g %g]%c
b=[%g %g %g]
b=[%g %g %g]%c
bias=[%g %g %g]
color_matrix_4x3%c
r=[%g %g %g %g]%c
g=[%g %g %g %g]%c
b=[%g %g %g %g]%c
color_matrix%c
a=[%g %g %g %g]%c
bias=[%g %g %g %g]
P3_to_709
709_to_P3
2020_to_709
709_to_2020
AdobeRGB_to_709
709_to_AdobeRGB
2020_to_P3
P3_to_2020
rgb_to_ycc601f
ycc601f_to_rgb
rgb_to_ycc709f
ycc709f_to_rgb
rgb_to_ycc601v
ycc601v_to_rgb
rgb_to_ycc709v
ycc709v_to_rgb
rgb_to_ycc601f8
ycc601f8_to_rgb
rgb_to_ycc709f8
ycc709f8_to_rgb
rgb_to_ycc601v8
ycc601v8_to_rgb
rgb_to_ycc709v8
ycc709v8_to_rgb
rgb_to_ycc601f10
ycc601f10_to_rgb
rgb_to_ycc709f10
ycc709f10_to_rgb
rgb_to_ycc601v10
ycc601v10_to_rgb
rgb_to_ycc709v10
ycc709v10_to_rgb
colormatrix
crop
curve gamma=%g
curve gamma=%g a=%g b=%g c=%g d=%g e=%g f=%g
curve%cgamma=%g
curve%cgamma=%g%ca=%g b=%g c=%g d=%g e=%g f=%g
curve
fill
kernel vec4 _thresholdRed(__sample s,float value) { float v = s.r >= value ? 1.0 : 0.0; return vec4(v,v,v,1.0); }
kernel vec4 _linearMappingNoSecondaryImage(__sample s,float scalingFactor) 
 float v = sqrt((1.0 - max(0.0, ((s.r - 0.5) * 2.0)))*scalingFactor); 
 return vec4(v,v,v,1.0); 
kernel vec4 _linearMapping(__sample s0,__sample s1,float scalingFactor) 
 float v = sqrt((1.0 - max(0.0, ((s0.r - 0.5) * 2.0)))*(1.0 - s1.r)*scalingFactor); 
 return vec4(v,v,v,1.0); 
CIBlurmapRefinementThreshold
CIBlurmapRefinementLinearMapping
builtin_sqr
builtin_pow4
builtin_sqrt
builtin_gamma
sqrt
pow4
gamma
<CI::%s %p, %s>
<CI::%s %p [%s]>
noop_affine
noop_multiuse
noop_samplemode
noop_disablemerging
noop_intermediate_uncached
noop_intermediate_cached
noop_full_intermediate
noop_intermediate
noop
builtin_premultiply
builtin_unpremultiply
Invalid premultiply power %d.
premultiply
unpremultiply
nopremultiply
badpremultiply
premul
unpremul
  canReduceChannels
processor_render
convert_processor
CI::MainProgramArgsQ
program
 type=%s 
%.*s
 format=%s%s
 cycles=%llu
 ms=%.1f
<CI::%s %p>
v24@?0^v8r^v16
this is Processor
this is Convert
child sets threadgroup dimensions
child is Processor
child is Convert
child is Noop affine
child is Noop multiuse
child is Noop samplemode
child is Noop disablemerging
child is Noop intermediate_uncached
child is Noop intermediate_cached
child is Noop full_intermediate
child is Noop intermediate
child is raster leaf
child is a previously seen program
beyond CI_MAX_PROGRAM_DEPTH
beyond CI_MAX_CL_COMPLEXITY
child is a kernel with ReturnTypeNone
beyond max_texture_units
child of this GeneralKernel is a non-trivail Affine
child of this GeneralKernel is non-trivial Swizzle
child of this GeneralKernel is Clamp
this is a GeneralKernel
child is non-trivial Swizzle
child is GeneralKernel
child is a precompiled Kernel
child is a non-precompiled Kernel
vertexTransform0
vertexTransform1
vertexTransform
CI_PRINT_PROGRAM %s (%s context %d%s%s frame %lu) node:%d digest:0x%llX = 
// Argument Names
// Argument Types
// Arguments
Argument count mismatch for program (%s) <0x%llx> (%d != %d).
[argument types]
[argument names]
[argument objects]
%u  %s%s
<%d>
 // stopped concat because %s
type= %s
rois=
     
pixels=%ld
extent=
luma-only opaque
r-only opaque
rg-only opaque
opaque
 shallow
 deep
digest=%llX
kernel-digest=%llX
compile-time=%.5f ms
render-time=%.5f ms
cycles=%llu
%s/%d_output_%d_%d_%d_%d_%d.png
[%i] = %p <%s> 
-Pool-
QueuePoolLock
ProvTile %llu
ProvTile
v16@?0^{__IOSurface=}8
ProvAssembled %llu
ProvAssembled %p frame %llu
ProvAssembled %p
surface_for_roi_from_prov
samplemode
builtin_linear_to_srgb
builtin_srgb_to_linear
Invalid srgb direction %d.
lintosrgb
srgbtolin
IOSurface
surface_for_roi_from_surface
 %dx%d
%.*sNULL
<%ld>
 <%ld>
 rois=
 luma opaque
 r-only opaque
 rg-only opaque
%cluma opaque
%cr-only opaque
%crg-only opaque
CI: Dispatch Pool Access Queue
CI: Pooled Dispatch Queue
AffineImage
CGImage
ClampToAlphaImage
ColorMatchImage
ColorMatrixImage
CropImage
ClampImage
FillImage
GammaImage
ColorKernelImage
WarpKernelImage
GeneralKernelImage
SRGBImage
NoopImage
PremultiplyImage
ProcessorImage
ProviderImage
SampleModeImage
SetPropsImage
SurfaceImage
SwitchImage
SwizzleImage
TagColorSpaceImage
TextueImage
AffineNode
ColorKernelNode
WarpKernelNode
GeneralKernelNode
CGNode
ClampToAlphaNode
ClampToZeroToOneNode
ColorMatrixNode
CropNode
ClampNode
GammaNode
CurveNode
FillNode
NoopNode
PremultiplyNode
ProcessorNode
ConvertNode
ProviderNode
SRGBNode
SampleModeNode
SurfaceNode
SwizzleNode
TextureNode
ProgramNode
Bitmap
Vector
Color
TextureSampler
ColorKernel
WarpKernel
GeneralKernel
MainProgram
MetalDAG
CLContext
GLContext
MetalContext
SurfaceCacheEntry
TileTask
RenderTask
RenderToBitmap
RenderToPixelBuffer
RenderToSurface
RenderToGLTexture
RenderToMTLTexture
RenderToPixelBufferProvider
RenderToSurfaceProvider
RenderToMTLTextureProvider
<CI::Object %s %p ref=%u>
[infinite]
[null]
[empty]
v32@?0^v8^v16i24i28
bitmap: %p
image_chroma
sampler2D
buffer_reference
dest_coord
dest_coord_priv_struct
dest_gid
dest_extent
dest_transform
dest_image
dest_image_plane
sampler_transform
sampler_transform_and_extent
sampler_transform_row0
sampler_transform_row1
vertex_transform
vertex_transform_packed
vertex_transform_row0
vertex_transform_row1
r*12@?0i8
[%i] = %s
pixelbuffer: %p
Could not allocate memory for intermediate 444 buffer.
render_block_invoke
Could not access memory of destination pixelbuffer.
convert_YCC444_to_420
surface: %p
Surface rowbytes must be a multiple of %ld.
Could not allocate memory.
gltexture: %u
Render to GL texture requires a GL-backed CIContext.
mtltexture: %p
Rendering to texture of %s is not supported on the CIContex's MTLDevice.
Rendering to this texture is not supported on the CIContex's MTLDevice.
Render to Metal texture requires a Metal-backed CIContext.
mtltexprov: %p
{Texture=(?=Q{?=II}{?=^v^v})}8@?0
Render to Metal texture provider requires a Metal context.
Failed to set texture destination.
render_to_texture
v36@?0^v8^v16i24i28i32
v36@?0r^v8r^v16i24i28i32
B32@?0r^v8r^v16i24i28
v32@?0r^v8r^v16i24i28
%s:%d: Assertion failed: %s
/Library/Caches/com.apple.xbs/Sources/EmbeddedCoreImage_Sim/EmbeddedCoreImage-1200.29/Framework/internal/render.cpp
graph != NULL
^v48@?0^v8{CGRect={CGPoint=dd}{CGSize=dd}}16
CI_PRINT_TIME %s (%s%s context %d%s%s frame %lu) (%llux%llu) = %.3f seconds%s
 (aborted)
render_to_display
Invalid context
render:toIOSurface: failed because format was %.4s.
render:toIOSurface: failed because format was %ld.
Unsupported format for large surfaces
render_to_surface
Dumped output to: %s
get_bitmap
traverse_gathering_digests
prepare_initial_graph
destination=%@
initial graph
(%s%s context %d%s%s frame %lu)
%@format=%s roi=[%g %g %g %g]
%d%s%s_%d_%lu_initial_graph
[%s] 
initial graph graphviz %s (%s%s context %d%s%s frame %lu) format=%s roi=
  %s/%s.%s
initial graph %s (%s%s context %d%s%s frame %lu) 
format=%s 
workingspace=
roi=
optimized graph
(%s%s context %d%s%s frame %lu)
%@format=%s roi=[%g %g %g %g]
workingFormat=%s%s
(lossyAllowed)
%d%s%s_%d_%lu_optimized_graph
optimized graph graphviz %s (%s%s context %d%s%s frame %lu) format=%s roi=
optimized graph %s (%s%s context %d%s%s frame %lu) 
format=%s roi=
Invalid graph
Render aborted
No need to render
Cannot render to infinite output region.
Failed to render %llu pixels 
Failed to render %llu of %llu pixels 
because a CIKernel's ROI function did not allow tiling.
Failed to render part of the image because %s
destination %dx%d too big
memory requirement of %d too big
main
make_program_graph_if_renderable
render_tile
program graph
(%s%s context %d%s%s frame %lu tile %lu)
%@deviceName=%s
cacheIntermediates=%s
intermediatesLimit=%ldMB
format=%s roi=[%g %g %g %g]
workingFormat=%s%s
%d%s%s_%d_%lu_program_graph_%lu
program graph graphviz %s (%s%s context %d%s%s frame %lu tile %lu) format=%s roi=
program graph %s (%s%s context %d%s%s frame %lu tile %lu) 
 frameTime=%dms
 peakNonVolatile=%ldMB
 kernelTime=%dms
 kernelCycles=%d
%d%s%s_%d_%lu_program_graph
program graph graphviz %s (%s context %d%s%s frame %lu) format=%s roi=
highp 
lowp 
static constant float4 _ci_constants = (float4)(1.0,0.0,1.0/257.0,256.0/257.0);
const lowp vec4 _ci_constants = vec4(1.0,0.0,1.0/257.0,256.0/257.0);
static constant metal::float4 _ci_constants = metal::float4(1.0,0.0,1.0/257.0,256.0/257.0);
#define writeImage(c, p, _dc) write_imagef(_outputTexture, (int2)p, c)
#define writeImagePlane(c, p, _dc) write_imagef(_outputTexturePlane, (int2)p, c)
#define writePixel(r, g, b, a, p, _dc) write_imagei(_outputTexture, (int2)p, (int4)(r,g,b,a))
#define writeCoord(_dc) (float2)_writeLoc
#define writeImage(c, p) gl_FragData[0] = c
#define writeImagePlane(c, p) gl_FragData[1] = c
#define writePixel(r, g, b, a, p) 
#define writeCoord() p0
#define writeImage(c, p, _dc) _outputTexture.write(c, static_cast<uint2>(p))
#define writeImagePlane(c, p, _dc) _outputTexturePlane.write(c, static_cast<uint2>(p))
#define writePixel(r, g, b, a, p, _dc) _outputTexture.write(float4(r,g,b,a) / 255.0, static_cast<uint2>(p))
#define writeCoord(_dc) static_cast<float2>(_wc)
#define _ci_simd_shuffle_down(c, p, _dc) simd_shuffle_down(c, p)
gid += static_cast<uint2>(params.outputRect.xy * step(params.outputRect.w, 0.0));
gid.y += lessThan(params.outputRect.w, 0) * ((-params.outputRect.w-1)-2*gid.y);
  gid += static_cast<uint2>(params.outputRect.xy);
write_only image2d_t out
texture2d<float, access::write> outputTexture
write_imagef
gl_FragColor
outputTexture.write
writeImage
_STUB_
writeImagePlane
writePixel
writeCoord
_ci_simd_shuffle_down
write_only image2d_t _outputTexture
write_only image2d_t _outputTexturePlane
int2 _writeLoc
out1
_writeLoc
texture2d<float, access::write> _outputTexture
texture2d<float, access::write> _outputTexturePlane
uint2 _wc
outputTexture
outputTexture1
, %s
threadgroup float2 tgcc[]
float2 tgcc
 %s1,
threadgroup float2 _ci_writeTG_420_tgcc[16*16];
_ci_writeTG_420_tgcc
kernel void
struct PixelData {
  float4 c
 [[color(0)]]
imageblock<PixelData> imageBlock, ushort2 lid [[ thread_position_in_threadgroup ]],
if (gid.x >= abs(params.outputRect.z) || gid.y >= abs(params.outputRect.w)) return;
if (any(static_cast<float2>(gid) < params.outputRect.xy)) return;
if (any(static_cast<float2>(gid) >= params.outputRect.xy + abs(params.outputRect.zw))) return;
 + params.outputRect.xy
  PixelData output = { 
  imageBlock.write(output, lid);
  threadgroup_imageblock PixelData* output = imageBlock.data(lid);
  output->c = 
  threadgroup_barrier(mem_flags::mem_threadgroup_imageblock);
  if (lid.x == 0 && lid.y == 0)
    outputTexture.write(imageBlock.slice(output->c)
construct_shader
Cache Stats: count=%ld size=%ld%s non-volatile=%ld%s peakCount=%ld peakSize=%ld%s peakNVSize=%ld%s
surface=%p(%.3u)
 fmt=%.4s
 fmt=%ld
 x=%+.4lld y=%+.4lld w=%.4zu h=%.4zu surfaceWidth=%.4zu surfaceHeight=%.4zu ctx=%u img=%u vol=%d
 id='%s'
 id=nil
 size=%ld%s
 empty
 use=%ld
SurfaceCacheEntry 
GetSurfaceFromCacheAndFill was passed compressed format '%.4s'.  Ignoring compression.
GetSurfaceFromCacheAndFill was passed contextIndex=%d and imageIndex=%d.  Ignoring imageIndex.
GetSurfaceFromCacheAndFill
GetValidSurfaceFromCache was passed contextIndex=%d and imageIndex=%d.  Ignoring imageIndex.
GetValidSurfaceFromCache
GetSurfaceFromCache was passed contextIndex=%d and imageIndex=%d.  Ignoring imageIndex.
GetSurfaceFromCache
ReturnSurfaceToCache
AddReleaseSurfaceBlock_block_invoke
surface-cache.cpp
CI::gReleaseSurfaceBlockMap().find(queue) == CI::gReleaseSurfaceBlockMap().end()
RemoveCacheEntriesForContext
PurgeCacheEntriesForImage
CISurfaceCacheQueue
MemoryPreasure
SurfaceCache: %s
  count: %ld
  size: %ld%s
  non-volatile: %ld%s
  volatile: %ld%s
  capacity: %ld%s
  cumulativeStats:
    allocCount=%ld peakCount=%ld peakSize=%ld%s peakNVSize=%ld%s totalAlloced=%ld%s totalFilled=%ld%s timeFilling=%gs
    hits=%ld (%lu%%)  purgedHits=%ld (%lu%%)  recycledMisses=%ld (%lu%%)  misses=%ld (%lu%%)  inusemisses=%ld (%lu%%)
useCountDecrement
_useCount > 0
kernel vec2 _perspectiveWarp(mat3 invM) { vec3 hdc = vec3(_dc, 1.0); hdc = invM * hdc; hdc /= hdc.z; return hdc.xy; }
CI::TileTaskQueue
program graph
(%s context %d%s%s frame %lu tile %lu)
%@deviceName=%s
cacheIntermediates=%s
intermediatesLimit=%ldMB
format=%s roi=[%g %g %g %g]
workingFormat=%s%s
kernelExecutionTime=%.5f ms
passCount=%ld
pixelsProcessed=%ld
pixelsOverdrawn=%ld
peakNonVolatile=%ldMB
completionTime=%.3fs
rate=%.3f MP/s
program graph
(%s context %d%s%s frame %lu tile %lu)
%@deviceName=%s
cacheIntermediates=%s
intermediatesLimit=%ldMB
format=%s roi=[%g %g %g %g]
workingFormat=%s%s
passCount=%ld
pixelsProcessed=%ld
pixelsOverdrawn=%ld
peakNonVolatile=%ldMB
completionTime=%.3fs
CIRenderTask <%s context %d%s%s frame %lu>
optimized graph
(%s context %d%s%s frame %lu)
%@format=%s roi=[%g %g %g %g]
CIRenderInfo <%s context %d%s%s frame %lu>
passCount=%ld
pixelsProcessed=%ld
completionTime=%.3fs
%s/%s.pdf
%s_%lu
wait
CI::complete_intermediate
CI::TextureManager
TextureManager::TextureManager() failed to create empty surface
TextureManager::remove_lru() did not find an info struct!
TextureCache Matched: context:%ld count:%d hits:%zu misses:%zu
TextureCache Missed: context:%ld count:%d hits:%zu misses:%zu
node%d
 %s %s
 transform:
edge_black
vector.cpp
values != NULL
<CI::Vector %p>[]
<CI::Vector %p>[%g]
<CI::Vector %p>[%g %g]
<CI::Vector %p>[%g %g %g]
<CI::Vector %p>[%g %g %g %g]
<CI::Vector %p>[%d values]
%c%g
True
False
TRUE
?UUUUUU
?333333
MbP?
:D7V
"nN%
AA)Z
>Y1\
?*Ral!
WXp?
>J6h
iQ~V?
iN^d
iN^d
N} y
?9(a
g|_\
&4I,)
|F"4
_Cp\
vj.7
ip[[
'Hlw
?VF#
uoEb
?\='
@ut\
?'/2
h?RD
"nN%
t><K
!sePmp
|zlK
c\qq
0Xr
9x&4
^Cp\
`!sePm
?aobHN
.5B?S
i3NCT
"nN%
|a2U0
%Tpx
"nN%
~NA~
lscz
AA)Z
r?jl@
<e5]O
! _B
?`vO
^Cp\F
@Y32
d:tz
N} y
?Uka
SrNl
-:Yj
tBFe@
@!"5
O7+]3n@
h8en
;a@O
?!=E
"LQ.
OVW
"nN%
0Xr
W zR&
/5B?S
|a2U0*
?EUwv
E|'f
i3NCT
1zn!
"nN%
#gaO;|
[@h=|
2uWv
 |(
?K[\
p}?33S?333?
?ffffff
Dfff?
?es-8R
?UUUUUU
@UUUUUU
?UUUUUU
Y>t$7?*
Y>t$7?
I?t$7?
?333333
<<*9%
<S*m%
+Y'R8
<_+F(
<s+q(
+/*:
,t*(:
,R+s:
,--);
,[-:;
,".x;
<i+10
<L+R0
<(+t0
<"*&1
<C(H2
&"49;
&84&;
<`&z4
$-5{:
$D5m:
$Z5a:
$q5V:
<f"B6
<%"Y6
.7?9
B7*9
<Z +8
<S!18_7
<Y"8867
<_#?8
<3$E8
<2%S8
%Z8q6
&a8J6
&h8#6
<Y'v8
<a7x89(
7h8Y'
<$8`8
<K8X8f&
<r8P8
8?8t%
888M%
9089%
<99(89%
<`9 8M%
;D8`)
;W8/)
;"9L'
;}9t&
<S;:Z%
<N;%:2%
<K;>:
<I;V:
<H;o:
<k;5;
<t;N;
<|;h;
?3U0
|a2U0
MbP?
ff&?ff&
 @'%
Mbp?q
?ffffff
?333333
?ffffff
?333333
?333333
:gUU
|?5^
@ffffff
?        
MbP?
MbP?o
333333
;ZC:33
?UUUUUU
?UUUUUU
>@F]k
?-{8
333333
Ww'&l
333333
?ffffff
?U0*
?U0*
?333333
@~@(
z?ffffff
~?UUUUUU
B433333
?59$5r:
?59$5r:
0Xr
?g|_\
ADBE
mntrRGB XYZ 
;acspAPPL
none
-ADBE
cprt
2desc
kwtpt
bkpt
rTRC
gTRC
bTRC
rXYZ
gXYZ
bXYZ
text
Copyright 2000 Adobe Systems Incorporated
desc
Adobe RGB (1998)
XYZ 
XYZ 
curv
XYZ 
XYZ 
XYZ 
<@es-8R
?es-8R
?es-8R
?es-8R
?333333
ffffff
es-8R
es-8R
ffffff
?~0d>
?333333
333333
?333333
333333
:gUU
0Xr
?g|_\
Mb@?
$@M-[
N@\r
++MJ
?|'f
i@r3
 l@a
pw@L7
 |@)?
@gDio
?33333S7
@UUUUUU
i?yCu
JQ/#
?333333
?es-8R
@es-8R
<appl
mntrRGB XYZ 
9acspAPPL
APPL
-appl
desc
ocprt
#wtpt
rXYZ
gXYZ
bXYZ
rTRC
chad
,bTRC
gTRC
desc
Linear Display P3
text
Copyright Apple Inc., 2015
XYZ 
XYZ 
XYZ 
XYZ 
para
sf32
ncurv
@?fff?
@?fff?
@?fff?
@?fff?
@?fff?
REND
REND
REND
333333
333333
333333
333333
?333333
?333333
333333
333333
APPL
mntrRGB XYZ 
acspAPPL
APPLsRGB
-APPL
desc
icprt
"wtpt
rXYZ
gXYZ
bXYZ
rTRC
bTRC
gTRC
desc
sRGB Linear
text
Copyright 2012 Apple Inc.
XYZ 
XYZ 
XYZ 
XYZ 
curv
pappl
mntrGRAYXYZ 
acspAPPL
none
-appl
desc
qcprt
#wtpt
kTRC
desc
Linear Gray Profile
text
Copyright Apple Inc., 2017
XYZ 
curv
MbP?
333333
?333333
?ffffff
eUB
m#39
?eUB
;gM$
?[+5
.z<g
`*h 
Kfie
?cc^G
?cWb
x/k 
7:Ba
:ua;
lErd
m|X5
tZ;z
?333333
@XUUUUU
?OUUUUU
E(knN 
$@ffffff
-r0@
|?uS@
(\%p@/
M`@33333[a@
>B`e=
~%<(
333333
?333333
?333333
?333333
?333333
?333333
?333333
?Zd;
333333
$@M-[
N@\r
++MJ
?|'f
i@r3
 l@a
pw@L7
 |@)?
@gDio
?33333S7
<<*9%
<S*m%
+Y'R8
<_+F(
<s+q(
+/*:
,t*(:
,R+s:
,--);
,[-:;
,".x;
<i+10
<L+R0
<(+t0
<"*&1
<C(H2
&"49;
&84&;
<`&z4
$-5{:
$D5m:
$Z5a:
$q5V:
<f"B6
<%"Y6
.7?9
B7*9
<Z +8
<S!18_7
<Y"8867
<_#?8
<3$E8
<2%S8
%Z8q6
&a8J6
&h8#6
<Y'v8
<a7x89(
7h8Y'
<$8`8
<K8X8f&
<r8P8
8?8t%
888M%
9089%
<99(89%
<`9 8M%
;D8`)
;W8/)
;"9L'
;}9t&
<S;:Z%
<N;%:2%
<K;>:
<I;V:
<H;o:
<k;5;
<t;N;
<|;h;
?CUL
?;q9^
?yCu
333333
a2U0*
?"lxz
?S\U
))))))))))))))))
vH7B
W4vC
9Y>)F$
MbP?-C
]r2<
 9^;Q
%{public}s Using 3D bilateral grid hash instead of 5D.
%{public}s: inputTransfom is not a valid object.
%{public}s %@: instantiating abstract barcode descriptor objects is prohibited
%{public}s %@: requires coder that supports keyed coding of objects
%{public}s %{public}@: symbolVersion must be in the range of [1,40]
%{public}s %{public}@: invalid errorCorrectionLevel
%{public}s %{public}@: layerCount must be in the range of [1,32]
%{public}s %{public}@: dataCodewordCount must be in the range of [1,2048]
%{public}s %{public}@: rowCount must be in the range of [3,90]
%{public}s %{public}@: columnCount must be in the range of [1,30]
CIBarcodeDetector
%{public}s bounds is too large
%{public}s format %s is unsupported%s.
%{public}s rowBytes must be a multiple of %ld.
%{public}s given an infinite rect
%{public}s context's output colorspace can't be used with pixel format %s. Using default output colorspace instead.
%{public}s Could not execute the inpainting network. Error: %s
%{public}s colorSpace must be kCGColorSpaceModelRGB.
%{public}s The input palette should be a K x 1 image but received %.1f x %.1f]
%{public}s: input coefficients are not inverable.
frame %lu
render_lock
%{public}s unsupported object %{public}@ for key %{public}@.
%{public}s unsupported key %{public}@.
%{public}s No supported back-end renderer is usable.
%{public}s can only be created with ES 2.0 or 3.0 EAGLContexts.
%{public}s format %{public}s on GLES.
%{public}s format %{public}s is unsupported%{public}s.
%{public}s unsupported colorspace.
%{public}s rowBytes must be a multiple of %ld.
%{public}s cannot render an infinite image into an infinite context.
%{public}s requires a CIContext created with a GL context or a CG context.
%{public}s target must be GL_TEXTURE_2D.
%{public}s requires a GL or CL context!
%{public}s texture type must be MTLTextureType2D.
%{public}s requires a Metal context (with the same device used to create the given texture).
%{public}s was called but ignored.
CIContext workingformat must be %s. Ignoring request for %{public}s.
CIContext workingformat must be %s. Ignoring request.
CIContext workingformat must be %{public}s. Ignoring request for %{public}s.
CIContext workingformat must be %{public}s. Ignoring request.
Created CIContext (%{public}s context %{public}d%{public}s%{public}s)%{public}s%{public}s %{public}s
No Metal renderer available.
Metal disabled via CI_ENABLE_METAL_GPU envar.
Unsupported object %{public}@ for key %{public}@.
CIContext kCIContextOutputColorSpace must be [NSNull null], or a CGColorSpaceRef with kCGColorSpaceModelRGB or kCGColorSpaceModelMonochrome that supports output.
CIContext kCIContextWorkingColorSpace must be [NSNull null], or a CGColorSpaceRef with kCGColorSpaceModelRGB that supports output.
%{public}s unsupported object %{public}@ for key kCIContextHLGOpticalScale.
CIContext for CL: do something about disabling software fallback here.
[CIContext createCGImage:fromRect:format:colorSpace:] unsupported format %{public}s.
[CIContext createCGImage:fromRect:format:colorSpace:] unsupported format %{public}s on GLES.
[CIContext createCGImage:fromRect:format:colorSpace:] unsupported colorspace.
%{public}s requires an image with a finite non-empty extent.
%{public}s Unable to read RGB image data from data
%{public}s Unable to extract disparity image data from data
%{public}s Unable to read RGB image data from URL
%{public}s Unable to extract disparity image data from URL
%{public}s requires an RGB image and a disparity image.
%{public}s requires a valid image orientation.
%{public}s prediction error
%{public}s Input image and input mask cannot be nil.
%{public}s Input image and input mask have to both have (0,0) origin.
%{public}s Unknown inpainting mode: %d
%{public}s [abort] L center is NaN
%{public}s [abort] Centroid distance from L center failed: (%.0f, %.0f)
%{public}s [abort] Centroid distance from R center failed: (%.0f, %.0f)
%{public}s [abort] Inter centroid distance failed: %.3f > %.3f
%{public}s [abort] Interpeak percentile distance failed at p=%.2f: %hhu < %hhu
%{public}s [abort] Center pixel failed: L = %hhu < %hhu | R = %hhu < %hhu
%{public}s Density (left): %.4f < %.4f
%{public}s [abort] Minimum density failed (left): %.4f < %.4f
%{public}s Density (right): %.4f < %.4f
%{public}s [abort] Minimum density failed (right): %.4f < %.4f
%{public}s [abort] Maximum density failed (left): %.4f > %.4f
%{public}s [abort] Maximum density failed (right): %.4f > %.4f
%{public}s [abort] Minimum dispersion not reached (L): %.3f
%{public}s [abort] Minimum dispersion not reached (R): %.3f
%{public}s [abort] Maximum inter dispersion reached: %.3f. Eliminating right.
%{public}s [abort] Maximum inter dispersion reached: %.3f. Eliminating left.
%{public}s [abort] Mask response (L) too close to global: %.0f%%
%{public}s [abort] Mask response (R) too close to global: %.0f%%
%{public}s [abort] Convex fill failed due to invalid centroid: %d, %d
%{public}s Convex fill seeding from (%d,%d)
%{public}s [abort] Empty seed fill!
%{public}s [abort] Convex fill reached upper bound: %zu > %d
%{public}s [abort] Convex fill reached lower bound: %zu < %d
%{public}s Prewarming failed: could not allocate CIRenderDestination
%{public}s Prewarming failed: no context available
%{public}s Prewarming failed: prepareRender failed with error %@
%{public}s pixelformat of primary image is %c%c%c%c
%{public}s primary image colorspace %@ and attachments %@
%{public}s fail: should not provide both a command queue and Metal texture, and pixel buffers
%{public}s fail: should provide either a command queue and Metal texture, or a primary pixel buffer
%{public}s fail: nil primary
%{public}s fail: no primary Metal texture was provided
%{public}s fail: image too small (%lu)
%{public}s fail: no landmarks found
%{public}s fail: missing capture metadata
%{public}s fail: flash was forced and the flash would not have normally fired.
%{public}s fail: no faces to repair
%{public}s fail: need to provide all required Metal textures (primary, secondary, output)
%{public}s fail: primary %@ | secondary %@
%{public}s setPrimary:landmarks:metadata must be called first.
%{public}s fail: no CIContext available
%{public}s skip: no landmarks for this face observation
%{public}s skip: missing eye landmarks for this face observation
%{public}s Left  Eye landmarks %@
%{public}s Right Eye landmarks %@
%{public}s Properties for primaryImage %@
%{public}s skip: unexpected constellation size: %d != (6 or 8)
%{public}s skip: unable to compute eye short and long axes
%{public}s Confidence=%.3f | junk=%.3f | Anisotropy=%.3f | area=%.0f
%{public}s skip: confidence too low (%f)
%{public}s skip: junkiness too high (%f)
%{public}s skip: eye isotropy too large (%f)
%{public}s skip: eye constellation area too small (%f)
%{public}s skip: left and right eyes should have exactly the same size
%{public}s ERROR: VNObservation does not have face segments but its use was requested.
%{public}s Probabilities for face segments returned nil. Skipping this face.
%{public}s Probabilities for face segments returned not enough features (%d but expected 5). Skipping this face.
%{public}s Inferring pupils from face segmentation
%{public}s Unexpected size for face probabilities: %d != %d, %d != %d
%{public}s Inferring pupils from eye constellation
%{public}s Skipping focus check
%{public}s Focus variance = %.3f, count = %ld
%{public}s Time spent computing focus stats: %.3fms
%{public}s skip: face out of focus: %.3f > %.3f
%{public}s Intersection: %f,%f,%f,%f
%{public}s Output image took %.3fms
%{public}s Error in startTaskToRender: %@
%{public}s Error in waitUntilCompletedAndReturnError: %@
%{public}s startTaskToRender (composite) took %.3fms
%{public}s startTaskToRender (left) took %.3fms
%{public}s Error in startTaskToRender (left): %@
%{public}s startTaskToRender (right) took %.3fms
%{public}s Error in startTaskToRender (right): %@
%{public}s Kernel execution took %.3fms
eyeCount:%d
setPrimary
%{public}s setPrimary %d observations
%{public}s setPrimary metadata:
%{public}s setPrimary session tuning:
%{public}s setPrimary repair tuning:
%{public}s Landmarks computed from orientation %d and size %f, %f
%{public}s Failed to validate inputs during set primary
%{public}s Processing face observation %d / %d
%{public}s Good face: size %@ | left %@ axes %@ | right %@ axes %@ 
%{public}s Bad face, skipping
%{public}s fail: no good landmarks found
%{public}s Total time spent during setPrimary: %.3fms
%{public}s setPrimary returning successfully
repairPrimaryWithSecondary
%{public}s repairPrimaryWithSecondary called
%{public}s repairPrimary session tuning:
%{public}s repairPrimary repair tuning:
%{public}s Forcing working format to RGBAh
%{public}s CVPixelBuffer size (primary) = %d, %d
%{public}s CVPixelBuffer size (secondary) = %d, %d
face:%d
repairFace
%{public}s Repair %d/%d
%{public}s Error while repairing face
%{public}s Total time spent during repair: %.3fms = %.3fms/eye
%{public}s pixelformat of secondary image is %c%c%c%c
%{public}s secondary image colorspace %@ and attachments %@
%{public}s Failed to archive the observations: %@
%{public}s Eye size: major axis %.0f -> %@
%{public}s Convex area threshold range for radius %d = [%d, %d]
%{public}s Masking centroid with face segmentation
%{public}s Long %.2f | Short %.2f | Ratio %.0f | Conf %.2f
%{public}s Masking repair mask with face segmentation
%{public}s Repair tuning set to default
%{public}s Repair tuning passing through
%{public}s Repair tuning set to A wide
%{public}s Repair tuning set to A tele
%{public}s Repair tuning set to A portrait
%{public}s Repair tuning set to B
%{public}s Repair tuning set to C
%{public}s Session tuning set to default
%{public}s Session tuning set to A wide
%{public}s Session tuning set to A tele
%{public}s Session tuning set to A portrait
%{public}s Session tuning set to B
%{public}s No CaptureSetup session tuning for port type %@
%{public}s No CaptureSetup repair tuning for port type %@
%{public}s Unknown tuning key encountered: %@
%{public}s eye outset = %.3f x %.3f
%{public}s Focus Stats: Error in creating pixel buffer
CI_LOG_FILE path: %s
%.*s%.*s
%.*s...
...%.*s...
%{public}s option CIUserInfo is no longer encoded for security.
%{public}s first parameter should be CIKernel.
%{public}s kCIApplyOptionDefinition is not a CIFilterShape or an NSArray with four elements.
%{public}s kCIApplyOptionExtent is not an NSArray with four elements. Ignoring.
%{public}s The filter PXSoftProofingFilter has an incorrect ROI method for sampler index 1.  This may fail in the future.
%{public}s The filter PX_CIF_Noise has an incorrect ROI method for sampler index 1.  This may fail in the future.
[%@ apply:...] First argument should be CIKernel.
[%{public}@ apply:...] The last key "%{public}@" at index %d is followed by nil. It will be ignored.
[%{public}@ apply:...] Argument at index %d should be a CIImage, CISampler, CIVector, or NSNumber.
CIFilter %{public}@ cannot be serialized because %{public}@ value is a %{public}@. Only NSString, NSNumber and CIVector is supported at this time.
%{public}s warning: affine+crop region falls outside of image area, results may be wrong
%{public}s now returns nil.  Use _filterArrayFromProperties:inputImageExtent: instead
%{public}s Was called reentrantly for class %{public}s
LoadMoreFilters
%{public}s
LoadFilter
BundleLoad
[CIImage initWithIOSurface:options:] failed because surface format was %{public}.4s.
[CIImage initWithIOSurface:options:] failed because surface format was %ld.
[CIImage initWithIOSurface:options:] kCIImageSurfaceFormat option value is not compatable with actual format of surface.
[CIImage initWithIOSurface:options:] kCIImageEdgeRepeat option not supported. Ignoring.
[CIImage initWithCGImage:] kCIImageEdgeRepeat option not supported. Ignoring.
%{public}s failed because the CGImage is nil.
%{public}s CI_CONVERSION: Rendered to intermediate %{public}s CGImage because the CGImage (bpc:%zu bpp:%zu info:0x%X) passed to Core Image has a %{public}s.
%{public}s failed because the CGImage format is not supported and we failed to create a CGBitmapContext.
[CIImage initWithBitmapData:] failed because the format '%{public}s' is not supported.
[CIImage initWithBitmapData:] failed because the format is not supported.
[CIImage initWithBitmapData:] failed because data length was less than height times bytesPerRow.
%{public}s kCIImageTextureTarget option value is not supported. Value was %{public}@
%{public}s kCIImageEdgeRepeat option not supported. Ignoring.
%{public}s texture type must include MTLTextureUsageShaderRead.
[CIImage initWithCVPixelBuffer:optiopns:] failed because it is not a CVPixelBuffer.
[CIImage initWithCVImageBuffer:] kCIImageEdgeRepeat option not supported. Ignoring.
CIImage will use Rec. %d YCC Matrix because the CVPixelBuffer was not tagged with a kCVImageBufferYCbCrMatrixKey.
%{public}s failed because the buffer is nil.
%{public}s failed because the buffer is not a CVPixelBufferRef.
%{public}s failed because its pixel format %{public}.4s is not supported.
%{public}s failed because its pixel format %ld is not supported.
%{public}s failed because the type of buffer is not yet supported.
%{public}s ColorSpace must be an RGB CGColorSpaceRef that supports output.
%{public}s ColorSpace must be an RGB or Gray CGColorSpaceRef that supports output.
%{public}s ColorSpace must be an RGB CGColorSpaceRef.
%{public}s ColorSpace must be an HDR RGB CGColorSpaceRef.
%{public}s properties is not a NSDictionary.
%{public}s object at index %d of array is not a CIImage.
%{public}s CIUserInfo is no longer encoded for sake of security.
%{public}s CIUserInfo is no longer decoded for sake of security.
%{public}s not supported for keypath %{public}@.
%{public}s init is not a valid initializer for CIImageAccumulator
%{public}s failed because the extent is empty.
%{public}s failed because the format '%s' is not supported.
%{public}s failed because the format is not supported.
%{public}s blendKernel ignored (invalid value of type '%s').
%{public}s failed.
%{public}s context is nil.
%{public}s surface is nil.
%{public}s a biplanar surface cannot be accessed via its base address.
%{public}s command buffer provided to processor does not hold strong references to resources.
%{public}s processor block must be provided.
%{public}s inputFormat must be 0, %{public}s.
%{public}s outputFormat must be 0, %{public}s.
%{public}s argumentDigest is 0 which will prevent CoreImage from caching %{public}s optimally.
%{public}s each object in arguments dictionary be an NSArray, NSDictionary, NSNumber, NSData, NSString, NSNull, CIVector, CIColor, CIImage, CGImageRef or CGColorSpaceRef for CoreImage to cache optimally (%@).
%{public}s provider does not implement provideImageData:bytesPerRow:origin::size::userInfo:.
CIImageProvider <%{public}s %p> %zux%zu at %zu,%zu
%{public}s format %{public}s is not supported.
%{public}s kCIImageProviderTileSize value is not a NSNumber, NSArray, CIVector, or NSNull.
%{public}s kCIImageProviderContentDigest value is not NSData of at least 16 bytes.
%{public}s Input format not supported: %d
%{public}s Output format not supported: %d
%{public}s Could not allocate %lu bytes of memory
[CIKernel initWithString:] failed because no valid kernels were in the string.
[CIKernel initWithString:] failed because '%{public}s', the first kernel in the string, has an unsupported type for the parameter '%{public}s'.
%{public}s is not an known pixel format name. Will use working format instead.
%{public}s Function '%s' does not exist.
%{public}s Available function names are: %@
%{public}s Function '%s' has an unsupported return type.
%{public}s Function '%s' has an unsupported type for the parameter '%@'.
%{public}s Function '%s' has too many destination parameters.
%{public}s Could not determine required constants for '%s'.
[%{public}@ initWithString:] failed due to error parsing kernel source.
[%{public}@ initWithString:] failed because no valid kernels were in the string.
[CIWarpKernel initWithString:] failed because '%{public}s', the first kernel in the string, does not conform to the calling convensions of a CIWarpKernel.
[CIColorKernel initWithString:] failed because '%{public}s', the first kernel in the string, does not conform to the calling convensions of a CIColorKernel.
%{public}s Function '%s' does not conform to the calling conventions of a CIColorKernel.
%{public}s Function '%s' does not conform to the calling conventions of a CIWarpKernel.
[CIKernel kernelsWithString:] passed an empty or nil string.
%{public}s User-specified output group size not yet supported.
%{public}s Cannot initialize kernel with given library data.
%{public}s Cannot initialize kernel with Metal DAG compiler disabled.
%{public}s [CIKernel kernelNamesFromMetalLibraryData:] passed an incorrect Metal library NSData argument
%{public}s [CIKernel kernelNamesFromMetalLibraryData:] error creating Metal library for NSData%s
kCIKernelOutputFormat value (%s) is not supported.Use one of these formats instead: %@
Warning: specified  as kernel attribute output format of %s and apply option kCIKernelOutputFormat of %s. The former will be used.
%{public}s argument count mismatch for kernel '%{public}s', expected %d but saw %d.
%{public}s type mismatch for kernel '%{public}s' parameter %d. %{public}sGot %{public}@.
%{public}s no image in arguments array.
%{public}s ignores callback and is not recomended.  Use applyWithExtent:arguments:options: instead.
%{public}s ignores callback and is not recomended.  Use applyWithExtent:arguments: instead.
%{public}s kernel '%{public}s' is not a color kernel.
%{public}s kernel '%{public}s' specified 'preservesAlpha' but has no inputs.
%{public}s kernel '%{public}s' specified 'preservesAlpha' but extent is not the same as the extent of the first input image.
%{public}s is not supported.  Use applyWithExtent:roiCallback:inputImage:arguments:options: instead.
%{public}s is not supported.  Use applyWithExtent:roiCallback:inputImage:arguments: instead.
%{public}s kernel '%{public}s' is not a warp kernel.
%{public}s provided rect for kernel %{public}s is %{public}@ but should be at least %{public}@
cmdBuffer: %p outputSize: [%u, %u]
gpu_compute
Internal error: Input texture has volatile backing surface (%p)
Calling abort() because a volatile surface was detected
Error excuting command buffer = %s (%s)
Aborting ICS due to command buffer error
Unable to create filter wrapper image for filter %s
Unable to create Metal wrapper image for filter %s; will not render on OpenGL/OpenCL based CIContexts.
%{public}s unable to read file %{private}@.
%{public}s Could not initialize boundary tile.
%{public}s Invalid argument type
%{public}s The file does not support version %{public}@. The version %{public}@ will be used instead.
CIRectangleDetector
ctx:%llu version %d
CIRedEyeCorrection_processor
%{public}s Could not initialize inpainting model. Error: %s
%{public}s [ConvexFill] center lies outside of the buffer
%{public}s [ConvexFill] center is below threshold (%d < %d)
count:%d
CIFaceCoreDetector
%{public}s %{public}@
%{public}s init is not a valid initializer for CIRenderDestination
%{public}s requires a valid pixelBuffer argument.
%{public}s requires a pixelBuffer with valid width and height.
%{public}s unsupported pixelBuffer format.
%{public}s unsupported pixelBuffer plane count.
CIRenderDestination will use Rec. %d YCC Matrix because the CVPixelBuffer was not tagged with a kCVImageBufferYCbCrMatrixKey.
%{public}s requires a valid pixelBuffer provider block.
%{public}s requires a valid width and height.
%{public}s not supported yet.
%{public}s requires a valid surface argument.
%{public}s requires a surface with valid width and height.
%{public}s unsupported surface format.
%{public}s unsupported surface plane count.
%{public}s requires a valid surface provider block.
%{public}s requires a valid MTLTexture argument.
%{public}s requires a MTLTexture with valid width and height.
%{public}s requires a MTLTexture with depth 1.
%{public}s texture usage must include MTLTextureUsageShaderWrite.
%{public}s unsupported MTLPixelFormat.
%{public}s requires a valid metal texture provider block.
%{public}s requires a valid data argument.
%{public}s requires a valid bytesPerRow.
%{public}s bytesPerRow must be greater than or equal to width times format's bytes per pixel .
%{public}s unsupported alpha mode.
%{public}s unsupported colorspace for this destination.
%{public}s blendKernel must be a subclass of CIBlendKernel.
%{public}s destination texture usage must include MTLTextureUsageShaderRead to support blending.
Using a blend kernel is not supported for this CIRenderDestination%{public}s.
%{public}s init is not a valid initializer for CIRenderInfo
%{public}s init is not a valid initializer for CIRenderTask
%{public}s Unexpected error in the backing renderer.
%{public}s The CIContext is invalid.
%{public}s The destination is nil.
%{public}s The destination is invalid.
%{public}s The image extent and destination extent do not intersect.
%{public}s Unsupported format %{public}s on GLES.
%{public}s %s
CISampler value for key '%s' is nil. Skipping.
CISampler value for key '%s' must be a NSObject or a CGColorSpaceRef. Skipping.
CISampler option key must be a NSString. Skipping.
%{public}s ignoring kCISamplerBlurFormat because it is not supported.
%{public}s ignoring kCISamplerWrapPeriodic because it is not supported.
%{public}s ignoring kCISamplerAffineMatrix value because it is not a valid object '%@'.
%{public}s ignoring kCISamplerColorSpace value because it is not an RGB CGColorSpaceRef that supports output.
imageSize: %d x %d
compute
imageSize: %f x %f
StandardizeImage
gradMapSize: %lu x %lu
CreateGradientMap
NormalizeGradientMap
ThresholdGradientMap
GradientMapRender
EDLines
ExtractLineSegments
clusterLineSegments
vClusterInliers: %lu vClusterOutliers: %luhClusterInliers: %lu hClusterOutliers: %lu
runOptimization
CITextDetector
%{public}s inputText must be a NSString.
%{public}s inputText must be a NSAttributedString.
CIVNFaceDetector
%{public}s Error while detecting faces: %@
%{public}s Error while detecting landmarks: %@
vLineClusterSize: %lu hLineClusterSize: %lu
computeGuides
Unsupported disparity refinement configuration = %d
Unable to run CIFocalPlane
input image(s) to CIDepthBlurEffect apply is of inifite extent; returning input image
Unable to load Portrait rendering bundle; returning as unajustable image.
Failed to parse rendering parameters; unknown version %d
Params data too small
Invalid parameters data; no start marker found
Incorrect parameters version
Size mismatch
Unable to create filter from string.
Unable to create CIImage from filter for prewarming
Unable to create render destination for prewarming
Error asking CI to prepare render = %@
Unable to set new image metadata
Unknown depth blur effect rendering version %d
Invalid rendering parameter start marker.
Invalid rendering parameter header size (%d)
%{public}s: Unable to create XMP data from CGImageMetadataRef for key %@
%{public}s: CGColorSpaceRef does not conform to NSCoding protocol; skipping.
%{public}s: Error encoding dict = %@
%{public}s: Unable to compress data = %@
%{public}s: Unable to decompress data: = %@
%{public}s: Unable to unarchive data: = %@
%{public}s: Unable to find name of filter to create
%{public}s: Unable to create filter with name %@
%{public}s: Unable to find value in dictionary for key %@
%{public}s: Unable extract XMP metadata for key %@
%{public}s: Unable to load camera calibration data %@
%{public}s: Values for %@ are not identical %g != %g
%{public}s: Intrisic matrix may not identical
%{public}s: Intrisic matrix dimensions not identical
%{public}s: Extrinsic matrix dimensions not identical
%{public}s: pixel size not identical
%{public}s: lens distortion lookup table not identical
%{public}s: inverse lens distortion lookup table not identical
%{public}s: lens distortion center not identical
%{public}s: vectors don't have the same # of components for key %@ (%zu != %zu)
%{public}s: Values for vector (%@) at index %lu are not equal %g != %g
%{public}s: colors don't have the same # of components for key %@ (%zu != %zu)
%{public}s: Values for color (%@) at index %lu are not equal %g != %g
%{public}s: XMP Image metadata may differ for array tag %@ at index %lu (%@ != %@)
%{public}s: XMP Image metadata may differ for tag %@ (%@ != %@)
%{public}s: XMP Image metadata may differ
%{public}s: Colorspaces not identical
%{public}s: value for key %@ (%@) differs.
%{public}s: object for key %@ (%@) is nil.
%{public}s: don't know how to check for equality of contents for key %@ (%@) is nil.
seedFill: seed is outside bitmask
Could not set current EAGL context to %p.
%{public}s requires an inputImage with a finite extent.
ctx:%llu
Unable to get macro state for the GLContext: %{public}p.
release_surface_block
ctx:%llu node:%llu
compile_gl
finish_render
after_render
quad
readback_bitmap
bind_arguments
compile_shader
Failed to convert intermediate to sRGB
compile_metal
compute_quad
ctx:%llu node:%llu [%g %g %g %g]
wait_for_cache
create_intermediate
render_quad
CI_CONVERSION: (Metal) %{public}s_buffer
CI_CONVERSION: (Metal) %{public}s_texture
convert_metal
CI_CONVERSION: (CPU) %{public}s
convert_cpu
%{public}s an old value for kPixelFormat%{public}s was used.
foslFunctions
Matching a color failed: from %{public}s to %{public}s
Could not support source colorspace: %{public}s
Failed to create a ColorSync converter: from %{public}s to %{public}s
Could not support destination colorspace: %{public}s
Cannot render image (with Metal kernel '%s') using an %s context.
%{public}s CI_CONVERSION: Rendered to intermediate between two CIImageProcessorKernels.
compile_metal_dag
build_dag
Failed to allocate IOSurface for CGNode
surface_for_roi_from_cg
Failed to render - cannot access data from CGImage %p
processor_render
convert_processor
surface_for_roi_from_prov
surface_for_roi_from_surface
CI_CONVERSION: Converted input surface to a new surface with required rowbytes alignment (of %d bytes).
%{public}s CI_CONVERSIONS: Rendered via an intermediate YCC444 buffer instead of directly to a (%zux%zu) %{public}s pixel buffer.
%{public}s could not access pixelbuffer.
convert_YCC444_to_420
%{public}s CI_CONVERSIONS: Rendered via an intermediate YCC444 buffer instead of directly to a (%zux%zu) %{public}s surface.
%{public}s could not access surface.
traverse_gathering_digests
prepare_initial_graph
make_program_graph_if_renderable
render_tile
construct_shader
Failed to allocate IOSurface (%zux%zu format:%.4s)
Failed to allocate IOSurface (%zux%zu format:%ld)
Cache Stats: count=%ld size=%ld%s non-volatile=%ld%s peakCount=%ld peakSize=%ld%s peakNVSize=%ld%s
CacheEntryFillAsync
cid:%u iid:%u [%lld %lld %zu %zu]
GetSurfaceFromCacheAndFill
GetSurfaceFromCache
wait
softlink:r:path:/System/Library/PrivateFrameworks/Espresso.framework/Espresso
softlink:r:path:/System/Library/PrivateFrameworks/CMPhoto.framework/CMPhoto
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/CoreML.framework/CoreML
softlink:r:path:/System/Library/Frameworks/AVFoundation.framework/AVFoundation
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/PrivateFrameworks/Espresso.framework/Espresso
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/PrivateFrameworks/Espresso.framework/Espresso
softlink:r:path:/System/Library/Frameworks/CoreML.framework/CoreML
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/PrivateFrameworks/Espresso.framework/Espresso
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/PrivateFrameworks/Espresso.framework/Espresso
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/PrivateFrameworks/Espresso.framework/Espresso
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/VideoProcessors/CCPortrait.bundle/CCPortrait
softlink:r:path:/System/Library/Frameworks/Vision.framework/Vision
softlink:r:path:/System/Library/PrivateFrameworks/Espresso.framework/Espresso
softlink:r:path:/System/Library/PrivateFrameworks/Espresso.framework/Espresso
Q@A5
AutoCropper
CIBilateralGridHash
CIBilateralSolverGPU
CIAccordionFoldTransition
CIClamp
CIAffineClamp
CISimpleTile
CIAffineTile
CIAffineTransform
_CIFilterProperties
CIASGPercent
CIASG50Percent
CIASG66Percent
CIASG75Percent
CIASG80Percent
CIASG60Percent
CIAppleSmithGossettScale
CIAreaHistogram
CIPercentileRed
CIBarcodeDescriptor
NSSecureCoding
NSCoding
NSCopying
CIQRCodeDescriptor
CIAztecCodeDescriptor
CIPDF417CodeDescriptor
CIDataMatrixCodeDescriptor
CIBarcodeDetector
CIBarsSwipeTransition
CICheapBilateral
CIBitmapContext
BuiltIn
CIBlendModeFilter
CIMultiplyBlendMode
CIScreenBlendMode
CIOverlayBlendMode
CIDarkenBlendMode
CILightenBlendMode
CIColorDodgeBlendMode
CIColorBurnBlendMode
CIHardLightBlendMode
CISoftLightBlendMode
CIDifferenceBlendMode
CIExclusionBlendMode
CIPDFNonSeparableBlendMode
CIHueBlendMode
CISaturationBlendMode
CIColorBlendMode
CILuminosityBlendMode
CISubtractBlendMode
CIDivideBlendMode
CILinearBurnBlendMode
CILinearDodgeBlendMode
CIVividLightBlendMode
CILinearLightBlendMode
CIPinLightBlendMode
CIHardMixBlendMode
CIMix
CIBlendWithMask
CIBlendWithRedMask
CIBlendWithBlueMask
CIBlendWithAlphaMask
CIBloom
CIGloom
CIBoxBlur
CIBumpDistortion
CIBumpDistortionLinear
CIBurstActionClassifier
CIBurstClusterDivider
CIBurstFaceConfigEntry
CIBurstFaceScoreEntry
CIBurstFaceInfo
CIBurstImageFaceAnalysisContext
CIBurstImageSet
InpaintingMultiresolutionFilter
InpaintingGeneralHelpers
CIBurstImageSetInternal
CIBurstFaceStat
CIBurstImageStat
CIBurstThumbnailCluster
CIBurstYUVImage
CICMYKHalftone
CICameraCalibrationLensCorrection
CICheapBlur
CICheatBlur
CICheckerboardGenerator
CICircleGenerator
CICircleSplashDistortion
CICircularWrap
CIConstColor
CIColor
CIColorBalance
CIColorClamp
CIColorControls
CIHueAdjust
CIColorCube
CIColorCubeWithColorSpace
CIColorCubesMixedWithMask
CIColorCurves
CIColorThreshold
CIColorThresholdOtsu
CIColorMonochrome
CIPalettize
CIDither
CIDesaturateShadows
CIColorMap
CISingleChannelColorMap
CIColorMatrix
CIColorInvert
CIColorPolynomial
CIColorPolynomialInverse
CIColorCrossPolynomial
CIColorPosterize
CIFusionDelta
CIFusionTwoImagesDelta
CILineOverlay
CISpotColor
CIComicEffect
_CICompositeFilter
CISourceOverCompositing
CISourceInCompositing
CISourceOutCompositing
CISourceAtopCompositing
CIAdditionCompositing
CIMultiplyCompositing
CIMinimumCompositing
CIMaximumCompositing
CIPlusDarkerCompositing
CIPlusLighterCompositing
CIConstantColorGenerator
CIContext
Internal
QuicklookSupport
CIContextCache
createCGImage
ImageRepresentationPrivate
ImageRepresentation
InpaintingExecutionContext
CIDepthBlurEffect
CIConvolution3X3
CIConvolutionRGB3X3
CIConvolution5X5
CIConvolutionRGB5X5
CIConvolution7X7
CIConvolutionRGB7X7
CIConvolution9Horizontal
CIConvolutionRGB9Horizontal
CIConvolution9Vertical
CIConvolutionRGB9Vertical
CICopyMachineTransition
CIPredictionModel
MLFeatureProvider
CICoreMLKernel
CIFeatureProviderMultiArray
CIFeatureProviderImage
CICoreMLProcessorImageArray
CICoreMLModelFilter
CICrop
CICrystallize
CIDepthOfField
CIDetector
CIConvolution
CIBokehBlur
CIDiscBlur
CIRingBlur
CIDisintegrateWithMaskTransition
CIInpaintingFilter
CIDisparityRefinement
CIDisparitySmoothing
CIDisparitySmoothingProcessor
CIDisplacementDistortion
CIDissolveTransition
CIDocumentEnhancer
CIPaperWash
CIContrastEnhancer
CIDroste
CheapRandomness
RadialFalloffFilter
PercentileClipProcessor_RGBA8_CPU
HistoClip_RGBA8_CPU
ConvexFillProcessor
CIConvexFill
CISeedFillProcessor
CISeedFill
CICircularityDescriptor
RedEyeSpecular
RedEyeRecolor
RedPupilLocalizer
RedEyeFace
CIDualRedEyeRepairSession
CIRedEyeRaw
CIDualRedEyeRepairTuning
Algebra
CIEdgePreserveUpsampleFilter
CIEdgePreserveUpsampleRGFilter
CIEdgeWork
CIEdges
CIGaborGradients
CIExposureAdjust
CIFaceBalance
CIFaceMaskApply
CIFaceMaskDelta
CIFaceMaskCalculator
CIFaceMaskKernel
CIFaceSegmentationFilter
CIFeature
CIFaceFeature
CIRectangleFeature
CIQRCodeFeature
CITextFeature
CIFilter
Private
Interposer
CIFilterRegistry
CIFilterRegistryPrivate
CIFilterClassAttributes
CIFilterClassCategories
CIFilterClassDefaults
CIFilterClassInfo
CIFilterShape
CIFilterShapePrivate
CIFlashTransition
CIFocalPlanePreprocessorInternal
CIFocalPlaneNative
CIFocalPlane
CIGVNode
CGRenderer
CIGVRenderer
GVRenderer
NSObject
PDFRenderer
PNGRenderer
DOTRenderer
CIModifyBlurmap
CIGammaAdjust
CIGaussianBlur
CIGaussianBlurXY
CIGenericMetalProcessorSingleChannel
CIGenericMetalProcessor
CIGlassDistortion
CIRadialGradient
CILinearGradient
CISmoothLinearGradient
CIGaussianGradient
CIHueSaturationValueGradient
CIGuidedFilter
_CIScreenFilter
CIDotScreen
CIHatchedScreen
CILineScreen
CICircularScreen
CIHeightFieldFromMask
CIHighlightShadowAdjust
CIHistogramDisplayFilter
CIHoleDistortion
BlockDeallocator
CIImage
AVDepthData
AVPortraitEffectsMatte
AVSemanticSegmentationMatte
TextImage
ClearImage
CIImageAccumulator
AutoAdjust
AutoAdjustCrop
CIImageProcessorInOut
CIImageProcessorOutput
CIImageProcessorInput
CIImageProcessor
CIImageProcessorKernel
MTLComputePipelineState
CIImageProvider
CIImageRowReader
ImageRowReading
CIFileSaverProcessor
CIImageWriter
YCCExtensions
CIIntegralImageProcessorCPU
CIIntegralImage
CIKaleidoscope
CIKernel
CIColorKernel
CIWarpKernel
CIBlendKernel
CILabDeltaE
CILanczosScaleTransform
CIGlassLozenge
CITorusLensDistortion
CILensModelCalculatorCPU
CILensModelCalculator
CILensModelApply
CILensModelKernelMetalProcessor
CILenticularHaloGenerator
CILightTunnel
CILocalContrast
PrivateLocalLight
CILocalLightMapPrepare
CILocalLightFilter
CILumaMap
CIXRay
CIThermal
CIMaskToAlpha
CIMaskedVariableBlur
CIMattingSolverInternal
CIMattingSolver
CIMedianFilter
CIMeshGenerator
CIMetalConverter
CIMetalProcessor
CIMetalWrapper
CIMinimumComponent
CIMaximumComponent
CIMirror
CIModTransition
CIMorphology
CICheapMorphology
CIMorphologyMinimum
CIMorphologyMaximum
CIMorphologyGradient
CIMorphologyLaplacian
CIPseudoMedian
CIMorphologyRectangle
CIMorphologyRectangleMaximum
CIMorphologyRectangleMinimum
CIMotionBlur
CIZoomBlur
CIOpTile
CIOpacity
CIPageCurlTransition
CIPageCurlWithShadowTransition
CIParallelogramTile
CIPerspectiveTransformWithExtent
CIPerspectiveTransform
CIPerspectiveTile
CIPerspectiveCorrection
CIPhotoEffect
CIPhotoEffectNoir
CIPhotoEffectChrome
CIPhotoEffectFade
CIPhotoEffectInstant
CIPhotoEffectMono
CIPhotoEffectProcess
CIPhotoEffectTonal
CIPhotoEffectTransfer
CIPhotoEffectStageMono
CIPhotoEffect3D
CIPhotoEffect3DVivid
CIPhotoEffect3DVividWarm
CIPhotoEffect3DVividCool
CIPhotoEffect3DDramatic
CIPhotoEffect3DDramaticWarm
CIPhotoEffect3DDramaticCool
CIPhotoEffect3DSilverplate
CIPhotoEffect3DCommercial
CIPhotoEffect3DNoir
CIPhotoGrain
CIPinchDistortion
CIPixellate
CIHexagonalPixellate
CIPointillize
CIBlurmapSmoothing
CIPortraitBlurNoise
CIPortraitBlurDirectionalBlur
CIPortraitBlur
CIPortraitBlurPreProcess
CIHighlightRecoveryProcessor
CISDOFHighlightRecovery
CIHighlightRecovery
CIPortraitAntialias
CISparseRendererPreFiltering
CISparseRenderer
CIPortraitBlurV2
CIPortraitBlurCombiner
CIPremultiply
CIUnpremultiply
CIRAWFilterPrivate
CIRAWFilter
InpaintingTilingFilter
CIRAWFilterImpl
CustomAccessors
WhiteBalance
Apply
CIRAWTemperatureAdjust
CIRAWGamutMapping
CIPerspectiveAutoCalc
PerspectiveAutoCalc
CIRandomGenerator
CIRectangleDetector
CIRectangleGenerator
CIRoundedRectangleGenerator
CIRedEyeCorrection
CIRedEyeCorrections
InpaintingSinglePassFilter
CIRedEyeRepair3
RedEye
CIFaceCoreDetector
CIReductionFilter
CIAreaAverage
CIColumnAverage
CIRowAverage
CIAreaMinMax
CIAreaMaximum
CIAreaMinimum
CIAreaMaximumAlpha
CIAreaMinimumAlpha
CIAreaMinMaxRed
CIAreaMinMaxNormalize
CIAreaMinMaxRedNormalize
CIKMeans
CIAreaCentroid
CIAreaRedCentroid
CIAreaRedRadialCentroid
CICircularMaskFromPointImage
CIPaletteCentroid
CITileFilter
CITile2Filter
CIFourfoldRotatedTile
CISixfoldRotatedTile
CITwelvefoldReflectedTile
CIFourfoldTranslatedTile
CIGlideReflectedTile
CIEightfoldReflectedTile
CIFourfoldReflectedTile
CISixfoldReflectedTile
CIRenderDestination
CIRenderInfo
CIRenderTask
CIRippleTransition
CISRGBToneCurveToLinear
CILinearToSRGBToneCurve
CISaliencyMapKernel
CISaliencyMapFilter
CISampleNearest
CISampler
CISepiaTone
CIShadedMaterial
CIPerspectiveAutoCalcV2
CINoiseReduction
CIProSharpenEdges
CISharpenLuminance
CISkyAndGrassAdjust
CISmartBlackAndWhite
PrivateSmartBlackAndWhite
PrivateSmartToneAndColor
CISmartToneFilter
CISmartColorFilter
InpaintingImageHelpers
CIBicubicScaleTransform
CISoftCubicUpsample
CISpotLight
CIStarShineGenerator
CIStraightenFilter
CIStretch
CIStretchCrop
CINinePartStretched
CINinePartTiled
CIStripesGenerator
CISunbeamsGenerator
CISwipeTransition
CITemperatureAndTint
CIWhitePointAdjust
CIFalseColor
CITextDetector
CITextImageGenerator
CIAttributedTextImageGenerator
CIToneCurve
CITriangleKaleidoscope
CITriangleTile
CITwirlDistortion
CIUnsharpMask
CIVNFeature
CIVNDetector
CIVNFaceDetector
CIVariableBoxBlur
InpaintingEspressoExecutionResources
InpaintingEspressoHelpers
CIVector
CIVibrance
CIVignette
CIVignetteEffect
CIPerspectiveAutoCalcV1
Builtins
CIVortexDistortion
AutoROI
CIWrapMirror
MetalAdditions
SDOF
CIDepthToDisparity
CIDisparityToDepth
CIDepthDisparityConverter
CISegmentationFusion
CILensModelApplyV3
CIDisparityWeightsV3
CIDisparityPreprocV3
CIDisparityRefinementSparseSamplerV3
CIDisparityRefinementAntialiasV3
CIDisparityRefinementV3
CIDepthEffectMakeBlurMap
CIDepthEffectApplyBlurMap
CIDepthEffect
PrivateDepthUtilities
Utilities
CUIScaleClampFilter
CUIInnerGlowOrShadowFilter
CUIOuterGlowOrShadowFilter
CUIShapeEffectBlur1
CUIOuterBevelEmbossFilter
CUIInnerBevelEmbossFilter
CIEnhancementCalculation
CIEnhancementCalculator
CIEnhancementHistogram
CIAutoEnhanceFace
RedEyeGlintFinder
RedEyeMinMorphology
RedEyeMaxMorphology
RedEyeDifference
RedEyeGradient
SDOFOnlyPrewarmingPrivate
CIRedEyeRepair3Analyze
RedEyeChannel
CIRedEyeRepair
CIPersonSegmentationKernel
CIPersonSegmentation
CIColorAbsoluteDifference
InpaintingMembraneGeneration
InpaintingFullPipelineFilter
CIKernelLibrary
InpaintingVImageWrapper
CIBlurmapRefinementThreshold
CIBlurmapRefinementLinearMapping
CIBlurmapRefinementDistanceDelta
CIPerspectiveRotate
CIKeystoneCorrection
CIKeystoneCorrectionCombined
CIKeystoneCorrectionHorizontal
CIKeystoneCorrectionVertical
init
setShouldFavorTop:
setShouldFavorBottom:
count
arrayWithArray:
objectAtIndex:
getValue:
rectContainingRect:andOtherRect:
valueWithBytes:objCType:
replaceObjectAtIndex:withObject:
removeObjectAtIndex:
standardUserDefaults
valueForKey:
floatValue
countByEnumeratingWithState:objects:count:
rectWithSize:andPoint:inPosition:fromOriginalSize:
scaleRect:toFitSize:withAnchorPoint:
determineBestPositionWithinSize:forImportantRect:restrictRect:
scaleRect:byScale:
expandRect:toContainRect:
computeClippingWithinSize:andImportantRect:
getRatioOfSize:
clusterRects:
computeClippingWithinSize:andImportantRects:
computeClippingWithinSize:forImportantRect:andType:restrictRect:
computeClippingWithinSize:forMultipleRects:
shouldFavorTop
shouldFavorBottom
originalImageSize
setOriginalImageSize:
TB,N,VshouldFavorBottom
TB,N,VshouldFavorTop
T{CGSize=dd},N,VoriginalImageSize
dealloc
clear
_computeBilateralSpaceYCC444:region:cropRect:sigma_s:sigma_r_luma:sigma_r_chroma:
_computeBlurIndices
_computeCoordIndices
_computeInterpIndices
_createWithSurface:region:cropRect:sigma_s:sigma_r_luma:sigma_r_chroma:
countVertices
width
height
countDims
_addHashKeyAtX:Y:key:isKeyExist:
_hashMapFindKey:to:
_hashMapAddKey:andValue:
sigma_s
sigma_r_luma
sigma_r_chroma
initWithWidth:height:maxHashTableSize:
createWithSurface:region:cropRect:sigma_s:sigma_r_luma:sigma_r_chroma:
splat:pout:
splat_w_mul_x:inPixelBuffer:pout:
slice:outPixelBuffer:
slice_trilinear:pin:pout:
blur:pout:
normalize:pout:
normalize_blur:pout:
splat_ones:
blur_ones:
blur_n:
blur_indices:n_blur_indices:
hash_table
hash_matrix
blur_table
coord_indices
coord_table
interp_indices
interp_table
interp_pad
_n_dims
_width
_height
_sigma_s
_sigma_r_luma
_sigma_r_chroma
_max_hash_table_size
_hash_table_size
_hash_map
_hash_table
_hash_matrix_data
_blur_indices
_coord_indices
_coord_table
_coord_indices_off
_interp_indices
_interp_table
_interp_pad
dictionary
registryID
numberWithUnsignedLong:
objectForKeyedSubscript:
objectAtIndexedSubscript:
arrayWithCapacity:
addObject:
setObject:forKeyedSubscript:
_setupPipelinesAsync:
_setupMetal
_setupPipelineCache
_setupBuffer
_prepareResources:
_doBistochastizeWithCommandBuffer:t_tex:c_tex:lambda:nIterations:
_doPCGWithCommandBuffer:nIterations:
_doSliceTrilinearWithCommandBuffer:ref_tex:o_tex:
_doSliceWithCommandBuffer:o_tex:
device
bundleForClass:
newDefaultLibraryWithBundle:error:
initWithUTF8String:
newFunctionWithName:
newComputePipelineStateWithFunction:completionHandler:
texture2DDescriptorWithPixelFormat:width:height:mipmapped:
setUsage:
newTextureWithDescriptor:
newBufferWithLength:options:
newBufferWithBytes:length:options:
replaceRegion:mipmapLevel:withBytes:bytesPerRow:
computeCommandEncoder
setComputePipelineState:
setBuffer:offset:atIndex:
setBytes:length:atIndex:
dispatchThreadgroups:threadsPerThreadgroup:
endEncoding
setTexture:atIndex:
threadExecutionWidth
maxTotalThreadsPerThreadgroup
initWithWidth:height:maxVertices:commandBuffer:
doSolveWithBilateralGridhash:reference:disparity:confidence:output:lambda:maxIterations:offsets:
useTrilinearInterpolation
setUseTrilinearInterpolation:
.cxx_destruct
_commandBuffer
_metalDevice
_computePipelines
_computePipelinesGroup
_threadGroupInfo
_params
_offsets
_maxVertices
_gridHashBuffer
_gridBlurBuffer
_gridCoordIndicesBuffer
_gridCoordTableBuffer
_gridHashMatrix
_gridInterpIndicesBuffer
_gridInterpTableBuffer
_gridInterpPadBuffer
_A_buf
_b_buf
_s_buf
_q_buf
_Dn_buf
_x_buf
_r_buf
_d_buf
_idxDnBufIn
_idxSwapBufIn
_useTrilinearInterpolation
TB,N,V_useTrilinearInterpolation
arrayWithObjects:count:
dictionaryWithObjects:forKeys:count:
cachedKernelWithString:
extent
doubleValue
imageByApplyingTransform:
vectorWithX:Y:Z:W:
vectorWithX:Y:Z:
_kernelWarpS
applyWithExtent:roiCallback:inputImage:arguments:
_kernelWarpT
_kernelMix
numberWithDouble:
applyWithExtent:arguments:
customAttributes
_kernel
outputImage
inputImage
setInputImage:
inputTargetImage
setInputTargetImage:
inputBottomHeight
setInputBottomHeight:
inputNumberOfFolds
setInputNumberOfFolds:
inputFoldShadowAmount
setInputFoldShadowAmount:
inputTime
setInputTime:
T@"CIImage",&,N,VinputImage
T@"CIImage",&,N,VinputTargetImage
T@"NSNumber",&,N,VinputBottomHeight
T@"NSNumber",&,N,VinputNumberOfFolds
T@"NSNumber",&,N,VinputFoldShadowAmount
T@"NSNumber",&,N,VinputTime
CGRectValue
imageByClampingToRect:
inputExtent
setInputExtent:
T@"CIVector",&,N,VinputExtent
description
UTF8String
inputTransform
setInputTransform:
T@"NSValue",&,N,VinputTransform
transformStruct
imageByClampingToExtent
vectorWithCGPoint:
filteredImage:keysAndValues:
vectorWithX:Y:
_outputProperties
_initFromProperties:
imageBySamplingNearest
applyWithExtent:roiCallback:arguments:
imageByCroppingToRect:
outputImageScale:outset:hKernel:vKernel:
kernelWithString:
imageByApplyingFilter:withInputParameters:
inputScale
setCanReduceOutputChannels:
intValue
_netExtent
_inputsAreOK
dataWithLength:
mutableBytes
length
defaultWorkingColorSpace
_singletonContext
render:toBitmap:rowBytes:bounds:format:colorSpace:
numberWithFloat:
stringWithFormat:
imageWithExtent:processorDescription:argumentDigest:inputFormat:outputFormat:options:roiCallback:processor:
clearColor
imageWithColor:
outputImageNonMPS
outputData
setInputScale:
inputCount
setInputCount:
T@"NSNumber",&,N,VinputScale
T@"NSNumber",&,N,VinputCount
boolValue
vectorWithCGRect:
inputPercentile
setInputPercentile:
inputNormalize
setInputNormalize:
inputClip
setInputClip:
inputHard
setInputHard:
T@"NSNumber",&,N,VinputPercentile
T@"NSNumber",&,N,VinputNormalize
T@"NSNumber",&,N,VinputClip
T@"NSNumber",&,N,VinputHard
baseAddress
region
bytesPerRow
format
allowsKeyedCoding
supportsSecureCoding
encodeWithCoder:
initWithCoder:
TB,R
copyWithZone:
isValid
initWithPayload:symbolVersion:maskPattern:errorCorrectionLevel:
decodeObjectOfClass:forKey:
decodeIntegerForKey:
encodeObject:forKey:
encodeInteger:forKey:
allocWithZone:
descriptorWithPayload:symbolVersion:maskPattern:errorCorrectionLevel:
errorCorrectedPayload
symbolVersion
maskPattern
errorCorrectionLevel
T@"NSData",R,VerrorCorrectedPayload
Tq,R,VsymbolVersion
TC,R,VmaskPattern
Tq,R,VerrorCorrectionLevel
initWithPayload:isCompact:layerCount:dataCodewordCount:
decodeBoolForKey:
encodeBool:forKey:
descriptorWithPayload:isCompact:layerCount:dataCodewordCount:
isCompact
layerCount
dataCodewordCount
TB,R,VisCompact
Tq,R,VlayerCount
Tq,R,VdataCodewordCount
initWithPayload:isCompact:rowCount:columnCount:
copy
descriptorWithPayload:isCompact:rowCount:columnCount:
rowCount
columnCount
Tq,R,VrowCount
Tq,R,VcolumnCount
initWithPayload:rowCount:columnCount:eccVersion:
descriptorWithPayload:rowCount:columnCount:eccVersion:
eccVersion
Tq,R,VeccVersion
_objectForIdentifier:
_payloadForIdentifier:
_setPayloadIdentifier:object:withBlock:
detectedBarcodeDescriptor
setDetectedCode:
T@"CIBarcodeDescriptor",R,C,N
setContext:
objectForKey:
isEqual:
setObject:forKey:
finalize
context
render:toCVPixelBuffer:
integerValue
unsignedCharValue
initWithInternalRepresentation:
featuresInImage:options:
initWithContext:options:
featuresInImage:
featureOptions
T@"CIContext",&,N,Vcontext
imageByCompositingOverImage:
inputAngle
setInputAngle:
inputWidth
setInputWidth:
inputBarOffset
setInputBarOffset:
T@"NSNumber",&,N,VinputAngle
T@"NSNumber",&,N,VinputWidth
T@"NSNumber",&,N,VinputBarOffset
numberWithInt:
imageByUnpremultiplyingAlpha
imageByPremultiplyingAlpha
inputSource
setInputSource:
inputSigmaSpace
setInputSigmaSpace:
inputSigmaRange
setInputSigmaRange:
T@"CIImage",&,N,VinputSource
T@"NSNumber",&,N,VinputSigmaSpace
T@"NSNumber",&,N,VinputSigmaRange
initWithOptions:
initWithBitmap:rowBytes:bounds:format:
initWithBitmap:rowBytes:bounds:format:options:
dictionaryWithDictionary:
setValue:forKey:
setBitmap:rowBytes:bounds:format:
_internalContext
_outputColorSpace
defaultGrayColorSpace
defaultRGBColorSpace
contextWithOptions:
contextWithBitmap:rowBytes:bounds:format:
contextWithBitmap:rowBytes:bounds:format:options:
drawImage:inRect:fromRect:
bounds
_bcpriv
cachedKernelWithString:extentType:
setIsForeIfBackIsClear:
setIsClearIfForeIsClear:
setIsClearIfBackIsClear:
setIsBackIfForeIsClear:
componentAdd
componentMultiply
componentMin
componentMax
source
destination
sourceOver
destinationOver
sourceIn
destinationIn
sourceOut
destinationOut
sourceAtop
destinationAtop
exclusiveOr
multiply
screen
overlay
darken
lighten
colorDodge
colorBurn
hardLight
softLight
difference
exclusion
saturation
color
luminosity
subtract
divide
linearBurn
linearDodge
vividLight
linearLight
pinLight
hardMix
darkerColor
lighterColor
plusDarker
plusLighter
T@"CIBlendKernel",R
applyWithForeground:background:
inputBackgroundImage
setInputBackgroundImage:
T@"CIImage",&,N,VinputBackgroundImage
_defaultVersion
setDefaults
_kernel_v0
_kernel_v1
_maxVersion
emptyImage
inputAmount
setInputAmount:
T@"NSNumber",&,N,VinputAmount
_maskFillColorValue
_kernelB0
inputMaskImage
setInputMaskImage:
T@"CIImage",&,N,VinputMaskImage
_internalRepresentation
_isIdentity
imageByApplyingGaussianBlurWithSigma:
inputRadius
setInputRadius:
inputIntensity
setInputIntensity:
T@"NSNumber",&,N,VinputRadius
T@"NSNumber",&,N,VinputIntensity
setPreservesRange:
inputCenter
setInputCenter:
T@"CIVector",&,N,VinputCenter
setSvmParameters:
svmParameters
computeKernelValueWithSupportVector:
scaleVector
predictResult
initWithVersion:
isBurstAction
testAverageCameraTravelDistance
setTestAverageCameraTravelDistance:
testMaxRegistrationErrorIntegral
setTestMaxRegistrationErrorIntegral:
testMaxPeakRegistrationError
setTestMaxPeakRegistrationError:
testMeanPeakRegistrationError
setTestMeanPeakRegistrationError:
testBeginningVsEndAEMatrixVsAverageAdjacentAEMatrix
setTestBeginningVsEndAEMatrixVsAverageAdjacentAEMatrix:
testInOutRatio
setTestInOutRatio:
testMaxInnerDistance
setTestMaxInnerDistance:
testAverageRegistrationErrorSkewness
setTestAverageRegistrationErrorSkewness:
testMinRegionOfInterestSize
setTestMinRegionOfInterestSize:
testMaxRegistrationErrorSkewness
setTestMaxRegistrationErrorSkewness:
hasBeenScaled
testVector
_svmParameters
Tf,VtestMaxInnerDistance
Tf,VtestInOutRatio
Tf,VtestMaxPeakRegistrationError
Tf,VtestMeanPeakRegistrationError
Tf,VtestMinRegionOfInterestSize
Tf,VtestMaxRegistrationErrorSkewness
Tf,VtestMaxRegistrationErrorIntegral
Tf,VtestAverageCameraTravelDistance
Tf,VtestAverageRegistrationErrorSkewness
Tf,VtestBeginningVsEndAEMatrixVsAverageAdjacentAEMatrix
T^{__SVMParameters=[7{__SVMScaleOffset=ff}]ddii^{CIBurstSupportVector}^{CIBurstSupportVector}},V_svmParameters
dividerScore
leftImage
actionAmount
compareDividers:
compareIndices:
compareActionAmounts:
setDividerScore:
setLeftImage:
trueLocalMaximum
setTrueLocalMaximum:
setActionAmount:
noiseThreshold
setNoiseThreshold:
highNoiseThreshold
setHighNoiseThreshold:
Tf,VdividerScore
Ti,VtrueLocalMaximum
Ti,VleftImage
Tf,VactionAmount
Tf,VnoiseThreshold
Tf,VhighNoiseThreshold
initWithRect:withFaceId:
faceId
setFaceId:
faceRect
setFaceRect:
framesSinceLast
setFramesSinceLast:
Ti,VfaceId
T{CGRect={CGPoint=dd}{CGSize=dd}},VfaceRect
Ti,VframesSinceLast
computeAverage
initWithScore:
addScore:
computeStandardDeviation
maxScore
setMaxScore:
minScore
setMinScore:
numScores
setNumScores:
sumScores
sumSqScores
Tf,VmaxScore
Tf,VminScore
Ti,VnumScores
setSwFaceId:
setSwCenter:
setSwSize:
setSwLastFrameSeen:
setHwFaceId:
setHwCenter:
setHwSize:
setHwLastFrameSeen:
hwCenter
hwSize
swCenter
swSize
hwFaceId
hwFaceRect
swFaceId
swFaceRect
overlapWithHwRect:
overlapWithSwRect:
swLastFrameSeen
hwLastFrameSeen
Ti,VswFaceId
T{CGPoint=dd},VswCenter
T{CGSize=dd},VswSize
Ti,VswLastFrameSeen
Ti,VhwFaceId
T{CGPoint=dd},VhwCenter
T{CGSize=dd},VhwSize
Ti,VhwLastFrameSeen
dictionaryWithCapacity:
isEqualToString:
setVersion:
addEntriesFromDictionary:
faceDetectorWithOptions:
orientation
version
faceStatArray
setHwFaceRect:
hasLeftEye
hasRightEye
padRoiRect:paddingX:paddingY:
isSyncedWithImage
temporalOrder
setFacesRoiRect:
setNumHWFaces:
setupFaceDetector
calculateFaceCoreROI:imageStat:needFaceCore:
Ybuffer
dataWithBytesNoCopy:length:freeWhenDone:
array
hasRollAngle
rollAngle
setFaceAngle:
faceAngle
hasYawAngle
yawAngle
setFaceType:
setFace:
setFaceSize:
leftEyeRect
leftEyeBlinkScore
numberWithBool:
rightEyeRect
rightEyeBlinkScore
smileScore
setExpressionFeatures:
setLeftEye:
setRightEye:
setMouth:
detectFacesInData:width:height:bytesPerRow:options:error:
arrayByAddingObjectsFromArray:
face
findOverlappingFaceStat:imageStat:
sortedArrayUsingComparator:
subarrayWithRange:
extractDetailsForFaces:inData:width:height:bytesPerRow:options:error:
localizedDescription
expressionFeatures
numHWFaces
facesRoiRect
setNormalizedFaceRect:
setFoundByFaceCore:
setHasLeftEye:
setHasRightEye:
setLeftEyeOpen:
setRightEyeOpen:
setSmiling:
setLeftEyeBlinkScore:
setRightEyeBlinkScore:
setSmileScore:
leftEye
setLeftEyeRect:
rightEye
setRightEyeRect:
leftEyeOpen
rightEyeOpen
foundByFaceCore
value:withObjCType:
setFocusScore:
burstImages
focusScore
setNormalizedFocusScore:
setNormalizedSigma:
imageId
removeObjectForKey:
allKeys
unsignedLongLongValue
insertObject:atIndex:
addFaceToArray:
timestamp
setTimestamp:
setHasRollAngle:
setRollAngle:
setHasYawAngle:
setYawAngle:
setIsSyncedWithImage:
findFacesInImage:imageStat:
calculateFaceFocusInImage:imageStat:
calcFaceScores:
adjustFaceIdsForImageStat:
extractFacesFromMetadata:
addFacesToImageStat:imageSize:
dumpFaceInfoArray
timeBlinkDetectionDone
setTimeBlinkDetectionDone:
timeFaceDetectionDone
setTimeFaceDetectionDone:
forceFaceDetectionEnable
setForceFaceDetectionEnable:
latestFaceTimestamp
setLatestFaceTimestamp:
curConfig
faceIdMapping
renameMapping
faceIdCounter
faceInfoArray
numFramesSinceFullFaceCore
numFramesNoFaces
faceDetector
faceTimestampArray
latestImageTimestamp
lastFaceIndex
_version
Td,VtimeFaceDetectionDone
Td,VtimeBlinkDetectionDone
TB,VforceFaceDetectionEnable
Td,VlatestFaceTimestamp
Ti,V_version
defaultVersionString
burstId
addImageFromIOSurface:properties:identifier:completionBlock:
bestImageIdentifiersArray
secondsSinceStart
bestImageIdentifiers
burstLogFileName
allImageIdentifiers
statsForImageWithIdentifier:
maxNumPendingFrames
enableAnalysis
enableFaceCore
dummyAnalysisCount
isFaceDetectionForced
enableDumpYUV
isAction
isPortrait
burstDocumentDirectory
stringByAppendingPathExtension:
burstCoverSelection
writeToFile:atomically:
dictionaryWithContentsOfFile:
imageClusterForIdentifier:
clusterArray
statsByImageIdentifier
burstImageSet
burstImageSetWithOptions:
coverImageIdentifier
imageClusterCount
imageClusterForIndex:
setLoggingListener:withUserInfo:
_priv
setLastInpaintingModeUsed:
setLastNumberOfTilesUsed:
imageByColorMatchingWorkingSpaceToColorSpace:
scaleImage:toWidth:andHeight:
thresholdMask:
runInpaintingNeuralNetworkOnSRGBImage:usingThresholdedMask:inpaintingResourceDescriptor:espressoResources:executionContext:error:
cStringUsingEncoding:
blurImage:withSigma:
blendImage:withBackgroundImage:usingMask:
erodeMask:usingRadius:
absoluteDiffBetweenImage:andImage:
invertMask:
imageByColorMatchingColorSpaceToWorkingSpace:
performMultiresolutionInpaintingPipelineOnImage:usingMask:boundingBox:additionalParameters:espressoResources:executionContext:
fillError:withGeneralErrorWithMessage:
dictionaryWithObjectsAndKeys:
errorWithDomain:code:userInfo:
errorWithCode:message:underlyingError:
generalErrorWithMessage:
getMainBundleUsingError:
pathForResource:ofType:
resourcePath
stringByDeletingPathExtension
pathExtension
pathForResource:ofType:error:
URLForResource:withExtension:
fillError:withErrorWithCode:message:underlyingError:
pathForResourceWithFilename:error:
URLForResource:ofType:error:
stringFromCGRect:
persistentDomainForName:
defaultManager
stringByAppendingPathComponent:
createDirectoryAtPath:withIntermediateDirectories:attributes:error:
setVersionString:
versionString
setWithCapacity:
stringWithCString:encoding:
setBurstId:
initWithCGImage:maxDimension:
setDateFormat:
date
stringFromDate:
fileExistsAtPath:
releaseImage
isGarbage
registrationErrorIntegral
imageProps
image
normalizedFaceRect
computeImageData:faceIDCounts:
smiling
smallFace
FCRLeftEyeFeaturesOffset
FCRRightEyeFeaturesOffset
FCRSmileFeaturesOffset
FCRBlinkFeaturesSize
FCRSmileFeaturesSize
dataWithBytes:length:
Cbuffer
AEAverage
AETarget
AEStable
AFStable
aeMatrix
completionBlock
initWithImageData:dict:identifier:imageProps:completionBlock:
setTemporalOrder:
setTimeReceived:
processClusters:
stringWithString:
initWithIOSurface:maxDimension:
addYUVImage:properties:identifier:imageProps:completionBlock:
normalizedFocusScore
computeEmotion:
setEmotionallyRejected:
avgHorzDiffY
blurExtent
setImageScore:
setActionScore:
computeAEMatrixDifference:
canRegister
allocateMeanStdPingPongBuffers::::
assignMeanStdBuffers:
performRegistration:deltaCol:deltaRow:
maxSkewness
setMaxSkewness:
setTx:
setTy:
computeSmoothedGridROI:nextStat:
doLimitedSharpnessAndBlur
hasRegistrationData
countForObject:
removeObject:
collapseSharpnessGrid
setIsGarbage:
flagAsGarbage
roiSize
registrationErrorX
registrationErrorY
computeCameraTravelDistance
computeBeginningVsEndAEMatrixDiffVsAverageAdjacent
computeActionSelectionThreshold
computeScore:
writeGridROI:
actionScore
imageScore
lastObject
computeAllImageScores
performEmotionalRejectionOnCluster:
findBestImage:useActionScores:
emotionallyRejected
selectCoverPhotoFromMultiple:burstSize:
addItemsFromCluster:
setBestImageIdentifiersArray:
setClusterArray:
faceIDCounts
setFaceIDCounts:
setAllImageIdentifiers:
actionClassifier
setActionClassifier:
setStatsByImageIdentifier:
clusterByImageIdentifier
setClusterByImageIdentifier:
setBurstLogFileName:
setMaxNumPendingFrames:
setEnableAnalysis:
setDummyAnalysisCount:
setEnableFaceCore:
setEnableDumpYUV:
setBurstCoverSelection:
dq_yuvdump
faceAnalysisContext
overrideImage
overrideProps
burstLogFileHandle
curClusterIndexToProcess
_versionString
T@"NSMutableArray",VclusterArray
Ti,VtemporalOrder
T@"NSCountedSet",VfaceIDCounts
T@"NSMutableArray",VallImageIdentifiers
T@"NSMutableDictionary",VstatsByImageIdentifier
T@"NSMutableDictionary",VclusterByImageIdentifier
T@"NSString",VburstLogFileName
T@"CIBurstActionClassifier",VactionClassifier
Ti,VmaxNumPendingFrames
TB,VenableAnalysis
Ti,VdummyAnalysisCount
TB,VenableFaceCore
TB,VenableDumpYUV
T@"NSString",VburstCoverSelection
T@"NSString",&,N,VburstId
T@"NSArray",VbestImageIdentifiersArray
T@"NSString",V_versionString
computeImageDistance:
actionClusteringScore
sortedArrayUsingSelector:
addObjectsFromArray:
removeAllObjects
compareImageOrder:
normalizedSigma
faceScore
initWithFaceStat:
setFaceScore:
setFCRLeftEyeFeaturesOffset:
setFCRRightEyeFeaturesOffset:
setFCRSmileFeaturesOffset:
setFCRBlinkFeaturesSize:
setFCRSmileFeaturesSize:
FCRSmileAndBlinkFeatures
setFCRSmileAndBlinkFeatures:
setSmallFace:
_isSyncedWithImage
_hwFaceRect
TB,VleftEyeOpen
TB,VrightEyeOpen
TB,Vsmiling
Tf,VleftEyeBlinkScore
Tf,VrightEyeBlinkScore
Tf,VsmileScore
TB,VhasLeftEye
TB,VhasRightEye
TB,VfoundByFaceCore
T{CGRect={CGPoint=dd}{CGSize=dd}},VnormalizedFaceRect
Tf,VfocusScore
Tf,VfaceScore
T{CGRect={CGPoint=dd}{CGSize=dd}},VleftEyeRect
T{CGRect={CGPoint=dd}{CGSize=dd}},VrightEyeRect
Ti,VFCRLeftEyeFeaturesOffset
Ti,VFCRRightEyeFeaturesOffset
Ti,VFCRSmileFeaturesOffset
Ti,VFCRBlinkFeaturesSize
Ti,VFCRSmileFeaturesSize
T@"NSMutableArray",VFCRSmileAndBlinkFeatures
T{CGRect={CGPoint=dd}{CGSize=dd}},V_hwFaceRect
Tf,VnormalizedFocusScore
Tf,VnormalizedSigma
TB,VhasRollAngle
TB,VhasYawAngle
Tf,VrollAngle
Tf,VyawAngle
Td,Vtimestamp
TB,V_isSyncedWithImage
TB,VsmallFace
getSharpnessAndBlurLimits
setAEDelta:
setRegistrationErrorX:
setRegistrationErrorY:
setHasRegistrationData:
setRegistrationErrorIntegral:
setActionClusteringScore:
updateROI:
computeImageColorHistogram:
computeImageSharpnessOnGrid:
computeBlurStatsOnGrid:
computeImageProjections:
getBytes:length:
computeFacialFocusScoreSum
initWithIdentifier:
computeRuleOfThreeDistance
computeSmilePercentage
setAEMatrix:
computeAEMatrix:
compareImageStats:
colorHistogram
setImageId:
setOrientation:
setFaceStatArray:
exclude
setExclude:
setAEStable:
setAEAverage:
setAETarget:
setAFStable:
setAvgHorzDiffY:
setBlurExtent:
timeReceived
setDoLimitedSharpnessAndBlur:
setRoiSize:
AEDelta
fullsizeJpegData
setFullsizeJpegData:
fullsizeJpegSize
setFullsizeJpegSize:
numEntries
dissimilarity
projectionMemoryBlock
projectionSignature
sharpnessGrid
gridWidth
gridHeight
gridROI
smoothedROI
_AEDelta
_fullsizeJpegSize
_fullsizeJpegData
T@"NSString",VimageId
Ti,Vorientation
T@"NSMutableArray",VfaceStatArray
TB,Vexclude
TB,VAEStable
Ti,VAEAverage
Ti,VAETarget
TB,VAFStable
Tf,VavgHorzDiffY
Tf,VblurExtent
Tf,VimageScore
Tf,VactionScore
Td,VtimeReceived
Tf,VmaxSkewness
Tf,VregistrationErrorX
Tf,VregistrationErrorY
Tf,VregistrationErrorIntegral
Tf,VactionClusteringScore
TB,VhasRegistrationData
T{CGRect={CGPoint=dd}{CGSize=dd}},VfacesRoiRect
Ti,VnumHWFaces
TB,VemotionallyRejected
TB,VdoLimitedSharpnessAndBlur
Tf,Vtx
Tf,Vty
TB,VisGarbage
Tf,VroiSize
Ti,V_AEDelta
T^{__IOSurface=},V_fullsizeJpegData
Ti,V_fullsizeJpegSize
setImageProps:
setImage:
setCompletionBlock:
computeMergeCost:::
setBurstImages:
T@"NSMutableArray",VburstImages
T@"NSMutableDictionary",VimageProps
T@"CIBurstYUVImage",Vimage
T@?,VcompletionBlock
convertRGBAToYUV420:rgbaBytesPerRow:
pixelBuffer
setWidth:
setHeight:
setYbuffer:
setCbuffer:
setBytesPerRow:
dataPtr
ioSurf
Ti,Vwidth
Ti,Vheight
Ti,VbytesPerRow
T*,VYbuffer
T*,VCbuffer
_CICMYK_convert
_CIWhite
_CICMYK_cyan
_CICMYK_magenta
_CICMYK_yellow
_CICMYK_black
inputSharpness
inputGCR
inputUCR
depthData
bytes
ReferenceensDistortionPointForPoint:lookupTable:distortionOpticalCenter:imageSize:
imageWithBitmapData:bytesPerRow:size:format:colorSpace:
regionOf:destRect:userInfo:
applyWithExtent:roiCallback:arguments:options:
inputAVCameraCalibrationData
inputUseInverseLookUpTable
_CICheapBlur
vectorWithX:
_CILerp
inputPasses
inputSampling
_CIBox6
_CIBox4
_CICross4
colorWithRed:green:blue:
setInputSharpness:
inputColor0
setInputColor0:
inputColor1
setInputColor1:
T@"NSNumber",&,N,VinputSharpness
T@"CIColor",&,N,VinputColor0
T@"CIColor",&,N,VinputColor1
_CICircle
inputColor
inputEdgeBlur
raise:format:
cgColor
colorSpace
components
numberOfComponents
alloc
retainCount
retain
release
autorelease
green
blue
alpha
rgbColor
hash
initWithCGColor:
initWithRed:green:blue:alpha:
colorWithRed:green:blue:alpha:
initWithRed:green:blue:alpha:colorSpace:
colorWithRed:green:blue:alpha:colorSpace:
initWithString:
encodeFloat:forKey:
decodeFloatForKey:
performSelector:withObject:
colorWithCGColor:
colorWithRed:green:blue:colorSpace:
colorWithString:
blackColor
whiteColor
grayColor
redColor
greenColor
blueColor
cyanColor
magentaColor
yellowColor
T@"CIColor",R
initWithRed:green:blue:
initWithRed:green:blue:colorSpace:
stringRepresentation
debugQuickLookObject
_pad
TQ,R
Tr^d,R
Td,R
T^{CGColorSpace=},R
T@"NSString",R
_imageByApplyingGamma:
setInputColor:
inputStrength
setInputStrength:
inputWarmth
setInputWarmth:
inputDamping
setInputDamping:
T@"CIColor",&,N,VinputColor
T@"NSNumber",&,N,VinputStrength
T@"NSNumber",&,N,VinputWarmth
T@"NSNumber",&,N,VinputDamping
setPerservesAlpha:
_kernelAlphaPreserving
inputMinComponents
setInputMinComponents:
inputMaxComponents
setInputMaxComponents:
T@"CIVector",&,N,VinputMinComponents
T@"CIVector",&,N,VinputMaxComponents
_imageByApplyingColorMatrixRed:green:blue:bias:
inputSaturation
setInputSaturation:
inputBrightness
setInputBrightness:
inputContrast
setInputContrast:
T@"NSNumber",&,N,VinputSaturation
T@"NSNumber",&,N,VinputBrightness
T@"NSNumber",&,N,VinputContrast
initWithImageProvider:width:height:format:colorSpace:options:
_checkInputs
cubeImage
isOpaque
_kernelOpaque
setInputCubeData:
inputCubeDimension
setInputCubeDimension:
inputCubeData
_cubeImage
T@"NSNumber",&,N,VinputCubeDimension
T@"NSData",C,N,VinputCubeData
null
inputColorSpace
setInputColorSpace:
T@,&,N,VinputColorSpace
filterWithName:
inputCube0Data
setInputCube0Data:
inputCube1Data
setInputCube1Data:
T@"NSData",C,N,VinputCube0Data
T@"NSData",C,N,VinputCube1Data
curvesImage
setInputCurvesData:
inputCurvesDomain
setInputCurvesDomain:
inputCurvesData
_curvesImage
T@"NSData",C,N,VinputCurvesData
T@"CIVector",&,N,VinputCurvesDomain
inputThreshold
setInputThreshold:
T@"NSNumber",&,N,VinputThreshold
_kernelApplyPalette
imageByApplyingFilter:
inputPaletteImage
setInputPaletteImage:
inputPerceptual
setInputPerceptual:
T@"CIImage",&,N,VinputPaletteImage
T@"NSNumber",&,N,VinputPerceptual
_kernelDither
inputSoftness
setInputSoftness:
T@"NSNumber",&,N,VinputSoftness
inputGradientImage
setInputGradientImage:
T@"CIImage",&,N,VinputGradientImage
numberWithUnsignedInt:
inputChannelIndex
setInputChannelIndex:
inputShouldNormalize
setInputShouldNormalize:
inputColorMapIndex
setInputColorMapIndex:
T@"NSNumber",&,N,VinputChannelIndex
T@"NSNumber",&,N,VinputShouldNormalize
T@"NSNumber",&,N,VinputColorMapIndex
imageWithInternalRepresentation:
inputRVector
setInputRVector:
inputGVector
setInputGVector:
inputBVector
setInputBVector:
inputAVector
setInputAVector:
inputBiasVector
setInputBiasVector:
T@"CIVector",&,N,VinputRVector
T@"CIVector",&,N,VinputGVector
T@"CIVector",&,N,VinputBVector
T@"CIVector",&,N,VinputAVector
T@"CIVector",&,N,VinputBiasVector
_isIdentityAlpha
_kernelRGB
inputRedCoefficients
setInputRedCoefficients:
inputGreenCoefficients
setInputGreenCoefficients:
inputBlueCoefficients
setInputBlueCoefficients:
inputAlphaCoefficients
setInputAlphaCoefficients:
T@"CIVector",&,N,VinputRedCoefficients
T@"CIVector",&,N,VinputGreenCoefficients
T@"CIVector",&,N,VinputBlueCoefficients
T@"CIVector",&,N,VinputAlphaCoefficients
_isInvertible
vectorWithValues:count:
valueAtIndex:
inputLevels
setInputLevels:
T@"NSNumber",&,N,VinputLevels
kernel
applyWithExtent:arguments:options:
inputAddBlur
inputRemoveBlur
inputApertureScaling
inputMaxBlur
inputSecondaryImage
setInputSecondaryImage:
inputProtectStrength
setInputProtectStrength:
setInputApertureScaling:
inputAdditive
setInputAdditive:
inputSubtractive
setInputSubtractive:
setInputMaxBlur:
T@"CIImage",&,VinputImage
T@"CIImage",&,VinputSecondaryImage
T@"NSNumber",&,VinputProtectStrength
T@"NSNumber",&,VinputApertureScaling
T@"CIVector",&,VinputAdditive
T@"CIVector",&,VinputSubtractive
T@"NSNumber",&,VinputMaxBlur
_CIComicNoiseReduction
_CISobelEdges
_CIColorControls
inputNRNoiseLevel
inputNRSharpness
inputEdgeIntensity
_CISpotColor
inputCenterColor1
inputReplacementColor1
inputCloseness1
inputContrast1
inputCenterColor2
inputReplacementColor2
inputCloseness2
inputContrast2
inputCenterColor3
inputReplacementColor3
inputCloseness3
inputContrast3
internalCommandQueue
sharedCaptureManager
defaultCaptureScope
beginScope
endScope
loadArchive:
internalContextWithMTLDevice:options:
internalGLContextWithOptions:
_initWithInternalRepresentation:
initWithCGContext:options:
initWithEAGLContext:
initWithEAGLContext:options:
internalContextWithEAGLContext:options:
initWithMTLDevice:options:
internalContextWithMTLCommandQueue:options:
contextWithMTLCommandQueue:options:
initWithMTLCommandQueue:options:
_gpuContextCheck
_crashed_because_nonaddressable_memory_was_passed_to_render:toBitmap:rowBytes:bounds:format:colorSpace:
lock
unlock
render:toCVPixelBuffer:bounds:colorSpace:
initWithPixelBuffer:
setColorSpace:
setAlphaMode:
setClamped:
startTaskToRender:fromRect:toDestination:atPoint:error:
waitUntilCompletedAndReturnError:
_isGLBackedContext
_isCGBackedContext
createCGImage:fromRect:format:colorSpace:
createCGImage:fromRect:
render:toTexture:target:bounds:colorSpace:
initWithGLTexture:target:width:height:
setFlipped:
textureType
initWithMTLTexture:commandBuffer:
iosurface
render:toIOSurface:bounds:colorSpace:
initWithIOSurface:
workingColorSpace
regionOfInterestForImage:inRect:
_isMetalInternalContext
stringByAppendingFormat:
createColorCubeDataForFilters:dimension:colorSpace:
clearArchives
purgeArchive:
contextWithCGContext:options:
contextWithEAGLContext:
contextWithEAGLContext:options:
contextWithMTLDevice:
contextWithMTLDevice:options:
contextWithMTLCommandQueue:
clientCommandQueue
identifier
abort
invalidate
_isGLInternalContext
_insertEventMarker:
render:
drawImage:atPoint:fromRect:
render:toTexture:bounds:colorSpace:
render:toMTLTexture:commandBuffer:bounds:colorSpace:
createCGLayerWithSize:info:
maximumInputImageSize
maximumOutputImageSize
inputImageMaximumSize
outputImageMaximumSize
workingFormat
reclaimResources
clearCaches
flatten:fromRect:format:colorSpace:
measureRequirementsOf:query::results:
setCTM:
setBounds:
createColorCubeDataForFilters:dimension:
T^{CGColorSpace=},R,N
Ti,R,N
newCaptureScopeWithDevice:
name
setLabel:
setDefaultCaptureScope:
internalCLContextWithOptions:glContext:
internalCLContextWithOptions:
T^v,R
_pdfDataRepresentation
resetStatistics
peakNonVolatileSize
currentNonVolatileSize
countAllocated
Tq,R
_createCGImage:fromRect:format:colorSpace:deferred:error:
createCGImage:fromRect:format:colorSpace:deferred:error:
_createClone
createCGImage:fromRect:format:
createCGImage:fromRect:format:colorSpace:deferred:
initWithBitmapData:width:height:bytesPerRow:format:
_TIFFRepresentationOfImage:format:colorSpace:options:error:
properties
mutableCopy
_PNGRepresentationOfImage:format:colorSpace:options:error:
_JPEGRepresentationOfImage:colorSpace:options:error:
_HEIFRepresentationOfImage:format:colorSpace:options:error:
startTaskToRender:toDestination:error:
TIFFRepresentationOfImage:format:colorSpace:options:
writeToURL:options:error:
PNGRepresentationOfImage:format:colorSpace:options:
HEIFRepresentationOfImage:format:colorSpace:options:
HEIF10RepresentationOfImage:colorSpace:options:error:
JPEGRepresentationOfImage:colorSpace:options:
writeTIFFRepresentationOfImage:toURL:format:colorSpace:options:error:
writePNGRepresentationOfImage:toURL:format:colorSpace:options:error:
writeJPEGRepresentationOfImage:toURL:colorSpace:options:error:
writeHEIFRepresentationOfImage:toURL:format:colorSpace:options:error:
writeHEIF10RepresentationOfImage:toURL:colorSpace:options:error:
currentHandler
stringWithUTF8String:
handleFailureInFunction:file:lineNumber:description:
filterProcessingCount
CIImageProcessorDigestObject
lastProcessingResolution
lastExecutionTime
appendProcessingResolution:andTime:
processingResolutionsLog
executionTimesLog
lastNumberOfTilesUsed
lastModelResourceUsed
setLastModelResourceUsed:
lastInpaintingModeUsed
processingResolutions
executionTimes
_lastNumberOfTilesUsed
_lastModelResourceUsed
_lastInpaintingModeUsed
Ti,V_lastNumberOfTilesUsed
T@"NSString",&,V_lastModelResourceUsed
Ti,V_lastInpaintingModeUsed
imageWithData:
imageWithData:options:
depthBlurEffectFilterForImage:disparityImage:portraitEffectsMatte:hairSemanticSegmentation:glassesMatte:gainMap:orientation:options:
imageWithContentsOfURL:
imageWithContentsOfURL:options:
detectorOfType:context:options:
imageByApplyingTransform:highQualityDownsample:
hasLeftEyePosition
hasRightEyePosition
landmarks
hasFaceAngle
leftEyePosition
rightEyePosition
_performFaceDetection:image:orientation:filter:
depthBlurEffectFilterForImageData:options:
depthBlurEffectFilterForImageURL:options:
depthBlurEffectFilterForImage:disparityImage:portraitEffectsMatte:orientation:options:
depthBlurEffectFilterForImage:disparityImage:portraitEffectsMatte:hairSemanticSegmentation:orientation:options:
CGPointValue
imageTransformForOrientation:
containsString:
_values
inputWeights
setInputWeights:
inputBias
setInputBias:
T@"CIVector",&,N,VinputWeights
T@"NSNumber",&,N,VinputBias
inputOpacity
setInputOpacity:
T@"NSNumber",&,N,VinputOpacity
processInputModel:
modelDescription
inputDescriptionsByName
outputDescriptionsByName
allValues
processInputFeatureWithName:featureDescription:
processOutputFeatureWithName:featureDescription:
type
imageConstraint
pixelsWide
pixelsHigh
pixelFormatType
model
predictionFromFeatures:error:
outputImageFeatures
featureValueForName:
imageBufferValue
inputImageFeatures
setWithObject:
featureValueWithPixelBuffer:
featureNames
T@"NSSet",R,N
initWithModel:
predictUsingInputBuffer:error:
setModel:
setInputImageFeatures:
setOutputImageFeatures:
imageBuffer
_model
_inputImageFeatures
_outputImageFeatures
T@"MLModel",&,N,V_model
T{CIPredictionModelImageFeatures=@qqI},N,V_inputImageFeatures
T{CIPredictionModelImageFeatures=@qqI},N,V_outputImageFeatures
copyInput:toBuffer:usingFormat:
copyToOutput:fromBuffer:usingFormat:
roiForInput:arguments:outputRect:
processWithInputs:arguments:output:error:
formatForInputAtIndex:
outputFormat
setName:
setMultiArray:
featureValueWithMultiArray:
initWithName:array:
multiArray
T@"MLMultiArray",&,N,VmultiArray
T@"NSString",&,N,Vname
setBuffer:
buffer
initWithName:buffer:
T^{__CVBuffer=},N,Vbuffer
unsignedIntegerValue
multiArrayValue
inputModel
setInputModel:
inputHeadIndex
setInputHeadIndex:
inputSoftmaxNormalization
setInputSoftmaxNormalization:
T@"MLModel",&,N,VinputModel
T@"NSNumber",&,N,VinputHeadIndex
T@"NSNumber",&,N,VinputSoftmaxNormalization
initWithDataPointer:shape:dataType:strides:deallocator:error:
dataPointer
shape
strides
numberWithInteger:
applyWithExtent:inputs:arguments:error:
multiArrayConstraint
shapeConstraint
enumeratedShapes
sizeConstraint
enumeratedImageSizes
setInputRectangle:
inputRectangle
T@"CIVector",&,N,VinputRectangle
noiseImageNearest
_CICrystallize
_CIAlphaNormalize
_CITiltShift
_DistanceColored
inputPoint0
inputPoint1
inputUnsharpMaskRadius
inputUnsharpMaskIntensity
depthDataFromDictionaryRepresentation:error:
depthDataType
depthDataByConvertingToDepthDataType:
depthDataByReplacingDepthDataMapWithPixelBuffer:error:
depthDataMap
dictionaryRepresentationForAuxiliaryDataType:
cameraCalibrationData
performSelector:withObject:withObject:
intrinsicMatrix
extrinsicMatrix
pixelSize
intrinsicMatrixReferenceDimensions
lensDistortionLookupTable
inverseLensDistortionLookupTable
lensDistortionCenter
cameraCalibrationDataDictionary
mattingImage
portraitEffectsMatteFromDictionaryRepresentation:error:
semanticSegmentationMatteFromImageSourceAuxiliaryDataType:dictionaryRepresentation:error:
matteType
_CIConvolutionAdd_1
_CIConvolutionAdd_2
_CIConvolutionAdd_3
_CIConvolutionAdd_4
_CIConvolutionAdd_5
_CIConvolutionAdd_6
_CIConvolutionAdd_7
_CIConvolutionAdd_8
doConvolutionPass:weights:sums:
samplesPerPass
inputPoints
inputLinearFilterModeEnabled
inputRingAmount
inputRingSize
_recipe
inputPointCount
removeLastObject
imageBySamplingLinear
_kernelG
inputShadowRadius
setInputShadowRadius:
inputShadowDensity
setInputShadowDensity:
inputShadowOffset
setInputShadowOffset:
T@"NSNumber",&,N,VinputShadowRadius
T@"NSNumber",&,N,VinputShadowDensity
T@"CIVector",&,N,VinputShadowOffset
registerFilterUsage
deregisterFilterUsage
releaseModelIfNoLongerNeeded
computePerChannelSumsOfPixelsInImage:onArea:
shouldFaceSpecificModelBeUsed
getSelectedFacesInpaintingModelDescriptor
getSelectedGeneralInpaintingModelDescriptor
performSinglePassInpaintingWithParameters:
performTilingPipelineInpaintingWithParameters:
performMultiresolutionInpaintingWithParameters:
performFullPipelineInpaintingWithParameters:
inputMaskBoundingBoxAsValidCGRect
performSinglePassInpaintingPipelineOnImage:usingMask:boundingBox:additionalParameters:espressoResources:executionContext:
performInpaintingTilingPipelineOnImage:usingMask:boundingBox:additionalParameters:espressoResources:executionContext:
performFullInpaintingPipelineOnImage:usingMask:boundingBox:additionalParameters:espressoResources:executionContext:
getEspressoResources
getLastProcessingResolution
getLastExecutionTime
inputMaskBoundingBox
setInputMaskBoundingBox:
inputFaceBoundingBoxes
setInputFaceBoundingBoxes:
inputInpaintingProcessingResolutions
setInputInpaintingProcessingResolutions:
inputInpaintingBlendingRadius
setInputInpaintingBlendingRadius:
inputInpaintingMode
setInputInpaintingMode:
executionContext
_executionContext
T@"CIVector",&,N,VinputMaskBoundingBox
T@"NSArray",&,N,VinputFaceBoundingBoxes
T@"NSArray",&,N,VinputInpaintingProcessingResolutions
T@"NSNumber",&,N,VinputInpaintingBlendingRadius
T@"NSNumber",&,N,VinputInpaintingMode
Ti,R,GgetLastProcessingResolution
Td,R,GgetLastExecutionTime
T@"InpaintingExecutionContext",R,V_executionContext
_initialConversionRGB
applyWithExtent:shader:inputs:roiMethods:insetRects:scaleFactors:arguments:error:
_pyramidGenerateLevel
_smoothDisparity
applyWithExtent:shader:inputs:arguments:error:
_propagateDisparityR1
_propagateDisparity
initialConversionForSize:useMetal:
generatePyramidLevel:useMetal:
shiftmapLevelZeroWithSize:useMetal:
propagateDisparity:pyramids:useMetal:computedPyramidLevels:
smoothDisparityImage:useMetal:
outputImageUsingMetal:
imageWithArrayOfImages:selector:
_propagateDisparityR1Combined
_propagateDisparityCombined
_combineImages
inputDisparityImage
setInputDisparityImage:
inputPropagateKernel
setInputPropagateKernel:
inputSmoothSigma
setInputSmoothSigma:
inputPropagateMinWeightSum
setInputPropagateMinWeightSum:
inputPropagateSigmaLuma
setInputPropagateSigmaLuma:
inputPropagateSigmaChma
setInputPropagateSigmaChma:
inputOriginalSize
setInputOriginalSize:
T@"CIImage",&,VinputDisparityImage
T@"NSNumber",C,VinputPropagateKernel
T@"NSNumber",C,VinputSmoothSigma
T@"NSNumber",C,VinputPropagateMinWeightSum
T@"NSNumber",C,VinputPropagateSigmaLuma
T@"NSNumber",C,VinputPropagateSigmaChma
T@"NSNumber",C,VinputScale
T@"CIVector",C,VinputOriginalSize
fileURLWithPath:
_customBoxBlur5Kernel
outputImageMetal
inputNumIterations
setInputNumIterations:
T@"NSNumber",C,VinputNumIterations
newComputePipelineStateWithFunction:error:
localizedFailureReason
hasValidPipelines
releasePipelines
compilePipelines:
metalCommandBuffer
compilePipelinesIfNeeded:
metalTexture
outputIsOpaque
synchronizeInputs
_CIDisplaceFromImage
inputDisplacementImage
_fadeKernel
T@"NSNumber",C,N,VinputAmount
inputGreyscale
setInputGreyscale:
T@"NSNumber",C,N,VinputSaturation
T@"NSNumber",C,N,VinputGreyscale
inputLocal
setInputLocal:
T@"NSNumber",&,N,VinputLocal
newCommandQueue
commandBuffer
commit
waitUntilCompleted
bundleWithIdentifier:
setConstantValue:type:atIndex:
imageWithBitmapData:bytesPerRow:size:format:options:
newFunctionWithName:constantValues:error:
imageWithCGImage:
_CIDroste
inputInsetPoint0
inputInsetPoint1
inputStrands
inputPeriodicity
inputRotation
inputZoom
redEyeMetalKernelWithFunctionName:outputPixelFormat:error:
inputDither
setInputDither:
T@"NSNumber",&,N,VinputDither
inputFalloff
setInputFalloff:
inputAnisotropic
setInputAnisotropic:
T@"CIImage",&,N,VinputCenter
T@"NSNumber",&,N,VinputFalloff
T@"NSNumber",&,N,VinputAnisotropic
centerInImg:fromRect:toRect:offset:
canReduceOutputChannels
allowPartialOutputRegion
inputCenterLeft
setInputCenterLeft:
inputCenterRight
setInputCenterRight:
inputCenterExtentLeft
setInputCenterExtentLeft:
inputCenterExtentRight
setInputCenterExtentRight:
inputPercentileRepair
setInputPercentileRepair:
inputPercentileSpecular
setInputPercentileSpecular:
inputPercentRepair
setInputPercentRepair:
inputPercentSpecular
setInputPercentSpecular:
inputInterPeakMinRepair
setInputInterPeakMinRepair:
inputAbortMaxCenterDist
setInputAbortMaxCenterDist:
inputMinDensity
setInputMinDensity:
inputMaxRelDensity
setInputMaxRelDensity:
inputDensityRadius
setInputDensityRadius:
inputMinInterDispersion
setInputMinInterDispersion:
inputMaxInterDispersion
setInputMaxInterDispersion:
inputMinGobalLocalMeanDiff
setInputMinGobalLocalMeanDiff:
inputMinimum
setInputMinimum:
inputMaxArea
setInputMaxArea:
inputMaxAreaRatio
setInputMaxAreaRatio:
inputCenterOffsetLeft
setInputCenterOffsetLeft:
inputCenterOffsetRight
setInputCenterOffsetRight:
inputDetectionLeft
setInputDetectionLeft:
inputDetectionRight
setInputDetectionRight:
inputTuning
setInputTuning:
T@"CIImage",&,N,VinputCenterLeft
T@"CIImage",&,N,VinputCenterRight
T@"CIVector",&,N,VinputCenterExtentLeft
T@"CIVector",&,N,VinputCenterExtentRight
T@"NSNumber",&,N,VinputPercentileRepair
T@"NSNumber",&,N,VinputPercentileSpecular
T@"NSNumber",&,N,VinputPercentRepair
T@"NSNumber",&,N,VinputPercentSpecular
T@"NSNumber",&,N,VinputInterPeakMinRepair
T@"NSNumber",&,N,VinputAbortMaxCenterDist
T@"NSNumber",&,N,VinputMinDensity
T@"NSNumber",&,N,VinputMaxRelDensity
T@"NSNumber",&,N,VinputDensityRadius
T@"NSNumber",&,N,VinputMinInterDispersion
T@"NSNumber",&,N,VinputMaxInterDispersion
T@"NSNumber",&,N,VinputMinGobalLocalMeanDiff
T@"CIVector",&,N,VinputMinimum
T@"CIVector",&,N,VinputMaxArea
T@"CIVector",&,N,VinputMaxAreaRatio
T@"CIVector",&,N,VinputCenterOffsetLeft
T@"CIVector",&,N,VinputCenterOffsetRight
T@"CIImage",&,N,VinputDetectionLeft
T@"CIImage",&,N,VinputDetectionRight
T@"NSNumber",&,N,VinputTuning
inputAreaThresholdLoHi
setInputAreaThresholdLoHi:
inputSplat
setInputSplat:
T@"CIVector",&,N,VinputAreaThresholdLoHi
T@"NSNumber",&,N,VinputSplat
inputCentroid
setInputCentroid:
T@"CIImage",&,N,VinputCentroid
inputSpecularMask
setInputSpecularMask:
inputSpecularThreshold
setInputSpecularThreshold:
inputSpecIntensity
setInputSpecIntensity:
inputDebugFlag
setInputDebugFlag:
T@"CIImage",&,N,VinputSpecularMask
T@"NSNumber",&,N,VinputSpecularThreshold
T@"NSNumber",&,N,VinputSpecIntensity
T@"NSNumber",&,N,VinputDebugFlag
kernelRecovery
filterWithName:withInputParameters:
kernelRepair
inputMask
setInputMask:
inputNoiseAmount
setInputNoiseAmount:
inputRecovery
setInputRecovery:
inputWhiteCutoff
setInputWhiteCutoff:
inputChroma
setInputChroma:
T@"CIImage",&,N,VinputMask
T@"NSNumber",&,N,VinputNoiseAmount
T@"NSNumber",&,N,VinputRecovery
T@"NSNumber",&,N,VinputWhiteCutoff
T@"NSNumber",&,N,VinputChroma
_norm
inputIterations
setInputIterations:
inputDecay
setInputDecay:
inputGamma
setInputGamma:
inputLocalizationRadius
setInputLocalizationRadius:
inputDebug
setInputDebug:
inputAxisLong
setInputAxisLong:
inputAxisShort
setInputAxisShort:
inputPupilCenter
setInputPupilCenter:
inputSearchAxisLong
setInputSearchAxisLong:
inputSearchAxisShort
setInputSearchAxisShort:
T@"NSNumber",&,N,VinputIterations
T@"NSNumber",&,N,VinputDecay
T@"NSNumber",&,N,VinputGamma
T@"NSNumber",&,N,VinputLocalizationRadius
T@"NSNumber",&,N,VinputDebug
T@"CIVector",&,N,VinputAxisLong
T@"CIVector",&,N,VinputAxisShort
T@"CIVector",&,N,VinputPupilCenter
T@"NSNumber",&,N,VinputSearchAxisLong
T@"NSNumber",&,N,VinputSearchAxisShort
setObservation:
setLandmarks:
setSegmentationSkin:
setSegmentationSclera:
setSegmentationIris:
setUvLeft:
setUvRight:
setRoiRenderOriginLeft:
setRoiRenderOriginRight:
setRoiRenderSize:
setPupilLeft:
setPupilRight:
imageOrientation
setImageOrientation:
faceOrientation
setFaceOrientation:
junkiness
setJunkiness:
areaMax
setAreaMax:
observation
segmentationSkin
segmentationSclera
segmentationIris
uvLeft
uvRight
roiRenderOriginLeft
roiRenderOriginRight
roiRenderSize
pupilLeft
pupilRight
_imageOrientation
_faceOrientation
_junkiness
_areaMax
_observation
_landmarks
_segmentationSkin
_segmentationSclera
_segmentationIris
_uvLeft
_uvRight
_faceRect
_roiRenderOriginLeft
_roiRenderOriginRight
_roiRenderSize
_pupilLeft
_pupilRight
Ti,N,V_imageOrientation
Tf,N,V_faceOrientation
Tf,N,V_junkiness
Tf,N,V_areaMax
T@"VNFaceObservation",&,N,V_observation
T@"VNFaceLandmarks2D",&,N,V_landmarks
T@"CIImage",&,N,V_segmentationSkin
T@"CIImage",&,N,V_segmentationSclera
T@"CIImage",&,N,V_segmentationIris
T@"NSArray",&,N,V_uvLeft
T@"NSArray",&,N,V_uvRight
T@"CIVector",&,N,V_faceRect
T@"CIVector",&,N,V_roiRenderOriginLeft
T@"CIVector",&,N,V_roiRenderOriginRight
T@"CIVector",&,N,V_roiRenderSize
T@"CIVector",&,N,V_pupilLeft
T@"CIVector",&,N,V_pupilRight
initWithTuning:
setTuning:
cleanupState
setObservations:
setDestination:
setPrimaryImage:
setSecondaryImage:
setMetadata:
setImageProperties:
setFaces:
initWithWidth:height:pixelFormat:commandBuffer:mtlTextureProvider:
repairTuning
setValuesForKeysWithDictionary:
sessionTuning
customizeRepairFilter:forFace:
prepareRender:fromRect:toDestination:atPoint:error:
_contextRGBAh
setTuningParametersByPortType:
prepareRepair
commandQueue
primaryTexture
secondaryTexture
outputTexture
primaryImage
renderUsingPixelBuffers
renderUsingProvidedCommandQueue
validateRenderState
tuning
observations
metadata
faces
boundingBox
confidence
faceJunkinessIndex
faceOrientationIndex
faceSegments
imageByInsertingIntermediate:
kernelExecutionTime
tuningParametersByPortType
setTuningParametersByPortType:withCameraMetadata:
imageProperties
imageWithMTLTexture:options:
imageWithCVPixelBuffer:options:
dumpInputs
validateSetPrimary
dumpObservation:index:
redEyeFaceFromObservation:exifOrientation:
compare:
sortUsingComparator:
_repairPrimaryWithSecondary:to:
dumpSecondary
validateRepair
secondaryImage
setCommandBuffer:
repairFace:filter:
archivedDataWithRootObject:requiringSecureCoding:error:
prewarm
prepareRepairWithTuningParametersByPortType:
setPrimary:observations:metadata:
repairPrimaryWithSecondary:
setCommandQueue:
setPrimaryTexture:
setSecondaryTexture:
setOutputTexture:
_primary
_secondary
_output
T@"NSArray",&,N,Vobservations
T@"CIRenderDestination",&,N,Vdestination
T@"CIImage",&,N,VprimaryImage
T@"CIImage",&,N,VsecondaryImage
T@"NSDictionary",&,N,Vmetadata
T@"NSDictionary",&,N,VimageProperties
T@"NSArray",&,N,Vfaces
T@"CIDualRedEyeRepairTuning",&,N,Vtuning
T@"NSDate",&,N,Vtimestamp
T@"NSDictionary",&,N,VtuningParametersByPortType
T@"<MTLCommandBuffer>",&,N,VcommandBuffer
T@"<MTLCommandQueue>",&,N,VcommandQueue
T@"<MTLTexture>",&,N,VprimaryTexture
T@"<MTLTexture>",&,N,VsecondaryTexture
T@"<MTLTexture>",&,N,VoutputTexture
inputIrisMask
inputScleraMask
inputSkinMask
irisProtectionMaskWithThresholdIris:thresholdSclera:thresholdSkin:
skinProtectionMaskWithThreshold:
imageBySettingAlphaOneInExtent:
_imageByRenderingToIntermediate
inputPrimary
setInputPrimary:
inputSecondary
setInputSecondary:
inputSize
setInputSize:
inputOriginLeft
setInputOriginLeft:
inputOriginRight
setInputOriginRight:
inputAxisShortLeft
setInputAxisShortLeft:
inputAxisShortRight
setInputAxisShortRight:
inputAxisLongLeft
setInputAxisLongLeft:
inputAxisLongRight
setInputAxisLongRight:
inputPupilCenterLeft
setInputPupilCenterLeft:
inputPupilCenterRight
setInputPupilCenterRight:
inputOrientationHint
setInputOrientationHint:
inputOrientationScale
setInputOrientationScale:
inputRepairSource
setInputRepairSource:
inputRepairDarken
setInputRepairDarken:
inputRepairChroma
setInputRepairChroma:
inputCutoff
setInputCutoff:
inputSpecMin
setInputSpecMin:
inputSpecMax
setInputSpecMax:
inputSpecular
setInputSpecular:
inputShowMask
setInputShowMask:
inputRepairPercent
setInputRepairPercent:
inputInterPeakMin
setInputInterPeakMin:
inputRepairPercentile
setInputRepairPercentile:
inputClipMin
setInputClipMin:
inputMidSpectrumWhiteOffsetsX
setInputMidSpectrumWhiteOffsetsX:
inputMidSpectrumWhiteOffsetsY
setInputMidSpectrumWhiteOffsetsY:
inputClosingErosion
setInputClosingErosion:
inputClosingDilation
setInputClosingDilation:
inputFlooding
setInputFlooding:
inputFeathering
setInputFeathering:
inputFSmooth
setInputFSmooth:
inputRepairDither
setInputRepairDither:
inputRecover
setInputRecover:
inputSpecArea
setInputSpecArea:
inputSpecAreaScale
setInputSpecAreaScale:
inputSpecularCutoff
setInputSpecularCutoff:
inputAbortDensityLo
setInputAbortDensityLo:
inputAbortDensityDiff
setInputAbortDensityDiff:
inputCircularity
setInputCircularity:
inputIntersect
setInputIntersect:
inputSkinThreshold
setInputSkinThreshold:
inputSkinThresholdMed
setInputSkinThresholdMed:
inputScleraThreshold
setInputScleraThreshold:
inputCenterSpecRad
setInputCenterSpecRad:
inputFalloffDensity
setInputFalloffDensity:
inputFalloffRepair
setInputFalloffRepair:
inputFalloffSpecular
setInputFalloffSpecular:
inputRadiusRepair
setInputRadiusRepair:
inputRadiusDensity
setInputRadiusDensity:
inputRadiusSpecular
setInputRadiusSpecular:
inputCentroidIterations
setInputCentroidIterations:
inputCentroidGamma
setInputCentroidGamma:
inputCentroidRadius
setInputCentroidRadius:
inputCentroidRadiusSmall
setInputCentroidRadiusSmall:
inputSearchLong
setInputSearchLong:
inputSearchShort
setInputSearchShort:
inputParam
setInputParam:
inputParam2
setInputParam2:
inputParam3
setInputParam3:
inputParam4
setInputParam4:
inputRefilterSpace
setInputRefilterSpace:
inputRefilterRange
setInputRefilterRange:
inputDetectWhite
setInputDetectWhite:
inputDetectRed
setInputDetectRed:
inputMinMaskDiff
setInputMinMaskDiff:
inputGlintThreshold
setInputGlintThreshold:
inputTargetClosing
setInputTargetClosing:
inputUseFaceSegmentationMask
setInputUseFaceSegmentationMask:
inputDetectionThresholdIrisSmall
setInputDetectionThresholdIrisSmall:
inputDetectionThresholdScleraSmall
setInputDetectionThresholdScleraSmall:
inputDetectionThresholdSkinSmall
setInputDetectionThresholdSkinSmall:
inputScleraProtectionThresholdIrisSmall
setInputScleraProtectionThresholdIrisSmall:
inputScleraProtectionThresholdScleraSmall
setInputScleraProtectionThresholdScleraSmall:
inputScleraProtectionThresholdSkinSmall
setInputScleraProtectionThresholdSkinSmall:
inputSkinProtectionThresholdSmall
setInputSkinProtectionThresholdSmall:
inputDetectionThresholdIrisMedium
setInputDetectionThresholdIrisMedium:
inputDetectionThresholdScleraMedium
setInputDetectionThresholdScleraMedium:
inputDetectionThresholdSkinMedium
setInputDetectionThresholdSkinMedium:
inputScleraProtectionThresholdIrisMedium
setInputScleraProtectionThresholdIrisMedium:
inputScleraProtectionThresholdScleraMedium
setInputScleraProtectionThresholdScleraMedium:
inputScleraProtectionThresholdSkinMedium
setInputScleraProtectionThresholdSkinMedium:
inputSkinProtectionThresholdMedium
setInputSkinProtectionThresholdMedium:
inputDetectionThresholdIrisLarge
setInputDetectionThresholdIrisLarge:
inputDetectionThresholdScleraLarge
setInputDetectionThresholdScleraLarge:
inputDetectionThresholdSkinLarge
setInputDetectionThresholdSkinLarge:
inputScleraProtectionThresholdIrisLarge
setInputScleraProtectionThresholdIrisLarge:
inputScleraProtectionThresholdScleraLarge
setInputScleraProtectionThresholdScleraLarge:
inputScleraProtectionThresholdSkinLarge
setInputScleraProtectionThresholdSkinLarge:
inputSkinProtectionThresholdLarge
setInputSkinProtectionThresholdLarge:
setInputIrisMask:
setInputScleraMask:
setInputSkinMask:
T@"CIImage",&,N,VinputPrimary
T@"CIImage",&,N,VinputSecondary
T@"CIVector",&,N,VinputSize
T@"CIVector",&,N,VinputOriginLeft
T@"CIVector",&,N,VinputOriginRight
T@"CIVector",&,N,VinputAxisShortLeft
T@"CIVector",&,N,VinputAxisShortRight
T@"CIVector",&,N,VinputAxisLongLeft
T@"CIVector",&,N,VinputAxisLongRight
T@"CIVector",&,N,VinputPupilCenterLeft
T@"CIVector",&,N,VinputPupilCenterRight
T@"NSNumber",&,N,VinputRepairSource
T@"NSNumber",&,N,VinputRepairDarken
T@"NSNumber",&,N,VinputRepairChroma
T@"NSNumber",&,N,VinputCutoff
T@"NSNumber",&,N,VinputSpecMin
T@"NSNumber",&,N,VinputSpecMax
T@"NSNumber",&,N,VinputOrientationHint
T@"NSNumber",&,N,VinputOrientationScale
T@"NSNumber",&,N,VinputSpecular
T@"NSNumber",&,N,VinputShowMask
T@"NSNumber",&,N,VinputRepairPercent
T@"NSNumber",&,N,VinputInterPeakMin
T@"NSNumber",&,N,VinputRepairPercentile
T@"NSNumber",&,N,VinputClipMin
T@"NSNumber",&,N,VinputMidSpectrumWhiteOffsetsX
T@"NSNumber",&,N,VinputMidSpectrumWhiteOffsetsY
T@"NSNumber",&,N,VinputClosingErosion
T@"NSNumber",&,N,VinputClosingDilation
T@"NSNumber",&,N,VinputFlooding
T@"NSNumber",&,N,VinputFeathering
T@"NSNumber",&,N,VinputFSmooth
T@"NSNumber",&,N,VinputRepairDither
T@"NSNumber",&,N,VinputRecover
T@"NSNumber",&,N,VinputSpecArea
T@"NSNumber",&,N,VinputSpecAreaScale
T@"NSNumber",&,N,VinputSpecularCutoff
T@"NSNumber",&,N,VinputAbortDensityLo
T@"NSNumber",&,N,VinputAbortDensityDiff
T@"NSNumber",&,N,VinputCircularity
T@"NSNumber",&,N,VinputIntersect
T@"NSNumber",&,N,VinputSkinThreshold
T@"NSNumber",&,N,VinputSkinThresholdMed
T@"NSNumber",&,N,VinputScleraThreshold
T@"NSNumber",&,N,VinputFalloffDensity
T@"NSNumber",&,N,VinputFalloffRepair
T@"NSNumber",&,N,VinputFalloffSpecular
T@"NSNumber",&,N,VinputRadiusRepair
T@"NSNumber",&,N,VinputRadiusDensity
T@"NSNumber",&,N,VinputRadiusSpecular
T@"NSNumber",&,N,VinputCenterSpecRad
T@"NSNumber",&,N,VinputParam
T@"NSNumber",&,N,VinputParam2
T@"NSNumber",&,N,VinputParam3
T@"NSNumber",&,N,VinputParam4
T@"NSNumber",&,N,VinputCentroidIterations
T@"NSNumber",&,N,VinputCentroidGamma
T@"NSNumber",&,N,VinputCentroidRadius
T@"NSNumber",&,N,VinputCentroidRadiusSmall
T@"NSNumber",&,N,VinputSearchLong
T@"NSNumber",&,N,VinputSearchShort
T@"NSNumber",&,N,VinputRefilterSpace
T@"NSNumber",&,N,VinputRefilterRange
T@"NSNumber",&,N,VinputDetectWhite
T@"NSNumber",&,N,VinputDetectRed
T@"NSNumber",&,N,VinputMinMaskDiff
T@"NSNumber",&,N,VinputGlintThreshold
T@"NSNumber",&,N,VinputTargetClosing
T@"NSNumber",&,N,VinputUseFaceSegmentationMask
T@"NSNumber",&,N,VinputDetectionThresholdIrisSmall
T@"NSNumber",&,N,VinputDetectionThresholdScleraSmall
T@"NSNumber",&,N,VinputDetectionThresholdSkinSmall
T@"NSNumber",&,N,VinputScleraProtectionThresholdIrisSmall
T@"NSNumber",&,N,VinputScleraProtectionThresholdScleraSmall
T@"NSNumber",&,N,VinputScleraProtectionThresholdSkinSmall
T@"NSNumber",&,N,VinputSkinProtectionThresholdSmall
T@"NSNumber",&,N,VinputDetectionThresholdIrisMedium
T@"NSNumber",&,N,VinputDetectionThresholdScleraMedium
T@"NSNumber",&,N,VinputDetectionThresholdSkinMedium
T@"NSNumber",&,N,VinputScleraProtectionThresholdIrisMedium
T@"NSNumber",&,N,VinputScleraProtectionThresholdScleraMedium
T@"NSNumber",&,N,VinputScleraProtectionThresholdSkinMedium
T@"NSNumber",&,N,VinputSkinProtectionThresholdMedium
T@"NSNumber",&,N,VinputDetectionThresholdIrisLarge
T@"NSNumber",&,N,VinputDetectionThresholdScleraLarge
T@"NSNumber",&,N,VinputDetectionThresholdSkinLarge
T@"NSNumber",&,N,VinputScleraProtectionThresholdIrisLarge
T@"NSNumber",&,N,VinputScleraProtectionThresholdScleraLarge
T@"NSNumber",&,N,VinputScleraProtectionThresholdSkinLarge
T@"NSNumber",&,N,VinputSkinProtectionThresholdLarge
T@"CIImage",&,N,VinputIrisMask
T@"CIImage",&,N,VinputScleraMask
T@"CIImage",&,N,VinputSkinMask
repairParametersForTuning:
setRepairTuning:
sessionParametersForTuning:
setSessionTuning:
tuningFromCameraModel:portType:
updateWithCaptureSetup:portType:
defaultRepairParameters
defaultSessionParameters
T@"NSDictionary",&,N,VrepairTuning
T@"NSDictionary",&,N,VsessionTuning
substringToIndex:
uppercaseString
substringFromIndex:
_dot:
_orthonormalizeTo:
requestRevision
leftPupil
rightPupil
stringByAppendingString:
appendBytes:length:
_kernelGuideMono
_kernelGuideCombine
_kernelJointUpsamp
_kernelJointUpsampRG
_kernelGuideCombine4
inputSmallImage
setInputSmallImage:
inputSpatialSigma
setInputSpatialSigma:
inputLumaSigma
setInputLumaSigma:
T@"CIImage",&,N,VinputSmallImage
T@"NSNumber",&,N,VinputSpatialSigma
T@"NSNumber",&,N,VinputLumaSigma
_CIEdgeWork
_CIEdgeWorkContrast
_CIEdges
inputEV
setInputEV:
T@"NSNumber",&,N,VinputEV
setInputOrigI:
setInputOrigQ:
inputOrigI
inputOrigQ
T@"NSNumber",&,N,VinputOrigI
T@"NSNumber",&,N,VinputOrigQ
inputParameterImage
setInputParameterImage:
inputFacesCenterX
setInputFacesCenterX:
inputFacesCenterY
setInputFacesCenterY:
inputFacesChinX
setInputFacesChinX:
inputFacesChinY
setInputFacesChinY:
inputK0
setInputK0:
inputK1
setInputK1:
inputK2
setInputK2:
inputK3
setInputK3:
inputK4
setInputK4:
inputTuningParameters
setInputTuningParameters:
T@"CIImage",&,N,VinputParameterImage
T@"CIVector",C,N,VinputFacesCenterX
T@"CIVector",C,N,VinputFacesCenterY
T@"CIVector",C,N,VinputFacesChinX
T@"CIVector",C,N,VinputFacesChinY
T@"CIVector",C,N,VinputK0
T@"CIVector",C,N,VinputK1
T@"CIVector",C,N,VinputK2
T@"CIVector",C,N,VinputK3
T@"NSNumber",C,N,VinputK4
T@"NSDictionary",C,N,VinputTuningParameters
_isValidFace:
findMostProminentFace
_landmarksToDist:minimumDistance:maximumDistance:scalingFactor:offset:
SDOFV2MetalKernelNamed:
distanceToAdd
inputImageSize
setInputImageSize:
inputFacesLeftEyeX
setInputFacesLeftEyeX:
inputFacesLeftEyeY
setInputFacesLeftEyeY:
inputFacesRightEyeX
setInputFacesRightEyeX:
inputFacesRightEyeY
setInputFacesRightEyeY:
inputDistanceAdd
setInputDistanceAdd:
inputAdditiveMaxBlur
setInputAdditiveMaxBlur:
inputSubtractiveMaxBlur
setInputSubtractiveMaxBlur:
inputFocusRect
setInputFocusRect:
inputSubjectDistanceMinimumFocusDistance
setInputSubjectDistanceMinimumFocusDistance:
inputSubjectDistanceMaximumFocusDistance
setInputSubjectDistanceMaximumFocusDistance:
inputSubjectDistanceScalingFactor
setInputSubjectDistanceScalingFactor:
inputSubjectDistanceOffset
setInputSubjectDistanceOffset:
T@"CIVector",&,N,VinputImageSize
T@"CIVector",C,N,VinputFacesLeftEyeX
T@"CIVector",C,N,VinputFacesLeftEyeY
T@"CIVector",C,N,VinputFacesRightEyeX
T@"CIVector",C,N,VinputFacesRightEyeY
T@"NSNumber",C,N,VinputDistanceAdd
T@"NSNumber",C,N,VinputAdditiveMaxBlur
T@"NSNumber",C,N,VinputSubtractiveMaxBlur
T@"NSNumber",C,N,VinputApertureScaling
T@"NSNumber",C,N,VinputMaxBlur
T@"NSNumber",C,N,VinputSubjectDistanceMinimumFocusDistance
T@"NSNumber",C,N,VinputSubjectDistanceMaximumFocusDistance
T@"NSNumber",C,N,VinputSubjectDistanceScalingFactor
T@"NSNumber",C,N,VinputSubjectDistanceOffset
T@"CIVector",C,N,VinputFocusRect
metalKernel
outputImage_V4
inputFacesCapMultip
setInputFacesCapMultip:
inputFacesMaxBlurOnEyes
setInputFacesMaxBlurOnEyes:
inputFacesMaxBlurDistFromFocus
setInputFacesMaxBlurDistFromFocus:
inputFacesLinearBlurGrowthM
setInputFacesLinearBlurGrowthM:
inputFacesLinearBlurGrowthC
setInputFacesLinearBlurGrowthC:
inputFacesEyeToEyebrowRatio
setInputFacesEyeToEyebrowRatio:
inputFacesDistToBlurScaling
setInputFacesDistToBlurScaling:
inputFacesGainMultip
setInputFacesGainMultip:
T@"CIVector",&,N,VinputFacesLeftEyeX
T@"CIVector",&,N,VinputFacesLeftEyeY
T@"CIVector",&,N,VinputFacesCenterX
T@"CIVector",&,N,VinputFacesCenterY
T@"CIVector",&,N,VinputFacesRightEyeX
T@"CIVector",&,N,VinputFacesRightEyeY
T@"CIVector",&,N,VinputFacesChinX
T@"CIVector",&,N,VinputFacesChinY
T@"NSNumber",C,N,VinputFacesCapMultip
T@"NSNumber",C,N,VinputFacesMaxBlurOnEyes
T@"NSNumber",C,N,VinputFacesMaxBlurDistFromFocus
T@"NSNumber",C,N,VinputFacesLinearBlurGrowthM
T@"NSNumber",C,N,VinputFacesLinearBlurGrowthC
T@"NSNumber",C,N,VinputFacesEyeToEyebrowRatio
T@"NSNumber",C,N,VinputFacesDistToBlurScaling
T@"NSNumber",C,N,VinputFacesGainMultip
T@"NSDictionary",&,N,VinputTuningParameters
hasValidBuffers
releaseBuffers
allocateBuffers:
allocateBuffersIfNeeded:
addCompletedHandler:
createMaskImageOfFaceSegments:error:
imageWithCVPixelBuffer:
faceSegmentToSegmentMaskGrayLevelDictionary
numberWithUnsignedInteger:
createProbabilityImageOfFaceSegment:region:normalize:error:
imageBySettingProperties:
faceObservationWithRequestRevision:boundingBox:andAlignedBoundingBox:
setInputFaceObservations:
initWithCIImage:options:
performRequests:error:
results
inputRegion
setInputRegion:
inputOrientation
setInputOrientation:
inputFaceRect
setInputFaceRect:
T@"NSNumber",&,N,VinputRegion
T@"NSNumber",&,N,VinputOrientation
T@"CIVector",&,N,VinputFaceRect
T@"NSString",R,&
T{CGRect={CGPoint=dd}{CGSize=dd}},R
initWithDictionary:copyItems:
initWithBounds:hasLeftEyePosition:leftEyePosition:hasRightEyePosition:rightEyePosition:hasMouthPosition:mouthPosition:hasFaceAngle:faceAngle:hasTrackingID:trackingID:hasTrackingFrameCount:trackingFrameCount:hasSmile:leftEyeClosed:rightEyeClosed:landmarks:
hasMouthPosition
mouthPosition
hasTrackingID
trackingID
hasTrackingFrameCount
trackingFrameCount
hasSmile
leftEyeClosed
rightEyeClosed
T@"NSDictionary",R,Vlandmarks
T{CGRect={CGPoint=dd}{CGSize=dd}},R,Vbounds
TB,R,VhasLeftEyePosition
T{CGPoint=dd},R,VleftEyePosition
TB,R,VhasRightEyePosition
T{CGPoint=dd},R,VrightEyePosition
TB,R,VhasMouthPosition
T{CGPoint=dd},R,VmouthPosition
TB,R,VhasTrackingID
Ti,R,VtrackingID
TB,R,VhasTrackingFrameCount
Ti,R,VtrackingFrameCount
TB,R,VhasFaceAngle
Tf,R,VfaceAngle
TB,R,VhasSmile
TB,R,VleftEyeClosed
TB,R,VrightEyeClosed
initWithBounds:topLeft:topRight:bottomLeft:bottomRight:
topLeft
topRight
bottomLeft
bottomRight
T{CGPoint=dd},R,VtopLeft
T{CGPoint=dd},R,VtopRight
T{CGPoint=dd},R,VbottomLeft
T{CGPoint=dd},R,VbottomRight
numberWithUnsignedChar:
featureWithInternalRepresentation:
messageString
symbolDescriptor
T@"CIQRCodeDescriptor",R,VsymbolDescriptor
initWithBounds:topLeft:topRight:bottomLeft:bottomRight:subFeatures:messageString:
subFeatures
T@"NSString",R,VmessageString
T@"NSArray",R,VsubFeatures
inputKeys
setValue:forUndefinedKey:
valueForUndefinedKey:
classInfoForClass:
inputClasses
instanceMethodForSelector:
_crashed_when_dealloc_called_setValue_nil_forKey_probably_because_the_subclass_already_released_it:className:overridesDealloc:
outputKeys
classAttributesForClass:
classDefaultsForClass:
setWithArray:
keyPathsForValuesAffectingValueForKey:
initWithFormat:
userInfo
setWithObjects:
decodeObjectOfClasses:forKey:
containsValueForKey:
_copyFilterWithZone:
_propertyArrayFromFilters:inputImageExtent:
_filterArrayFromProperties:inputImageExtent:
ROISelector
methodForSelector:
apply:arguments:options:
serializedXMPFromFilters:inputImageExtent:
filterArrayFromSerializedXMP:inputImageExtent:error:
attributes
mutableCopyWithZone:
debugDescription
apply:
isEnabled
setEnabled:
_enabled
T@"CIImage",R,D,N
T@"NSString",C,N
enabled
TB,GisEnabled,V_enabled
T@"NSArray",R,N
T@"NSDictionary",R,N
clearCache
classCategoriesForClass:
containsObject:
componentsSeparatedByString:
hasPrefix:
vectorWithString:
substringWithRange:
_filterClassInCategory:
stringValue
rangeOfString:
isSubclassOfClass:
conformsToProtocol:
_serializedXMPString
filterWithString:
setIdentity
setUserInfo:
setOption:forKey:
_imageMetadataFromFilters:inputImageExtent:
_filterArrayFromImageMetadata:inputImageExtent:
_filterArrayFromProperties:
indexForWrapperNumber:
exchangeImplementationsForClass
intersectSet:
_prependSingleFilter:
_appendSingleFilterTo:filterAndSettings:
_prepend:
performSelector:
_append:image:
wrapClassIfNeeded:
arrayWithObjects:
outputImageCatchAll:
filterName:replacement:arguments:
wrappedOutputImage10
wrappedOutputImage11
wrappedOutputImage12
wrappedOutputImage13
wrappedOutputImage14
wrappedOutputImage15
wrappedOutputImage16
wrappedOutputImage17
wrappedOutputImage18
wrappedOutputImage19
wrappedOutputImage20
wrappedOutputImage21
wrappedOutputImage22
wrappedOutputImage23
wrappedOutputImage24
wrappedOutputImage25
wrappedOutputImage26
wrappedOutputImage27
wrappedOutputImage28
wrappedOutputImage29
wrappedOutputImage30
wrappedOutputImage31
wrappedOutputImage32
wrappedOutputImage33
wrappedOutputImage34
wrappedOutputImage35
wrappedOutputImage36
wrappedOutputImage37
wrappedOutputImage38
wrappedOutputImage39
wrappedOutputImage40
wrappedOutputImage41
wrappedOutputImage42
wrappedOutputImage43
wrappedOutputImage44
wrappedOutputImage45
wrappedOutputImage46
wrappedOutputImage47
wrappedOutputImage48
wrappedOutputImage49
wrappedOutputImage50
wrappedOutputImage51
wrappedOutputImage52
wrappedOutputImage53
wrappedOutputImage54
wrappedOutputImage55
wrappedOutputImage56
wrappedOutputImage57
wrappedOutputImage58
wrappedOutputImage59
wrappedOutputImage60
wrappedOutputImage61
wrappedOutputImage62
wrappedOutputImage63
wrappedOutputImage64
wrappedOutputImage65
wrappedOutputImage66
wrappedOutputImage67
wrappedOutputImage68
wrappedOutputImage69
wrappedOutputImage70
wrappedOutputImage71
wrappedOutputImage72
wrappedOutputImage73
wrappedOutputImage74
wrappedOutputImage75
wrappedOutputImage76
wrappedOutputImage77
wrappedOutputImage78
wrappedOutputImage79
wrappedOutputImage80
wrappedOutputImage81
wrappedOutputImage82
wrappedOutputImage83
wrappedOutputImage84
wrappedOutputImage85
wrappedOutputImage86
wrappedOutputImage87
wrappedOutputImage88
wrappedOutputImage89
wrappedOutputImage90
wrappedOutputImage91
wrappedOutputImage92
wrappedOutputImage93
wrappedOutputImage94
wrappedOutputImage95
wrappedOutputImage96
wrappedOutputImage97
wrappedOutputImage98
wrappedOutputImage99
filterName:append:arguments:
filterName:prepend:imageName:arguments:
addFilterToSkip:
filterName:replacement:
valueWithPointer:
filterWithName:setDefaults:
filterNamesInCategories:
isSubsetOfSet:
caseInsensitiveCompare:
notificationWithName:object:
defaultQueue
enqueueNotification:postingStyle:coalesceMask:forModes:
classAttributesForName:
localizedStringForKey:value:table:
filterWithName:keysAndValues:
filterNamesInCategory:
registerFilterName:constructor:classAttributes:
localizedNameForFilterName:
localizedNameForCategory:
localizedDescriptionForFilterName:
localizedReferenceDocumentationForFilterName:
compatibilityVersion
filterWithName:compatibilityVersion:
filterWithName:compatibilityVersion:keysAndValues:
allCategories:
unregisterFilterName:
URLWithString:
_attributesWithClass:
setCountLimit:
setEvictsObjectsWhenApplicationEntersBackground:
cache
initWithClass:
indexOfObject:
setObject:atIndexedSubscript:
superclass
bundlePath
stringByDeletingLastPathComponent
fileURLWithPath:isDirectory:
contentsOfDirectoryAtURL:includingPropertiesForKeys:options:error:
lastPathComponent
bundleWithURL:
objectForInfoDictionaryKey:
path
executablePath
characterAtIndex:
initWithRect:
_shapeInfinite
shapeWithRect:
initWithStruct:
transformBy:interior:
insetByX:Y:
unionWith:
unionWithRect:
intersectWith:
intersectWithRect:
CGSRegion
_geomKernel
_colorKernel
noiseImage
inputMaxStriationRadius
setInputMaxStriationRadius:
inputStriationStrength
setInputStriationStrength:
inputStriationContrast
setInputStriationContrast:
inputFadeThreshold
setInputFadeThreshold:
T@"NSNumber",&,N,VinputMaxStriationRadius
T@"NSNumber",&,N,VinputStriationStrength
T@"NSNumber",&,N,VinputStriationContrast
T@"NSNumber",&,N,VinputFadeThreshold
inputMatteImage
inputZeroShiftPercentile
inputAlphaThreshold
inputAmplitude
inputExponent
inputMinFactor
inputMaxFactor
_focalPlanePreProcessorKernelPow2
_focalPlanePreProcessorKernel
inputLensModelCalculatorImage
updateSize
textAttributesForTitle
updateBadgeSize
textAttributesForLabel
updateContentSize
size
origin
contentInsertSize
setSize:
label
T^{__CFDictionary=},R
initWithCINode:extent:
images
rois
setShape:
setColor:
setTitle:
addImage:
addRoi:
titleFrame
badgeFrame
contentCornerSize
labelFrame
imagesFrame
roisFrame
contentFrame
title
titleSize
labelSize
imagesSize
roisSize
badgeSize
contentSize
Ti,N,Vshape
Ti,N,Vcolor
T^{__CFString=},N,Vtitle
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N
T^{__CFString=},N,Vlabel
T^{__CFArray=},R,N
T{CGSize=dd},R,N
_colorForNodeColor:
_drawNodeContent:
_drawNodeBadge:
from
frame
hyperlinkEdge:from:to:
_drawCubicSpline:
_drawPolyline:
class
self
isProxy
isKindOfClass:
isMemberOfClass:
respondsToSelector:
zone
T#,R
T@"NSString",R,C
setCanvasWidth:height:
drawNode:
drawEdge:withPath:
direction
separation
drawEdgesFirst
Ti,R
T{CGSize=dd},R
setFileURL:
setFileTitle:
flushRender
setDirection:
setSeparation:
setDrawEdgesFirst:
T{CGSize=dd}
drawWithSplines
setDrawWithSplines:
TB,VdrawWithSplines
Ti,Vdirection
T{CGSize=dd},Vseparation
TB,VdrawEdgesFirst
URLByAppendingPathExtension:
pdfdata
info
data
dataConsumer
cgimage
fullURL
background
whitespaceCharacterSet
componentsSeparatedByCharactersInSet:
componentsJoinedByString:
stringByReplacingOccurrencesOfString:withString:
file
fileURL
fileTitle
inputPersonAlpha
setInputPersonAlpha:
inputHairAlpha
setInputHairAlpha:
inputFaceMaskDeltaImage
setInputFaceMaskDeltaImage:
inputSmoothstepMin
setInputSmoothstepMin:
inputSmoothstepMax
setInputSmoothstepMax:
inputRelativeApertureScalingStrength
setInputRelativeApertureScalingStrength:
inputPersonDistance
setInputPersonDistance:
inputPersonThreshold
setInputPersonThreshold:
inputPersonAdditive
setInputPersonAdditive:
inputPersonSubtractive
setInputPersonSubtractive:
inputPersonMaxBlur
setInputPersonMaxBlur:
inputHairDistance
setInputHairDistance:
inputHairThreshold
setInputHairThreshold:
inputHairAdditive
setInputHairAdditive:
inputHairSubtractive
setInputHairSubtractive:
inputHairMaxBlur
setInputHairMaxBlur:
inputProtectBodyStrength
setInputProtectBodyStrength:
inputLeftEyeX
setInputLeftEyeX:
inputLeftEyeY
setInputLeftEyeY:
inputRightEyeX
setInputRightEyeX:
inputRightEyeY
setInputRightEyeY:
inputFaceMidPointX
setInputFaceMidPointX:
inputFaceMidPointY
setInputFaceMidPointY:
inputEyeProtectionMaxFaces
setInputEyeProtectionMaxFaces:
inputEyeProtectionFaceWeightsSmoothStepMin
setInputEyeProtectionFaceWeightsSmoothStepMin:
inputEyeProtectionFaceWeightsSmoothStepMax
setInputEyeProtectionFaceWeightsSmoothStepMax:
inputEyeProtectionOvalDimsDistanceScale
setInputEyeProtectionOvalDimsDistanceScale:
inputEyeProtectionOvalDimsDistanceOffset
setInputEyeProtectionOvalDimsDistanceOffset:
inputEyeProtectionOvalDimsRadiusHorizontal
setInputEyeProtectionOvalDimsRadiusHorizontal:
inputEyeProtectionOvalDimsRadiusVertical
setInputEyeProtectionOvalDimsRadiusVertical:
inputEyeProtectionOvalFallOffSmoothStepMin
setInputEyeProtectionOvalFallOffSmoothStepMin:
inputEyeProtectionOvalFallOffSmoothStepMax
setInputEyeProtectionOvalFallOffSmoothStepMax:
inputEyeProtectionPersonMaskSmoothStepMin
setInputEyeProtectionPersonMaskSmoothStepMin:
inputEyeProtectionPersonMaskSmoothStepMax
setInputEyeProtectionPersonMaskSmoothStepMax:
inputEyeProtectionPreventStrength
setInputEyeProtectionPreventStrength:
inputEyeProtectionSubtractiveMaxBlur
setInputEyeProtectionSubtractiveMaxBlur:
inputEyeProtectionSubtractiveApertureScaling
setInputEyeProtectionSubtractiveApertureScaling:
T@"CIImage",&,VinputPersonAlpha
T@"CIImage",&,VinputHairAlpha
T@"CIImage",&,VinputFaceMaskDeltaImage
T@"NSNumber",&,VinputScale
T@"NSNumber",&,VinputDistanceAdd
T@"NSNumber",&,VinputRelativeApertureScalingStrength
T@"NSNumber",&,VinputSmoothstepMin
T@"NSNumber",&,VinputSmoothstepMax
T@"NSNumber",&,VinputPersonDistance
T@"NSNumber",&,VinputPersonThreshold
T@"CIVector",&,VinputPersonAdditive
T@"CIVector",&,VinputPersonSubtractive
T@"NSNumber",&,VinputPersonMaxBlur
T@"NSNumber",&,VinputHairDistance
T@"NSNumber",&,VinputHairThreshold
T@"CIVector",&,VinputHairAdditive
T@"CIVector",&,VinputHairSubtractive
T@"NSNumber",&,VinputHairMaxBlur
T@"NSNumber",&,VinputProtectBodyStrength
T@"CIVector",&,VinputLeftEyeX
T@"CIVector",&,VinputLeftEyeY
T@"CIVector",&,VinputRightEyeX
T@"CIVector",&,VinputRightEyeY
T@"CIVector",&,VinputFaceMidPointX
T@"CIVector",&,VinputFaceMidPointY
T@"NSNumber",&,VinputEyeProtectionMaxFaces
T@"NSNumber",&,VinputEyeProtectionFaceWeightsSmoothStepMin
T@"NSNumber",&,VinputEyeProtectionFaceWeightsSmoothStepMax
T@"NSNumber",&,VinputEyeProtectionOvalDimsDistanceScale
T@"NSNumber",&,VinputEyeProtectionOvalDimsDistanceOffset
T@"NSNumber",&,VinputEyeProtectionOvalDimsRadiusHorizontal
T@"NSNumber",&,VinputEyeProtectionOvalDimsRadiusVertical
T@"NSNumber",&,VinputEyeProtectionOvalFallOffSmoothStepMin
T@"NSNumber",&,VinputEyeProtectionOvalFallOffSmoothStepMax
T@"NSNumber",&,VinputEyeProtectionPersonMaskSmoothStepMin
T@"NSNumber",&,VinputEyeProtectionPersonMaskSmoothStepMax
T@"NSNumber",&,VinputEyeProtectionPreventStrength
T@"NSNumber",&,VinputEyeProtectionSubtractiveMaxBlur
T@"NSNumber",&,VinputEyeProtectionSubtractiveApertureScaling
inputPower
setInputPower:
T@"NSNumber",&,N,VinputPower
inputSigmaX
setInputSigmaX:
inputSigmaY
setInputSigmaY:
T@"NSNumber",&,N,VinputSigmaX
T@"NSNumber",&,N,VinputSigmaY
newComputePipelineStateWithFunction:options:reflection:error:
arguments
index
access
skipFormatChecks
applyWithExtent:shader:inputs:insetRects:arguments:error:
applyWithExtent:shader:inputs:scaleFactors:arguments:error:
applyWithExtent:shader:inputs:className:arguments:error:
inputTexture
setInputTexture:
T@"CIImage",&,N,VinputTexture
inputRadius0
setInputRadius0:
inputRadius1
setInputRadius1:
T@"NSNumber",&,N,VinputRadius0
T@"NSNumber",&,N,VinputRadius1
setInputPoint0:
setInputPoint1:
T@"CIVector",&,N,VinputPoint0
T@"CIVector",&,N,VinputPoint1
_kernelD
inputValue
setInputValue:
T@"NSNumber",&,N,VinputValue
addNode:
addEdgeFrom:to:
samplerWithImage:options:
_fullFloatBoxFilter
_multiplyImagesKernel
_boxFilter:fullFloat:
_swizzleImageXXX1:
_swizzleImageYYZ1:
_swizzleImageYZZ1:
multiplyImages:imageB:
subtract:minus:
_computeABKernel
_downsampledColorImage:
_combineRGB_and_A
computeAB:
_upsampleImage:targetImageSize:
_finalResult
inputGuideImage
setInputGuideImage:
inputEpsilon
setInputEpsilon:
T@"CIImage",&,VinputGuideImage
T@"NSNumber",C,VinputRadius
T@"NSNumber",C,VinputEpsilon
_CIResetalpha
_kernelSnoB_v0
_kernelSHnoB_v0
_kernelSH_v0
_kernelSHnoB_v1
_kernelSH_v1
_kernelSHnoB_v2
_kernelSH_v2
setInputShadowAmount:
setInputHighlightAmount:
inputShadowAmount
inputHighlightAmount
T@"NSNumber",&,N,VinputShadowAmount
T@"NSNumber",&,N,VinputHighlightAmount
inputHeight
setInputHeight:
inputHighLimit
setInputHighLimit:
inputLowLimit
setInputLowLimit:
T@"NSNumber",&,N,VinputHeight
T@"NSNumber",&,N,VinputHighLimit
T@"NSNumber",&,N,VinputLowLimit
computeDOD
initWithBlock:
_block
initWithColor:
unsignedIntValue
imageWithIOSurface:options:
initWithIOSurface:options:
_initWithIOSurface:options:owner:
removeObjectsForKeys:
CGImage
imageWithCGImage:options:
initWithCGImage:options:
initWithCGImageSource:index:options:
_initNaiveWithCGImage:options:
_setOriginalCGImage:options:
initWithCVPixelBuffer:options:
unsignedLongValue
_pixelBufferFromAuxProps:
initAuxiliaryWithImageSource:options:depth:
initMatteWithImageSource:options:
valueForKeyPath:
imageWithCGLayer:options:
initWithCGLayer:options:
initWithBitmapData:bytesPerRow:size:format:options:
initWithBitmapData:bytesPerRow:size:format:colorSpace:
_initWithBitmapData:bytesPerRow:size:format:options:
initWithBytesNoCopy:length:deallocator:
initWithTexture:size:flipped:colorSpace:
initWithTexture:size:options:
initWithTexture:size:flipped:options:
initWithMTLTexture:options:
usage
_initWithCVImageBuffer:options:
_setOriginalCVPixelBuffer:options:
imageWithCVImageBuffer:options:
initWithCVImageBuffer:options:
initWithEmptyClearColor
imageTransformForCGOrientation:
initWithData:options:
initWithContentsOfURL:options:
imageWithContentsOfFile:options:
initWithContentsOfFile:options:
baseColorSpace
imageByToneMappingColorSpaceToWorkingSpace:
initForRenderingWithMetal:orNonMetal:
initWithArrayOfImages:selector:
initForRenderingWithMPS:orNonMPS:
initForRenderingWithMetalContext:orOpenGLContextUsingMetal:orNonMetalContext:
initWithCGImage:
blackImage
whiteImage
grayImage
redImage
greenImage
blueImage
cyanImage
magentaImage
yellowImage
clearImage
nullImage
imageWithIOSurface:
imageWithCGImageSource:index:options:
imageWithCGLayer:
imageWithTexture:size:flipped:colorSpace:
imageWithTexture:size:options:
imageWithTexture:size:flipped:options:
imageWithCVImageBuffer:
noiseImagePadded
imageWithContentsOfFile:
imageForRenderingWithMetal:orNonMetal:
imageForRenderingWithMPS:orNonMPS:
imageForRenderingWithMetalContext:orOpenGLContextUsingMetal:orNonMetalContext:
T@"CIImage",R
_originalCGImage
initWithCGLayer:
_originalCVPixelBuffer
portraitEffectsMatte
semanticSegmentationMatte
initWithCVPixelBuffer:
initWithCVImageBuffer:
initWithColorR:G:B:A:
imageByApplyingOrientation:
imageByApplyingCGOrientation:
initWithData:
initWithContentsOfURL:
initWithContentsOfFile:
_imageByPremultiplying
_imageByUnpremultiplying
_imageByClampingAlpha
_imageByApplyingBlur:
_imageByMatchingWorkingSpaceToColorSpace:
imageByColorMatchingWorkingSpaceToRGBorGrayColorSpace:
_imageByMatchingColorSpaceToWorkingSpace:
imageByTaggingWithColorSpace:
imageByInsertingIntermediate
imageBySettingPropertiesNoCopy:
_imageBySamplingNearest
_imageBySamplingLinear
definition
setCacheHint:
cacheHint
writeToTIFF:
printTree
TIFFRepresentation
setValue:forKeyPath:
T@"NSDictionary",R
T@"CIFilterShape",R
T@"NSURL",R
T^{__CVBuffer=},R,N
T^{CGImage=},R,N
initWithDepthData:options:
initWithDepthData:
imageWithDepthData:options:
imageWithDepthData:
T@"AVDepthData",R,N
initWithPortaitEffectsMatte:options:
initWithPortraitEffectsMatte:options:
initWithPortaitEffectsMatte:
initWithPortraitEffectsMatte:
imageWithPortaitEffectsMatte:options:
imageWithPortaitEffectsMatte:
imageWithPortraitEffectsMatte:options:
imageWithPortraitEffectsMatte:
T@"AVPortraitEffectsMatte",R,N
initWithSemanticSegmentationMatte:options:
initWithSemanticSegmentationMatte:
imageWithSemanticSegmentationMatte:options:
imageWithSemanticSegmentationMatte:
T@"AVSemanticSegmentationMatte",R,N
initWithAttributedString:format:options:
string
appendData:
initWithAttributedString:format:
imageWithAttributedString:format:
imageWithAttributedString:format:options:
pixelFormat
swizzle
encodeInt:forKey:
decodeIntForKey:
clearImage:
setBlendKernel:
initWithExtent:format:options:
initWithExtent:format:
initWithExtent:format:colorSpace:
setImage:dirtyRect:
imageAccumulatorWithExtent:format:options:
imageAccumulatorWithExtent:format:
imageAccumulatorWithExtent:format:colorSpace:
commitUpdates:
_state
_autoRedEyeFilterWithFeatures:imageProperties:context:options:
setFaceBalanceEnabled:
setVibranceEnabled:
setCurvesEnabled:
setShadowsEnabled:
faceBalanceEnabled
setupFaceColorFromImage:usingContext:features:
drain
_scaleImageToMaxDimension:
forImage:usingContext:
setupHistogramsUsing:redIndex:greenIndex:blueIndex:
getAutoRotateFilter:ciImage:inputRect:rotateCropRect:minTiltAngle:maxTiltAngle:detectVerticalLines:thrVertAngle:thrDomAngleDiff:
getAutocropRect:rotateXfrm:inputImageRect:clipRect:
faceBalanceWarmth
faceBalanceStrength
originalFaceColor
vibranceEnabled
vibrance
curvesEnabled
curveCount
curvePointAtIndex:
shadowsEnabled
shadow
autoAdjustmentFiltersWithOptions:
autoAdjustmentFiltersWithImageProperties:options:
pointWithDictionary:name:index:transformedBy:
_dictForFeature:invOrientationTransform:extent:
supportRectangleWithFaceArray:options:
supportRectangleWithFaceArray:imageSize:
initWithExternalBuffer:subRectangle:rowBytes:options:
autoRepairWithFaceArray:
repairArray
initWithExternalBuffer:subRectangle:fullSize:rowBytes:cameraModel:
autoAdjustmentFilters
imageWithMesh:transform:
inverseImageTransformForOrientation:
autoRedEyeFilterWithFeatures:imageProperties:options:
autoRedEyeFilterWithFeatures:options:
autoRotateFilterFFT:image:inputRect:minTiltAngle:maxTiltAngle:detectVerticalLines:thrVertAngle:thrDomAngleDiff:
calcIntersection:slope1:pt2:slope2:
initWithCapacity:
initWithSurface:texture:allowSRGB:bounds:context:
surface
usesSRGBTransferFunction
_region
_surface
_usesSRGB
_context
_mtlTexture
_surfaceLocked
T{CGRect={CGPoint=dd}{CGSize=dd}},R,N,V_region
T^{__IOSurface=},R,N
TB,R,N
TQ,R,N
T@"<MTLDevice>",R,N
retainedReferences
T^v,R,N
T@"<MTLTexture>",R,N
T@"<MTLCommandBuffer>",R,N
metalCommandBufferRequested
contextID
metalContext
_cmdBuffer
Tr^v,R,N
exceptionWithName:reason:userInfo:
allowSRGBTranferFuntionOnOutput
_digestForArgs:
allowSRGBTranferFuntionOnInputAtIndex:
allowCompressedInputsAndOutputs
canOutputLossyCompressed
lengthOfBytesUsingEncoding:
imageblockMemoryLengthForDimensions:
functionHandleWithFunction:
newComputePipelineStateWithAdditionalBinaryFunctions:error:
newVisibleFunctionTableWithDescriptor:
newIntersectionFunctionTableWithDescriptor:
staticThreadgroupMemoryLength
supportIndirectCommandBuffers
T@"<MTLDevice>",R
uniqueIdentifier
initWithImageProvider:userInfo:size:format:flipped:colorSpace:
initWithImageProvider:size::format:colorSpace:options:
provideImageData:bytesPerRow:origin::size::userInfo:
_initWithImageProvider:width:height:format:colorSpace:surfaceCache:options:
imageWithImageProvider:userInfo:size:format:flipped:colorSpace:
imageWithImageProvider:size::format:colorSpace:options:
fromImage:
initFileURLWithPath:
_dumpImage:colorspace:
forImage:usingContext:colorspace:
numberWithShort:
shortValue
fromImageFile:
forImage:downscaleToMax:colorspace:usingContext:
withDictionary:
rowAtIndex:
bytesPerPixel
dumpImage:
dumpImageAsDeviceRGB:
dumpImageAsDict:
blitCommandEncoder
copyFromTexture:sourceSlice:sourceLevel:sourceOrigin:sourceSize:toTexture:destinationSlice:destinationLevel:destinationOrigin:
inputShouldDumpInputValues
writeToURL:atomically:encoding:error:
inputFilename
setInputFilename:
setInputShouldDumpInputValues:
inputOriginalFilter
setInputOriginalFilter:
T@"NSString",&,VinputFilename
T@"NSNumber",&,VinputShouldDumpInputValues
T@"CIFilter",&,VinputOriginalFilter
imageWithYCCImage:matrix:fullRange:precision:colorSpace:
imageWithYImage:CrCbImage:CrCbScale:matrix:fullRange:precision:colorSpace:
imageYCC444:matrix:fullRange:precision:colorSpace:
imageWithYCCImage:matrix:fullRange:colorSpace:
imageWithYImage:CrCbImage:CrCbScale:matrix:fullRange:colorSpace:
imageYCC444:matrix:fullRange:colorSpace:
_outputExtent
functionWithName:
functionCount
functionNames
returnType
dataType
functionType
dataTypeDescription
typeName
members
newLibraryWithImageFilterFunctionsSPI:imageFilterFunctionInfo:error:
functionConstantsDictionary
_initWithReflection:
allocForType:
_initWithString:andMetalLibrary:usingCruftCompatibility:
libraryWithData:error:
kernelsWithString:andMetalLibrary:messageLog:
kernelWithFunctionName:fromMetalLibraryData:options:error:
_initWithReflection:constants:constantTypes:
_initWithString:usingCruftCompatibility:
appendString:
longValue
_isValidOutputPixelFormat:
_outputFormatUsingDictionary:andKernel:
preservesRange
perservesAlpha
parameters
kernelsWithString:fromMetalLibraryData:
kernelsWithString:messageLog:
kernelsWithString:
kernelWithString:fromMetalLibraryData:
kernelWithFunctionName:fromMetalLibraryData:error:
kernelWithFunctionName:fromMetalLibraryData:outputPixelFormat:error:
kernelWithFunctionName:fromMetalLibraryData:outputGroupSize:error:
kernelWithFunctionName:fromMetalLibraryData:constants:error:
kernelNamesFromMetalLibraryData:
colorMatrixBiasKernel
outputGroupSize
setOutputGroupSize:
setROISelector:
TB,N
T{CGSize=dd},N
autogenerateROI:args:arguments:extent:
applyWithExtent:roiCallback:inputImage:arguments:options:
initWithString:extentType:
getBlendBehaviorBit:
setBlendBehaviorBit:value:
isBackIfForeIsClear
isForeIfBackIsClear
isClearIfForeIsClear
isClearIfBackIsClear
kernelWithString:extentType:
applyWithForeground:background:colorSpace:
characterSetWithCharactersInString:
invertedSet
stringByTrimmingCharactersInSet:
enumerateLinesUsingBlock:
CGAffineTransformValue
inputImage2
setInputImage2:
T@"CIImage",&,N,VinputImage2
outputImageNewScaleX:scaleY:
outputImageOldScaleX:scaleY:
inputAspectRatio
setInputAspectRatio:
T@"NSNumber",&,N,VinputAspectRatio
_CILozengeRefraction
inputRefraction
_CITorusRefraction
appendFormat:
writeToFile:atomically:encoding:error:
cpuParams
mtlKernel
inputMinMaxImage
setInputMinMaxImage:
inputSimulatedAperture
setInputSimulatedAperture:
inputIntrinsicMatrixFocalLength
setInputIntrinsicMatrixFocalLength:
T@"CIImage",&,VinputMinMaxImage
T@"CIVector",C,N,VinputOriginalSize
T@"NSNumber",C,N,VinputSimulatedAperture
T@"NSNumber",C,N,VinputIntrinsicMatrixFocalLength
inputLensModelParams
setInputLensModelParams:
T@"CIImage",&,N,VinputLensModelParams
setThreadgroupMemoryLength:atIndex:
_CILenticularHalo
inputHaloRadius
inputHaloWidth
inputHaloOverlap
setInputRotation:
T@"NSNumber",&,N,VinputRotation
_kernelLocalContrast
setLength:
localLightStatisticsWithProxy:
localLightStatistics
localLightStatisticsNoProxy
inputLightMap
inputLightMapWidth
inputLightMapHeight
_polyKernel
_shadowKernel
inputLightMapImage
inputLocalLight
inputSmartShadows
initWithLength:
lumaTable
_tableImage
_kernelD2
downTwo:
upCubic:scale:
_kernelCombine
inputMainImage
inputPredicateImage
inputSubsampling
inputEPS
inputErosionKernelSize
inputUseDepthFilter
inputFGThresholdValue
inputBGThresholdValue
_kernel3x3
extentOfMeshStart:count:halfWidth:
_CIMesh32
_CIMesh16
_CIMesh8
_CIMesh4
_CIMesh2
_CIMesh1
inputMesh
setInputMesh:
T@"NSArray",&,N,VinputMesh
pointerValue
processInfo
processName
supportsFamily:
maxTextureWidth2D
maxTextureHeight2D
maxComputeTextures
maxComputeSamplers
maxBufferLength
iosurfaceReadOnlyTextureAlignmentBytes
iosurfaceTextureAlignmentBytes
sharedMemorySize
dedicatedMemorySize
setStorageMode:
newTextureWithDescriptor:offset:bytesPerRow:
newTextureWithDescriptor:iosurface:plane:
setMinFilter:
setMagFilter:
setSAddressMode:
setTAddressMode:
setNormalizedCoordinates:
newSamplerStateWithDescriptor:
getBytes:bytesPerRow:fromRegion:mipmapLevel:
newBufferWithBytesNoCopy:length:options:deallocator:
setComputeFunction:
setInsertLibraries:
newComputePipelineStateWithDescriptor:options:reflection:error:
setTileFunction:
setThreadgroupSizeMatchesTileSize:
colorAttachments
setPixelFormat:
newRenderPipelineStateWithTileDescriptor:options:reflection:error:
newLibraryWithURL:error:
setBackgroundGPUPriority:
setGPUPriority:
commandBufferWithUnretainedReferences
iosurfacePlane
setSamplerState:atIndex:
addScheduledHandler:
waitUntilScheduled
renderPassDescriptor
imageblockSampleLength
setImageblockSampleLength:
setTexture:
setStoreAction:
setLoadAction:
setDefaultColorSampleCount:
setRenderTargetWidth:
setRenderTargetHeight:
renderCommandEncoderWithDescriptor:
setRenderPipelineState:
setTileTexture:atIndex:
setTileSamplerState:atIndex:
setTileBuffer:offset:atIndex:
tileWidth
tileHeight
dispatchThreadsPerTile:
copyFromBuffer:sourceOffset:toBuffer:destinationOffset:size:
status
error
GPUEndTime
GPUStartTime
setAdditionalCompilerArguments:
newLibraryWithSource:options:error:
allBundles
setBinaryArchives:
newLibraryWithDescriptorSPI:error:
functionGraphs
newDagStringWithGraphs:
userDictionary
addPerfSampleHandler:
setStatEnabled:
setStatLocations:
setStatOptions:
requestCounters:withIndex:
initWithDevice:kernelName:
encodeToCommandBuffer:sourceBuffer:sourceRowBytes:destinationTexture:
encodeToCommandBuffer:sourceBuffer:sourceRowBytes:destinationBuffer:destinationRowBytes:destinationSize:
_device
_convertToTexture
_convertToBuffer
setFilterParams:arguments:filter:
setFilterParamsAndImages:arguments:filter:
dummyImagesForImages:
_dict
set_dict:
inputFilterName
setInputFilterName:
T@"NSMutableDictionary",&,V_dict
T@"NSString",C,VinputFilterName
computeDOD:tst:off:mtx:
inputPoint
setInputPoint:
T@"CIVector",&,N,VinputPoint
inputCompression
setInputCompression:
T@"NSNumber",&,N,VinputCompression
regionOf:destRect:Offset:
T@"NSNumber",&,N,VinputWeights
_doMinimum
_blur:pass:weightsFactor:legacyExtent:
_kernelNew
_blur:pass:weightsFactor:
_CIOpTile
_CIPageCurlTransNoEmap
_CIPageCurlTransition
inputBacksideImage
inputShadingImage
_CIPageCurlWithShadowTransition
_CIPageCurlNoShadowTransition
inputShadowSize
inputShadowExtent
inputAcuteAngle
inputTopLeft
setInputTopLeft:
inputTopRight
setInputTopRight:
inputBottomRight
setInputBottomRight:
inputBottomLeft
setInputBottomLeft:
T@"CIVector",&,N,VinputTopLeft
T@"CIVector",&,N,VinputTopRight
T@"CIVector",&,N,VinputBottomRight
T@"CIVector",&,N,VinputBottomLeft
inputCrop
setInputCrop:
T@"NSNumber",&,N,VinputCrop
cubeName
dataWithContentsOfFile:
cubePath
cubeColorSpaceName
_maxVersionBG
backgroundCubeName
applyCubeWithName:toImage:
_CIPhotoEffectDepthBlend
backgroundCubePath
inputDepthMap
setInputDepthMap:
inputGrainAmount
setInputGrainAmount:
T@"CIImage",&,N,VinputDepthMap
T@"NSNumber",&,N,VinputGrainAmount
dataWithContentsOfFile:options:error:
_interpolateGrainKernel
_paddedTileKernel
_grainBlendAndMixKernel
inputISO
setInputISO:
inputSeed
setInputSeed:
T@"NSNumber",C,N,VinputISO
T@"NSNumber",C,N,VinputSeed
computeDOD:scale:
_pinchDistortionScaleLT1
_pinchDistortionScaleGE1
_CIHexagonalPixellate
_CIPointillize
_kernelH
_kernelV
inputDraftMode
getDraftMode:
performPass:reference:values:rect:
setInputDraftMode:
T@"NSDictionary",&,VinputTuningParameters
T@"NSNumber",&,N,VinputDraftMode
_kernelMetal
inputLumaNoiseAmpl
setInputLumaNoiseAmpl:
inputLumaNoiseModelCoeff
setInputLumaNoiseModelCoeff:
inputUseMetal
setInputUseMetal:
T@"NSNumber",C,N,VinputLumaNoiseAmpl
T@"NSNumber",C,N,VinputLumaNoiseModelCoeff
T@"CIVector",C,VinputExtent
T@"NSNumber",C,N,VinputUseMetal
inputHorizontalBlur
setInputHorizontalBlur:
inputAntiAliasBlurStrength
setInputAntiAliasBlurStrength:
T@"NSNumber",C,N,VinputHorizontalBlur
T@"NSNumber",C,N,VinputAntiAliasBlurStrength
_kernelWithShapesMetal
_kernelsWithShapes
_ourBlendKernelMetal
_ourBlendKernel
outputImage:
metalFilterWithName:
outputImageV2
outputImageV3
inputBlurmapImage
setInputBlurmapImage:
setInputMatteImage:
inputLumaNoiseScale
setInputLumaNoiseScale:
inputAperture
setInputAperture:
inputShape
setInputShape:
T@"CIImage",&,VinputBlurmapImage
T@"CIImage",&,VinputMatteImage
T@"NSNumber",C,N,VinputLumaNoiseScale
T@"NSNumber",C,N,VinputScale
T@"NSNumber",C,N,VinputAperture
T@"NSString",&,N,VinputShape
setConstantValue:type:withName:
functionConstantValuesTuningParameters:
compilePipelineForDevice:functionName:constantValues:
fillBuffer:range:value:
dispatchThreadgroupsWithIndirectBuffer:indirectBufferOffset:threadsPerThreadgroup:
inputBlurRadius
setInputBlurRadius:
inputMaxIntensity
setInputMaxIntensity:
inputMinIntensity
setInputMinIntensity:
T@"NSNumber",&,VinputIterations
T@"CIVector",&,VinputBlurRadius
T@"CIVector",&,VinputMaxIntensity
T@"CIVector",&,VinputMinIntensity
_kernel:withAddedNoise:
_noiseGeneratorKernel
noiseColorKernel
outputImage:horizontal:
inputMaxBlurInPixels
setInputMaxBlurInPixels:
inputAntiAliasRadius
setInputAntiAliasRadius:
inputRect
setInputRect:
inputSensorSize
setInputSensorSize:
T@"NSNumber",C,N,VinputMaxBlurInPixels
T@"NSNumber",C,N,VinputAntiAliasRadius
T@"CIVector",C,N,VinputRect
T@"CIVector",C,N,VinputSensorSize
_kernel:
outputImage:horizontal:width:
dumpImage:extent:prefixFilename:
T@"NSNumber",C,VinputApertureScaling
stepsLUTGenerator
baseVecsLUTGenerator
_useD2XRenderer
stepsLUT:
baseVecsLUT:
_lutKernel:alpha:
_kernel:alpha:
_packageParams:extent:image:haveAlpha:
T@"NSNumber",C,N,VinputDraftMode
sensorSize
effectiveScale
nonMetalKernel
nonMetalKernelYCC
_blendKernel:
inputBlurImage
setInputBlurImage:
T@"CIImage",&,VinputBlurImage
filterImplementation
imageURL
imageData
imageDataHint
auxImageWithKey:
filterWithImageURL:options:
filterWithImageData:options:
filterWithCVPixelBuffer:properties:options:
supportedRawCameraModels
initWithImageURL:
initWithImageData:identifierHint:
initWithCVPixelBuffer:properties:
supportedCameraModels
filterWithImageURL:
filterWithImageData:identifierHint:
filterWithCVPixelBuffer:properties:
T@"NSArray",R
nativeSize
isDraftModeEnabled
setDraftModeEnabled:
supportedDecoderVersions
decoderVersion
setDecoderVersion:
exposure
setExposure:
shadowBias
setShadowBias:
baselineExposure
setBaselineExposure:
boostAmount
setBoostAmount:
boostShadowAmount
setBoostShadowAmount:
isGamutMappingEnabled
setGamutMappingEnabled:
isLensCorrectionSupported
lensCorrectionEnabled
setIsEnableLensCorrection:
isLuminanceNoiseReductionSupported
luminanceNoiseReductionAmount
setLuminanceNoiseReductionAmount:
isColorNoiseReductionSupported
colorNoiseReductionAmount
setColorNoiseReductionAmount:
isSharpnessSupported
sharpnessAmount
setSharpnessAmount:
isContrastSupported
contrastAmount
setContrastAmount:
isDetailSupported
detailAmount
setDetailAmount:
isMoireReductionSupported
moireReductionAmount
setMoireReductionAmount:
isLocalToneMapSupported
localToneMapAmount
setLocalToneMapAmount:
extendedDynamicRangeAmount
setExtendedDynamicRangeAmount:
neutralChromaticity
setNeutralChromaticity:
neutralLocation
setNeutralLocation:
neutralTemperature
setNeutralTemperature:
neutralTint
setNeutralTint:
linearSpaceFilter
setLinearSpaceFilter:
previewImage
semanticSegmentationSkinMatte
semanticSegmentationHairMatte
semanticSegmentationGlassesMatte
semanticSegmentationSkyMatte
semanticSegmentationTeethMatte
setFilterImplementation:
scaleFactor
setScaleFactor:
isLensCorrectionEnabled
setLensCorrectionEnabled:
_lensCorrectionEnabled
_scaleFactor
T@"CIRAWFilterImpl",&,VfilterImplementation
T@"NSURL",R,VimageURL
T@"NSData",R,VimageData
T@"NSString",R,VimageDataHint
draftModeEnabled
TB,GisDraftModeEnabled
T@"NSString",&
Tf,V_scaleFactor
gamutMappingEnabled
TB,GisGamutMappingEnabled
lensCorrectionSupported
TB,R,GisLensCorrectionSupported
TB,GisLensCorrectionEnabled,V_lensCorrectionEnabled
luminanceNoiseReductionSupported
TB,R,GisLuminanceNoiseReductionSupported
colorNoiseReductionSupported
TB,R,GisColorNoiseReductionSupported
sharpnessSupported
TB,R,GisSharpnessSupported
contrastSupported
TB,R,GisContrastSupported
detailSupported
TB,R,GisDetailSupported
moireReductionSupported
TB,R,GisMoireReductionSupported
localToneMapSupported
TB,R,GisLocalToneMapSupported
T{CGPoint=dd}
T@"CIFilter",&
isFileURL
isReadableFileAtPath:
computeDistanceMultiplierForMask:andTileSize:
findEquidistantPointsOnMaskDiagonal:tileSize:maxDistanceBetweenPoints:diagonalityDirection:
extractTileFromImage:aroundCenterPoint:tileSize:
isMaskRelativeAreaTooLargeForTiling:maskBoundingBox:expandedMaskBoundingBox:andMaxRelativeAreaSize:
compositeImage:overImage:
scaleImage:toSize:
computeTileSize:andMaxDistanceBetweenTiles:forExpandedMaskBBox:
computeTileCentersForNarrowDiagonalMask:tileSize:maxBaseDistanceBetweenPoints:maxRelativeMaskAreaSize:
initializeBoundaryPreservingTile
expandBoundingBoxToRectangle:withSideExtraPercentage:maxExtraSidePixels:withinArea:roundUpSidesToClosestResolution:
moveOriginForImage:to:
computeTileRectForImage:aroundCenterPoint:tileSize:
performInpaintingAndBlendingOnSRGBImage:usingThresholdedMask:blendingRadius:inpaintingResourceDescriptor:espressoResources:executionContext:
multiplyImage:withMask:
blendImage:withBackgroundImage:usingMask:andGaussianBlendRadius:
isMaskSmallOrElongated:maskBoundingBox:expandedMaskBoundingBox:maxElogatedMaskEdgeSize:
isMaskNarrowDiagonal:maskBoundingBox:expandedMaskBoundingBox:maxDiagonalMaskEdgeSize:maxRelativeMaskAreaSize:
initWithImageSource:options:
initWithCVPixelBuffer:properties:options:
optionKeys
defaultInputLuminanceNoiseReductionAmount
setInputLuminanceNoiseReductionAmount:
defaultInputColorNoiseReductionAmount
setInputColorNoiseReductionAmount:
defaultInputNoiseReductionContrastAmount
setInputNoiseReductionContrastAmount:
defaultInputNoiseReductionDetailAmount
setInputNoiseReductionDetailAmount:
defaultInputNoiseReductionSharpnessAmount
setInputNoiseReductionSharpnessAmount:
defaultInputMoireAmount
setInputMoireAmount:
defaultInputEnableVendorLensCorrection
setInputEnableVendorLensCorrection:
setInputIgnoreOrientation:
setInputEnableNoiseTracking:
setInputNoiseReductionAmount:
setInputEnableSharpening:
setInputScaleFactor:
setInputBoost:
defaultBoostShadowAmount
setInputBoostShadowAmount:
defaultImageOrientation
setInputImageOrientation:
defaultDecoderVersion
setInputDecoderVersion:
defaultInputBaselineExposureAmount
setInputBaselineExposure:
defaultInputBiasAmount
defaultInputHueMagMRAmount
setInputHueMagMR:
defaultInputHueMagRYAmount
setInputHueMagRY:
defaultInputHueMagYGAmount
setInputHueMagYG:
defaultInputHueMagGCAmount
setInputHueMagGC:
defaultInputHueMagCBAmount
setInputHueMagCB:
defaultInputHueMagBMAmount
setInputHueMagBM:
setInputDisableGamutMap:
defaultNeutralTemperature
setInputNeutralTemperature:
defaultNeutralTint
setInputNeutralTint:
defaultNeutralChromaticityX
setInputNeutralChromaticityX:
defaultNeutralChromaticityY
setInputNeutralChromaticityY:
defaultInputEnableEDRMode
setInputEnableEDRMode:
defaultInputLocalToneMapAmount
setInputLocalToneMapAmount:
defaultInputReturnDemosaiced
setInputReturnDemosaiced:
arrayByAddingObject:
isRawSource
_inputImageSource
_inputImageAndProperties
_inputImage
_nativeSize
_isRawSource
_calledDealloc
_matteOption
_baseImageProperties
_rawDictionary
_rawReconstructionDefaultsDictionary
_supportedSushiModes
_supportedDecoderVersions
_filters
_typeIdentifierHint
_defaultOrientation
inputRequestedSushiMode
inputNeutralChromaticityX
inputNeutralChromaticityY
inputNeutralTemperature
inputNeutralTint
inputNeutralLocation
inputBoost
inputScaleFactor
inputIgnoreOrientation
inputImageOrientation
inputEnableSharpening
inputEnableNoiseTracking
inputEnableVendorLensCorrection
inputNoiseReductionAmount
inputLuminanceNoiseReductionAmount
inputColorNoiseReductionAmount
inputNoiseReductionSharpnessAmount
inputNoiseReductionContrastAmount
inputNoiseReductionDetailAmount
inputMoireAmount
inputDecoderVersion
inputBoostShadowAmount
inputBaselineExposure
inputDisableGamutMap
inputHueMagMR
inputHueMagRY
inputHueMagYG
inputHueMagGC
inputHueMagCB
inputHueMagBM
inputLinearSpaceFilter
inputEnableEDRMode
inputLocalToneMapAmount
inputReturnDemosaiced
matteOptionNameFromOptions:
rawReconstructionDefaultsDictionary
rawOptions
rawDictionary
whitePointArray
whitePoint
getWhitePointVectorsR:g:b:
sushiMode
invalidateFilters
rawOptionsWithSubsampling:
subsampling
transformedImageIgnoringOrientation:
filters
getScaleTransform:
getOrientationTransform:
rawMajorVersion
invalidateInputImage
setTempTintAtPoint:
applyMatrix:toCIImage:
T@"NSDictionary",R,&
T@"NSNumber",R,&
T@"NSArray",R,&
automaticallyNotifiesObserversForKey:
isEqualToValue:
isEqualToNumber:
RAWFiltersValueForKeyPath:
setInputNeutralLocation:
supportedSushiModes
setInputLinearSpaceFilter:
activeKeys
outputNativeSize
convertNeutralX:y:toTemperature:tint:
convertNeutralTemperature:tint:toX:y:
updateTemperatureAndTint
willChangeValueForKey:
didChangeValueForKey:
updateChomaticityXAndY
handleFailureInMethod:object:file:lineNumber:description:
setInputRequestedSushiMode:
apply:image:arguments:inoutSpace:
apply:image:arguments:inSpace:
inputWhitePoint
inputVersion
inputRAWDictionary
initWithContext:image:config:
compute
pitch
roll
generateDebugImage
setGenerateDebugImage:
debugImage
pitchFailureReason
yawFailureReason
config
Td,R,Vpitch
Td,R,Vyaw
Td,R,Vroll
Td,R,Vconfidence
TB,VgenerateDebugImage
T@"CIImage",R,VdebugImage
Tq,R,VpitchFailureReason
Tq,R,VyawFailureReason
setMinimumPitchCorrectionAreaCoverage:
setMinimumYawCorrectionAreaCoverage:
pitchCorrectionAreaCoverage
yawCorrectionAreaCoverage
unlimitedPitch
unlimitedYaw
unlimitedRoll
autoPerspectiveFilterWithOptions:
autoPerspectiveResultWithOptions:
releaseResources
setMinimumConfidence:
setQuadratureTolerance:
setMaximumObservations:
setMinimumSize:
setMinimumAspectRatio:
setMaximumAspectRatio:
_CIRectangle
supportRectangleWithRepair:imageSize:
inputCameraModel
setInputCameraModel:
inputCorrectionInfo
setInputCorrectionInfo:
T@"NSString",C,N,VinputCameraModel
T@"NSDictionary",C,N,VinputCorrectionInfo
T@"NSArray",C,N,VinputCorrectionInfo
executeRepair:
repairExternalBuffer
createVImageWrapperForProcessorInput:thatMatchesOutput:
initWithWidth:height:bpp:bpr:bytes:freeBytesWhenDone:
isModelInitialized
modelResourceDescriptor
initializeInpaintingModelForResourceDescriptor:error:
performInpaintingOnBGRA8VImage:usingMask:atProcessingResolution:withOutputFormat:outputImage:andModel:error:
timeIntervalSinceDate:
expandBoundingBoxToSquare:withSideExtraPercentage:maxExtraSidePixels:withinArea:roundUpSidesToClosestResolution:
selectModelProcessingResolutionBasedOnEdgeSize:amongResolutions:
descriptorIsAMembraneModel:error:
fillSmoothMembraneForSRGBImage:andMask:error:
reclampImageWith1PixBoundary:
yawAngleWithFaceDictionary:
bitmapRect:point:polygon:andDistMatrix:forEye:inFaceDictionary:settings:
faceContext:withFaceArray:index:settings:
centroidWithConvexHull:
dictionaryPointArrayWithEyeBitmapPoint:
dictionaryRectArrayWithGlobalBitmapRect:
dictionaryPointArrayWithBitmapPoint:
dictionaryRectArrayWithBitmapRect:
dictionaryPointArrayWithGlobalBitmapPoint:
globalBitmapRectWithDictionaryRectArray:
globalBitmapPointWithDictionaryPointArray:
unpackToGlobalRepairDictionary:convexHull:facts:
settingsWithOptions:
bitmapRectWithImageSubRectangle:settings:
setInspector:
printFaceArray
updateWithFaceIndex:
stringWithRER3Error:
gatherFaceStatistics:
getFaceStatistics:
repairDictionary:withEyeIndex:
getIdentifyingString:settings:
transformRepairArray:
dataWithPropertyList:format:options:error:
defaultCStringEncoding
getCString:maxLength:encoding:
propertyListWithData:options:format:error:
leftHandedTransform:ofPoint:
transformGlobalsWithTransform:
transformConvexHull:withTransform:
packGlobalRepairDictionary:withConvexHull:facts:
mutableCopyOfArray:
executeRepairWithRepairDictionary:
repairMap
repairRect
bitmapPointWithDictionaryPoint:
globalBitmapPointWithDictionaryPoint:
bitmapPointWithDictionaryPointArray:
dictionaryPointWithBitmapPoint:
dictionaryPointWithGlobalBitmapPoint:
bitmapRectWithDictionaryRectArray:
saveRepairDictionary:withConvexHull:facts:
openRepairDictionary:convexHull:facts:
repairWithSide:
inspector
fullBitmap
subRectangle
faceArray
faceBitmap
printFaceArrayLevel
ROIRect
avgLuminance
minLuminance
maxLuminance
skinval
ioffx
ioffy
erError
repairs
failureCauses
redEyeMetalLibData
redEyeMetalKernelWithFunctionName:error:
setFaceCoreDetector:
adjustedImageFromImage:orientation:inverseCTM:
createFaceCoreDataFromCIImage:width:height:
mouth
trackID
trackDuration
faceCoreDetector
_tracking
T@"FCRFaceDetector",&,VfaceCoreDetector
ctmForImageWithBounds:orientation:
_reduceCrop
offsetAndCrop
outputImageNonMPS:
_reduce2X2
_reduce1X4
_reduce4X1
_reduce4x4
_combine:
_kernelKmeans
defuse:seed:
setInputPasses:
inputMeans
setInputMeans:
T@"CIImage",&,N,VinputMeans
T@"NSNumber",C,N,VinputCount
T@"NSNumber",C,N,VinputPasses
T@"NSNumber",C,N,VinputPerceptual
_kernelWeightedCoordinate
_kernelCentroid
_kernelCenter
_kernelDisk
_kernelGaussian
inputRadialMode
setInputRadialMode:
inputMinWeight
setInputMinWeight:
T@"NSNumber",&,N,VinputRadialMode
T@"NSNumber",&,N,VinputMinWeight
_kernelDraw
inputCoordinate
setInputCoordinate:
inputInnerRadius
setInputInnerRadius:
inputOuterRadius
setInputOuterRadius:
T@"CIImage",&,N,VinputCoordinate
T@"NSNumber",C,N,VinputInnerRadius
T@"NSNumber",C,N,VinputOuterRadius
_kernelClusterMask
_croppedCenterPixelImage
_roiArea
_roiCenter
_singlePixelImage
_roiRect
setInputAcuteAngle:
T@"NSNumber",&,N,VinputAcuteAngle
_internalRenderDestination
_initWithInternalRenderDestination:width:height:format:colorspace:
_set_YCC_matrix:fullRange:deep:isFloat:
depth
isDrawable
_crashed_because_nonaddressable_memory_was_passed_to_initWithBitmapData:width:height:bytesPerRow:format:
_render:withContext:
initWithWidth:height:pixelFormat:colorSpace:pixelBufferProvider:
initWithWidth:height:pixelFormat:colorSpace:surfaceProvider:
alphaMode
isFlipped
isDithered
setDithered:
ditherDepth
isClamped
isCompressed
setCompressed:
blendKernel
blendsInDestinationColorSpace
setBlendsInDestinationColorSpace:
imageRepresentation
flipped
TB,GisFlipped
dithered
TB,GisDithered
clamped
TB,GisClamped
T^{CGColorSpace=},N
T@"CIBlendKernel",&,N
internalRepresentation
initWithCompletedTask:
renderInfoWithCompletedTask:
kernelExecutionCycles
passCount
pixelsProcessed
pixelsOverdrawn
timeForNodeID:
initWithInternalTask:
rendertaskWithInternalTask:
_startTaskToRender:toDestination:forPrepareRender:forClear:error:
startTaskToClear:error:
_CIRippleTransition
firstObject
createSaliencyImageAndReturnError:
initWithImage:
initWithImage:options:
_initWithImage:key0:vargs:
samplerWithImage:
samplerWithImage:keysAndValues:
initWithImage:keysAndValues:
opaqueShape
wrapMode
encodeDouble:forKey:
decodeDoubleForKey:
unarchivedObjectOfClass:fromData:error:
unarchivedObjectOfClasses:fromData:error:
_CIShadedmaterial_0
_CIShadedmaterial
standardizeImage
createGradientMap
normalizeGradientMap
thresholdGradientMap
extractLineSegments
clusterLineSegments
setupCostFunction
runOptimization
computeConfidence
evaluateCost:
evaluateCostXZ:
evaluateCostYZ:
.cxx_construct
invK
invT
gradMap
gradMapW
gradMapH
gradMapBmp
gradMapRb
vLines
hLines
vClusterInliers
hClusterInliers
vClusterOutliers
hClusterOutliers
vClusterInliersProxies
hClusterInliersProxies
vClusterOutliersProxies
hClusterOutliersProxies
initialSimplexVerticesXYZ
initialSimplexVerticesXZ
initialSimplexVerticesYZ
solutionType
solution
Td,R,VunlimitedPitch
Td,R,VunlimitedYaw
Td,R,VunlimitedRoll
_CINoiseReduction
inputNoiseLevel
_CIEdgesPrep
_CIFindEdges
_CIConvertRGBtoY
_CIBlur1
_CIBlur2
_CIBlur4
_CISharpenCombineEdges
inputEdgeScale
inputSkyAmount
setInputSkyAmount:
inputGrassAmount
setInputGrassAmount:
T@"NSNumber",&,N,VinputSkyAmount
T@"NSNumber",&,N,VinputGrassAmount
getNonNormalizedSettings:
createHueArray
hueArrayImage:
inputNeutralGamma
setInputNeutralGamma:
inputTone
setInputTone:
inputHue
setInputHue:
inputGrain
setInputGrain:
T@"NSNumber",C,N,VinputStrength
T@"NSNumber",C,N,VinputNeutralGamma
T@"NSNumber",C,N,VinputTone
T@"NSNumber",C,N,VinputHue
T@"NSNumber",C,N,VinputGrain
T@"NSNumber",C,N,VinputScaleFactor
smartBlackAndWhiteStatistics
smartBlackAndWhiteAdjustmentsForValue:andStatistics:
smartToneAdjustmentsForValue:andStatistics:
smartToneAdjustmentsForValue:localLightAutoValue:andStatistics:
smartColorAdjustmentsForValue:andStatistics:
smartToneStatistics
smartColorStatistics
inputUseCube
inputUseCubeColorSpace
_kernelBneg
_kernelBpos
_kernelRH
_kernelC
inputExposure
setInputExposure:
inputShadows
setInputShadows:
inputHighlights
setInputHighlights:
inputBlack
setInputBlack:
inputRawHighlights
setInputRawHighlights:
setInputLocalLight:
setInputLightMap:
setInputUseCube:
setInputUseCubeColorSpace:
_inputLightMap
_cubeData
_cubeContext
T@"NSNumber",&,N,VinputExposure
T@"NSNumber",&,N,VinputShadows
T@"NSNumber",&,N,VinputHighlights
T@"NSNumber",&,N,VinputBlack
T@"NSNumber",&,N,VinputRawHighlights
T@"NSNumber",&,N,VinputLocalLight
T@"NSData",&,N,V_inputLightMap
T@"NSNumber",&,N,VinputUseCube
T@,&,N,VinputUseCubeColorSpace
_kernelV_lt1
_kernelV_gt1
_kernelCPos
_kernelCNeg
_kernelCast
inputVibrancy
setInputVibrancy:
inputCast
setInputCast:
T@"NSNumber",&,N,VinputVibrancy
T@"NSNumber",&,N,VinputCast
compositeImageNoReclamping:overImage:
compositeImageWithReclamping:overImage:
findTile1DOffsetForCenter:maxBound:tileSize:
expandBoundingBox:toWidth:andHeight:withinArea:
expandBoundingBox:withSideExtraPercentage:maxExtraSidePixels:withinArea:
expandDimension:toOneOfTheResolutions:
dilateMaskUsingClampingAndCropping:usingRadius:
erodeMaskUsingClampingAndCropping:usingRadius:
padImage:toExtent:usingColor:
computePerChannelAvgPixelValueInImage:onArea:
initWithWidth:height:bpp:
getData
getBytesPerRow
stringByExpandingTildeInPath
getHeight
getWidth
saveCIImage:asPNGAt:
scaleImage:toShorterEdgeSize:
dilateMask:usingRadius:
padMask:toImageSize:
createBGRAVImageWrapperFromCIImage:
saveCIImage:asTIFFAt:
saveVImageWrapper:asPNGAt:
_scale
inputB
setInputB:
inputC
setInputC:
T@"NSNumber",&,N,VinputB
T@"NSNumber",&,N,VinputC
_CISpotLight
inputLightPosition
inputLightPointsAt
inputConcentration
inputCrossAngle
setInputCrossAngle:
inputCrossScale
setInputCrossScale:
inputCrossWidth
setInputCrossWidth:
inputCrossOpacity
setInputCrossOpacity:
T@"NSNumber",&,N,VinputCrossScale
T@"NSNumber",&,N,VinputCrossAngle
T@"NSNumber",&,N,VinputCrossOpacity
T@"NSNumber",&,N,VinputCrossWidth
T@"NSNumber",&,N,VinputEpsilon
computeDOD:
inputCropAmount
inputCenterStretchAmount
inputBreakpoint0
setInputBreakpoint0:
inputBreakpoint1
setInputBreakpoint1:
inputGrowAmount
setInputGrowAmount:
T@"CIVector",&,N,VinputBreakpoint0
T@"CIVector",&,N,VinputBreakpoint1
T@"CIVector",&,N,VinputGrowAmount
_kernelAlt
inputFlipYTiles
setInputFlipYTiles:
T@"NSNumber",&,N,VinputFlipYTiles
_CISunbeams
inputSunRadius
inputNeutral
setInputNeutral:
inputTargetNeutral
setInputTargetNeutral:
T@"CIVector",&,D,N
T@"CIVector",&,N,VinputTargetNeutral
bundleWithPath:
load
classNamed:
initWithDimensions:
resetOptions
setMinimumCharacterHeight:
setDetectDiacritics:
setReturnSubFeatures:
setMinimizeFalseDetections:
setRecognitionLanguage:
detectFeaturesInBuffer:withRegionOfInterest:error:
text
textDetector
corners
inputText
setInputText:
inputFontName
setInputFontName:
inputFontSize
setInputFontSize:
T@"NSString",&,N,VinputText
T@"NSString",&,N,VinputFontName
T@"NSNumber",&,N,VinputFontSize
T@"NSNumber",&,N,VinputScaleFactor
T@"NSAttributedString",&,N,VinputText
_kernel16
curveImageFromPoints:
splineCurveTable:tableSize:gamma:from:
curveImageFromPoints:linear:
setInputPoint2:
setInputPoint3:
setInputPoint4:
inputPoint2
inputPoint3
inputPoint4
_curveImage
T@"CIVector",C,N,VinputPoint0
T@"CIVector",C,N,VinputPoint1
T@"CIVector",C,N,VinputPoint2
T@"CIVector",C,N,VinputPoint3
T@"CIVector",C,N,VinputPoint4
T@"NSNumber",&,N,VinputSize
_CITriangleTile
initWithObservation:inImage:
Tf,R,Vconfidence
featuresInImage:withContext:
pose
computeYawPitchRollFromPoseMatrix:outputYaw:outputPitch:outputRoll:
faceAttributes
smilingCategory
allLabelsWithConfidences
eyesCategory
T@"CIContext",R,&,Vcontext
inputRadiusImage
setInputRadiusImage:
T@"CIImage",&,N,VinputRadiusImage
parseModelResourceDescriptor:extractMembraneInfo:inputPixelFormat:outputPixelFormat:andResourceFileName:error:
initializeModelForResourceDescriptor:resourceFileName:inputBlobNames:outputBlobNames:cpuOnlyModel:membraneModel:modelInputPixelFormat:modelOutputPixelFormat:error:
freeEspressoResources
createSingleNetworkPlanFromResourceDescriptor:resourceFileName:lowPriorityMode:cpuOnlyModel:membraneModel:modelInputPixelFormat:modelOutputPixelFormat:inputBlobNames:outputBlobNames:storeInEspressoResources:error:
tearDownEspressoContext:andPlan:
updateWithModelResourceDescriptor:modelResourceFileName:network:plan:context:inputBlobNames:outputBlobNames:membraneModel:modelInputPixelFormat:modelOutputPixelFormat:
modelResourceFileName
network
plan
modelConfigurationName
setModelConfigurationName:
inputBlobNames
outputBlobNames
filterUsageCount
modelInputPixelFormat
modelOutputPixelFormat
membraneModel
_network
_plan
_modelResourceDescriptor
_modelResourceFileName
_configurationName
_inputBlobNames
_outputBlobNames
_filterUsageCount
_modelInputPixelFormat
_modelOutputPixelFormat
_membraneModel
T{?=^vi},R,V_network
T^v,R,V_plan
T^v,R,V_context
T@"NSString",R,V_modelResourceDescriptor
T@"NSString",R,V_modelResourceFileName
T@"NSString",&,V_configurationName
T@"NSArray",R,V_inputBlobNames
T@"NSArray",R,V_outputBlobNames
TB,R,V_membraneModel
Ti,R,V_modelInputPixelFormat
Ti,R,V_modelOutputPixelFormat
Ti,R,V_filterUsageCount
selectConfigurationAndBuildPlanForNetwork:configurationName:error:
bindEspressoInputBufferForInputName:buffer:preprocessingParams:network:noAlphaPremultiply:error:
convertEspressoOutput:intoOutputImageWrapper:usingOutputPixelsRange:andOutputFormat:error:
dictionaryRepresentation
pathForEspressoNetworkModelFileWithName:error:
createEspressoContextForCPUEngine:
createEspressoContextUsingFastestDevicePresent__engineUsed:
performInpaintingOnImage:usingMask:atProcessingResolution:withModel:error:
generatePoissonMembraneOnBGRA8VTargetImage:forSourceImage:usingMaskOutline:atProcessingResolution:withOutputFormat:outputImage:andModel:error:
initWithValues:count:
initWithX:
initWithX:Y:
initWithX:Y:Z:
initWithX:Y:Z:W:
initWithCGPoint:
initWithCGRect:
initWithCGAffineTransform:
decodeRectForKey:
vectorWithCGAffineTransform:
_count
T{CGPoint=dd},R
T{CGAffineTransform=dddddd},R
T^d,R
_kernelNeg
_kernelPos
_poskernel
_negkernel
setRevision:
setDetectionLevel:
pointsInImageOfSize:
pointCount
allPoints
faceContour
innerLips
leftEyebrow
medianLine
nose
noseCrest
outerLips
rightEyebrow
rangeLimitGradientMap
computeGuides
computeTransform
minimumPitchCorrectionAreaCoverage
minimumYawCorrectionAreaCoverage
vLineCluster
hLineCluster
vGuidesValid
hGuidesValid
vGuidesAOE
hGuidesAOE
vGuide0
vGuide1
hGuide0
hGuide1
pseudoRando
Td,VminimumPitchCorrectionAreaCoverage
Td,VminimumYawCorrectionAreaCoverage
Tf,R,VpitchCorrectionAreaCoverage
Tf,R,VyawCorrectionAreaCoverage
center
setCenter:
color0
setColor0:
color1
setColor1:
radius
setRadius:
value
setValue:
softness
setSoftness:
dither
setDither:
point0
setPoint0:
point1
setPoint1:
radius0
setRadius0:
radius1
setRadius1:
sharpness
setSharpness:
intensity
setIntensity:
angle
setAngle:
grayComponentReplacement
setGrayComponentReplacement:
underColorRemoval
setUnderColorRemoval:
scale
setScale:
aspectRatio
setAspectRatio:
parameterB
setParameterB:
parameterC
setParameterC:
smallImage
setSmallImage:
spatialSigma
setSpatialSigma:
lumaSigma
setLumaSigma:
focalLength
setFocalLength:
setTopLeft:
setTopRight:
setBottomRight:
setBottomLeft:
crop
setCrop:
setPitch:
setYaw:
setRoll:
setExtent:
targetImage
setTargetImage:
bottomHeight
setBottomHeight:
numberOfFolds
setNumberOfFolds:
foldShadowAmount
setFoldShadowAmount:
time
setTime:
barOffset
setBarOffset:
opacity
setOpacity:
maskImage
setMaskImage:
shadowRadius
setShadowRadius:
shadowDensity
setShadowDensity:
shadowOffset
setShadowOffset:
maxStriationRadius
setMaxStriationRadius:
striationStrength
setStriationStrength:
striationContrast
setStriationContrast:
fadeThreshold
setFadeThreshold:
compression
setCompression:
backsideImage
setBacksideImage:
shadingImage
setShadingImage:
shadowSize
setShadowSize:
shadowAmount
setShadowAmount:
shadowExtent
setShadowExtent:
backgroundImage
setBackgroundImage:
setImage2:
minComponents
setMinComponents:
maxComponents
setMaxComponents:
setSaturation:
brightness
setBrightness:
contrast
setContrast:
RVector
setRVector:
GVector
setGVector:
BVector
setBVector:
AVector
setAVector:
biasVector
setBiasVector:
redCoefficients
setRedCoefficients:
greenCoefficients
setGreenCoefficients:
blueCoefficients
setBlueCoefficients:
alphaCoefficients
setAlphaCoefficients:
threshold
setThreshold:
setEV:
power
setPower:
neutral
setNeutral:
targetNeutral
setTargetNeutral:
point2
setPoint2:
point3
setPoint3:
point4
setPoint4:
amount
setAmount:
cubeDimension
setCubeDimension:
cubeData
setCubeData:
cube0Data
setCube0Data:
cube1Data
setCube1Data:
curvesData
setCurvesData:
curvesDomain
setCurvesDomain:
gradientImage
setGradientImage:
levels
setLevels:
image2
paletteImage
setPaletteImage:
perceptual
setPerceptual:
falloff
setFalloff:
displacementImage
setDisplacementImage:
insetPoint0
setInsetPoint0:
insetPoint1
setInsetPoint1:
strands
setStrands:
periodicity
setPeriodicity:
rotation
setRotation:
zoom
setZoom:
textureImage
setTextureImage:
refraction
setRefraction:
breakpoint0
setBreakpoint0:
breakpoint1
setBreakpoint1:
growAmount
setGrowAmount:
flipYTiles
setFlipYTiles:
cropAmount
setCropAmount:
centerStretchAmount
setCenterStretchAmount:
transform
setTransform:
acuteAngle
setAcuteAngle:
setCount:
point
setPoint:
decay
setDecay:
setText:
message
setMessage:
correctionLevel
setCorrectionLevel:
layers
setLayers:
compactStyle
setCompactStyle:
barcodeDescriptor
setBarcodeDescriptor:
quietSpace
setQuietSpace:
barcodeHeight
setBarcodeHeight:
haloRadius
setHaloRadius:
haloWidth
setHaloWidth:
haloOverlap
setHaloOverlap:
mesh
setMesh:
minWidth
setMinWidth:
maxWidth
setMaxWidth:
minHeight
setMinHeight:
maxHeight
setMaxHeight:
dataColumns
setDataColumns:
rows
setRows:
preferredAspectRatio
setPreferredAspectRatio:
compactionMode
setCompactionMode:
alwaysSpecifyCompaction
setAlwaysSpecifyCompaction:
crossScale
setCrossScale:
crossAngle
setCrossAngle:
crossOpacity
setCrossOpacity:
crossWidth
setCrossWidth:
epsilon
setEpsilon:
sunRadius
setSunRadius:
fontName
setFontName:
fontSize
setFontSize:
weights
setWeights:
bias
setBias:
headIndex
setHeadIndex:
softmaxNormalization
setSoftmaxNormalization:
unsharpMaskRadius
setUnsharpMaskRadius:
unsharpMaskIntensity
setUnsharpMaskIntensity:
highlightAmount
setHighlightAmount:
NRNoiseLevel
setNRNoiseLevel:
NRSharpness
setNRSharpness:
edgeIntensity
setEdgeIntensity:
qualityLevel
setQualityLevel:
centerColor1
setCenterColor1:
replacementColor1
setReplacementColor1:
closeness1
setCloseness1:
contrast1
setContrast1:
centerColor2
setCenterColor2:
replacementColor2
setReplacementColor2:
closeness2
setCloseness2:
contrast2
setContrast2:
centerColor3
setCenterColor3:
replacementColor3
setReplacementColor3:
closeness3
setCloseness3:
contrast3
setContrast3:
lightPosition
setLightPosition:
lightPointsAt
setLightPointsAt:
concentration
setConcentration:
ringAmount
setRingAmount:
ringSize
setRingSize:
mask
setMask:
noiseLevel
setNoiseLevel:
highLimit
setHighLimit:
lowLimit
setLowLimit:
passes
setPasses:
gaussianGradientFilter
hueSaturationValueGradientFilter
linearGradientFilter
radialGradientFilter
smoothLinearGradientFilter
sharpenLuminanceFilter
unsharpMaskFilter
circularScreenFilter
CMYKHalftone
dotScreenFilter
hatchedScreenFilter
lineScreenFilter
bicubicScaleTransformFilter
edgePreserveUpsampleFilter
keystoneCorrectionCombinedFilter
keystoneCorrectionHorizontalFilter
keystoneCorrectionVerticalFilter
lanczosScaleTransformFilter
perspectiveCorrectionFilter
perspectiveRotateFilter
perspectiveTransformFilter
perspectiveTransformWithExtentFilter
straightenFilter
accordionFoldTransitionFilter
barsSwipeTransitionFilter
copyMachineTransitionFilter
disintegrateWithMaskTransitionFilter
dissolveTransitionFilter
flashTransitionFilter
modTransitionFilter
pageCurlTransitionFilter
pageCurlWithShadowTransitionFilter
rippleTransitionFilter
swipeTransitionFilter
additionCompositingFilter
colorBlendModeFilter
colorBurnBlendModeFilter
colorDodgeBlendModeFilter
darkenBlendModeFilter
differenceBlendModeFilter
divideBlendModeFilter
exclusionBlendModeFilter
hardLightBlendModeFilter
hueBlendModeFilter
lightenBlendModeFilter
linearBurnBlendModeFilter
linearDodgeBlendModeFilter
linearLightBlendModeFilter
luminosityBlendModeFilter
maximumCompositingFilter
minimumCompositingFilter
multiplyBlendModeFilter
multiplyCompositingFilter
overlayBlendModeFilter
pinLightBlendModeFilter
saturationBlendModeFilter
screenBlendModeFilter
softLightBlendModeFilter
sourceAtopCompositingFilter
sourceInCompositingFilter
sourceOutCompositingFilter
sourceOverCompositingFilter
subtractBlendModeFilter
vividLightBlendModeFilter
colorAbsoluteDifferenceFilter
colorClampFilter
colorControlsFilter
colorMatrixFilter
colorPolynomialFilter
colorThresholdFilter
colorThresholdOtsuFilter
depthToDisparityFilter
disparityToDepthFilter
exposureAdjustFilter
gammaAdjustFilter
hueAdjustFilter
linearToSRGBToneCurveFilter
sRGBToneCurveToLinearFilter
temperatureAndTintFilter
toneCurveFilter
vibranceFilter
whitePointAdjustFilter
colorCrossPolynomialFilter
colorCubeFilter
colorCubesMixedWithMaskFilter
colorCubeWithColorSpaceFilter
colorCurvesFilter
colorInvertFilter
colorMapFilter
colorMonochromeFilter
colorPosterizeFilter
ditherFilter
documentEnhancerFilter
falseColorFilter
LabDeltaE
maskToAlphaFilter
maximumComponentFilter
minimumComponentFilter
paletteCentroidFilter
palettizeFilter
photoEffectChromeFilter
photoEffectFadeFilter
photoEffectInstantFilter
photoEffectMonoFilter
photoEffectNoirFilter
photoEffectProcessFilter
photoEffectTonalFilter
photoEffectTransferFilter
sepiaToneFilter
thermalFilter
vignetteFilter
vignetteEffectFilter
xRayFilter
bumpDistortionFilter
bumpDistortionLinearFilter
circleSplashDistortionFilter
circularWrapFilter
displacementDistortionFilter
drosteFilter
glassDistortionFilter
glassLozengeFilter
holeDistortionFilter
lightTunnelFilter
ninePartStretchedFilter
ninePartTiledFilter
pinchDistortionFilter
stretchCropFilter
torusLensDistortionFilter
twirlDistortionFilter
vortexDistortionFilter
affineClampFilter
affineTileFilter
eightfoldReflectedTileFilter
fourfoldReflectedTileFilter
fourfoldRotatedTileFilter
fourfoldTranslatedTileFilter
glideReflectedTileFilter
kaleidoscopeFilter
opTileFilter
parallelogramTileFilter
perspectiveTileFilter
sixfoldReflectedTileFilter
sixfoldRotatedTileFilter
triangleKaleidoscopeFilter
triangleTileFilter
twelvefoldReflectedTileFilter
attributedTextImageGeneratorFilter
aztecCodeGeneratorFilter
barcodeGeneratorFilter
checkerboardGeneratorFilter
code128BarcodeGeneratorFilter
lenticularHaloGeneratorFilter
meshGeneratorFilter
PDF417BarcodeGenerator
QRCodeGenerator
randomGeneratorFilter
roundedRectangleGeneratorFilter
starShineGeneratorFilter
stripesGeneratorFilter
sunbeamsGeneratorFilter
textImageGeneratorFilter
blendWithAlphaMaskFilter
blendWithBlueMaskFilter
blendWithMaskFilter
blendWithRedMaskFilter
bloomFilter
comicEffectFilter
convolution3X3Filter
convolution5X5Filter
convolution7X7Filter
convolution9HorizontalFilter
convolution9VerticalFilter
convolutionRGB3X3Filter
convolutionRGB5X5Filter
convolutionRGB7X7Filter
convolutionRGB9HorizontalFilter
convolutionRGB9VerticalFilter
coreMLModelFilter
crystallizeFilter
depthOfFieldFilter
edgesFilter
edgeWorkFilter
gaborGradientsFilter
gloomFilter
heightFieldFromMaskFilter
hexagonalPixellateFilter
highlightShadowAdjustFilter
lineOverlayFilter
mixFilter
personSegmentationFilter
pixellateFilter
pointillizeFilter
saliencyMapFilter
shadedMaterialFilter
spotColorFilter
spotLightFilter
bokehBlurFilter
boxBlurFilter
discBlurFilter
gaussianBlurFilter
maskedVariableBlurFilter
medianFilter
morphologyGradientFilter
morphologyMaximumFilter
morphologyMinimumFilter
morphologyRectangleMaximumFilter
morphologyRectangleMinimumFilter
motionBlurFilter
noiseReductionFilter
zoomBlurFilter
areaAverageFilter
areaHistogramFilter
areaMaximumFilter
areaMaximumAlphaFilter
areaMinimumFilter
areaMinimumAlphaFilter
areaMinMaxFilter
areaMinMaxRedFilter
columnAverageFilter
histogramDisplayFilter
KMeansFilter
rowAverageFilter
stringByReplacingCharactersInRange:withString:
instancesRespondToSelector:
insertString:atIndex:
replaceOccurrencesOfString:withString:options:range:
generateGeneralKernelFromWarpKernel:args:
generateMainFromWarpKernel:args:
makeGridImage:nx:ny:
metalFilterWithName:withInputParameters:
metalImageByApplyingFilter:withInputParameters:
metalImageByApplyingFilter:
dataWithContentsOfURL:
SDOFV3MetalKernelNamed:
inputLensModelImage
setInputLensModelImage:
T@"CIImage",&,VinputLensModelImage
weightsXKernel
weightsYKernel
preprocKernel
preprocKernelNoAlpha
inputAlphaImage
setInputAlphaImage:
T@"CIImage",&,VinputAlphaImage
sampleKernel
inputPreprocImage
setInputPreprocImage:
T@"CIImage",&,VinputPreprocImage
antialiasKernel
inputDisparityWeightImage
setInputDisparityWeightImage:
T@"CIImage",&,VinputDisparityWeightImage
alphaImageForMainImage:disparity:
setInputMainImage:
T@"CIImage",&,VinputMainImage
calibrationData
originalShiftMapSize
intrinsicMatrixFocalLength
inputLeftEyePosition
inputRightEyePosition
inputFaceMidPoint
inputChinPosition
upsampledShiftMap:
smoothShiftMapV2:
lensModelParams:
lensModelApply:shiftMap:
needToRunFaceMask
faceMaskParams:useNormalizedCoords:
faceMaskApply:blurMap:
refineShiftMapV3WithMainImage:shiftmap:lensModel:
faceMaskDelta:extent:parameters:distanceToAdd:
unifiedRenderingOutputImage:
blurMapV2:
blurMapV3:shiftmap:alphaImage:
blurMapV4:shiftmap:alphaImage:hairImage:
inputShiftmapImage
setInputShiftmapImage:
inputHairImage
setInputHairImage:
inputGlassesImage
setInputGlassesImage:
inputGainMap
setInputGainMap:
setInputLeftEyePosition:
setInputRightEyePosition:
setInputChinPosition:
setInputFaceMidPoint:
inputAuxDataMetadata
setInputAuxDataMetadata:
inputCalibrationData
setInputCalibrationData:
tuningParameters
simulatedAperture
T@"CIImage",&,VinputShiftmapImage
T@"CIImage",&,VinputHairImage
T@"CIImage",&,VinputGlassesImage
T@"CIImage",&,VinputGainMap
T@"CIVector",&,VinputLeftEyePosition
T@"CIVector",&,VinputRightEyePosition
T@"CIVector",&,VinputChinPosition
T@"CIVector",&,VinputFaceMidPoint
T@"CIVector",&,N,VinputFocusRect
T@"AVCameraCalibrationData",&,N,VinputCalibrationData
T@,&,N,VinputAuxDataMetadata
inputBlurMap
setInputBlurMap:
T@"CIImage",&,VinputBlurMap
getMinMaxSimulatedApertureFrom:minValue:maxValue:version:
_getFocusRect:focusRect:
prewarm:
inputLeftEyePositions
setInputLeftEyePositions:
inputRightEyePositions
setInputRightEyePositions:
inputChinPositions
setInputChinPositions:
inputNosePositions
setInputNosePositions:
T@"NSNumber",&,N,VinputAperture
T@"NSNumber",&,N,VinputLumaNoiseScale
T@"CIVector",&,VinputLeftEyePositions
T@"CIVector",&,VinputRightEyePositions
T@"CIVector",&,VinputChinPositions
T@"CIVector",&,VinputNosePositions
tuningParametersFromMetadata:
metadataFromDictionary:metadata:
replaceRenderingParameters:tuningParameters:
augmentMetadataWithRenderingPropertiesForImage:
initWithBase64EncodedString:options:
initWithDictionary:
initWithMetalQueue:
imageUsingArgs:
prewarmedFilterFromString:
base64EncodedDataWithOptions:
inputOffset
setInputOffset:
inputRange
setInputRange:
T@"CIVector",&,N,VinputOffset
T@"NSNumber",&,N,VinputRange
inputSpread
setInputSpread:
T@"NSNumber",&,N,VinputSpread
inputFill
setInputFill:
inputGlowColorInner
setInputGlowColorInner:
inputGlowColorOuter
setInputGlowColorOuter:
inputShadowColorInner
setInputShadowColorInner:
inputShadowColorOuter
setInputShadowColorOuter:
inputShadowBlurInner
setInputShadowBlurInner:
inputShadowBlurOuter
setInputShadowBlurOuter:
T@"CIImage",&,N,VinputFill
T@"CIColor",&,N,VinputGlowColorInner
T@"CIColor",&,N,VinputGlowColorOuter
T@"CIColor",&,N,VinputShadowColorInner
T@"CIColor",&,N,VinputShadowColorOuter
T@"NSNumber",&,N,VinputShadowBlurInner
T@"NSNumber",&,N,VinputShadowBlurOuter
inputSoften
setInputSoften:
inputHighlightColor
setInputHighlightColor:
inputShadowColor
setInputShadowColor:
T@"NSNumber",&,N,VinputSoften
T@"CIColor",&,N,VinputHighlightColor
T@"CIColor",&,N,VinputShadowColor
_kernelInvertMask
_kernelMultiplyByMask
bestWarmthForI:q:percentChange:
setFaceColorFromChromaI:andChromaQ:
values
rawShadow
putShadowsAnalysisInto:
downSampleHistogram:to:storeIn:
printAnalysis
setCurvePercent:
setLuminanceHistogram:
setRGBSumHistogram:
setBorderHistogram:
setSaturationHistogram:
setupFaceColor:redIndex:greenIndex:blueIndex:
setExposureValue:
setShadowsMin:max:zeroExposure:
printHistogram:downsampledTo:
printHistogramsDownsampledTo:
lumHist
rgbSumHist
satHist
borderHist
exposureValue
maxShadow
minShadow
exposureValueAtZeroShadow
curvePercent
faceInputSet
percentFaceChange
T{?=dd},R,VoriginalFaceColor
T@"CIEnhancementHistogram",R,VlumHist
T@"CIEnhancementHistogram",R,VrgbSumHist
T@"CIEnhancementHistogram",R,VsatHist
T@"CIEnhancementHistogram",R,VborderHist
histogramFromData:
initWithBounds:andImage:usingContext:
analyzeFeatures:usingContext:baseImage:
histogramFromRows:componentOffset:
setupFaceColorFromImage:usingContext:detectorOpts:
TB,VfaceBalanceEnabled
TB,VvibranceEnabled
TB,VcurvesEnabled
TB,VshadowsEnabled
histogramFromFloatData:
histogramFromDoubleData:
hist
centerX
centerY
Ti,R,Vsize
Ti,R,VcenterX
Ti,R,VcenterY
Td,R,VI
Td,R,VQ
inputThresholds
inputSubtractedImage
compressedDataUsingAlgorithm:error:
base64EncodedStringWithOptions:
decompressedDataUsingAlgorithm:error:
isEqualToDictionary:
isEqualToData:
prewarmingString
verifyPrewarmedFilter:
termShapePoints:
point:toGridRow:column:
removeThreadAtIndex:
gatherThreadInfo:
lookForPoint:onLine:nearestPoint:
forAllGridPointsNear:withinRadius:do:context:
initHull:withOrientation:
termHull:
addPoint:toHull:
trimConcaveFromHull:
trimEndPointFromHull:
trimStartPointFromHull:
isConvex:
renderHull:toBitmap:
debuggingThisFaceAndEye:
printThreadWithIndex:
newThread:
putThreadAtIndex:
printThreadsOnlyClosed:message:
forAllGridThreadsNear:withinRadius:do:context:
printConnectionHopper:message:
connectThreads:drop1:and:drop2:
computeLengthsAnglesAndDeltaAnglesForShape:
debuggingThisFaceAndEye:andThreadIndex:
newShape:
initShapePoints:withMaxPoints:
addPoint:toShapePoints:
updatedCheckpoint:withCheckpoint:checkpointIndex:angle:width:height:inChannel:threadIndex:returningEdgeWidth:
newShape:byInterpolatingBetweenCheckpoints:nc:usingVectorField:
removeRedundantPointsFromShape:closerThan:
removeSmallBumpsFromShape:center:threshold:
removeSpikesFromShape:
improvedShape:withShape:
insertPoint:andDirection:intoGrid:
closeThreadIndex:usingVectorField:
attemptClosureOfThreadIndex:
threadCentroid:
threadSignedArea:centroid:
shape:withThreadAtIndex:centroid:
slidingWindowAnalysisOfShape:into:
newSavedShape
copyShape:into:transform:height:
convexHull:ofOriented:shape:
measureHull:majorAxis:majorTo:majorDiameter:minorAxis:minorTo:minorDiameter:
color:underConvexHull:saturated:
RGBtoHSV:
insertIntoThreadHopper:index:recChannel:hue:saturation:luminance:shapeMetricTotal:xPosition:
hopperElement:isMoreScleraThanElement:
swapHopperElement:withElement:
initGradients:
initGridWithBitmap:scale:
termGradients:
edgePoint:withBitmap:center:perp:
addGradientRow:column:good:toList:
regressionWithPointIndex:
replacePointAndDirection:
nextPointIndexWithPointIndex:
linkUpPointIndex:toPointIndex:
findThreadsInGrid
boolOptionIsOn:
initEyeMarkUpsWithBitmap:
emitEyeMarkUps:pixel:rectangleAtRow:column:settings:
emitEyeMarkUps:threadsWithGrid:settings:
getIdentifyingStringEdge:settings:
saveEyeMarkUps:withName:
termEyeMarkUps:
connectThreadsInGrid
recognizeThreadsWinningThreadIndex:info:
setDebugFaceIndex:side:
newSavedGradientList
copyGradients:into:bitmap:transform:
newSavedGrid
copyGridInto:transform:height:
convexHull:ofOriented:threadIndex:
emitEyeMarkUps:convexHull:settings:
termGrid
saveBitmap:format:faceIndex:side:name:which:
condenseFourChannelRecognitionMap:intoOneChanneMap:
magnitudeMap:fromGabor:
renderEyePolygonToBitmap:
analyzeMask:usingConvexHull:producingOptimizedMask:
widenedHull:withHull:by:
renderConvexHull:distance:fieldToBitmap:
start12BitRandom:
next12BitRandom
initBitmaps
prepareTransformWithEyeIndex:
prepareBitmapsWithString:
prominenceConvexHull:facts:
termBitmaps
prepareMasksWithConvexHull:
focusStatsWithBitmap:IOD:
isBlurryWithFocusStats:
insertIntoConnectionHopper:index1:drop1:index2:drop2:score:
filterNameForChannel:
parameterNamesForChannel:
inputChannel
inputParam1
getBlockSetWithImage:into:width:height:
getDataProviderBytePtrWithImage:into:width:height:
getDataProviderCopyWithImage:into:
initWithDeskView:andFrame:
skinInit
initializeNonDebugVariables
initWithFrameExternalBuffer:
repairWithTag:
upperRepairSizeFraction:
lowerRepairSizeFraction:
upperRepairDistance:
lowerRepairSize:
upperRepairSize:
extractReusableAlignedBitmapsAroundPoint:YR:subYBitmap:subCbCrBitmap:
averageValueFromY:withinSkinMask:butOutsideAlpha:
computeTrimmedBitmaps:newY:newCbCr:IR:newTrimY:newTrimCbCr:returningYR:andCbCrR:
undoRepair:
redEyeRemovalWithPoint:alignPupilShades:matching:force:IOD:tap:
redoRepairWithTag:IOD:
upperRepairDistanceFraction:
insertIntoProminenceVettingHopper:max:outside:confidence:distance:row:column:IOD:
gatherProminencesWithC:MC:maxwindowsize:repairsize:IR:fr:intoHopper:faceIndex:left:coss:sins:bitmapName:
gatherProminencesWithC:MC:altC:altMC:maxwindowsize:repairsize:IR:fr:intoHopper:faceIndex:left:
confidenceWithIOD:repair:andProminenceDifference:
extractAndGatherProminencesWithRect:face:faceIndex:left:maxwindowsize:repairsize:returningRedHopper:whiteHopper:redChannel:redChannelMask:
repairDecisionWithFaceRecord:left:redHopper:whiteHopper:
extractAverageFaceY:contrast:faceIndex:
applyEyeRepairWithEye:left:IOD:autoPupilTonality:match:faceIndex:whiteHopper:
distanceMaskFromPolyToCb:Cr:
prepareLineFunctions
autoRepairExtractAndSearchLeft:right:data:repairSize:autoPupilTonality:faceIndex:
getFloat:d:s:
orientPointX:Y:
getInt:d:s:
getBool:d:s:
orientRectangleMinX:maxX:minY:maxY:
redEyeRemovalWithData:
supportRectangleWithPoint:imageSize:IOD:
initWithCGImage:cameraModel:
createRepairedImage
initWithExternalBuffer:size:rowBytes:
debug
setDebug:
logRepairs
setLogRepairs:
redEyeThresholdKind
setRedEyeThresholdKind:
renderAlpha
setRenderAlpha:
infillBackground
setInfillBackground:
renderSpecularShine
setRenderSpecularShine:
specularSize
setSpecularSize:
specularSoftness
setSpecularSoftness:
pupilShadeAlignment
setPupilShadeAlignment:
autoPupilTonality
setAutoPupilTonality:
forceLoValue
setForceLoValue:
loValue
setLoValue:
standardTemplate
nRepairs
lastRepairTag
redoLastRepair
executeRepairArray:
setFaceIndex:
setLeft:
ownLF
imageSourceType
blockSet
releaseMe
dataRef
nextRepairTag
lastRepairIOD
iFaceIndex
iLeft
debugRedEye
lastClickYBitmap
lastClickCbCrBitmap
lastClickBitmapMinX
lastClickBitmapMaxX
lastClickBitmapMinY
lastClickBitmapMaxY
lastClickYBitmaps
lastClickCbCrBitmaps
lastClickBitmapRects
lastSearchYBitmap
lastSearchCbCrBitmap
lastSearchBitmapMinX
lastSearchBitmapMaxX
lastSearchBitmapMinY
lastSearchBitmapMaxY
nPolyPoints
polyClosed
polyPoints
polyLines
polyPointConcave
CbCrDistanceTable
nLinears
linearCoefficients
currentContext
setCurrentContext:
sharegroup
initWithAPI:properties:
setDebugLabel:
setParameter:to:
initWithAPI:
getMacroContextPrivate
inputQualityLevel
setInputQualityLevel:
T@"NSNumber",&,N,VinputQualityLevel
presentDrawable:
contents
storageMode
setTextureType:
setDepth:
mipmapLevelCount
setMipmapLevelCount:
sampleCount
setSampleCount:
arrayLength
setArrayLength:
resourceOptions
setResourceOptions:
copyFromTexture:toTexture:
copyFromBuffer:sourceOffset:sourceBytesPerRow:sourceBytesPerImage:sourceSize:toTexture:destinationSlice:destinationLevel:destinationOrigin:
initializeMembraneModelForResolution:error:
getMembraneModelForResolution:error:
selectMembraneProcessingResolutionBasedOnImageSize:
initWithData:error:
initFunctionNames
externFunctionNames
newExternFunctionWithName:
initWithArray:
newFunctionWithName:device:
newSpecializedFunctionWithName:device:constants:
_data
_library
_extern_function_names
_stitchable_function_names
supportsDynamicLibraries
newDynamicLibraryWithURL:error:
internalLibraryWithName:device:
coreImageDylibWithDevice:
newLibraryWithData:error:
initWithWidth:height:bpp:bytes:freeBytesWhenDone:
getBytesPerPixel
vImageWrapperByCroppingWrapper:toRect:
free
initWithShapeOf:
_image
freeWhenDone
_bpp
T^{vImage_Buffer=^vQQQ},R,V_image
Ti,R,GgetWidth
Ti,R,GgetHeight
Ti,R,GgetBytesPerPixel
Ti,R,GgetBytesPerRow
T^v,R,GgetData
bindIndex
byteOffset
setByteOffset:
setDereference:
setBindIndex:
unsignedShortValue
charValue
importedLibraries
initWithName:arguments:controlDependencies:
initWithName:arguments:controlDependencies:isEarlyReturn:
initWithFunctionName:nodes:outputNode:attributes:
initWithObjects:
setFunctionGraphs:
setFunctions:
member:
T@"NSNumber",&,VinputThreshold
kernelNoSecondaryImage
inputScalingFactor
setInputScalingFactor:
T@"NSNumber",&,VinputScalingFactor
inputDistance
setInputDistance:
T@"NSNumber",&,VinputDistance
computeCameraIntrinsics
outputTransform
inputFocalLength
setInputFocalLength:
inputPitch
setInputPitch:
inputYaw
setInputYaw:
inputRoll
setInputRoll:
T@"NSNumber",C,N,VinputFocalLength
T@"NSNumber",C,N,VinputPitch
T@"NSNumber",C,N,VinputYaw
T@"NSNumber",C,N,VinputRoll
T{?=[3]},R,N
computeRotation
outputRotationFilter
T@"CIVector",C,N,VinputTopLeft
T@"CIVector",C,N,VinputTopRight
T@"CIVector",C,N,VinputBottomRight
T@"CIVector",C,N,VinputBottomLeft
T@"CIFilter",R,N
@16@0:8
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16d48
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGRect={CGPoint=dd}{CGSize=dd}}48
{CGRect={CGPoint=dd}{CGSize=dd}}64@0:8{CGSize=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32
i32@0:8{CGSize=dd}16
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGSize=dd}48{CGPoint=dd}64
{CGRect={CGPoint=dd}{CGSize=dd}}68@0:8{CGSize=dd}16{CGPoint=dd}32i48{CGSize=dd}52
@24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}40@0:8{CGSize=dd}16@32
i96@0:8{CGSize=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32{CGRect={CGPoint=dd}{CGSize=dd}}64
{CGRect={CGPoint=dd}{CGSize=dd}}100@0:8{CGSize=dd}16{CGRect={CGPoint=dd}{CGSize=dd}}32i64{CGRect={CGPoint=dd}{CGSize=dd}}68
B16@0:8
v20@0:8B16
{CGSize=dd}16@0:8
v32@0:8{CGSize=dd}16
{CGSize="width"d"height"d}
i16@0:8
@32@0:8i16i20Q24
v16@0:8
i100@0:8^{__IOSurface=}16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56i88i92i96
v32@0:8^{__CVBuffer=}16^f24
v40@0:8^{__CVBuffer=}16^{__CVBuffer=}24^f32
v32@0:8r^f16^{__CVBuffer=}24
v40@0:8^{__IOSurface=}16r^f24^{__CVBuffer=}32
v32@0:8r^f16^f24
v24@0:8^f16
r^I28@0:8i16^i20
r^v16@0:8
r^I16@0:8
r*16@0:8
B32@0:8Q16^I24
v28@0:8Q16I24
i40@0:8i16i20Q24^B32
^{BGHashMapContext=}
^{?=(?=Q[8C])IIII}
@40@0:8i16i20Q24@32
i72@0:8@16@24@32@40@48f56i60^{?=}64
v24@0:8@?16
v24@0:8@16
i48@0:8@16@24@32f40i44
i28@0:8@16i24
i32@0:8@16@24
i40@0:8@16@24@32
@"<MTLCommandBuffer>"
@"<MTLDevice>"
[9@"<MTLComputePipelineState>"]
@"NSObject<OS_dispatch_group>"
{?="dispatchThreadgroups"{?="width"Q"height"Q"depth"Q}"threadsPerThreadgroup"{?="width"Q"height"Q"depth"Q}}
{?="lambda"f"N"I"dims"S"sigma_s"f"sigma_r_luma"f}
{?="reference""confidence""disparity""output"}
@"<MTLBuffer>"
@"<MTLTexture>"
[2@"<MTLBuffer>"]
@"CIImage"
@"NSNumber"
@"CIVector"
@"NSValue"
@"NSArray"16@0:8
@"CIFilter"24@0:8@"NSArray"16
@44@0:8d16i24@28@36
{IRect={IPoint=qq}{ISize=QQ}}16@0:8
v24@0:8@"NSCoder"16
@24@0:8@"NSCoder"16
@24@0:8^{_NSZone=}16
@44@0:8@16q24C32q36
q16@0:8
C16@0:8
@"NSData"
@44@0:8@16B24q28q36
@48@0:8@16q24q32q40
@32@0:8@16@24
@"CIContext"
@"NSMutableDictionary"
@68@0:8^v16q24{CGRect={CGPoint=dd}{CGSize=dd}}32i64
@76@0:8^v16q24{CGRect={CGPoint=dd}{CGSize=dd}}32i64@68
B68@0:8^v16q24{CGRect={CGPoint=dd}{CGSize=dd}}32i64
v88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56
{CGRect={CGPoint=dd}{CGSize=dd}}16@0:8
^{CIBitmapContextPrivate=^vq{CGRect={CGPoint=dd}{CGSize=dd}}i}
f16@0:8
@20@0:8i16
d24@0:8r^{CIBurstSupportVector=d[7d]}16
v20@0:8f16
^{__SVMParameters=[7{__SVMScaleOffset=ff}]ddii^{CIBurstSupportVector}^{CIBurstSupportVector}}16@0:8
v24@0:8^{__SVMParameters=[7{__SVMScaleOffset=ff}]ddii^{CIBurstSupportVector}^{CIBurstSupportVector}}16
[7d]
^{__SVMParameters=[7{__SVMScaleOffset=ff}]ddii^{CIBurstSupportVector}^{CIBurstSupportVector}}
q24@0:8@16
v20@0:8i16
@52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16i48
v48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}
@20@0:8f16
f48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
{CGPoint=dd}16@0:8
v32@0:8{CGPoint=dd}16
{CGPoint="x"d"y"d}
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48f52
{CGRect={CGPoint=dd}{CGSize=dd}}40@0:8@16@24^B32
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48
v32@0:8@16@24
v40@0:8@16{CGSize=dd}24
d16@0:8
v24@0:8d16
@"NSMutableArray"
@"FCRFaceDetector"
v48@0:8^{__IOSurface=}16@24@32@?40
Q16@0:8
@24@0:8Q16
v32@0:8^v16^v24
@"CIBurstImageSetInternal"
@88@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32@64@72@80
@24@0:8^@16
@40@0:8q16@24@32
B32@0:8^@16@24
B48@0:8^@16q24@32@40
@40@0:8@16@24^@32
@32@0:8@16^@24
@48@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16
v56@0:8@16@24@32@40@?48
i24@0:8@16
@28@0:8@16B24
v28@0:8@16i24
@"NSObject<OS_dispatch_queue>"
@"NSObject<OS_dispatch_semaphore>"
@"NSString"
@"CIBurstImageFaceAnalysisContext"
@"CIBurstYUVImage"
@"NSDictionary"
@"NSCountedSet"
^{__sFILE=*iiss{__sbuf=*i}i^v^?^?^?^?{__sbuf=*i}^{__sFILEX}i[3C][1C]{__sbuf=*i}iq}
@"CIBurstActionClassifier"
v48@0:8^^f16^^f24^^f32^^f40
{GridROI_t=iiii}16@0:8
f32@0:8@16@24
v32@0:8{GridROI_t=iiii}16
v40@0:8@16^f24^f32
f24@0:8@16
^S16@0:8
f20@0:8f16
^f16@0:8
^{__IOSurface=}16@0:8
v24@0:8^{__IOSurface=}16
[1024f]
[256S]
{FastRegistration_Signatures="piRow"^f"nPiRow"Q"piRowTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}"piCol"^f"nPiCol"Q"piColTable"{Projections_meanStdTable="sumTable"^f"sumSqTable"^f}}
^{SharpnessGridElement_t=CCf}
{GridROI_t="startX"i"startY"i"endX"i"endY"i}
^{__IOSurface=}
@56@0:8@16@24@32@40@?48
f36@0:8@16^i24i32
@?16@0:8
v28@0:8*16i24
@28@0:8^{CGImage=}16i24
@28@0:8^{__IOSurface=}16i24
^{__CVBuffer=}16@0:8
*16@0:8
v24@0:8*16
^{__CFData=}
^{__CVBuffer=}
{CGPoint=dd}72@0:8{CGPoint=dd}16@32{CGPoint=dd}40{CGSize=dd}56
{CGRect={CGPoint=dd}{CGSize=dd}}60@0:8i16{CGRect={CGPoint=dd}{CGSize=dd}}20@52
@"AVCameraCalibrationData"
@"CIColor"
Vv16@0:8
r^d16@0:8
^{CGColorSpace=}16@0:8
^{CGColor=}16@0:8
B24@0:8@16
@24@0:8^{CGColor=}16
@48@0:8d16d24d32d40
@40@0:8d16d24d32
@56@0:8d16d24d32d40^{CGColorSpace=}48
@48@0:8d16d24d32^{CGColorSpace=}40
[3^v]
@32@0:8^{CGContext=}16@24
i84@0:8@16^v24q32{CGRect={CGPoint=dd}{CGSize=dd}}40i72^{CGColorSpace=}76
v84@0:8@16^v24q32{CGRect={CGPoint=dd}{CGSize=dd}}40i72^{CGColorSpace=}76
v32@0:8@16^{__CVBuffer=}24
v72@0:8@16^{__CVBuffer=}24{CGRect={CGPoint=dd}{CGSize=dd}}32^{CGColorSpace=}64
v24@0:8r*16
v72@0:8@16{CGPoint=dd}24{CGRect={CGPoint=dd}{CGSize=dd}}40
v68@0:8@16I24{CGRect={CGPoint=dd}{CGSize=dd}}28^{CGColorSpace=}60
v72@0:8@16I24I28{CGRect={CGPoint=dd}{CGSize=dd}}32^{CGColorSpace=}64
v80@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40^{CGColorSpace=}72
v72@0:8@16^{__IOSurface=}24{CGRect={CGPoint=dd}{CGSize=dd}}32^{CGColorSpace=}64
^{CGLayer=}40@0:8{CGSize=dd}16^{__CFDictionary=}32
@68@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24i56^{CGColorSpace=}60
B44@0:8@16i24^@28^{CGRect={CGPoint=dd}{CGSize=dd}}36
v64@0:8{CGAffineTransform=dddddd}16
{CGAffineTransform=dddddd}16@0:8
@36@0:8@16i24^{CGColorSpace=}28
@28@0:8@16i24
^v16@0:8
@24@0:8^v16
^v24@0:8@16
^v32@0:8@16@24
^v32@0:8@16^v24
^{CGImage=}77@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24i56^{CGColorSpace=}60{Trilean=c}68@?69
^{CGImage=}56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
^{CGImage=}60@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24i56
^{CGImage=}68@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24i56^{CGColorSpace=}60
^{CGImage=}80@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24i56^{CGColorSpace=}60B68@72
^{CGImage=}72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24i56^{CGColorSpace=}60B68
@44@0:8@16i24^{CGColorSpace=}28@36
@52@0:8@16i24^{CGColorSpace=}28@36^@44
@40@0:8@16^{CGColorSpace=}24@32
@48@0:8@16^{CGColorSpace=}24@32^@40
B60@0:8@16@24i32^{CGColorSpace=}36@44^@52
B56@0:8@16@24^{CGColorSpace=}32@40^@48
v28@0:8i16d20
v44@0:8@16@24i32@36
@52@0:8@16@24@32I40@44
@60@0:8@16@24@32@40I48@52
@76@0:8@16@24@32@40@48@56I64@68
@"MLFeatureValue"24@0:8@"NSString"16
@"NSSet"16@0:8
B32@0:8@16@24
^{__CVBuffer=}32@0:8^{__CVBuffer=}16^@24
{CIPredictionModelImageFeatures=@qqI}16@0:8
v48@0:8{CIPredictionModelImageFeatures=@qqI}16
@"MLModel"
{CIPredictionModelImageFeatures="name"@"NSString""width"q"height"q"format"I}
{CGRect={CGPoint=dd}{CGSize=dd}}60@0:8i16@20{CGRect={CGPoint=dd}{CGSize=dd}}28
B48@0:8@16@24@32^@40
i20@0:8i16
v36@0:8@16^^{__CVBuffer}24I32
@"MLMultiArray"
@32@0:8@16^{__CVBuffer=}24
v24@0:8^{__CVBuffer=}16
@40@0:8@16@24@32
@"NSArray"
@"InpaintingExecutionContext"
@36@0:8{CGSize=dd}16B32
@40@0:8@16^@24B32i36
@20@0:8B16
{CGPoint=dd}104@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56{CGPoint=dd}88
@"VNFaceObservation"
@"VNFaceLandmarks2D"
B40@0:8^{__CVBuffer=}16@24@32
B24@0:8^{__CVBuffer=}16
B32@0:8^{__CVBuffer=}16^{__CVBuffer=}24
@"CIRenderDestination"
@"CIDualRedEyeRepairTuning"
@"NSDate"
@"<MTLCommandQueue>"
@28@0:8f16f20f24
Q32@0:8@16@24
d36@0:8I16f20f24f28f32
B20@0:8I16
I16@0:8
@152@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16B48{CGPoint=dd}52B68{CGPoint=dd}72B88{CGPoint=dd}92B108f112B116i120B124i128B132B136B140@144
@112@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGPoint=dd}48{CGPoint=dd}64{CGPoint=dd}80{CGPoint=dd}96
@24@0:8^{?={CGRect={CGPoint=dd}{CGSize=dd}}{CGPoint=dd}{CGPoint=dd}{CGPoint=dd}{CGPoint=dd}@}16
@"CIQRCodeDescriptor"
@128@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16{CGPoint=dd}48{CGPoint=dd}64{CGPoint=dd}80{CGPoint=dd}96@112@120
@56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24^@56
v36@0:8@16r*24B32
[8^v]
r^{CGImageMetadata=}56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
@56@0:8^{CGImageMetadata=}16{CGRect={CGPoint=dd}{CGSize=dd}}24
@20@0:8I16
I20@0:8I16
B24@0:8#16
@48@0:8@16@24@32@40
v40@0:8@16@24@32
@36@0:8@16i24@28
@24@0:8#16
@24@0:8^{filterShape={CGRect={CGPoint=dd}{CGSize=dd}}}16
@68@0:8{CGAffineTransform=dddddd}16B64
@24@0:8i16i20
^{CGSRegionObject=}16@0:8
^{__CFDictionary=}16@0:8
@56@0:8^v16{CGRect={CGPoint=dd}{CGSize=dd}}24
^{__CFArray=}16@0:8
v24@0:8^{__CFString=}16
v24@0:8^{CGImage=}16
^{__CFString=}16@0:8
^{__CFString=}
#16@0:8
@24@0:8:16
@32@0:8:16@24
@40@0:8:16@24@32
B24@0:8:16
^{_NSZone=}16@0:8
B24@0:8@"Protocol"16
@"NSString"16@0:8
B24@0:8I16I20
v24@0:8@"GVNode"16
v32@0:8@"GVEdge"16@"NSArray"24
v24@0:8@"NSURL"16
v24@0:8@"NSString"16
^{CGColor=}20@0:8i16
v56@0:8@16{CGPoint=dd}24{CGPoint=dd}40
^{CGContext=}
r^{__CFData=}16@0:8
^{__CFDictionary=}
^{CGDataConsumer=}
^{CGImage=}16@0:8
^{__CFURL=}
^{CGColor=}
^{CGColorSpace=}
@"NSURL"
@104@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56@64@72@80@88^@96
@88@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56@64@72^@80
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56@64^@72
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56^@64
@40@0:8@16{CGSize=dd}24
@24@0:8@?16
@24@0:8^{__IOSurface=}16
@32@0:8^{__IOSurface=}16@24
@24@0:8^{CGImage=}16
@32@0:8^{CGImage=}16@24
@40@0:8^{CGImageSource=}16Q24@32
@24@0:8^{CGLayer=}16
@32@0:8^{CGLayer=}16@24
@60@0:8@16Q24{CGSize=dd}32i48@52
@60@0:8@16Q24{CGSize=dd}32i48^{CGColorSpace=}52
@48@0:8I16{CGSize=dd}20B36^{CGColorSpace=}40
@44@0:8I16{CGSize=dd}20@36
@48@0:8I16{CGSize=dd}20B36@40
@24@0:8^{__CVBuffer=}16
@32@0:8^{__CVBuffer=}16@24
@32@0:8@16@?24
@40@0:8^{__IOSurface=}16@24^v32
v32@0:8^{CGImage=}16@24
@36@0:8^{CGImageSource=}16@24B32
^{__CVBuffer=}24@0:8^{__CFDictionary=}16
@32@0:8^{CGImageSource=}16@24
v32@0:8^{__CVBuffer=}16@24
{CGAffineTransform=dddddd}20@0:8i16
{CGAffineTransform=dddddd}20@0:8I16
@64@0:8{CGAffineTransform=dddddd}16
@24@0:8d16
@24@0:8^{CGColorSpace=}16
@80@0:816324864
{CGRect={CGPoint=dd}{CGSize=dd}}56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
@60@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16i48@52
@60@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16i48^{CGColorSpace=}52
v56@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24
@72@0:8@16{CGAffineTransform=dddddd}24
{CGPoint=dd}84@0:8@16@24i32{CGAffineTransform=dddddd}36
@104@0:8@16{CGAffineTransform=dddddd}24{CGRect={CGPoint=dd}{CGSize=dd}}72
{CGPoint=dd}80@0:8{CGPoint=dd}16{CGPoint=dd}32{CGPoint=dd}48{CGPoint=dd}64
@92@0:8@16@24{CGRect={CGPoint=dd}{CGSize=dd}}32^{CGRect={CGPoint=dd}{CGSize=dd}}64f72f76B80f84f88
@84@0:8@16^{CGImage=}24{CGRect={CGPoint=dd}{CGSize=dd}}32f64f68B72f76f80
v112@0:8@16{CGAffineTransform=dddddd}24{CGRect={CGPoint=dd}{CGSize=dd}}72^{CGRect={CGPoint=dd}{CGSize=dd}}104
@84@0:8^{__IOSurface=}16{Texture=(?=Q{?=II}{?=^v^v})}24B40{CGRect={CGPoint=dd}{CGSize=dd}}44^v76
@"<MTLTexture>"16@0:8
@"<MTLCommandBuffer>"16@0:8
@96@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48Q56i64i68@72@?80@?88
B20@0:8i16
Q24@0:8@16
Q40@0:8{?=QQQ}16
@"<MTLFunctionHandle>"24@0:8@"<MTLFunction>"16
@"<MTLComputePipelineState>"32@0:8@"NSArray"16^@24
@"<MTLVisibleFunctionTable>"24@0:8@"MTLVisibleFunctionTableDescriptor"16
@"<MTLIntersectionFunctionTable>"24@0:8@"MTLIntersectionFunctionTableDescriptor"16
@"<MTLDevice>"16@0:8
@64@0:8@16@24{CGSize=dd}32i48B52^{CGColorSpace=}56
@60@0:8@16Q24Q32i40^{CGColorSpace=}44@52
@60@0:8@?16Q24Q32i40^{CGColorSpace=}44@52
@64@0:8@?16Q24Q32i40^{CGColorSpace=}44B52@56
@44@0:8@16I24^{CGColorSpace=}28@36
@40@0:8@16@24^{CGColorSpace=}32
r*20@0:8I16
v32@0:8@16^{CGColorSpace=}24
s16@0:8
@"CIFilter"
@40@0:8@16i24B28^{CGColorSpace=}32
@44@0:8@16i24B28i32^{CGColorSpace=}36
@52@0:8@16@24i32i36B40^{CGColorSpace=}44
@56@0:8@16@24i32i36B40i44^{CGColorSpace=}48
@44@0:8@16@24i32^@36
@56@0:8@16@24{CGSize=dd}32^@48
@48@0:8@16@24@32^@40
@36@0:8@16@24B32
@128@0:8{CIKernelReflection=ii**{vector<CI::KernelArgumentType, std::allocator<CI::KernelArgumentType>>=^i^i{__compressed_pair<CI::KernelArgumentType *, std::allocator<CI::KernelArgumentType>>=^i}}{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}@IiQQBB}16
@144@0:8{CIKernelReflection=ii**{vector<CI::KernelArgumentType, std::allocator<CI::KernelArgumentType>>=^i^i{__compressed_pair<CI::KernelArgumentType *, std::allocator<CI::KernelArgumentType>>=^i}}{vector<std::string, std::allocator<std::string>>=^v^v{__compressed_pair<std::string *, std::allocator<std::string>>=^v}}@IiQQBB}16@128@136
i32@0:8@16^v24
@72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@?48@56@64
@64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@?48@56
v24@0:8:16
:16@0:8
@64@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@48@56
@80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16@?48@56@64@72
v24@0:8i16B20
@32@0:8d16d24
@28@0:8@16f24
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8i16i20d24
v48@0:8@16@24Q32@40
v80@0:8@16@24Q32@40Q48{?=QQQ}56
@"<MTLFunction>"
{Rectangle=dddd}68@0:8{vec2=(?=ff)(?=ff)}16{vec3=(?={?=fff}{?=fff}{?={vec2=(?=ff)(?=ff)}}{?={vec2=(?=ff)(?=ff)}})}24{vec4=(?={?=ffff}{?=ffff}{?={vec2=(?=ff)(?=ff)}{vec2=(?=ff)(?=ff)}}{?={vec2=(?=ff)(?=ff)}{vec2=(?=ff)(?=ff)}}{?={vec3=(?={?=fff}{?=fff}{?={vec2=(?=ff)(?=ff)}}{?={vec2=(?=ff)(?=ff)}})}}{?={vec3=(?={?=fff}{?=fff}{?={vec2=(?=ff)(?=ff)}}{?={vec2=(?=ff)(?=ff)}})}})}36{vec4=(?={?=ffff}{?=ffff}{?={vec2=(?=ff)(?=ff)}{vec2=(?=ff)(?=ff)}}{?={vec2=(?=ff)(?=ff)}{vec2=(?=ff)(?=ff)}}{?={vec3=(?={?=fff}{?=fff}{?={vec2=(?=ff)(?=ff)}}{?={vec2=(?=ff)(?=ff)}})}}{?={vec3=(?={?=fff}{?=fff}{?={vec2=(?=ff)(?=ff)}}{?={vec2=(?=ff)(?=ff)}})}})}52
{CGRect={CGPoint=dd}{CGSize=dd}}60@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24f56
@40@0:8@16i24f28^{CGRect={CGPoint=dd}{CGSize=dd}}32
@32@0:8@16i24f28
{CGRect={CGPoint=dd}{CGSize=dd}}24@0:8f16f20
@72@0:8@16@24@32{CGRect={CGPoint=dd}{CGSize=dd}}40
@24@0:8B16B20
@36@0:8@16B24d28
v64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@64@0:8B16{CGRect={CGPoint=dd}{CGSize=dd}}20@52B60
v20@0:8I16
@"CIRAWFilterImpl"
@40@0:8^{__CVBuffer=}16@24@32
B96@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56d88
B92@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56i88
d28@0:8@16i24
@36@0:8@16i24i28f32
v64@0:8^i16^d24{CGRect={CGPoint=dd}{CGSize=dd}}32
B96@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGRect={CGPoint=dd}{CGSize=dd}}56i88f92
^{CGImageSource=}
@"NSObject"
{CGAffineTransform=dddddd}24@0:8@16
@32@0:8r^d16@24
v40@0:8^@16^@24^@32
v48@0:8@16@24^@32^@40
@48@0:8@16@24@32^{CGColorSpace=}40
@40@0:8@16@24r^{?=dddddd@}32
{?="focalLength"d"lineSearchRangeV"d"lineSearchRangeH"d"pitchLimit"d"yawLimit"d"rollLimit"d"saliencyHeatmap"@"CIImage"}
@60@0:8@16@24i32@36@44@52
@64@0:8@16@24@32@40@48^@56
{?=iiii}56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16^{?=fffffiiiffiifffffB{CGRect={CGPoint=dd}{CGSize=dd}}iiiiff{CGAffineTransform=dddddd}i}48
i68@0:8^{?=iiii}16^{CGPoint=dd}24[8{CGPoint=dd}]32[4f]40i48@52^{?=fffffiiiffiifffffB{CGRect={CGPoint=dd}{CGSize=dd}}iiiiff{CGAffineTransform=dddddd}i}60
i44@0:8^{?={?=iiii}{CGPoint=dd}{CGPoint=dd}{?=iiii}{?=iiii}[4f][4f][8{CGPoint=dd}][8{CGPoint=dd}]f}16@24i32^{?=fffffiiiffiifffffB{CGRect={CGPoint=dd}{CGSize=dd}}iiiiff{CGAffineTransform=dddddd}i}36
{?=fffffiiiffiifffffB{CGRect={CGPoint=dd}{CGSize=dd}}iiiiff{CGAffineTransform=dddddd}i}24@0:8@16
{CGRect={CGPoint=dd}{CGSize=dd}}40@0:8@16{CGSize=dd}24
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8@16@24
^{?=*iiiiiiif}16@0:8
{?=iiii}16@0:8
{CGPoint=dd}32@0:8{CGPoint=dd}16
{CGPoint=dd}24@0:8@16
@32@0:8{CGPoint=dd}16
{?=iiii}24@0:8@16
@32@0:8{?=iiii}16
i40@0:8^@16^{?=Bii^{CGPoint}}24^{?={?=ffff}fffffffff}32
B40@0:8@16^^{?}24^{?={?=ffff}fffffffff}32
@72@0:8*16{CGRect={CGPoint=dd}{CGSize=dd}}24Q56@64
{CGPoint=dd}80@0:8{CGAffineTransform=dddddd}16{CGPoint=dd}64
v72@0:8^{?=Bii^{CGPoint}}16{CGAffineTransform=dddddd}24
i64@0:8{CGAffineTransform=dddddd}16
@"<RedEyeInspector3>"
{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}
{?="minrow"i"maxrow"i"mincol"i"maxcol"i}
{?="FR"{?="minrow"i"maxrow"i"mincol"i"maxcol"i}"leftEye"{CGPoint="x"d"y"d}"rightEye"{CGPoint="x"d"y"d}"LR"{?="minrow"i"maxrow"i"mincol"i"maxcol"i}"RR"{?="minrow"i"maxrow"i"mincol"i"maxcol"i}"leftDistMatrix"[4f]"rightDistMatrix"[4f]"LPoly"[8{CGPoint="x"d"y"d}]"RPoly"[8{CGPoint="x"d"y"d}]"IOD"f}
{?="xf"f"yf"f"xfi"f"yfi"f"ify"f"ioffx"i"ioffy"i"downsampleType"i"downsampleOversizeX"f"downsampleOversizeY"f"gradientChannel"i"edgeFindingChannel"i"minMagnitude"f"regressionRadius"f"capture"f"alignmentTolerance"f"connectThreshold"f"forceFail"B"inputImageExtent"{CGRect="origin"{CGPoint="x"d"y"d}"size"{CGSize="width"d"height"d}}"orientation"i"cameraType"i"faceIndex"i"side"i"scale"f"IOD"f"transform"{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}"height"i}
{?="width"i"height"i"T"{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}"Tp"{CGAffineTransform="a"d"b"d"c"d"d"d"tx"d"ty"d}"O"{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}"OO"{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}"computeEyePolygon"B"EP"{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}"maskRender"B"D"{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}"computeGradient"B"G"{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}"M"{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}"computeShine"B"S"{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}"P"{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}}
{?="width"i"height"i"scaleFactor"f"grid"^{?}"nPoints"i"maxPoints"i"points"^{?}"nextNetNumber"i"nThreads"i"maxThreads"i"threads"^{?}"nShapes"i"maxShapes"i"shapes"^{?}}
{?="skinval"f"avgLuminance"f"minLuminance"f"maxLuminance"f"darkPercent"f"clipPercent"f}
{?="variance"d"nNonZero"i}
@36@0:8@16i24^@28
{CGAffineTransform=dddddd}52@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16i48
@36@0:8@16i24^{CGAffineTransform=dddddd}28
@40@0:8@16^Q24^Q32
{vec2=(?=ff)(?=ff)}16@0:8
i52@0:8^v16Q24Q32Q40i48
^{CIRenderDestinationInternal=^{RenderDestination}QQii{?=[3d][3d][3d]dd}QBBiBBB@}16@0:8
@52@0:8^v16Q24Q32i40^{CGColorSpace=}44
^v32@0:8^v16^v24
v32@0:8i16B20B24f28
@52@0:8Q16Q24I32^{CGColorSpace=}36@?44
@56@0:8Q16Q24Q32@40@?48
@40@0:8I16I20Q24Q32
@52@0:8^v16Q24Q32Q40i48
v24@0:8Q16
v24@0:8^{CGColorSpace=}16
d24@0:8Q16
@88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56{CGPoint=dd}64^@80
@48@0:8@16@24B32B36^@40
B88@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56{CGPoint=dd}64^@80
@40@0:8@16@24[1{__va_list_tag=II^v^v}]32
f32@0:816
f24@0:816
{float3x3="columns"[3]}
{vector<CI::Perspective::Line, std::allocator<CI::Perspective::Line>>="__begin_"^{?}"__end_"^{?}"__end_cap_"{__compressed_pair<CI::Perspective::Line *, std::allocator<CI::Perspective::Line>>="__value_"^{?}}}
{vector<LineCostProxy, std::allocator<LineCostProxy>>="__begin_"^{LineCostProxy}"__end_"^{LineCostProxy}"__end_cap_"{__compressed_pair<LineCostProxy *, std::allocator<LineCostProxy>>="__value_"^{LineCostProxy}}}
[64]
[16]
{Solution="rX"f"rY"f"rZ"f"cost"f}
v24@0:8^{?=Bffff[3f]}16
@24@0:8^f16
@32@0:8d16@24
@40@0:8d16d24@32
@40@0:8@16d24d32
@32@0:8@16d24
@44@0:8@16@24@32i40
@40@0:8@16{CGPoint=dd}24
i28@0:8i16i20i24
{CGRect={CGPoint=dd}{CGSize=dd}}44@0:8@16{CGPoint=dd}24i40
@44@0:8@16{CGPoint=dd}24i40
{CGRect={CGPoint=dd}{CGSize=dd}}72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16i48i52{CGSize=dd}56
{CGRect={CGPoint=dd}{CGSize=dd}}72@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48i52{CGSize=dd}56
d32@0:8d16@24
{CGRect={CGPoint=dd}{CGSize=dd}}80@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16f48i52{CGSize=dd}56@72
@64@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56
@36@0:8@16i24i28i32
{CGRect={CGPoint=dd}{CGSize=dd}}32@0:8{vec4=(?={?=ffff}{?=ffff}{?={vec2=(?=ff)(?=ff)}{vec2=(?=ff)(?=ff)}}{?={vec2=(?=ff)(?=ff)}{vec2=(?=ff)(?=ff)}}{?={vec3=(?={?=fff}{?=fff}{?={vec2=(?=ff)(?=ff)}}{?={vec2=(?=ff)(?=ff)}})}}{?={vec3=(?={?=fff}{?=fff}{?={vec2=(?=ff)(?=ff)}}{?={vec2=(?=ff)(?=ff)}})}})}16
@"FKTextDetector"
@"NSAttributedString"
@28@0:8r^{CGPoint=dd}16B24
@24@0:8r^{CGPoint=dd}16
v44@0:8^d16i24d28r^{CGPoint=dd}36
v32@0:8^^v16^^v24
B64@0:8@16^B24^i32^i40^@48^@56
B32@0:8@16^@24
B72@0:8@16@24@32@40B48B52i56i60^@64
v92@0:8@16@24{?=^vi}32^v48^v56@64@72B80i84i88
{?=^vi}16@0:8
{?="plan"^v"network_index"i}
@52@0:8@16@24i32@36^@44
B104@0:8@16{vImage_Buffer=^vQQQ}24{?=ffffB}56{?=^vi}76B92^@96
@208@0:8{?=^v^v[4Q][4Q]QQQQQQQQQQi}16@184i192i196^@200
@64@0:8@16@24i32i36@40@48^@56
@72@0:8@16@24@32i40i44@48@56^@64
^v24@0:8^i16
B84@0:8@16@24B32B36B40i44i48@52@60@68^@76
B40@0:8@16@24^@32
i32@0:8d16@24
@32@0:8r^d16Q24
(?="vec"[4d]"ptr"^d)
^d16@0:8
{?="a""b"}
{PseudoRand="u"I"v"I}
@32@0:8^v16^{SerialObjectPtrArray=iii^^v}24
@56@0:8{CGRect={CGPoint=dd}{CGSize=dd}}16i48i52
{CGRect={CGPoint=dd}{CGSize=dd}}72@0:8^v16^{SerialObjectPtrArray=iii^^v}24@32{CGRect={CGPoint=dd}{CGSize=dd}}40
@72@0:8@16{CGRect={CGPoint=dd}{CGSize=dd}}24@56^f64
@24@0:8^{CGImageMetadata=}16
i48@0:8^{__CFData=}16^f24^f32^i40
^{CGImageMetadata=}32@0:8^{CGImageMetadata=}16@24
^{CGImageMetadata=}32@0:8@16^{CGImageMetadata=}24
^{CGImageMetadata=}24@0:8@16
d40@0:8d16d24^d32
v32@0:8d16d24
v36@0:8@16i24i28i32
v40@0:8d16d24d32
{?=dd}16@0:8
{CGPoint=dd}24@0:8Q16
i24@0:8^d16
v36@0:8@16I24^d28
v28@0:8@16I24
{?="i"d"q"d}
@"CIEnhancementHistogram"
@28@0:8@16I24
@24@0:8r^d16
@24@0:8r^f16
[256d]
v32@0:8^{?=*iiiiiiif}16^{?=*iiiiiiif}24
i28@0:8^{?=ii^{?}iii}16i24
i40@0:8{CGPoint=dd}16^{?=ii^{?}iii}32
v24@0:8^{?=ii^{?}iii}16
i84@0:8^{?=ii^{?}iii}16^{?=ii^{?}iii}24{CGAffineTransform=dddddd}32i80
B28@0:8^{?=*iiiiiiif}16i24
v48@0:8{CGPoint=dd}16^i32^i40
i52@0:8{CGPoint=dd}16{CGPoint=dd}32B48
i24@0:8^^{?}16
i32@0:8i16i20i24i28
i52@0:8^{CGPoint=dd}16{?=fff}24{CGPoint=dd}36
v40@0:8i16f20^?24^v32
v52@0:8{CGPoint=dd}16f32^?36^v44
i24@0:8i16i20
i76@0:8^{?=iif^{?}ii^{?}iii^{?}ii^{?}}16{CGAffineTransform=dddddd}24i72
i28@0:8^^{?}16B24
v24@0:8^{?=Bii^{CGPoint}}16
i40@0:8{CGPoint=dd}16^{?=Bii^{CGPoint}}32
B24@0:8^{?=Bii^{CGPoint}}16
i32@0:8^^{?}16B24i28
i36@0:8^^{?}16B24^{?=ii^{?}iii}28
v72@0:8^{?=Bii^{CGPoint}}16^{CGPoint=dd}24^{CGPoint=dd}32^f40^{CGPoint=dd}48^{CGPoint=dd}56^f64
i32@0:8^{?=Bii^{CGPoint}}16^{?=*iiiiiiif}24
i36@0:8^^{?}16^{?=Bii^{CGPoint}}24f32
i36@0:8^{?=Bii^{CGPoint}}16f24^{?=*iiiiiiif}28
{CGPoint=dd}24@0:8^{?=Bii^{CGPoint}}16
i40@0:8^{?=*iiiiiiif}16^{?=Bii^{CGPoint}}24^{?=*iiiiiiif}32
B64@0:8^{CGPoint=dd}16^{?=*iiiiiiif}24{CGPoint=dd}32{CGPoint=dd}48
v32@0:8^{?=i[20{?=iiiif}]}16*24
v28@0:8B16*20
i24@0:8^{?=iiiffiBBBiiffff{?=ffff}{?=ffff}fii}16
v28@0:8^{?=ii^{?}iii}16f24
v44@0:8^{?=ii^{?}iii}16{CGPoint=dd}24f40
v32@0:8^{?=ii^{?}iii}16^{?=[4f][4f][4f][4i]}24
i76@0:8^{CGPoint=dd}16{CGPoint=dd}24i40f44i48i52^{?=*iiiiiiif}56i64^f68
i44@0:8^^{?}16[100{?={CGPoint=dd}if}]24i32^{?=*iiiiiiif}36
i32@0:8^^{?}16^{?=ii^{?}iii}24
i44@0:8^^{?}16i24{CGPoint=dd}28
i28@0:8i16^{?=*iiiiiiif}20
{CGPoint=dd}24@0:8^{?=iiiffiBBBiiffff{?=ffff}{?=ffff}fii}16
f40@0:8^{?=iiiffiBBBiiffff{?=ffff}{?=ffff}fii}16{CGPoint=dd}24
i40@0:8^{?=ffff}16^{?=Bii^{CGPoint}}24^{?=ffff}32
B32@0:8^{?=iffffff}16^{?=iffffff}24
v32@0:8^{?=iffffff}16^{?=iffffff}24
i32@0:8^i16^{?=ffff}24
{?=ffff}32@0:8{?=ffff}16
i32@0:8^^{?}16^{?={?=ffff}fffffffff}24
i24@0:8^{?=*iiiiiiif}16
i24@0:8*16
i24@0:8^{?=Bii^{CGPoint}}16
i28@0:8^@16i24
B24@0:8^{?=ffffff}16
{?=di}28@0:8^{?=*iiiiiiif}16f24
B32@0:8{?=di}16
v44@0:8^{?=i[20{?=iiiif}]}16i24i28i32i36f40
v52@0:8^{?=i[20{?=iffffff}]}16i24f28f32f36f40f44f48
{CGRect={CGPoint=dd}{CGSize=dd}}52@0:8{CGPoint=dd}16{CGSize=dd}32f48
B48@0:8^{CGImage=}16^{?=*iiiiiiif}24Q32Q40
B32@0:8^{CGImage=}16^{?=*iiiiiiif}24
@32@0:8@16^{?=[256c][32c]{?=*iiiiiiif}ii{?=iiii}^{CGColorSpace}IiiBf}24
@24@0:8^{?=[256c][32c]{?=*iiiiiiif}ii{?=iiii}^{CGColorSpace}IiiBf}16
@48@0:8*16{CGSize=dd}24Q40
@88@0:8*16{CGRect={CGPoint=dd}{CGSize=dd}}24{CGSize=dd}56Q72@80
^{?=i{CGPoint=dd}iiii{?=*iiiiiiif}{?=iiii}{?=iiii}B{?=iiii}iBf{?=iiiiiiiiiiB{?=iiii}{?=iiii}iiif{?=^v^?ifBifff}{?=iiii}}{?={CGPoint=dd}ifffi{?=iiii}fBiiiiffff}}16@0:8
i40@0:8^{?=*iiiiiiif}16^{?=*iiiiiiif}24^{?=*iiiiiiif}32
B88@0:8^{?=*iiiiiiif}16^{?=*iiiiiiif}24^{?=*iiiiiiif}32{?=iiii}40^{?=*iiiiiiif}56^{?=*iiiiiiif}64^{?=iiii}72^{?=iiii}80
B56@0:8^{?=*iiiiiiif}16{?=iiii}24^{?=*iiiiiiif}40^{?=*iiiiiiif}48
i64@0:8{CGPoint=dd}16B32{?=iiii}36i52f56B60
^{?=i{CGPoint=dd}iiii{?=*iiiiiiif}{?=iiii}{?=iiii}B{?=iiii}iBf{?=iiiiiiiiiiB{?=iiii}{?=iiii}iiif{?=^v^?ifBifff}{?=iiii}}{?={CGPoint=dd}ifffi{?=iiii}fBiiiiffff}}20@0:8i16
i24@0:8i16f20
f36@0:8^{?=Biiffiiiiffiiii}16^f24i32
f28@0:8f16i20i24
v52@0:8^{?=i[4{?=fiifffiif}]}16i24i28f32f36i40i44f48
B104@0:8^{?=*iiiiiiif}16^{?=*iiiiiiif}24i32i36{?=iiii}40^{?=Biiffiiiiffiiii}56^{?=i[4{?=fiifffiif}]}64i72B76[10f]80[10f]88*96
B96@0:8^{?=*iiiiiiif}16^{?=*iiiiiiif}24^{?=*iiiiiiif}32^{?=*iiiiiiif}40i48i52{?=iiii}56^{?=Biiffiiiiffiiii}72^{?=i[4{?=fiifffiif}]}80i88B92
B88@0:8{?=iiii}16^{?=Biiffiiiiffiiii}32i40B44f48f52^{?=i[4{?=fiifffiif}]}56^{?=i[4{?=fiifffiif}]}64^{?=*iiiiiiif}72^{?=*iiiiiiif}80
{?=iiBBfiiii}44@0:8^{?=Biiffiiiiffiiii}16B24^{?=i[4{?=fiifffiif}]}28^{?=i[4{?=fiifffiif}]}36
i56@0:8^{?=iiBBfiiii}16B24f28B32^{?=iiii}36i44^{?=i[4{?=fiifffiif}]}48
v68@0:8{?=iiii}16{?=iiii}32^{?=Biiffiiiiffiiii}48f56B60i64
i176@0:8{?=iiiiiiiiiiB{?=iiii}{?=iiii}iiif{?=^v^?ifBifff}{?=iiii}}16
B40@0:8^f16@24@32
B40@0:8^i16@24@32
B40@0:8^B16@24@32
v48@0:8^f16^f24^f32^f40
v32@0:8^f16^f24
^{?=[256c][32c]{?=*iiiiiiif}ii{?=iiii}^{CGColorSpace}IiiBf}
^{CGImageBlockSet=}
[32{?="tag"i"pt2"{CGPoint="x"d"y"d}"eyeCase"i"forceCase"i"npixels"i"bignpixels"i"fullNew"{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}"YR"{?="minrow"i"maxrow"i"mincol"i"maxcol"i}"psTemplate"{?="lo"i"med"i"hi"i"average"i}"pupilShadeAlignment"B"matchingTemplate"{?="lo"i"med"i"hi"i"average"i}"faceIndex"i"left"B"IOD"f"data"{?="origHitX"i"origHitY"i"snapHitX"i"snapHitY"i"bitmaskSeedX"i"bitmaskSeedY"i"bitmaskThreshold"i"cornealReflectionSeedX"i"cornealReflectionSeedY"i"cornealReflectionThreshold"i"align"B"mTemplate"{?="lo"i"med"i"hi"i"average"i}"existingTemplate"{?="lo"i"med"i"hi"i"average"i}"averageSkinMapY"i"characterizeCase"i"finalEyeCase"i"IOD"f"O"{?="bitmapproc_context"^v"bproc"^?"orientation"i"SNR"f"N90"B"redBitmaskArea"i"imageCenterX"f"imageCenterY"f"halfDiagonalSize"f}"CR"{?="minrow"i"maxrow"i"mincol"i"maxcol"i}}"BI"{?="centroid"{CGPoint="x"d"y"d}"area"i"ovalness"f"contrast"f"mincontrast"f"nborder"i"IR"{?="minrow"i"maxrow"i"mincol"i"maxcol"i}"aspectRatio"f"touchingEdge"B"localmax"i"localmaxrow"i"localmaxcol"i"localfloor"i"rgmean"f"rgstd"f"ymean"f"ystd"f}}]
{?="lo"i"med"i"hi"i"average"i}
[3{?="baseAddress"*"width"i"height"i"rowSamples"i"rowBytes"i"size"i"samplesPerPixel"i"bytesPerSample"i"resolution"f}]
[3{?="minrow"i"maxrow"i"mincol"i"maxcol"i}]
[20{CGPoint="x"d"y"d}]
[20{?="a"f"b"f"c"f}]
[20B]
[65536C]
[8[3i]]
B28@0:8i16^@20
@28@0:8i16^@20
@40@0:8@16@24^v32
@"NSObject<OS_dispatch_data>"
@"<MTLLibrary>"
@"NSSet"
@44@0:8i16i20i24i28^v32B40
@40@0:8i16i20i24^v28B36
@28@0:8i16i20i24
^{vImage_Buffer=^vQQQ}16@0:8
^{vImage_Buffer=^vQQQ}
{?=[3]}16@0:8
ffffff
333333
333333
333333
MbP?
ffffff
333333
ffffff
333333
333333
ffffff
Mb`?
333333
ffffff
MbP?
333333
333333
ffffff
333333
333333
ffffff
ffffff
MbP?
333333
MbP?
333333
333333
:FL@
MbP?
?P$
?9EGr
333?
fff?
